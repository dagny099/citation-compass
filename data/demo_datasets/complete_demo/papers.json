[
  {
    "paper_id": "01e77cd46ab75bab8f4b176455f0daa592e5f979",
    "title": "Visual Cognition Modelling Search for People in 900 Scenes: a Combined Source Model of Eye Guidance",
    "abstract": "We present a comprehensive computational model of visual attention that combines bottom-up stimulus information with top-down guidance from cognitive tasks. Our model successfully predicts human eye movements during person search in natural scenes with 78% accuracy across 900 diverse scene categories.",
    "authors": [
      "Krista A. Ehinger",
      "Barbara Hidalgo-Sotelo",
      "Antonio Torralba",
      "Aude Oliva"
    ],
    "venue": "Journal of Vision",
    "year": 2009,
    "citation_count": 318,
    "field": "Computer Vision",
    "doi": "10.1167/9.2.25"
  },
  {
    "paper_id": "e15cf50aa89fee8535703b9f9512fca5bfc43327",
    "title": "Going Deeper with Convolutions",
    "abstract": "We propose a deep convolutional neural network architecture codenamed Inception that achieves state-of-the-art performance on ImageNet classification and detection. The main hallmark of this architecture is the improved utilization of computing resources inside the network through carefully crafted reduction and parallel convolutions.",
    "authors": [
      "Christian Szegedy",
      "Wei Liu",
      "Yangqing Jia",
      "Pierre Sermanet",
      "Scott Reed"
    ],
    "venue": "IEEE Conference on Computer Vision and Pattern Recognition",
    "year": 2015,
    "citation_count": 41763,
    "field": "Machine Learning",
    "doi": "10.1109/CVPR.2015.7298594"
  },
  {
    "paper_id": "7470a1702c8c86e6f28d32cfa315381150102f5b",
    "title": "Segment Anything",
    "abstract": "We introduce the Segment Anything (SA) project: a new task, model, and dataset for image segmentation. Using our efficient model in a data collection loop, we built the largest segmentation dataset to date with 1 billion masks on 11 million licensed and privacy respecting images.",
    "authors": [
      "Alexander Kirillov",
      "Eric Mintun",
      "Nikhila Ravi",
      "Hanzi Mao",
      "Chloe Rolland"
    ],
    "venue": "arXiv preprint arXiv:2304.02643",
    "year": 2023,
    "citation_count": 4734,
    "field": "Computer Vision",
    "doi": "10.48550/arXiv.2304.02643"
  },
  {
    "paper_id": "224537e971d63c5ab906342e1ac93c5de974de39",
    "title": "COLET: A Dataset for Cognitive Workload Estimation based on Eye-tracking",
    "abstract": "We present COLET, a comprehensive dataset for cognitive workload estimation in healthcare environments using eye-tracking technology. The dataset includes recordings from 127 medical professionals performing various clinical tasks, providing ground truth for workload assessment algorithms.",
    "authors": [
      "Maria Rodriguez",
      "James Chen",
      "Sarah Williams",
      "Michael Brown"
    ],
    "venue": "Nature Digital Medicine",
    "year": 2022,
    "citation_count": 17,
    "field": "Medical Informatics",
    "doi": "10.1038/s41746-022-00123-4"
  },
  {
    "paper_id": "d1c016ad763d3fbbebf79981af54d459c48f0a74",
    "title": "Learning from Observer Gaze: Zero-Shot Attention Prediction Oriented by Human-Object Interaction Recognition",
    "abstract": "This paper introduces a novel zero-shot attention prediction model that leverages human-object interaction patterns to predict visual attention without task-specific training. Our approach achieves 82% accuracy on the COCO-Attention dataset and demonstrates strong generalization across diverse visual contexts.",
    "authors": [
      "Li Zhou",
      "Wei Zhang",
      "Yuki Tanaka",
      "Anna Schmidt"
    ],
    "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
    "year": 2024,
    "citation_count": 12,
    "field": "Machine Learning",
    "doi": "10.1109/TPAMI.2024.3234567"
  },
  {
    "paper_id": "attention_mechanisms_review_2020",
    "title": "Attention Mechanisms in Deep Learning: A Comprehensive Survey",
    "abstract": "This survey provides a comprehensive overview of attention mechanisms in deep learning, covering their evolution from early visual attention models to modern transformer architectures. We analyze 200+ papers and identify key research directions.",
    "authors": [
      "Robert Johnson",
      "Emily Davis",
      "Carlos Martinez"
    ],
    "venue": "IEEE Transactions on Neural Networks and Learning Systems",
    "year": 2020,
    "citation_count": 892,
    "field": "Machine Learning",
    "doi": "10.1109/TNNLS.2020.1234567"
  },
  {
    "paper_id": "transformer_attention_2017",
    "title": "Attention Is All You Need",
    "abstract": "We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments show that these models are superior in quality while being more parallelizable.",
    "authors": [
      "Ashish Vaswani",
      "Noam Shazeer",
      "Niki Parmar",
      "Jakob Uszkoreit"
    ],
    "venue": "Advances in Neural Information Processing Systems",
    "year": 2017,
    "citation_count": 89234,
    "field": "Machine Learning",
    "doi": "10.5555/3295222.3295349"
  },
  {
    "paper_id": "visual_attention_neuroscience_2019",
    "title": "Neural Mechanisms of Visual Attention: Bridging Neuroscience and AI",
    "abstract": "We investigate the neural mechanisms underlying visual attention through a combination of fMRI studies and computational modeling. Our findings reveal key similarities between biological and artificial attention mechanisms.",
    "authors": [
      "Jennifer Adams",
      "David Kim",
      "Rachel Thompson"
    ],
    "venue": "Nature Neuroscience",
    "year": 2019,
    "citation_count": 245,
    "field": "Neuroscience",
    "doi": "10.1038/s41593-019-12345-6"
  },
  {
    "paper_id": "medical_ai_attention_2023",
    "title": "AI-Powered Medical Diagnosis: The Role of Attention in Radiological Analysis",
    "abstract": "This study examines how attention mechanisms in deep learning models can improve radiological diagnosis accuracy. We demonstrate 15% improvement in detecting subtle abnormalities across 50,000 medical images.",
    "authors": [
      "Dr. Patricia Wilson",
      "Dr. Ahmed Hassan",
      "Dr. Lisa Chen"
    ],
    "venue": "The Lancet Digital Health",
    "year": 2023,
    "citation_count": 78,
    "field": "Medical Informatics",
    "doi": "10.1016/S2589-7500(23)12345-6"
  },
  {
    "paper_id": "multimodal_attention_2021",
    "title": "Multimodal Attention for Vision and Language Understanding",
    "abstract": "We present a unified multimodal attention framework that jointly processes visual and textual information. Our model achieves state-of-the-art results on VQA, image captioning, and visual reasoning tasks.",
    "authors": [
      "Alex Cooper",
      "Maria Gonzalez",
      "Tom Anderson"
    ],
    "venue": "International Conference on Machine Learning",
    "year": 2021,
    "citation_count": 456,
    "field": "Machine Learning",
    "doi": "10.48550/arXiv.2021.12345"
  },
  {
    "paper_id": "robotics_visual_attention_2022",
    "title": "Visual Attention for Autonomous Robotic Navigation in Dynamic Environments",
    "abstract": "This paper presents a real-time visual attention system for autonomous robots operating in crowded environments. Our attention-guided navigation reduces collision rates by 67% compared to traditional path planning methods.",
    "authors": [
      "Mark Taylor",
      "Sophie Laurent",
      "Hiroshi Yamamoto"
    ],
    "venue": "IEEE Robotics and Automation Letters",
    "year": 2022,
    "citation_count": 89,
    "field": "Robotics",
    "doi": "10.1109/LRA.2022.123456"
  },
  {
    "paper_id": "attention_psychology_2018",
    "title": "The Psychology of Visual Attention: From Laboratory to Real World",
    "abstract": "We review 40 years of psychological research on visual attention, examining how laboratory findings translate to real-world scenarios. This comprehensive review covers 500+ studies and identifies key gaps in current understanding.",
    "authors": [
      "Prof. Margaret Foster",
      "Dr. James Liu",
      "Dr. Anna Petrov"
    ],
    "venue": "Psychological Review",
    "year": 2018,
    "citation_count": 567,
    "field": "Psychology",
    "doi": "10.1037/rev0000123"
  },
  {
    "paper_id": "edge_computing_attention_2024",
    "title": "Efficient Attention Mechanisms for Edge Computing Applications",
    "abstract": "We propose lightweight attention architectures optimized for edge computing devices. Our models achieve 95% accuracy of full attention while using 80% less computational resources.",
    "authors": [
      "Kevin Wu",
      "Isabella Romano",
      "Chen Wei"
    ],
    "venue": "ACM Transactions on Embedded Computing Systems",
    "year": 2024,
    "citation_count": 23,
    "field": "Computer Systems",
    "doi": "10.1145/3234567.3234568"
  }
]