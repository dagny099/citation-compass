{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Network Exploration Analysis\n\nThis notebook provides comprehensive exploration and analysis of citation networks using the Academic Citation Platform's advanced analytics capabilities.\n\n## Overview\n\n- **Network Structure Analysis**: Basic network properties and statistics\n- **Centrality Analysis**: Identification of influential papers and nodes\n- **Community Detection**: Discovery of research clusters and communities\n- **Visualization**: Interactive network visualizations and plots\n\n## Requirements\n\nThis notebook requires the Academic Citation Platform with advanced analytics components."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add project root to path\n",
    "project_root = os.path.dirname(os.getcwd())\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "# Import analytics components\n",
    "from src.services.analytics_service import get_analytics_service\n",
    "from src.analytics.export_engine import ExportConfiguration\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully\")\n",
    "print(f\"üìä Analysis started at: {datetime.now()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize analytics service\n",
    "analytics = get_analytics_service()\n",
    "\n",
    "# Check system health\n",
    "health = analytics.get_system_health()\n",
    "print(\"üè• System Health Check:\")\n",
    "print(f\"   Overall Status: {health['overall_health']['status']}\")\n",
    "print(f\"   ML Service: {'‚úÖ' if health['service_info']['ml_service_available'] else '‚ùå'}\")\n",
    "print(f\"   Database: {'‚úÖ' if health['service_info']['database_available'] else '‚ùå'}\")\n",
    "print(f\"   Active Tasks: {health['service_info']['active_tasks']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Analysis Configuration\n",
    "\n",
    "Configure the network analysis parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis configuration\n",
    "ANALYSIS_CONFIG = {\n",
    "    'max_papers': 1000,  # Maximum number of papers to analyze\n",
    "    'include_communities': True,  # Perform community detection\n",
    "    'include_centrality': True,   # Calculate centrality metrics\n",
    "    'export_results': True        # Export results to file\n",
    "}\n",
    "\n",
    "print(\"‚öôÔ∏è Analysis Configuration:\")\n",
    "for key, value in ANALYSIS_CONFIG.items():\n",
    "    print(f\"   {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Network Structure Analysis\n",
    "\n",
    "Perform comprehensive network structure analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform network analysis\n",
    "print(\"üîç Starting network analysis...\")\n",
    "network_results = analytics.analyze_citation_network(\n",
    "    max_papers=ANALYSIS_CONFIG['max_papers'],\n",
    "    include_communities=ANALYSIS_CONFIG['include_communities'],\n",
    "    include_centrality=ANALYSIS_CONFIG['include_centrality']\n",
    ")\n",
    "\n",
    "if 'error' in network_results:\n",
    "    print(f\"‚ùå Analysis failed: {network_results['error']}\")\n",
    "else:\n",
    "    print(\"‚úÖ Network analysis completed successfully!\")\n",
    "    \n",
    "    # Display basic network information\n",
    "    graph_info = network_results['graph_info']\n",
    "    print(f\"\\nüìä Network Overview:\")\n",
    "    print(f\"   Nodes (Papers): {graph_info['num_nodes']:,}\")\n",
    "    print(f\"   Edges (Citations): {graph_info['num_edges']:,}\")\n",
    "    print(f\"   Directed Graph: {graph_info['is_directed']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display network metrics\n",
    "if 'network_metrics' in network_results:\n",
    "    metrics = network_results['network_metrics']\n",
    "    \n",
    "    print(\"\\nüèóÔ∏è Network Structure Metrics:\")\n",
    "    print(f\"   Density: {metrics['density']:.6f}\")\n",
    "    print(f\"   Average Degree: {metrics['average_degree']:.2f}\")\n",
    "    print(f\"   Clustering Coefficient: {metrics['clustering_coefficient']:.4f}\")\n",
    "    print(f\"   Connected Components: {metrics['num_components']}\")\n",
    "    print(f\"   Largest Component Size: {metrics['largest_component_size']:,}\")\n",
    "    \n",
    "    if metrics['diameter'] is not None:\n",
    "        print(f\"   Network Diameter: {metrics['diameter']}\")\n",
    "    if metrics['average_path_length'] is not None:\n",
    "        print(f\"   Average Path Length: {metrics['average_path_length']:.2f}\")\n",
    "    \n",
    "    print(f\"   Modularity: {metrics['modularity']:.4f}\")\n",
    "    if metrics['assortativity'] is not None:\n",
    "        print(f\"   Assortativity: {metrics['assortativity']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Centrality Analysis\n",
    "\n",
    "Analyze the most influential papers in the network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display influential papers\n",
    "if 'influential_papers' in network_results:\n",
    "    influential = network_results['influential_papers']\n",
    "    \n",
    "    print(\"\\nüéØ Most Influential Papers:\")\n",
    "    \n",
    "    # Top papers by PageRank\n",
    "    print(\"\\n   Top 10 by PageRank:\")\n",
    "    for i, paper_id in enumerate(influential['pagerank'][:10], 1):\n",
    "        print(f\"   {i:2d}. {paper_id}\")\n",
    "    \n",
    "    # Top papers by Degree Centrality\n",
    "    print(\"\\n   Top 10 by Degree Centrality:\")\n",
    "    for i, paper_id in enumerate(influential['degree_centrality'][:10], 1):\n",
    "        print(f\"   {i:2d}. {paper_id}\")\n",
    "    \n",
    "    # Top papers by Betweenness Centrality\n",
    "    print(\"\\n   Top 10 by Betweenness Centrality:\")\n",
    "    for i, paper_id in enumerate(influential['betweenness_centrality'][:10], 1):\n",
    "        print(f\"   {i:2d}. {paper_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Community Detection\n",
    "\n",
    "Analyze community structure in the network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display community information\n",
    "if 'communities' in network_results and network_results['communities']:\n",
    "    communities = network_results['communities']\n",
    "    community_analysis = network_results.get('community_analysis', {})\n",
    "    \n",
    "    print(f\"\\nüèòÔ∏è Community Detection Results:\")\n",
    "    print(f\"   Total Communities Detected: {len(communities)}\")\n",
    "    \n",
    "    if community_analysis:\n",
    "        print(f\"   Coverage: {community_analysis['coverage']:.2%}\")\n",
    "        print(f\"   Modularity Score: {community_analysis['modularity']:.4f}\")\n",
    "        print(f\"   Average Community Size: {community_analysis['average_community_size']:.1f}\")\n",
    "        print(f\"   Largest Community: {community_analysis['largest_community_size']} papers\")\n",
    "        print(f\"   Smallest Community: {community_analysis['smallest_community_size']} papers\")\n",
    "    \n",
    "    # Display top 10 largest communities\n",
    "    print(\"\\n   Largest Communities:\")\n",
    "    sorted_communities = sorted(communities, key=lambda x: x['size'], reverse=True)\n",
    "    for i, community in enumerate(sorted_communities[:10], 1):\n",
    "        print(f\"   {i:2d}. Community {community['community_id']}: {community['size']} papers\")\n",
    "        print(f\"       Internal edges: {community['internal_edges']}, \"\n",
    "              f\"External edges: {community['external_edges']}, \"\n",
    "              f\"Conductance: {community['conductance']:.4f}\")\nelse:\n",
    "    print(\"\\nüèòÔ∏è No community detection results available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Data Visualization\n",
    "\n",
    "Create visualizations of the analysis results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Create figure with subplots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "fig.suptitle('Citation Network Analysis Results', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Plot 1: Network Metrics Bar Chart\n",
    "if 'network_metrics' in network_results:\n",
    "    metrics = network_results['network_metrics']\n",
    "    \n",
    "    metric_names = ['Density', 'Avg Degree', 'Clustering', 'Modularity']\n",
    "    metric_values = [\n",
    "        metrics['density'] * 1000,  # Scale for visibility\n",
    "        metrics['average_degree'],\n",
    "        metrics['clustering_coefficient'],\n",
    "        metrics['modularity']\n",
    "    ]\n",
    "    \n",
    "    axes[0, 0].bar(metric_names, metric_values, color=['blue', 'green', 'orange', 'red'])\n",
    "    axes[0, 0].set_title('Network Metrics')\n",
    "    axes[0, 0].set_ylabel('Value')\n",
    "    axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Plot 2: Community Size Distribution\n",
    "if 'communities' in network_results and network_results['communities']:\n",
    "    community_sizes = [c['size'] for c in network_results['communities']]\n",
    "    \n",
    "    axes[0, 1].hist(community_sizes, bins=20, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "    axes[0, 1].set_title('Community Size Distribution')\n",
    "    axes[0, 1].set_xlabel('Community Size')\n",
    "    axes[0, 1].set_ylabel('Frequency')\n",
    "\n",
    "# Plot 3: Top Papers by PageRank\n",
    "if 'centrality_metrics' in network_results:\n",
    "    centrality = network_results['centrality_metrics']\n",
    "    \n",
    "    # Get top 10 papers by PageRank\n",
    "    sorted_papers = sorted(centrality.items(), \n",
    "                         key=lambda x: x[1]['pagerank'], \n",
    "                         reverse=True)[:10]\n",
    "    \n",
    "    paper_names = [f\"Paper_{i}\" for i in range(len(sorted_papers))]\n",
    "    pagerank_values = [paper[1]['pagerank'] for paper in sorted_papers]\n",
    "    \n",
    "    axes[1, 0].barh(paper_names, pagerank_values, color='lightcoral')\n",
    "    axes[1, 0].set_title('Top 10 Papers by PageRank')\n",
    "    axes[1, 0].set_xlabel('PageRank Score')\n",
    "\n",
    "# Plot 4: Centrality Correlation\n",
    "if 'centrality_metrics' in network_results:\n",
    "    centrality = network_results['centrality_metrics']\n",
    "    \n",
    "    pagerank_scores = [metrics['pagerank'] for metrics in centrality.values()]\n",
    "    degree_scores = [metrics['degree_centrality'] for metrics in centrality.values()]\n",
    "    \n",
    "    axes[1, 1].scatter(degree_scores, pagerank_scores, alpha=0.6, color='purple')\n",
    "    axes[1, 1].set_title('PageRank vs Degree Centrality')\n",
    "    axes[1, 1].set_xlabel('Degree Centrality')\n",
    "    axes[1, 1].set_ylabel('PageRank')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä Visualizations created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Export Results\n",
    "\n",
    "Export the analysis results to various formats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export results if configured\n",
    "if ANALYSIS_CONFIG['export_results'] and 'error' not in network_results:\n",
    "    print(\"\\nüíæ Exporting analysis results...\")\n",
    "    \n",
    "    # Export configuration\n",
    "    export_config = ExportConfiguration(\n",
    "        format='html',\n",
    "        include_visualizations=True,\n",
    "        include_raw_data=True,\n",
    "        metadata={\n",
    "            'analysis_type': 'network_exploration',\n",
    "            'notebook': '01_network_exploration.ipynb',\n",
    "            'max_papers': ANALYSIS_CONFIG['max_papers']\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Export network analysis results\n",
    "    if 'network_metrics' in network_results:\n",
    "        network_metrics = network_results['network_metrics']\n",
    "        centrality_metrics = network_results.get('centrality_metrics', {})\n",
    "        communities = network_results.get('communities', [])\n",
    "        \n",
    "        export_result = analytics.export_engine.export_network_analysis(\n",
    "            network_metrics=network_metrics,\n",
    "            centrality_metrics=centrality_metrics,\n",
    "            communities=communities,\n",
    "            config=export_config\n",
    "        )\n",
    "        \n",
    "        if export_result.success:\n",
    "            print(f\"‚úÖ Network analysis exported to: {export_result.file_path}\")\n",
    "            print(f\"   File size: {export_result.file_size:,} bytes\")\n",
    "            print(f\"   Export time: {export_result.export_time:.2f} seconds\")\n",
    "        else:\n",
    "            print(f\"‚ùå Export failed: {export_result.error_message}\")\n",
    "    \n",
    "    # Also export as JSON for programmatic use\n",
    "    json_config = ExportConfiguration(format='json')\n",
    "    json_result = analytics.export_engine._export_json(\n",
    "        network_results, \n",
    "        'network_exploration', \n",
    "        datetime.now()\n",
    "    )\n",
    "    \n",
    "    if json_result.success:\n",
    "        print(f\"‚úÖ Raw data exported to: {json_result.file_path}\")\nelse:\n",
    "    print(\"\\nüíæ Export skipped (disabled in configuration or analysis failed)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook completed comprehensive network exploration analysis including:\n",
    "\n",
    "1. **Network Structure Analysis** - Basic properties and connectivity patterns\n",
    "2. **Centrality Analysis** - Identification of influential papers\n",
    "3. **Community Detection** - Discovery of research clusters\n",
    "4. **Visualization** - Multiple charts and graphs\n",
    "5. **Export** - Results saved in multiple formats\n",
    "\n",
    "### Key Insights\n",
    "\n",
    "The analysis reveals the structural properties of the citation network and identifies:\n",
    "- Most influential papers based on various centrality measures\n",
    "- Community structure showing clusters of related research\n",
    "- Network topology and connectivity patterns\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Run `02_citation_analysis.ipynb` for temporal analysis\n",
    "- Use `03_performance_benchmarks.ipynb` for performance evaluation\n",
    "- Explore specific communities or influential papers in detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéì NETWORK EXPLORATION ANALYSIS COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if 'error' not in network_results:\n",
    "    graph_info = network_results['graph_info']\n",
    "    print(f\"\\nüìä Network analyzed: {graph_info['num_nodes']:,} nodes, {graph_info['num_edges']:,} edges\")\n",
    "    \n",
    "    if 'communities' in network_results:\n",
    "        print(f\"üèòÔ∏è Communities detected: {len(network_results['communities'])}\")\n",
    "    \n",
    "    if 'centrality_metrics' in network_results:\n",
    "        print(f\"üéØ Centrality calculated for all nodes\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ Analysis completed successfully at {datetime.now()}\")\nelse:\n",
    "    print(f\"\\n‚ùå Analysis failed: {network_results['error']}\")\n",
    "\n",
    "print(\"\\nüìù Check exported files for detailed results\")\n",
    "print(\"üîó Continue with temporal analysis in the next notebook\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}