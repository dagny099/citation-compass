{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TransE Model Training Pipeline\n",
    "\n",
    "This notebook implements and trains the TransE (Translating Embeddings) model for citation link prediction. The TransE model learns embeddings such that for each citation relationship (source_paper, target_paper), the embedding of source_paper + relation ‚âà embedding of target_paper.\n",
    "\n",
    "## TransE Model Overview\n",
    "\n",
    "**Core Principle**: For a citation relationship (paper_A cites paper_B), we want:\n",
    "```\n",
    "embedding(paper_A) + embedding(\"CITES\") ‚âà embedding(paper_B)\n",
    "```\n",
    "\n",
    "**Training Objective**: Minimize the distance for positive citations while maximizing it for negative (non-existent) citations using margin ranking loss.\n",
    "\n",
    "## Training Pipeline\n",
    "\n",
    "1. **Data Preparation**: Load citation network and create train/test splits\n",
    "2. **Negative Sampling**: Generate negative examples for contrastive learning\n",
    "3. **Model Initialization**: Create TransE model with configurable embeddings\n",
    "4. **Training Loop**: Optimize with margin ranking loss and Adam optimizer\n",
    "5. **Monitoring**: Track loss convergence and embedding quality\n",
    "6. **Model Persistence**: Save trained model and metadata\n",
    "\n",
    "## Requirements\n",
    "\n",
    "- PyTorch for deep learning framework\n",
    "- Academic Citation Platform data from previous exploration\n",
    "- Sufficient memory for embedding matrices (num_papers √ó embedding_dim)\n",
    "- Optional: GPU for faster training on large networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add project root to path\n",
    "project_root = os.path.dirname(os.getcwd())\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "# Import project components\n",
    "from src.services.ml_service import TransEModel, get_ml_service\n",
    "from src.services.analytics_service import get_analytics_service\n",
    "from src.database.connection import Neo4jConnection\n",
    "from src.data.unified_database import UnifiedDatabase\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"viridis\")\n",
    "\n",
    "# Check for GPU availability\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"üîß Using device: {device}\")\n",
    "if device.type == 'cuda':\n",
    "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory // 1024**3} GB\")\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully\")\n",
    "print(f\"üöÇ Model training pipeline ready at: {datetime.now()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load Data from Previous Analysis\n",
    "\n",
    "We'll load the comprehensive data from our previous exploration notebook to ensure consistency and leverage the insights we've already gathered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load exploration data from previous notebook\n",
    "print(\"üìö Loading data from comprehensive exploration...\")\n",
    "\n",
    "try:\n",
    "    # Try to load exploration data first\n",
    "    exploration_data_path = '/Users/bhs/PROJECTS/academic-citation-platform/outputs/exploration_data.pkl'\n",
    "    with open(exploration_data_path, 'rb') as f:\n",
    "        exploration_data = pickle.load(f)\n",
    "    \n",
    "    print(\"‚úÖ Loaded exploration data from previous analysis\")\n",
    "    \n",
    "    # Extract data for training\n",
    "    papers_data = exploration_data['papers_data']\n",
    "    citation_data = exploration_data['citation_data']\n",
    "    entity_mapping = exploration_data['entity_mapping']\n",
    "    reverse_mapping = exploration_data['reverse_mapping']\n",
    "    num_entities = exploration_data['num_entities']\n",
    "    network_results = exploration_data.get('network_results', {})\n",
    "    \n",
    "    print(f\"   Papers: {len(papers_data):,}\")\n",
    "    print(f\"   Citations: {len(citation_data):,}\")\n",
    "    print(f\"   Entity mapping: {num_entities:,} entities\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"‚ö†Ô∏è Exploration data not found. Loading fresh data...\")\n",
    "    \n",
    "    # Fallback to loading fresh data\n",
    "    db_connection = Neo4jConnection()\n",
    "    db = UnifiedDatabase()\n",
    "    \n",
    "    if not db_connection.test_connection():\n",
    "        raise ConnectionError(\"‚ùå Failed to connect to Neo4j database\")\n",
    "    \n",
    "    # Load data\n",
    "    papers_data = db.get_papers_for_training()\n",
    "    citation_data = db.get_citation_edges()\n",
    "    \n",
    "    # Create mappings\n",
    "    entity_mapping = {paper['paper_id']: idx for idx, paper in enumerate(papers_data)}\n",
    "    reverse_mapping = {idx: paper['paper_id'] for idx, paper in enumerate(papers_data)}\n",
    "    num_entities = len(papers_data)\n",
    "    network_results = {}\n",
    "    \n",
    "    print(\"‚úÖ Fresh data loaded successfully\")\n",
    "    print(f\"   Papers: {len(papers_data):,}\")\n",
    "    print(f\"   Citations: {len(citation_data):,}\")\n",
    "    \n",
    "    # Close database connection\n",
    "    db_connection.close()\n",
    "\n",
    "print(f\"\\nüìä Dataset Overview:\")\n",
    "print(f\"   Entity vocabulary size: {num_entities:,}\")\n",
    "print(f\"   Citation relationships: {len(citation_data):,}\")\n",
    "print(f\"   Average citations per paper: {len(citation_data) / num_entities:.2f}\")\n",
    "print(f\"   Network density: {len(citation_data) / (num_entities * (num_entities - 1)):.6f}\")\n",
    "\n",
    "print(\"\\nüéØ Data ready for model training pipeline!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Prepare Training Data with Train/Test Split\n",
    "\n",
    "We'll create proper train/test splits with negative sampling to generate a balanced dataset for training our TransE model. This is crucial for learning meaningful embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure data preparation parameters\n",
    "DATA_CONFIG = {\n",
    "    'test_size': 0.2,           # 80/20 train/test split\n",
    "    'negative_ratio': 1,        # 1:1 ratio of negative to positive samples\n",
    "    'random_state': 42,         # For reproducible results\n",
    "    'min_degree': 1             # Minimum degree for papers to include\n",
    "}\n",
    "\n",
    "print(\"üîß Data Preparation Configuration:\")\n",
    "for key, value in DATA_CONFIG.items():\n",
    "    print(f\"   {key}: {value}\")\n",
    "\n",
    "print(f\"\\nüîÑ Preparing training data with train/test split...\")\n",
    "\n",
    "# Convert citation data to edge format\n",
    "edges = []\n",
    "for citation in citation_data:\n",
    "    # Handle different citation data formats\n",
    "    if 'source_idx' in citation and 'target_idx' in citation:\n",
    "        source_idx = citation['source_idx']\n",
    "        target_idx = citation['target_idx']\n",
    "    else:\n",
    "        source_paper_id = citation.get('source_paper_id')\n",
    "        target_paper_id = citation.get('target_paper_id')\n",
    "        \n",
    "        if source_paper_id in entity_mapping and target_paper_id in entity_mapping:\n",
    "            source_idx = entity_mapping[source_paper_id]\n",
    "            target_idx = entity_mapping[target_paper_id]\n",
    "        else:\n",
    "            continue  # Skip if papers not in mapping\n",
    "    \n",
    "    edges.append([source_idx, target_idx])\n",
    "\n",
    "# Convert to tensor\n",
    "positive_edges = torch.tensor(edges, dtype=torch.long)\n",
    "\n",
    "print(f\"‚úÖ Processed {len(positive_edges):,} positive citation edges\")\n",
    "\n",
    "# Create train/test split\n",
    "train_pos_edges, test_pos_edges = train_test_split(\n",
    "    positive_edges,\n",
    "    test_size=DATA_CONFIG['test_size'],\n",
    "    random_state=DATA_CONFIG['random_state']\n",
    ")\n",
    "\n",
    "print(f\"üìä Train/Test Split:\")\n",
    "print(f\"   Training positive edges: {len(train_pos_edges):,}\")\n",
    "print(f\"   Test positive edges: {len(test_pos_edges):,}\")\n",
    "\n",
    "# Generate negative samples for training\n",
    "print(f\"\\nüé≤ Generating negative samples (ratio 1:{DATA_CONFIG['negative_ratio']})...\")\n",
    "\n",
    "def generate_negative_samples(positive_edges, num_entities, num_negative, random_state=42):\n",
    "    \"\"\"\n",
    "    Generate negative samples by randomly sampling non-existent edges.\n",
    "    Ensures no overlap with positive edges for valid negative examples.\n",
    "    \"\"\"\n",
    "    np.random.seed(random_state)\n",
    "    \n",
    "    # Create set of positive edges for fast lookup\n",
    "    positive_set = set(map(tuple, positive_edges.numpy()))\n",
    "    \n",
    "    negative_edges = []\n",
    "    attempts = 0\n",
    "    max_attempts = num_negative * 10  # Avoid infinite loops\n",
    "    \n",
    "    print(f\"   Generating {num_negative:,} negative samples...\")\n",
    "    \n",
    "    with tqdm(total=num_negative, desc=\"Negative sampling\") as pbar:\n",
    "        while len(negative_edges) < num_negative and attempts < max_attempts:\n",
    "            # Random source and target\n",
    "            source = np.random.randint(0, num_entities)\n",
    "            target = np.random.randint(0, num_entities)\n",
    "            \n",
    "            # Ensure no self-loops and not in positive set\n",
    "            if source != target and (source, target) not in positive_set:\n",
    "                negative_edges.append([source, target])\n",
    "                pbar.update(1)\n",
    "            \n",
    "            attempts += 1\n",
    "    \n",
    "    if len(negative_edges) < num_negative:\n",
    "        print(f\"‚ö†Ô∏è Could only generate {len(negative_edges):,} negative samples (requested {num_negative:,})\")\n",
    "    \n",
    "    return torch.tensor(negative_edges, dtype=torch.long)\n",
    "\n",
    "# Generate negative samples for training and testing\n",
    "train_neg_edges = generate_negative_samples(\n",
    "    positive_edges, \n",
    "    num_entities, \n",
    "    len(train_pos_edges) * DATA_CONFIG['negative_ratio'],\n",
    "    random_state=DATA_CONFIG['random_state']\n",
    ")\n",
    "\n",
    "test_neg_edges = generate_negative_samples(\n",
    "    positive_edges,\n",
    "    num_entities,\n",
    "    len(test_pos_edges) * DATA_CONFIG['negative_ratio'],\n",
    "    random_state=DATA_CONFIG['random_state'] + 1  # Different seed for test\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Training Data Prepared:\")\n",
    "print(f\"   Training positive: {len(train_pos_edges):,}\")\n",
    "print(f\"   Training negative: {len(train_neg_edges):,}\")\n",
    "print(f\"   Test positive: {len(test_pos_edges):,}\")\n",
    "print(f\"   Test negative: {len(test_neg_edges):,}\")\n",
    "print(f\"   Total training samples: {len(train_pos_edges) + len(train_neg_edges):,}\")\n",
    "print(f\"   Total test samples: {len(test_pos_edges) + len(test_neg_edges):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Initialize TransE Model Architecture\n",
    "\n",
    "Now we'll create our TransE model with carefully chosen hyperparameters based on our network analysis. The model will learn entity embeddings and a relation embedding for the \"CITES\" relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure model hyperparameters\n",
    "MODEL_CONFIG = {\n",
    "    'embedding_dim': 128,       # Dimension of entity embeddings\n",
    "    'margin': 1.0,             # Margin for ranking loss\n",
    "    'learning_rate': 0.01,     # Learning rate for Adam optimizer\n",
    "    'l2_regularization': 1e-5, # L2 regularization strength\n",
    "    'norm_p': 1,               # L1 or L2 norm for distance computation\n",
    "    'normalize_embeddings': True # Whether to normalize embeddings\n",
    "}\n",
    "\n",
    "print(\"üß† Model Configuration:\")\n",
    "for key, value in MODEL_CONFIG.items():\n",
    "    print(f\"   {key}: {value}\")\n",
    "\n",
    "print(f\"\\nüîß Device configuration:\")\n",
    "print(f\"   Training device: {device}\")\n",
    "print(f\"   Entity count: {num_entities:,}\")\n",
    "print(f\"   Embedding dimension: {MODEL_CONFIG['embedding_dim']}\")\n",
    "\n",
    "# Calculate model parameters\n",
    "entity_params = num_entities * MODEL_CONFIG['embedding_dim']\n",
    "relation_params = MODEL_CONFIG['embedding_dim']  # Single relation embedding\n",
    "total_params = entity_params + relation_params\n",
    "\n",
    "print(f\"\\nüìä Model Size:\")\n",
    "print(f\"   Entity parameters: {entity_params:,}\")\n",
    "print(f\"   Relation parameters: {relation_params:,}\")\n",
    "print(f\"   Total parameters: {total_params:,}\")\n",
    "print(f\"   Estimated memory: {total_params * 4 / 1024**2:.1f} MB (float32)\")\n",
    "\n",
    "# Initialize TransE model\n",
    "print(f\"\\nüèóÔ∏è Initializing TransE model...\")\n",
    "\n",
    "class TransE(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    TransE model for knowledge graph embedding.\n",
    "    \n",
    "    The model learns embeddings such that for a triple (head, relation, tail):\n",
    "    embedding(head) + embedding(relation) ‚âà embedding(tail)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_entities, num_relations, embedding_dim, norm_p=1):\n",
    "        super(TransE, self).__init__()\n",
    "        \n",
    "        self.num_entities = num_entities\n",
    "        self.num_relations = num_relations\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.norm_p = norm_p\n",
    "        \n",
    "        # Entity embeddings\n",
    "        self.entity_embeddings = torch.nn.Embedding(num_entities, embedding_dim)\n",
    "        \n",
    "        # Relation embeddings (we only have one relation: \"CITES\")\n",
    "        self.relation_embeddings = torch.nn.Embedding(num_relations, embedding_dim)\n",
    "        \n",
    "        # Initialize embeddings\n",
    "        self.init_embeddings()\n",
    "    \n",
    "    def init_embeddings(self):\n",
    "        \"\"\"\n",
    "        Initialize embeddings with uniform distribution and normalize.\n",
    "        \"\"\"\n",
    "        # Initialize entity embeddings\n",
    "        torch.nn.init.uniform_(self.entity_embeddings.weight, -6/np.sqrt(self.embedding_dim), 6/np.sqrt(self.embedding_dim))\n",
    "        \n",
    "        # Initialize relation embeddings\n",
    "        torch.nn.init.uniform_(self.relation_embeddings.weight, -6/np.sqrt(self.embedding_dim), 6/np.sqrt(self.embedding_dim))\n",
    "        \n",
    "        # Normalize entity embeddings\n",
    "        self.normalize_entity_embeddings()\n",
    "    \n",
    "    def normalize_entity_embeddings(self):\n",
    "        \"\"\"\n",
    "        Normalize entity embeddings to unit norm.\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            entity_norms = torch.norm(self.entity_embeddings.weight, p=2, dim=1, keepdim=True)\n",
    "            self.entity_embeddings.weight.div_(entity_norms)\n",
    "    \n",
    "    def forward(self, head_indices, tail_indices, relation_indices=None):\n",
    "        \"\"\"\n",
    "        Compute TransE scores for given triples.\n",
    "        \n",
    "        Args:\n",
    "            head_indices: Source entity indices\n",
    "            tail_indices: Target entity indices  \n",
    "            relation_indices: Relation indices (default: 0 for \"CITES\")\n",
    "        \n",
    "        Returns:\n",
    "            Scores (lower = more plausible)\n",
    "        \"\"\"\n",
    "        if relation_indices is None:\n",
    "            # Default to relation 0 (\"CITES\")\n",
    "            relation_indices = torch.zeros_like(head_indices)\n",
    "        \n",
    "        # Get embeddings\n",
    "        head_embeddings = self.entity_embeddings(head_indices)\n",
    "        tail_embeddings = self.entity_embeddings(tail_indices)\n",
    "        relation_embeddings = self.relation_embeddings(relation_indices)\n",
    "        \n",
    "        # Compute TransE score: ||h + r - t||_p\n",
    "        scores = torch.norm(\n",
    "            head_embeddings + relation_embeddings - tail_embeddings,\n",
    "            p=self.norm_p,\n",
    "            dim=1\n",
    "        )\n",
    "        \n",
    "        return scores\n",
    "\n",
    "# Create model instance\n",
    "model = TransE(\n",
    "    num_entities=num_entities,\n",
    "    num_relations=1,  # Only \"CITES\" relation\n",
    "    embedding_dim=MODEL_CONFIG['embedding_dim'],\n",
    "    norm_p=MODEL_CONFIG['norm_p']\n",
    ").to(device)\n",
    "\n",
    "print(f\"‚úÖ TransE model created successfully!\")\n",
    "print(f\"   Model device: {next(model.parameters()).device}\")\n",
    "print(f\"   Actual parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "# Display model architecture\n",
    "print(f\"\\nüèõÔ∏è Model Architecture:\")\n",
    "print(model)\n",
    "\n",
    "# Initialize optimizer\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=MODEL_CONFIG['learning_rate'],\n",
    "    weight_decay=MODEL_CONFIG['l2_regularization']\n",
    ")\n",
    "\n",
    "print(f\"\\n‚öôÔ∏è Optimizer configured:\")\n",
    "print(f\"   Type: Adam\")\n",
    "print(f\"   Learning rate: {MODEL_CONFIG['learning_rate']}\")\n",
    "print(f\"   Weight decay (L2): {MODEL_CONFIG['l2_regularization']}\")\n",
    "\n",
    "print(f\"\\nüöÄ Model ready for training!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Training Configuration and Loss Function\n",
    "\n",
    "We'll set up our training configuration and implement the margin ranking loss that's essential for TransE training. This loss encourages positive citations to have lower scores than negative ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "TRAINING_CONFIG = {\n",
    "    'epochs': 100,              # Number of training epochs\n",
    "    'batch_size': 1024,         # Batch size for training\n",
    "    'eval_frequency': 10,       # Evaluate every N epochs\n",
    "    'save_frequency': 25,       # Save model every N epochs\n",
    "    'early_stopping_patience': 20,  # Stop if no improvement for N epochs\n",
    "    'verbose': True,            # Show training progress\n",
    "    'normalize_frequency': 10   # Normalize embeddings every N epochs\n",
    "}\n",
    "\n",
    "print(\"üéØ Training Configuration:\")\n",
    "for key, value in TRAINING_CONFIG.items():\n",
    "    print(f\"   {key}: {value}\")\n",
    "\n",
    "# Calculate training statistics\n",
    "total_train_samples = len(train_pos_edges) + len(train_neg_edges)\n",
    "batches_per_epoch = (total_train_samples + TRAINING_CONFIG['batch_size'] - 1) // TRAINING_CONFIG['batch_size']\n",
    "total_batches = batches_per_epoch * TRAINING_CONFIG['epochs']\n",
    "\n",
    "print(f\"\\nüìä Training Statistics:\")\n",
    "print(f\"   Total training samples: {total_train_samples:,}\")\n",
    "print(f\"   Batches per epoch: {batches_per_epoch}\")\n",
    "print(f\"   Total training batches: {total_batches:,}\")\n",
    "print(f\"   Estimated time per epoch: ~{batches_per_epoch * 0.1:.1f} seconds\")\n",
    "\n",
    "# Move data to device\n",
    "print(f\"\\nüîÑ Moving training data to {device}...\")\n",
    "train_pos_edges = train_pos_edges.to(device)\n",
    "train_neg_edges = train_neg_edges.to(device)\n",
    "test_pos_edges = test_pos_edges.to(device)\n",
    "test_neg_edges = test_neg_edges.to(device)\n",
    "\n",
    "print(f\"‚úÖ Training data prepared and moved to device\")\n",
    "\n",
    "# Define margin ranking loss function\n",
    "def margin_ranking_loss(positive_scores, negative_scores, margin):\n",
    "    \"\"\"\n",
    "    Compute margin ranking loss for TransE.\n",
    "    \n",
    "    The loss encourages positive triples to have lower scores than negative triples\n",
    "    by at least the specified margin.\n",
    "    \n",
    "    Args:\n",
    "        positive_scores: Scores for positive triples (lower = better)\n",
    "        negative_scores: Scores for negative triples (lower = better)\n",
    "        margin: Margin for ranking loss\n",
    "    \n",
    "    Returns:\n",
    "        Margin ranking loss\n",
    "    \"\"\"\n",
    "    # We want: positive_scores + margin < negative_scores\n",
    "    # Loss = max(0, positive_scores - negative_scores + margin)\n",
    "    loss = torch.relu(positive_scores - negative_scores + margin)\n",
    "    return loss.mean()\n",
    "\n",
    "# Test loss function with dummy data\n",
    "print(f\"\\nüß™ Testing loss function...\")\n",
    "dummy_pos_scores = torch.tensor([1.0, 2.0, 1.5], device=device)\n",
    "dummy_neg_scores = torch.tensor([3.0, 4.0, 3.5], device=device)\n",
    "dummy_loss = margin_ranking_loss(dummy_pos_scores, dummy_neg_scores, MODEL_CONFIG['margin'])\n",
    "print(f\"   Dummy loss (should be 0.0): {dummy_loss:.4f}\")\n",
    "\n",
    "# Create data loader for efficient batching\n",
    "def create_batches(pos_edges, neg_edges, batch_size, shuffle=True):\n",
    "    \"\"\"\n",
    "    Create batches from positive and negative edges.\n",
    "    \n",
    "    Args:\n",
    "        pos_edges: Positive edge tensor\n",
    "        neg_edges: Negative edge tensor  \n",
    "        batch_size: Size of each batch\n",
    "        shuffle: Whether to shuffle the data\n",
    "    \n",
    "    Yields:\n",
    "        Batches of (pos_batch, neg_batch)\n",
    "    \"\"\"\n",
    "    # Ensure we have equal numbers of positive and negative samples\n",
    "    min_samples = min(len(pos_edges), len(neg_edges))\n",
    "    pos_edges = pos_edges[:min_samples]\n",
    "    neg_edges = neg_edges[:min_samples]\n",
    "    \n",
    "    if shuffle:\n",
    "        # Shuffle indices\n",
    "        indices = torch.randperm(min_samples)\n",
    "        pos_edges = pos_edges[indices]\n",
    "        neg_edges = neg_edges[indices]\n",
    "    \n",
    "    # Create batches\n",
    "    for i in range(0, min_samples, batch_size):\n",
    "        end_idx = min(i + batch_size, min_samples)\n",
    "        yield pos_edges[i:end_idx], neg_edges[i:end_idx]\n",
    "\n",
    "print(f\"\\n‚úÖ Training infrastructure ready!\")\n",
    "print(f\"   Loss function: Margin ranking loss (margin={MODEL_CONFIG['margin']})\")\n",
    "print(f\"   Batch creation: Efficient data loading implemented\")\n",
    "print(f\"   Ready to start training loop!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Model Training Loop\n",
    "\n",
    "Now we'll execute the main training loop, monitoring loss convergence and periodically evaluating the model's performance. This is where the TransE model learns meaningful paper embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop with comprehensive monitoring\n",
    "print(\"üöÇ Starting TransE model training...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Initialize training tracking variables\n",
    "training_history = {\n",
    "    'loss': [],\n",
    "    'epoch_times': [],\n",
    "    'learning_rates': [],\n",
    "    'embedding_norms': []\n",
    "}\n",
    "\n",
    "best_loss = float('inf')\n",
    "epochs_without_improvement = 0\n",
    "start_time = datetime.now()\n",
    "\n",
    "# Training progress tracking\n",
    "epoch_pbar = tqdm(range(TRAINING_CONFIG['epochs']), desc='Training Progress')\n",
    "\n",
    "for epoch in epoch_pbar:\n",
    "    epoch_start_time = datetime.now()\n",
    "    \n",
    "    # Set model to training mode\n",
    "    model.train()\n",
    "    \n",
    "    epoch_losses = []\n",
    "    batch_count = 0\n",
    "    \n",
    "    # Create batches for this epoch\n",
    "    for pos_batch, neg_batch in create_batches(\n",
    "        train_pos_edges, \n",
    "        train_neg_edges, \n",
    "        TRAINING_CONFIG['batch_size'],\n",
    "        shuffle=True\n",
    "    ):\n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass for positive samples\n",
    "        pos_scores = model(pos_batch[:, 0], pos_batch[:, 1])\n",
    "        \n",
    "        # Forward pass for negative samples\n",
    "        neg_scores = model(neg_batch[:, 0], neg_batch[:, 1])\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = margin_ranking_loss(pos_scores, neg_scores, MODEL_CONFIG['margin'])\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Track batch loss\n",
    "        epoch_losses.append(loss.item())\n",
    "        batch_count += 1\n",
    "    \n",
    "    # Calculate epoch statistics\n",
    "    epoch_loss = np.mean(epoch_losses)\n",
    "    epoch_time = (datetime.now() - epoch_start_time).total_seconds()\n",
    "    \n",
    "    # Update training history\n",
    "    training_history['loss'].append(epoch_loss)\n",
    "    training_history['epoch_times'].append(epoch_time)\n",
    "    training_history['learning_rates'].append(optimizer.param_groups[0]['lr'])\n",
    "    \n",
    "    # Normalize entity embeddings periodically\n",
    "    if MODEL_CONFIG['normalize_embeddings'] and (epoch + 1) % TRAINING_CONFIG['normalize_frequency'] == 0:\n",
    "        model.normalize_entity_embeddings()\n",
    "        \n",
    "        # Track embedding norms\n",
    "        with torch.no_grad():\n",
    "            avg_entity_norm = torch.norm(model.entity_embeddings.weight, p=2, dim=1).mean().item()\n",
    "            training_history['embedding_norms'].append(avg_entity_norm)\n",
    "    \n",
    "    # Update progress bar\n",
    "    epoch_pbar.set_postfix({\n",
    "        'Loss': f'{epoch_loss:.4f}',\n",
    "        'Time': f'{epoch_time:.1f}s',\n",
    "        'Batches': batch_count\n",
    "    })\n",
    "    \n",
    "    # Early stopping check\n",
    "    if epoch_loss < best_loss:\n",
    "        best_loss = epoch_loss\n",
    "        epochs_without_improvement = 0\n",
    "        \n",
    "        # Save best model\n",
    "        if (epoch + 1) % TRAINING_CONFIG['save_frequency'] == 0 or epoch_loss < best_loss * 0.95:\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': epoch_loss,\n",
    "                'config': MODEL_CONFIG\n",
    "            }, f'/Users/bhs/PROJECTS/academic-citation-platform/models/best_model_checkpoint.pt')\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "    \n",
    "    # Early stopping\n",
    "    if epochs_without_improvement >= TRAINING_CONFIG['early_stopping_patience']:\n",
    "        print(f\"\\nüõë Early stopping at epoch {epoch + 1}\")\n",
    "        print(f\"   No improvement for {epochs_without_improvement} epochs\")\n",
    "        break\n",
    "    \n",
    "    # Verbose logging\n",
    "    if TRAINING_CONFIG['verbose'] and (epoch + 1) % TRAINING_CONFIG['eval_frequency'] == 0:\n",
    "        print(f\"\\nüìä Epoch {epoch + 1}/{TRAINING_CONFIG['epochs']}:\")\n",
    "        print(f\"   Loss: {epoch_loss:.6f} (best: {best_loss:.6f})\")\n",
    "        print(f\"   Time: {epoch_time:.2f}s\")\n",
    "        print(f\"   Batches processed: {batch_count}\")\n",
    "        \n",
    "        if training_history['embedding_norms']:\n",
    "            print(f\"   Avg embedding norm: {training_history['embedding_norms'][-1]:.4f}\")\n",
    "\n",
    "# Training completed\n",
    "total_training_time = (datetime.now() - start_time).total_seconds()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üèÅ TRAINING COMPLETED!\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nüìà Training Summary:\")\n",
    "print(f\"   Epochs completed: {len(training_history['loss'])}\")\n",
    "print(f\"   Final loss: {training_history['loss'][-1]:.6f}\")\n",
    "print(f\"   Best loss: {best_loss:.6f}\")\n",
    "print(f\"   Loss improvement: {(training_history['loss'][0] - training_history['loss'][-1]) / training_history['loss'][0] * 100:.1f}%\")\n",
    "print(f\"   Total training time: {total_training_time:.1f} seconds ({total_training_time/60:.1f} minutes)\")\n",
    "print(f\"   Average time per epoch: {np.mean(training_history['epoch_times']):.2f} seconds\")\n",
    "\n",
    "# Check convergence\n",
    "recent_losses = training_history['loss'][-10:] if len(training_history['loss']) >= 10 else training_history['loss']\n",
    "loss_variance = np.var(recent_losses)\n",
    "\n",
    "if loss_variance < 0.0001:\n",
    "    print(f\"\\n‚úÖ Model converged successfully (loss variance: {loss_variance:.6f})\")\n",
    "elif epochs_without_improvement >= TRAINING_CONFIG['early_stopping_patience']:\n",
    "    print(f\"\\n‚èπÔ∏è Training stopped early (no improvement for {epochs_without_improvement} epochs)\")\n",
    "else:\n",
    "    print(f\"\\n‚úÖ Training completed all epochs\")\n",
    "\n",
    "print(f\"\\nüéØ Model is ready for evaluation!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Training Progress Visualization\n",
    "\n",
    "Let's visualize the training progress to understand how well our model learned and whether the training was successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive training visualization\n",
    "print(\"üìä Creating training progress visualizations...\")\n",
    "\n",
    "# Set up the plotting environment\n",
    "fig = plt.figure(figsize=(16, 12))\n",
    "gs = fig.add_gridspec(3, 2, hspace=0.4, wspace=0.3)\n",
    "\n",
    "fig.suptitle('TransE Model Training Progress', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Plot 1: Loss curve over epochs\n",
    "ax1 = fig.add_subplot(gs[0, :])\n",
    "epochs_range = range(1, len(training_history['loss']) + 1)\n",
    "\n",
    "ax1.plot(epochs_range, training_history['loss'], 'b-', linewidth=2, alpha=0.8, label='Training Loss')\n",
    "ax1.fill_between(epochs_range, training_history['loss'], alpha=0.3, color='blue')\n",
    "\n",
    "# Add best loss line\n",
    "best_epoch = np.argmin(training_history['loss']) + 1\n",
    "ax1.axhline(y=best_loss, color='red', linestyle='--', alpha=0.7, \n",
    "           label=f'Best Loss: {best_loss:.4f} (Epoch {best_epoch})')\n",
    "ax1.axvline(x=best_epoch, color='red', linestyle='--', alpha=0.7)\n",
    "\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Margin Ranking Loss')\n",
    "ax1.set_title('Training Loss Convergence', fontweight='bold', fontsize=14)\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Add annotations\n",
    "initial_loss = training_history['loss'][0]\n",
    "final_loss = training_history['loss'][-1]\n",
    "improvement_pct = (initial_loss - final_loss) / initial_loss * 100\n",
    "\n",
    "ax1.annotate(f'Initial: {initial_loss:.4f}', \n",
    "            xy=(1, initial_loss), xytext=(len(epochs_range)*0.2, initial_loss*1.1),\n",
    "            arrowprops=dict(arrowstyle='->', color='green', alpha=0.7),\n",
    "            fontsize=10, color='green')\n",
    "\n",
    "ax1.annotate(f'Final: {final_loss:.4f}\\n({improvement_pct:.1f}% improvement)', \n",
    "            xy=(len(epochs_range), final_loss), xytext=(len(epochs_range)*0.8, final_loss*2),\n",
    "            arrowprops=dict(arrowstyle='->', color='orange', alpha=0.7),\n",
    "            fontsize=10, color='orange')\n",
    "\n",
    "# Plot 2: Training time per epoch\n",
    "ax2 = fig.add_subplot(gs[1, 0])\n",
    "ax2.bar(epochs_range, training_history['epoch_times'], alpha=0.7, color='lightblue')\n",
    "ax2.axhline(y=np.mean(training_history['epoch_times']), color='red', linestyle='--', \n",
    "           label=f'Avg: {np.mean(training_history['epoch_times']):.2f}s')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Time (seconds)')\n",
    "ax2.set_title('Training Time per Epoch', fontweight='bold')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Learning rate schedule (if it changes)\n",
    "ax3 = fig.add_subplot(gs[1, 1])\n",
    "if len(set(training_history['learning_rates'])) > 1:\n",
    "    ax3.plot(epochs_range, training_history['learning_rates'], 'g-', linewidth=2)\n",
    "    ax3.set_ylabel('Learning Rate')\n",
    "else:\n",
    "    # Show constant learning rate\n",
    "    ax3.axhline(y=MODEL_CONFIG['learning_rate'], color='green', linewidth=2)\n",
    "    ax3.set_ylabel('Learning Rate (constant)')\n",
    "    ax3.text(0.5, 0.5, f\"Constant LR\\n{MODEL_CONFIG['learning_rate']}\", \n",
    "            transform=ax3.transAxes, ha='center', va='center', fontsize=12, \n",
    "            bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.3))\n",
    "\n",
    "ax3.set_xlabel('Epoch')\n",
    "ax3.set_title('Learning Rate Schedule', fontweight='bold')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Embedding norms (if tracked)\n",
    "ax4 = fig.add_subplot(gs[2, :])\n",
    "if training_history['embedding_norms']:\n",
    "    norm_epochs = range(TRAINING_CONFIG['normalize_frequency'], \n",
    "                       len(training_history['embedding_norms']) * TRAINING_CONFIG['normalize_frequency'] + 1,\n",
    "                       TRAINING_CONFIG['normalize_frequency'])\n",
    "    \n",
    "    ax4.plot(norm_epochs, training_history['embedding_norms'], 'mo-', linewidth=2, markersize=6)\n",
    "    ax4.set_xlabel('Epoch')\n",
    "    ax4.set_ylabel('Average Embedding Norm')\n",
    "    ax4.set_title('Entity Embedding Norms Over Training', fontweight='bold')\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add ideal norm line (should be close to 1.0 if normalizing)\n",
    "    if MODEL_CONFIG['normalize_embeddings']:\n",
    "        ax4.axhline(y=1.0, color='red', linestyle='--', alpha=0.7, label='Target Norm (1.0)')\n",
    "        ax4.legend()\n",
    "else:\n",
    "    # Show training statistics instead\n",
    "    stats_text = f\"\"\"\n",
    "Training Statistics:\n",
    "\n",
    "üìä Model Performance:\n",
    "‚Ä¢ Final Loss: {training_history['loss'][-1]:.6f}\n",
    "‚Ä¢ Best Loss: {best_loss:.6f}\n",
    "‚Ä¢ Improvement: {improvement_pct:.1f}%\n",
    "\n",
    "‚è±Ô∏è Training Efficiency:\n",
    "‚Ä¢ Total Time: {total_training_time/60:.1f} minutes\n",
    "‚Ä¢ Avg Time/Epoch: {np.mean(training_history['epoch_times']):.2f}s\n",
    "‚Ä¢ Epochs: {len(training_history['loss'])}\n",
    "\n",
    "üéØ Convergence:\n",
    "‚Ä¢ Loss Variance (last 10): {np.var(training_history['loss'][-10:]):.6f}\n",
    "‚Ä¢ {'Converged' if loss_variance < 0.0001 else 'May need more training'}\n",
    "\"\"\"\n",
    "    \n",
    "    ax4.text(0.05, 0.95, stats_text, transform=ax4.transAxes,\n",
    "            fontsize=11, verticalalignment='top', fontfamily='monospace',\n",
    "            bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.2))\n",
    "    ax4.set_title('Training Statistics Summary', fontweight='bold')\n",
    "    ax4.axis('off')\n",
    "\n",
    "# Save the visualization\n",
    "plt.tight_layout()\n",
    "plt.savefig('/Users/bhs/PROJECTS/academic-citation-platform/outputs/training_progress.png', \n",
    "           dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ Training visualization created and saved!\")\n",
    "print(\"üìä File saved: outputs/training_progress.png\")\n",
    "\n",
    "# Additional training insights\n",
    "print(f\"\\nüí° Training Insights:\")\n",
    "\n",
    "if improvement_pct > 50:\n",
    "    print(f\"   ‚Ä¢ Excellent loss reduction ({improvement_pct:.1f}%) - model learned effectively\")\n",
    "elif improvement_pct > 20:\n",
    "    print(f\"   ‚Ä¢ Good loss reduction ({improvement_pct:.1f}%) - reasonable learning\")\n",
    "else:\n",
    "    print(f\"   ‚Ä¢ Limited loss reduction ({improvement_pct:.1f}%) - may need hyperparameter tuning\")\n",
    "\n",
    "avg_time_per_epoch = np.mean(training_history['epoch_times'])\n",
    "if avg_time_per_epoch < 10:\n",
    "    print(f\"   ‚Ä¢ Fast training ({avg_time_per_epoch:.1f}s/epoch) - efficient for this dataset size\")\n",
    "elif avg_time_per_epoch < 60:\n",
    "    print(f\"   ‚Ä¢ Moderate training speed ({avg_time_per_epoch:.1f}s/epoch) - reasonable for network size\")\n",
    "else:\n",
    "    print(f\"   ‚Ä¢ Slow training ({avg_time_per_epoch:.1f}s/epoch) - consider GPU or smaller batches\")\n",
    "\n",
    "if loss_variance < 0.0001:\n",
    "    print(f\"   ‚Ä¢ Model converged well (stable loss) - ready for evaluation\")\n",
    "else:\n",
    "    print(f\"   ‚Ä¢ Loss still varying - might benefit from more epochs or learning rate adjustment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Quick Training Validation\n",
    "\n",
    "Before saving the model, let's perform a quick validation to ensure the model learned meaningful patterns by checking if it correctly distinguishes between positive and negative citation examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick validation on training and test data\n",
    "print(\"üîç Performing quick training validation...\")\n",
    "\n",
    "# Set model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Sample validation data to avoid memory issues\n",
    "    sample_size = min(1000, len(train_pos_edges))\n",
    "    sample_indices = torch.randperm(len(train_pos_edges))[:sample_size].to(device)\n",
    "    \n",
    "    # Get sample data\n",
    "    sample_train_pos = train_pos_edges[sample_indices]\n",
    "    sample_train_neg = train_neg_edges[sample_indices]\n",
    "    \n",
    "    # Compute scores\n",
    "    train_pos_scores = model(sample_train_pos[:, 0], sample_train_pos[:, 1])\n",
    "    train_neg_scores = model(sample_train_neg[:, 0], sample_train_neg[:, 1])\n",
    "    \n",
    "    # Calculate statistics\n",
    "    pos_mean = train_pos_scores.mean().item()\n",
    "    neg_mean = train_neg_scores.mean().item()\n",
    "    pos_std = train_pos_scores.std().item()\n",
    "    neg_std = train_neg_scores.std().item()\n",
    "    \n",
    "    print(f\"\\nüìä Training Sample Validation ({sample_size} samples):\")\n",
    "    print(f\"   Positive citations (should be lower):\")\n",
    "    print(f\"     Mean score: {pos_mean:.4f} ¬± {pos_std:.4f}\")\n",
    "    print(f\"     Min score: {train_pos_scores.min().item():.4f}\")\n",
    "    print(f\"     Max score: {train_pos_scores.max().item():.4f}\")\n",
    "    \n",
    "    print(f\"\\n   Negative citations (should be higher):\")\n",
    "    print(f\"     Mean score: {neg_mean:.4f} ¬± {neg_std:.4f}\")\n",
    "    print(f\"     Min score: {train_neg_scores.min().item():.4f}\")\n",
    "    print(f\"     Max score: {train_neg_scores.max().item():.4f}\")\n",
    "    \n",
    "    # Calculate separation metrics\n",
    "    score_separation = neg_mean - pos_mean\n",
    "    separation_ratio = score_separation / (pos_std + neg_std) if (pos_std + neg_std) > 0 else 0\n",
    "    \n",
    "    print(f\"\\n   üìè Separation Analysis:\")\n",
    "    print(f\"     Score separation: {score_separation:.4f}\")\n",
    "    print(f\"     Separation ratio: {separation_ratio:.2f}\")\n",
    "    \n",
    "    # Accuracy calculation (how many negatives score higher than positives)\n",
    "    correct_rankings = (train_neg_scores > train_pos_scores).sum().item()\n",
    "    ranking_accuracy = correct_rankings / len(train_pos_scores)\n",
    "    \n",
    "    print(f\"     Ranking accuracy: {ranking_accuracy:.3f} ({ranking_accuracy*100:.1f}%)\")\n",
    "    \n",
    "    # Interpretation\n",
    "    print(f\"\\nüí° Validation Results:\")\n",
    "    if score_separation > 0.5 and ranking_accuracy > 0.7:\n",
    "        print(f\"   ‚úÖ Excellent: Model learned to distinguish citations well\")\n",
    "        print(f\"      Strong separation ({score_separation:.3f}) and high accuracy ({ranking_accuracy:.1%})\")\n",
    "    elif score_separation > 0.1 and ranking_accuracy > 0.6:\n",
    "        print(f\"   ‚úÖ Good: Model shows clear learning of citation patterns\")\n",
    "        print(f\"      Moderate separation ({score_separation:.3f}) and decent accuracy ({ranking_accuracy:.1%})\")\n",
    "    elif score_separation > 0:\n",
    "        print(f\"   ‚ö†Ô∏è Fair: Model learned some patterns but could improve\")\n",
    "        print(f\"      Limited separation ({score_separation:.3f}), accuracy: {ranking_accuracy:.1%}\")\n",
    "    else:\n",
    "        print(f\"   ‚ùå Poor: Model did not learn to distinguish citations\")\n",
    "        print(f\"      Negative separation ({score_separation:.3f}) indicates training issues\")\n",
    "\n",
    "# Test set validation (smaller sample)\n",
    "if len(test_pos_edges) > 0:\n",
    "    with torch.no_grad():\n",
    "        test_sample_size = min(500, len(test_pos_edges))\n",
    "        test_sample_indices = torch.randperm(len(test_pos_edges))[:test_sample_size].to(device)\n",
    "        \n",
    "        sample_test_pos = test_pos_edges[test_sample_indices]\n",
    "        sample_test_neg = test_neg_edges[test_sample_indices]\n",
    "        \n",
    "        test_pos_scores = model(sample_test_pos[:, 0], sample_test_pos[:, 1])\n",
    "        test_neg_scores = model(sample_test_neg[:, 0], sample_test_neg[:, 1])\n",
    "        \n",
    "        test_pos_mean = test_pos_scores.mean().item()\n",
    "        test_neg_mean = test_neg_scores.mean().item()\n",
    "        test_separation = test_neg_mean - test_pos_mean\n",
    "        test_accuracy = (test_neg_scores > test_pos_scores).float().mean().item()\n",
    "        \n",
    "        print(f\"\\nüß™ Test Set Validation ({test_sample_size} samples):\")\n",
    "        print(f\"   Positive mean: {test_pos_mean:.4f}\")\n",
    "        print(f\"   Negative mean: {test_neg_mean:.4f}\")\n",
    "        print(f\"   Score separation: {test_separation:.4f}\")\n",
    "        print(f\"   Ranking accuracy: {test_accuracy:.3f} ({test_accuracy*100:.1f}%)\")\n",
    "        \n",
    "        # Compare train vs test performance\n",
    "        generalization_gap = abs(ranking_accuracy - test_accuracy)\n",
    "        print(f\"\\n   üìà Generalization:\")\n",
    "        if generalization_gap < 0.05:\n",
    "            print(f\"     ‚úÖ Excellent generalization (gap: {generalization_gap:.3f})\")\n",
    "        elif generalization_gap < 0.1:\n",
    "            print(f\"     ‚úÖ Good generalization (gap: {generalization_gap:.3f})\")\n",
    "        else:\n",
    "            print(f\"     ‚ö†Ô∏è Some overfitting detected (gap: {generalization_gap:.3f})\")\n",
    "\n",
    "print(f\"\\n‚úÖ Validation completed - model performance assessed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Model Inspection and Embedding Analysis\n",
    "\n",
    "Let's examine the learned embeddings to understand what the model has learned about the papers and their relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect learned embeddings and model properties\n",
    "print(\"üî¨ Inspecting learned embeddings and model properties...\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # Get embeddings\n",
    "    entity_embeddings = model.entity_embeddings.weight.cpu()\n",
    "    relation_embeddings = model.relation_embeddings.weight.cpu()\n",
    "    \n",
    "    print(f\"\\nüìê Embedding Dimensions and Properties:\")\n",
    "    print(f\"   Entity embeddings shape: {entity_embeddings.shape}\")\n",
    "    print(f\"   Relation embeddings shape: {relation_embeddings.shape}\")\n",
    "    print(f\"   Total embedding parameters: {entity_embeddings.numel() + relation_embeddings.numel():,}\")\n",
    "    \n",
    "    # Analyze entity embeddings\n",
    "    entity_norms = torch.norm(entity_embeddings, p=2, dim=1)\n",
    "    entity_mean_norm = entity_norms.mean().item()\n",
    "    entity_std_norm = entity_norms.std().item()\n",
    "    \n",
    "    print(f\"\\n   üìä Entity Embedding Statistics:\")\n",
    "    print(f\"     Mean norm: {entity_mean_norm:.4f} ¬± {entity_std_norm:.4f}\")\n",
    "    print(f\"     Min norm: {entity_norms.min().item():.4f}\")\n",
    "    print(f\"     Max norm: {entity_norms.max().item():.4f}\")\n",
    "    \n",
    "    # Analyze relation embeddings\n",
    "    relation_norm = torch.norm(relation_embeddings[0], p=2).item()\n",
    "    print(f\"\\n   üîó Citation Relation Embedding:\")\n",
    "    print(f\"     Relation norm: {relation_norm:.4f}\")\n",
    "    print(f\"     First 10 dimensions: {relation_embeddings[0][:10].numpy()}\")\n",
    "    \n",
    "    # Analyze embedding value distributions\n",
    "    embedding_values = entity_embeddings.flatten()\n",
    "    print(f\"\\n   üìà Embedding Value Distribution:\")\n",
    "    print(f\"     Mean: {embedding_values.mean().item():.4f}\")\n",
    "    print(f\"     Std: {embedding_values.std().item():.4f}\")\n",
    "    print(f\"     Min: {embedding_values.min().item():.4f}\")\n",
    "    print(f\"     Max: {embedding_values.max().item():.4f}\")\n",
    "    \n",
    "    # Check for embedding quality indicators\n",
    "    print(f\"\\nüí° Embedding Quality Assessment:\")\n",
    "    \n",
    "    # Norm consistency\n",
    "    if MODEL_CONFIG['normalize_embeddings']:\n",
    "        if 0.9 < entity_mean_norm < 1.1:\n",
    "            print(f\"   ‚úÖ Good norm consistency (target ~1.0, actual {entity_mean_norm:.3f})\")\n",
    "        else:\n",
    "            print(f\"   ‚ö†Ô∏è Norm deviation from target (target ~1.0, actual {entity_mean_norm:.3f})\")\n",
    "    \n",
    "    # Value range check\n",
    "    if -3 < embedding_values.min().item() < embedding_values.max().item() < 3:\n",
    "        print(f\"   ‚úÖ Reasonable value range [{embedding_values.min().item():.2f}, {embedding_values.max().item():.2f}]\")\n",
    "    else:\n",
    "        print(f\"   ‚ö†Ô∏è Extreme values detected - may indicate training instability\")\n",
    "    \n",
    "    # Distribution check\n",
    "    if abs(embedding_values.mean().item()) < 0.1:\n",
    "        print(f\"   ‚úÖ Well-centered distribution (mean ‚âà 0)\")\n",
    "    else:\n",
    "        print(f\"   ‚ö†Ô∏è Off-center distribution (mean = {embedding_values.mean().item():.3f})\")\n",
    "\n",
    "# Analyze paper similarities using embeddings\n",
    "print(f\"\\nüîç Analyzing Paper Similarities...\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Sample some papers for similarity analysis\n",
    "    sample_papers = 20\n",
    "    sample_indices = torch.randperm(num_entities)[:sample_papers]\n",
    "    sample_embeddings = entity_embeddings[sample_indices]\n",
    "    \n",
    "    # Compute pairwise cosine similarities\n",
    "    normalized_embeddings = torch.nn.functional.normalize(sample_embeddings, p=2, dim=1)\n",
    "    similarity_matrix = torch.mm(normalized_embeddings, normalized_embeddings.t())\n",
    "    \n",
    "    # Analyze similarity statistics (excluding diagonal)\n",
    "    mask = ~torch.eye(sample_papers, dtype=bool)\n",
    "    similarities = similarity_matrix[mask]\n",
    "    \n",
    "    print(f\"   Pairwise Cosine Similarities (sample of {sample_papers} papers):\")\n",
    "    print(f\"     Mean similarity: {similarities.mean().item():.4f}\")\n",
    "    print(f\"     Std similarity: {similarities.std().item():.4f}\")\n",
    "    print(f\"     Min similarity: {similarities.min().item():.4f}\")\n",
    "    print(f\"     Max similarity: {similarities.max().item():.4f}\")\n",
    "    \n",
    "    # Find most and least similar pairs\n",
    "    max_sim_idx = similarities.argmax()\n",
    "    min_sim_idx = similarities.argmin()\n",
    "    \n",
    "    # Convert back to matrix indices\n",
    "    max_i, max_j = np.unravel_index(max_sim_idx.item(), (sample_papers, sample_papers))\n",
    "    min_i, min_j = np.unravel_index(min_sim_idx.item(), (sample_papers, sample_papers))\n",
    "    \n",
    "    print(f\"\\n   üìä Similarity Analysis:\")\n",
    "    if similarities.mean().item() > 0.1:\n",
    "        print(f\"   ‚ö†Ô∏è High average similarity - embeddings may be too uniform\")\n",
    "    elif similarities.mean().item() < -0.1:\n",
    "        print(f\"   ‚ö†Ô∏è Negative average similarity - unusual pattern\")\n",
    "    else:\n",
    "        print(f\"   ‚úÖ Good similarity distribution - embeddings are diverse\")\n",
    "    \n",
    "    if similarities.std().item() > 0.2:\n",
    "        print(f\"   ‚úÖ Good similarity variance - embeddings capture differences\")\n",
    "    else:\n",
    "        print(f\"   ‚ö†Ô∏è Low similarity variance - embeddings may be too similar\")\n",
    "\n",
    "# Create embedding visualization\n",
    "print(f\"\\nüìä Creating embedding analysis visualization...\")\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "fig.suptitle('TransE Model Embedding Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Plot 1: Embedding norm distribution\n",
    "axes[0, 0].hist(entity_norms.numpy(), bins=50, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "axes[0, 0].axvline(entity_mean_norm, color='red', linestyle='--', \n",
    "                   label=f'Mean: {entity_mean_norm:.3f}')\n",
    "if MODEL_CONFIG['normalize_embeddings']:\n",
    "    axes[0, 0].axvline(1.0, color='green', linestyle='--', label='Target: 1.0')\n",
    "axes[0, 0].set_xlabel('Embedding Norm')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "axes[0, 0].set_title('Entity Embedding Norms', fontweight='bold')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Embedding value distribution\n",
    "axes[0, 1].hist(embedding_values.numpy(), bins=50, alpha=0.7, color='lightgreen', edgecolor='black')\n",
    "axes[0, 1].axvline(0, color='red', linestyle='--', label='Zero')\n",
    "axes[0, 1].set_xlabel('Embedding Values')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "axes[0, 1].set_title('Embedding Value Distribution', fontweight='bold')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Similarity matrix heatmap (sample)\n",
    "im = axes[1, 0].imshow(similarity_matrix.numpy(), cmap='coolwarm', vmin=-1, vmax=1)\n",
    "axes[1, 0].set_xlabel('Paper Index')\n",
    "axes[1, 0].set_ylabel('Paper Index')\n",
    "axes[1, 0].set_title(f'Cosine Similarity Matrix\\n(Sample of {sample_papers} papers)', fontweight='bold')\n",
    "plt.colorbar(im, ax=axes[1, 0], shrink=0.8)\n",
    "\n",
    "# Plot 4: Model statistics summary\n",
    "axes[1, 1].axis('off')\n",
    "stats_text = f\"\"\"\n",
    "üß† MODEL STATISTICS\n",
    "\n",
    "üìê Architecture:\n",
    "‚Ä¢ Entities: {num_entities:,}\n",
    "‚Ä¢ Embedding Dim: {MODEL_CONFIG['embedding_dim']}\n",
    "‚Ä¢ Total Params: {total_params:,}\n",
    "‚Ä¢ Memory: {total_params * 4 / 1024**2:.1f} MB\n",
    "\n",
    "üìä Training Results:\n",
    "‚Ä¢ Final Loss: {training_history['loss'][-1]:.4f}\n",
    "‚Ä¢ Best Loss: {best_loss:.4f}\n",
    "‚Ä¢ Epochs: {len(training_history['loss'])}\n",
    "‚Ä¢ Training Time: {total_training_time/60:.1f} min\n",
    "\n",
    "üîç Embedding Quality:\n",
    "‚Ä¢ Mean Norm: {entity_mean_norm:.3f}\n",
    "‚Ä¢ Value Range: [{embedding_values.min().item():.2f}, {embedding_values.max().item():.2f}]\n",
    "‚Ä¢ Avg Similarity: {similarities.mean().item():.3f}\n",
    "\n",
    "‚úÖ Ready for Evaluation!\n",
    "\"\"\"\n",
    "\n",
    "axes[1, 1].text(0.05, 0.95, stats_text, transform=axes[1, 1].transAxes,\n",
    "                fontsize=10, verticalalignment='top', fontfamily='monospace',\n",
    "                bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.2))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/Users/bhs/PROJECTS/academic-citation-platform/outputs/embedding_analysis.png', \n",
    "           dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ Embedding analysis completed and visualized!\")\n",
    "print(\"üìä File saved: outputs/embedding_analysis.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Save Trained Model and Metadata\n",
    "\n",
    "Finally, we'll save our trained model along with all the necessary metadata for evaluation and deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model and comprehensive metadata\n",
    "print(\"üíæ Saving trained TransE model and metadata...\")\n",
    "\n",
    "# Create models directory if it doesn't exist\n",
    "models_dir = '/Users/bhs/PROJECTS/academic-citation-platform/models'\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "\n",
    "# 1. Save the complete model state\n",
    "model_save_path = os.path.join(models_dir, 'transe_citation_model.pt')\n",
    "\n",
    "torch.save({\n",
    "    # Model state\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'model_config': MODEL_CONFIG,\n",
    "    'model_architecture': {\n",
    "        'num_entities': num_entities,\n",
    "        'num_relations': 1,\n",
    "        'embedding_dim': MODEL_CONFIG['embedding_dim'],\n",
    "        'norm_p': MODEL_CONFIG['norm_p']\n",
    "    },\n",
    "    \n",
    "    # Training state\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'training_config': TRAINING_CONFIG,\n",
    "    'data_config': DATA_CONFIG,\n",
    "    \n",
    "    # Training results\n",
    "    'training_history': training_history,\n",
    "    'final_loss': training_history['loss'][-1],\n",
    "    'best_loss': best_loss,\n",
    "    'epochs_trained': len(training_history['loss']),\n",
    "    \n",
    "    # Data information\n",
    "    'num_entities': num_entities,\n",
    "    'num_train_pos': len(train_pos_edges),\n",
    "    'num_train_neg': len(train_neg_edges),\n",
    "    'num_test_pos': len(test_pos_edges),\n",
    "    'num_test_neg': len(test_neg_edges),\n",
    "    \n",
    "    # Metadata\n",
    "    'device': str(device),\n",
    "    'pytorch_version': torch.__version__,\n",
    "    'save_timestamp': datetime.now().isoformat(),\n",
    "    'training_time_seconds': total_training_time\n",
    "    \n",
    "}, model_save_path)\n",
    "\n",
    "print(f\"‚úÖ Model saved to: {model_save_path}\")\n",
    "\n",
    "# 2. Save entity mapping for prediction\n",
    "mapping_save_path = os.path.join(models_dir, 'entity_mapping.pkl')\n",
    "with open(mapping_save_path, 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'entity_mapping': entity_mapping,\n",
    "        'reverse_mapping': reverse_mapping,\n",
    "        'num_entities': num_entities\n",
    "    }, f)\n",
    "\n",
    "print(f\"‚úÖ Entity mapping saved to: {mapping_save_path}\")\n",
    "\n",
    "# 3. Save training metadata as JSON for easy reading\n",
    "import json\n",
    "\n",
    "metadata_save_path = os.path.join(models_dir, 'training_metadata.json')\n",
    "training_metadata = {\n",
    "    'dataset': {\n",
    "        'num_papers': len(papers_data),\n",
    "        'num_citations': len(citation_data),\n",
    "        'num_entities': num_entities,\n",
    "        'train_pos_samples': len(train_pos_edges),\n",
    "        'train_neg_samples': len(train_neg_edges),\n",
    "        'test_pos_samples': len(test_pos_edges),\n",
    "        'test_neg_samples': len(test_neg_edges),\n",
    "        'total_training_samples': len(train_pos_edges) + len(train_neg_edges)\n",
    "    },\n",
    "    \n",
    "    'model_config': MODEL_CONFIG,\n",
    "    'training_config': TRAINING_CONFIG,\n",
    "    'data_config': DATA_CONFIG,\n",
    "    \n",
    "    'training_results': {\n",
    "        'epochs_completed': len(training_history['loss']),\n",
    "        'final_loss': float(training_history['loss'][-1]),\n",
    "        'best_loss': float(best_loss),\n",
    "        'loss_improvement_pct': float((training_history['loss'][0] - training_history['loss'][-1]) / training_history['loss'][0] * 100),\n",
    "        'total_training_time_minutes': float(total_training_time / 60),\n",
    "        'avg_epoch_time_seconds': float(np.mean(training_history['epoch_times'])),\n",
    "        'converged': bool(np.var(training_history['loss'][-10:]) < 0.0001)\n",
    "    },\n",
    "    \n",
    "    'model_stats': {\n",
    "        'total_parameters': int(sum(p.numel() for p in model.parameters())),\n",
    "        'entity_embedding_shape': list(model.entity_embeddings.weight.shape),\n",
    "        'relation_embedding_shape': list(model.relation_embeddings.weight.shape),\n",
    "        'memory_usage_mb': float(sum(p.numel() for p in model.parameters()) * 4 / 1024**2)\n",
    "    },\n",
    "    \n",
    "    'system_info': {\n",
    "        'device': str(device),\n",
    "        'pytorch_version': torch.__version__,\n",
    "        'python_version': sys.version.split()[0],\n",
    "        'training_date': datetime.now().isoformat()\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(metadata_save_path, 'w') as f:\n",
    "    json.dump(training_metadata, f, indent=2)\n",
    "\n",
    "print(f\"‚úÖ Training metadata saved to: {metadata_save_path}\")\n",
    "\n",
    "# 4. Save test data for evaluation\n",
    "test_data_save_path = os.path.join(models_dir, 'test_data.pkl')\n",
    "with open(test_data_save_path, 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'test_pos_edges': test_pos_edges.cpu(),\n",
    "        'test_neg_edges': test_neg_edges.cpu(),\n",
    "        'train_pos_edges': train_pos_edges.cpu(),  # For reference\n",
    "        'train_neg_edges': train_neg_edges.cpu()   # For reference\n",
    "    }, f)\n",
    "\n",
    "print(f\"‚úÖ Test data saved to: {test_data_save_path}\")\n",
    "\n",
    "# 5. Create a model loading utility function\n",
    "def load_trained_model(model_path, device='cpu'):\n",
    "    \"\"\"\n",
    "    Utility function to load the trained TransE model.\n",
    "    \n",
    "    Args:\n",
    "        model_path: Path to the saved model file\n",
    "        device: Device to load the model on\n",
    "    \n",
    "    Returns:\n",
    "        Loaded TransE model and metadata\n",
    "    \"\"\"\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    \n",
    "    # Recreate model\n",
    "    arch = checkpoint['model_architecture']\n",
    "    model = TransE(\n",
    "        num_entities=arch['num_entities'],\n",
    "        num_relations=arch['num_relations'],\n",
    "        embedding_dim=arch['embedding_dim'],\n",
    "        norm_p=arch['norm_p']\n",
    "    ).to(device)\n",
    "    \n",
    "    # Load state\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    return model, checkpoint\n",
    "\n",
    "# Save the loader function documentation\n",
    "loader_doc_path = os.path.join(models_dir, 'model_loading_instructions.txt')\n",
    "with open(loader_doc_path, 'w') as f:\n",
    "    f.write(f\"\"\"\n",
    "TransE Citation Model - Loading Instructions\n",
    "==========================================\n",
    "\n",
    "Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "\n",
    "Files in this directory:\n",
    "- transe_citation_model.pt: Complete model checkpoint with training state\n",
    "- entity_mapping.pkl: Paper ID to entity index mapping\n",
    "- training_metadata.json: Human-readable training statistics\n",
    "- test_data.pkl: Test data for evaluation\n",
    "- model_loading_instructions.txt: This file\n",
    "\n",
    "Quick Loading Example:\n",
    "```python\n",
    "import torch\n",
    "import pickle\n",
    "\n",
    "# Load model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "checkpoint = torch.load('transe_citation_model.pt', map_location=device)\n",
    "\n",
    "# Recreate model architecture\n",
    "from your_model_file import TransE\n",
    "arch = checkpoint['model_architecture']\n",
    "model = TransE(**arch).to(device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "# Load mappings\n",
    "with open('entity_mapping.pkl', 'rb') as f:\n",
    "    mappings = pickle.load(f)\n",
    "    entity_mapping = mappings['entity_mapping']\n",
    "```\n",
    "\n",
    "Model Statistics:\n",
    "- Entities: {num_entities:,}\n",
    "- Embedding Dimension: {MODEL_CONFIG['embedding_dim']}\n",
    "- Total Parameters: {sum(p.numel() for p in model.parameters()):,}\n",
    "- Final Training Loss: {training_history['loss'][-1]:.6f}\n",
    "- Training Time: {total_training_time/60:.1f} minutes\n",
    "\n",
    "Next Steps:\n",
    "1. Run 03_prediction_evaluation.ipynb for comprehensive evaluation\n",
    "2. Use model for citation prediction and recommendation\n",
    "3. Generate embeddings for downstream tasks\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "print(f\"‚úÖ Loading instructions saved to: {loader_doc_path}\")\n",
    "\n",
    "# Display save summary\n",
    "print(f\"\\nüìÅ Model Save Summary:\")\n",
    "print(f\"   üì¶ Complete model: {os.path.basename(model_save_path)}\")\n",
    "print(f\"   üó∫Ô∏è Entity mapping: {os.path.basename(mapping_save_path)}\")\n",
    "print(f\"   üìä Training metadata: {os.path.basename(metadata_save_path)}\")\n",
    "print(f\"   üß™ Test data: {os.path.basename(test_data_save_path)}\")\n",
    "print(f\"   üìñ Instructions: {os.path.basename(loader_doc_path)}\")\n",
    "\n",
    "# Calculate file sizes\n",
    "model_size_mb = os.path.getsize(model_save_path) / 1024**2\n",
    "mapping_size_kb = os.path.getsize(mapping_save_path) / 1024\n",
    "test_data_size_mb = os.path.getsize(test_data_save_path) / 1024**2\n",
    "\n",
    "print(f\"\\nüíæ File Sizes:\")\n",
    "print(f\"   Model checkpoint: {model_size_mb:.1f} MB\")\n",
    "print(f\"   Entity mapping: {mapping_size_kb:.1f} KB\")\n",
    "print(f\"   Test data: {test_data_size_mb:.1f} MB\")\n",
    "print(f\"   Total: {model_size_mb + mapping_size_kb/1024 + test_data_size_mb:.1f} MB\")\n",
    "\n",
    "print(f\"\\nüéØ Model successfully saved and ready for evaluation!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Pipeline Summary\n",
    "\n",
    "Congratulations! We have successfully completed the TransE model training pipeline. Let's summarize what we've accomplished and prepare for the next phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comprehensive training pipeline summary\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üéì TRANSE MODEL TRAINING PIPELINE COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nüìä Dataset Processing Summary:\")\n",
    "print(f\"   Papers processed: {len(papers_data):,}\")\n",
    "print(f\"   Citation relationships: {len(citation_data):,}\")\n",
    "print(f\"   Entity vocabulary: {num_entities:,}\")\n",
    "print(f\"   Train/test split: {100*(1-DATA_CONFIG['test_size']):.0f}%/{DATA_CONFIG['test_size']*100:.0f}%\")\n",
    "print(f\"   Negative sampling ratio: 1:{DATA_CONFIG['negative_ratio']}\")\n",
    "print(f\"   Total training samples: {len(train_pos_edges) + len(train_neg_edges):,}\")\n",
    "\n",
    "print(f\"\\nüß† Model Architecture:\")\n",
    "print(f\"   TransE with {MODEL_CONFIG['embedding_dim']}-dimensional embeddings\")\n",
    "print(f\"   Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"   Memory footprint: {sum(p.numel() for p in model.parameters()) * 4 / 1024**2:.1f} MB\")\n",
    "print(f\"   Distance norm: L{MODEL_CONFIG['norm_p']}\")\n",
    "print(f\"   Margin ranking loss with margin: {MODEL_CONFIG['margin']}\")\n",
    "\n",
    "print(f\"\\n‚öôÔ∏è Training Configuration:\")\n",
    "print(f\"   Epochs completed: {len(training_history['loss'])} / {TRAINING_CONFIG['epochs']}\")\n",
    "print(f\"   Batch size: {TRAINING_CONFIG['batch_size']}\")\n",
    "print(f\"   Learning rate: {MODEL_CONFIG['learning_rate']}\")\n",
    "print(f\"   L2 regularization: {MODEL_CONFIG['l2_regularization']}\")\n",
    "print(f\"   Device: {device}\")\n",
    "\n",
    "print(f\"\\nüìà Training Results:\")\n",
    "improvement_pct = (training_history['loss'][0] - training_history['loss'][-1]) / training_history['loss'][0] * 100\n",
    "print(f\"   Initial loss: {training_history['loss'][0]:.6f}\")\n",
    "print(f\"   Final loss: {training_history['loss'][-1]:.6f}\")\n",
    "print(f\"   Best loss: {best_loss:.6f}\")\n",
    "print(f\"   Loss improvement: {improvement_pct:.1f}%\")\n",
    "print(f\"   Training time: {total_training_time/60:.1f} minutes\")\n",
    "print(f\"   Average time per epoch: {np.mean(training_history['epoch_times']):.2f} seconds\")\n",
    "\n",
    "print(f\"\\nüîç Model Validation Results:\")\n",
    "if 'pos_mean' in locals() and 'neg_mean' in locals():\n",
    "    print(f\"   Positive citation scores: {pos_mean:.4f} ¬± {pos_std:.4f}\")\n",
    "    print(f\"   Negative citation scores: {neg_mean:.4f} ¬± {neg_std:.4f}\")\n",
    "    print(f\"   Score separation: {score_separation:.4f}\")\n",
    "    print(f\"   Ranking accuracy: {ranking_accuracy:.1%}\")\n",
    "    \n",
    "    if 'test_accuracy' in locals():\n",
    "        print(f\"   Test set accuracy: {test_accuracy:.1%}\")\n",
    "        print(f\"   Generalization gap: {abs(ranking_accuracy - test_accuracy):.3f}\")\n",
    "\n",
    "print(f\"\\nüî¨ Embedding Quality:\")\n",
    "if 'entity_mean_norm' in locals():\n",
    "    print(f\"   Entity embedding mean norm: {entity_mean_norm:.4f} ¬± {entity_std_norm:.4f}\")\n",
    "    print(f\"   Relation embedding norm: {relation_norm:.4f}\")\n",
    "    print(f\"   Embedding value range: [{embedding_values.min().item():.3f}, {embedding_values.max().item():.3f}]\")\n",
    "    print(f\"   Average cosine similarity: {similarities.mean().item():.4f}\")\n",
    "\n",
    "print(f\"\\nüíæ Saved Artifacts:\")\n",
    "print(f\"   üì¶ Complete model checkpoint: models/transe_citation_model.pt\")\n",
    "print(f\"   üó∫Ô∏è Entity mappings: models/entity_mapping.pkl\")\n",
    "print(f\"   üìä Training metadata: models/training_metadata.json\")\n",
    "print(f\"   üß™ Test data: models/test_data.pkl\")\n",
    "print(f\"   üìä Training visualizations: outputs/training_progress.png\")\n",
    "print(f\"   üî¨ Embedding analysis: outputs/embedding_analysis.png\")\n",
    "\n",
    "print(f\"\\nüí° Key Insights:\")\n",
    "\n",
    "# Training quality assessment\n",
    "if improvement_pct > 50:\n",
    "    print(f\"   ‚Ä¢ Excellent training convergence ({improvement_pct:.1f}% loss reduction)\")\n",
    "elif improvement_pct > 20:\n",
    "    print(f\"   ‚Ä¢ Good training progress ({improvement_pct:.1f}% loss reduction)\")\n",
    "else:\n",
    "    print(f\"   ‚Ä¢ Limited training progress ({improvement_pct:.1f}% loss reduction)\")\n",
    "\n",
    "# Embedding quality assessment  \n",
    "if 'entity_mean_norm' in locals():\n",
    "    if MODEL_CONFIG['normalize_embeddings'] and 0.9 < entity_mean_norm < 1.1:\n",
    "        print(f\"   ‚Ä¢ Well-normalized embeddings (norm ‚âà 1.0)\")\n",
    "    elif not MODEL_CONFIG['normalize_embeddings']:\n",
    "        print(f\"   ‚Ä¢ Embeddings learned natural scaling\")\n",
    "\n",
    "# Model learning assessment\n",
    "if 'ranking_accuracy' in locals():\n",
    "    if ranking_accuracy > 0.8:\n",
    "        print(f\"   ‚Ä¢ Excellent citation pattern learning ({ranking_accuracy:.1%} accuracy)\")\n",
    "    elif ranking_accuracy > 0.6:\n",
    "        print(f\"   ‚Ä¢ Good citation pattern learning ({ranking_accuracy:.1%} accuracy)\")\n",
    "    else:\n",
    "        print(f\"   ‚Ä¢ Basic citation pattern learning ({ranking_accuracy:.1%} accuracy)\")\n",
    "\n",
    "# Scale assessment\n",
    "print(f\"   ‚Ä¢ Model scale appropriate for {num_entities:,} entities\")\n",
    "print(f\"   ‚Ä¢ Training completed efficiently in {total_training_time/60:.1f} minutes\")\n",
    "\n",
    "print(f\"\\nüéØ Model Readiness Assessment:\")\n",
    "readiness_score = 0\n",
    "\n",
    "# Check various readiness criteria\n",
    "if improvement_pct > 20:\n",
    "    readiness_score += 25\n",
    "    print(f\"   ‚úÖ Loss convergence: Good ({improvement_pct:.1f}% improvement)\")\n",
    "else:\n",
    "    print(f\"   ‚ö†Ô∏è Loss convergence: Limited ({improvement_pct:.1f}% improvement)\")\n",
    "\n",
    "if 'ranking_accuracy' in locals() and ranking_accuracy > 0.6:\n",
    "    readiness_score += 25\n",
    "    print(f\"   ‚úÖ Learning validation: Passed ({ranking_accuracy:.1%} accuracy)\")\n",
    "else:\n",
    "    print(f\"   ‚ö†Ô∏è Learning validation: Needs improvement\")\n",
    "\n",
    "if 'entity_mean_norm' in locals() and 0.5 < entity_mean_norm < 2.0:\n",
    "    readiness_score += 25\n",
    "    print(f\"   ‚úÖ Embedding quality: Good (norm = {entity_mean_norm:.3f})\")\n",
    "else:\n",
    "    print(f\"   ‚ö†Ô∏è Embedding quality: Check needed\")\n",
    "\n",
    "readiness_score += 25  # Model saved successfully\n",
    "print(f\"   ‚úÖ Model persistence: Complete\")\n",
    "\n",
    "print(f\"\\nüèÜ Overall Readiness Score: {readiness_score}/100\")\n",
    "\n",
    "if readiness_score >= 75:\n",
    "    print(f\"   ‚úÖ Model is ready for comprehensive evaluation!\")\n",
    "elif readiness_score >= 50:\n",
    "    print(f\"   ‚ö†Ô∏è Model is functional but may benefit from hyperparameter tuning\")\n",
    "else:\n",
    "    print(f\"   ‚ùå Model needs significant improvements before evaluation\")\n",
    "\n",
    "print(f\"\\nüöÄ Next Steps:\")\n",
    "print(f\"   1. Run 03_prediction_evaluation.ipynb for comprehensive evaluation\")\n",
    "print(f\"   2. Calculate MRR, Hits@K, and AUC metrics\")\n",
    "print(f\"   3. Generate missing citation predictions\")\n",
    "print(f\"   4. Create evaluation visualizations\")\n",
    "print(f\"   5. Proceed to narrative presentation (04_narrative_presentation.ipynb)\")\n",
    "\n",
    "print(f\"\\n‚úÖ TransE model training pipeline completed successfully!\")\n",
    "print(f\"üéì Ready for evaluation phase at {datetime.now()}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "# Clean up GPU memory if used\n",
    "if device.type == 'cuda':\n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"üßπ GPU memory cleared\")\n",
    "\n",
    "print(\"üèÅ Training pipeline complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}