[{"paperId":"0000347079f85a435badfc92a8adcad5db064c21","title":"Semantic metadata application for information resources systematization in water spectroscopy","abstract":"The information and knowledge layers of information-computational system for water spectroscopy are described.Semantic metadata for all the tasks of domain information model that are the basis of the layers have been studied.The principle of semantic metadata determination and mechanisms of the usage during information systematizationin molecular spectroscopy has been revealed. The software developed for the work with semantic metadata isdescribed as well.Formation of domain model in the framework of Semantic Web is based on the use of explicit speci\ufb01cation ofits conceptualization or, in other words, its ontologies. Formation of conceptualization for molecular spectroscopywas described in Refs. 1, 2. In these works two chains of task are selected for zeroth approximation for knowledgedomain description. These are direct tasks chain and inverse tasks chain. Solution schemes of these tasks de\ufb01nedapproximation of data layer for knowledge domain conceptualization. Spectroscopy tasks solutions properties leadto a step-by-step extension of molecular spectroscopy conceptualization. Information layer of information systemcorresponds to this extension.An advantage of molecular spectroscopy model designed in a form of tasks chain is actualized in the fact thatone can explicitly de\ufb01ne data and metadata at each step of solution of these molecular spectroscopy chain tasks.Metadata structure (tasks solutions properties) in knowledge domain also has form of a chain in which input dataand metadata of the previous task become metadata of the following tasks. The term metadata is used in its narrowsense: metadata are the properties of spectroscopy tasks solutions. Semantic metadata represented with the help ofOWL","venue":"","year":2009.0,"referenceCount":3,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"2285905940","name":"A. Fazliev"},{"authorId":"2285934365","name":"Sb Ras"}]},{"paperId":"0001a990b8268dbb9fa5e3461f5f62f5f13ead76","title":"Web-Based Learning Under Tacit Mining of Various Data Sources","abstract":"Nowadays, many platforms provide open educational resources to learners. So, they must browse and explore several suggested contents to better assimilate their courses. To facilitate the selecting task of these resources, the present paper proposes an intelligent tutoring system that can access teaching contents available on the web automatically and offers them to learners as additional information sources. In doing so, the authors highlight the description logic approach and its knowledge representation strength that underwrites the modulization, inference, and querying about a web ontology language, and enhanced traditional tutoring systems architecture using ontologies and description logic to enable them to access various data sources on the web. Finally, this article concludes that the combination of machine learning with the semantic web has provided a supportive study environment and enhanced the schooling conditions within open and distance learning.","venue":"International Journal of Emerging Technologies in Learning (iJET)","year":2021.0,"referenceCount":23,"citationCount":5,"fieldsOfStudy":["Computer Science"],"publicationDate":"2021-08-23","authors":[{"authorId":"1829777","name":"Abdelouahab Belazoui"},{"authorId":"31782512","name":"Abdelmoutia Telli"},{"authorId":"40442909","name":"C. Arar"}]},{"paperId":"0003382abd557070c5073adbcc944c0bfd7abb54","title":"The Challenges of Linked Open Data Semantic Enrichment, Discovery, and Dissemination (GRID)","abstract":null,"venue":"Physics of particles and nuclei","year":2024.0,"referenceCount":2,"citationCount":0,"fieldsOfStudy":null,"publicationDate":"2024-06-01","authors":[{"authorId":"2101187561","name":"Yurii Akatkin"},{"authorId":"8509498","name":"E. Yasinovskaya"},{"authorId":"47381189","name":"M. Bich"},{"authorId":"2304957796","name":"A. Shilin"}]},{"paperId":"00070f34910934c03888b7cb7f2391d4d339011e","title":"Data Providing Services Clustering and Management for Facilitating Service Discovery and Replacement","abstract":"In service-oriented computing, a user usually needs to locate a desired service for: (i) fulfilling her requirements or (ii) replacing a service, which disappears or is unavailable for some reasons, to perform an interaction. With the increasing number of services available within an enterprise and over the Internet, locating a service online may not be appropriate from the performance perspective, especially in large Internet-based service repositories. Instead, services usually need to be clustered according to their similarity. Thereafter, services in one or several clusters are necessary to be examined online during dynamic service discovery. In this paper, we propose to cluster data providing (DP) services using a refined fuzzy C-means algorithm. We consider the composite relation between DP service elements (i.e., input, output, and semantic relation between them) when representing DP services in terms of vectors. A DP service vector is assigned to one or multiple clusters with certain degrees. In addition, we introduce some operations for managing service clusters, when new services emerge or existing services disappear or become unavailable. When grouping similar services into one cluster, while partitioning different services into different clusters, the capability of service search engine is improved significantly. We have prototyped our approach and the source code is freely available on the web. We have evaluated our clustering approach in different settings and the results are very promising.","venue":"IEEE Transactions on Automation Science and Engineering","year":2013.0,"referenceCount":74,"citationCount":63,"fieldsOfStudy":["Computer Science"],"publicationDate":"2013-01-28","authors":[{"authorId":"8525897","name":"Zhangbing Zhou"},{"authorId":"144087499","name":"M. Sellami"},{"authorId":"1762930","name":"Walid Gaaloul"},{"authorId":"3293164","name":"M. Barhamgi"},{"authorId":"3009931","name":"Bruno Defude"}]},{"paperId":"00072e17c6b7938b3a0d0572d42d37baa978a053","title":"Exploiting Semantic Web Technologies in the Management of a Smart Classroom","abstract":"Interactive systems have been among the prevailing computing paradigms of recent years. After a lot of research in this eld, implicit human computer interaction is growing. It takes the user context into account when creating new applications for ambient intelligence. Context and context-awareness are central issues to ambient intelligence. The use of context information in interactive systems o ers new possibilities to adapt applications and systems to the current situation \"on-they\". In this thesis, we present the management system of a university smart classroom based on semantic web technologies. This work constitutes a real-time, context-aware system, applied in a smart classroom domain, which aims to assist its users after recognizing occurring activities. We have designed and developed several ontologies that capture and formally describe user pro les, context information and learning material information. Rule-based reasoning is applied for the elaboration of the stored knowledge and an existing recognition system undertakes to identify the current activity by exploiting the reasoning result. After the activity recognition, rules are responsible for the assistance of the activity. We describe an overview of our system as well as typical usage scenarios to indicate how our system would react in these situations. Depending on the current activity the system will provide di erent type of assistance to its users. Assistance consists of modifying the status of the devices that are located in the classroom or supplying the students with learning material. A live demonstration of our system with real users into a smart space is described in the end of this thesis. Supervisor: Dimitris Plexousakis Professor","venue":"","year":2012.0,"referenceCount":17,"citationCount":0,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"2234229","name":"Maria Koutraki"}]},{"paperId":"00075b6719540585dbd85057d11f114594c36f73","title":"News","abstract":null,"venue":"Botanical Gazette","year":1897.0,"referenceCount":1,"citationCount":0,"fieldsOfStudy":["Computer Science","Medicine"],"publicationDate":"1897-09-01","authors":[{"authorId":"2064260103","name":"Antonio Kr\u00fcger"}]},{"paperId":"000797009bb90802671dab18f71887b6d0143598","title":"An Enforcement Architecture for Security and Trust Policies in Federated Web-Service-Based Systems","abstract":"In policy-based management, the gap between policy definition and enforcement mechanisms needs an architectural innovation to fill. Policy-based trust management has this gap too. Enforcement of policies for federation activities, especially trust policies among web-service-based systems, requires a dynamic and flexible architecture to accommodate different trust models and different domains. Meanwhile, the choice of high-level policy languages cannot have an exact match to low-level enforcement mechanisms in network services or operating systems. An intermediate-level semantic translation architecture is proposed in this paper to bridge the gap between high-level policy languages used directly by humans and low-level mechanisms offered by machines. The merits of this architecture include: users can choose their high-level policy languages with the most usability they want; the system administrator can introduce a new core mathematical or logical model when it is more appropriate for system controls; the semantic translation in the intermediate-level is flexible.","venue":"2009 33rd Annual IEEE International Computer Software and Applications Conference","year":2009.0,"referenceCount":18,"citationCount":2,"fieldsOfStudy":["Computer Science"],"publicationDate":"2009-07-20","authors":[{"authorId":"35348117","name":"Zhengping Wu"},{"authorId":"2108573679","name":"Lifeng Wang"}]},{"paperId":"00081d576cb772cc680d2621a4278ea2fce48f31","title":"Text Summarization Based on Conceptual Data Classification","abstract":"In this article, we present an original approach for text summarization using conceptual data classification. We show how a given text can be summarized without losing meaningful knowledge and without using any semantic or grammatical concepts. In fact, concept date classification is used to extract the most interacting sentences from the main text and ignoring the other meaningless sentences in order to generate the text summary. The approach is tested on Arabic and English texts with different sizes and different topics and the obtained results are satisfactory. The system may be incorporated with the indexers of search engines over the Internet in order to find key words and other pertinent information of the new deployed Web pages that would be stored in databases for quick search.","venue":"International Journal of Information Technology and Web Engineering","year":2006.0,"referenceCount":1,"citationCount":34,"fieldsOfStudy":["Computer Science"],"publicationDate":"2006-10-01","authors":[{"authorId":"9306890","name":"J. Jaam"},{"authorId":"144502997","name":"A. Jaoua"},{"authorId":"2528543","name":"A. Hasnah"},{"authorId":"2058712437","name":"Fatma Hassan"},{"authorId":"146914693","name":"H. Mohamed"},{"authorId":"2712150","name":"Tahani Mosaid"},{"authorId":"2059406442","name":"H. Saleh"},{"authorId":"122387572","name":"F. Abdullah"},{"authorId":"143629061","name":"Hassan Cherif"}]},{"paperId":"00088986c30f3b32724562d84b4e9be87262bc21","title":"Reasoning support for Semantic Web ontology family languages using Alloy","abstract":"Semantic Web (SW), commonly regarded as the next generation of the Web, is an emerging vision of the new Web from the Knowledge Representation and the Web communities. To realize this vision, a series of techniques has been proposed. Semantic Web Ontology Langauge (OWL) and its extension Semantic Web rule Language (SWRL) and Semantic Web Logic Language (SWRL-FOL) are some of the most important outputs from the SW activities. However the existing reasoning and consistency checking tools for those languages are primitive. This paper proposes using the existing formal modelling tool, in particular Alloy, to provide an automatic reasoning service for the Semantic Web ontology family languages (OWL\/SWRL\/SWRL-FOL).","venue":"Multiagent and Grid Systems","year":2006.0,"referenceCount":24,"citationCount":26,"fieldsOfStudy":["Computer Science"],"publicationDate":"2006-07-01","authors":[{"authorId":"2113221282","name":"Hai H. Wang"},{"authorId":"50812829","name":"J. Dong"},{"authorId":"2157280262","name":"Jing Sun"},{"authorId":"2155020491","name":"Jun Sun"}]},{"paperId":"00088c52857a4260651b82ba3f4bbb91a6548b48","title":"Introduction to the REA 25th Anniversary Special Section","abstract":"The article discusses various reports published within the issue, including one by Frederik Gailly, Wim Laurier, and Geert Poels on the Resource-Event-Agent (REA) model, another by Tod Sedbrook and Richard I. Newmark on automation in the REA model, and one by A. Faye Borthick, Paul L. Bowen, and Gregory J. Gerard on the use of the REA model in semantic web technologies.","venue":"The Journal of Information Systems","year":2008.0,"referenceCount":3,"citationCount":4,"fieldsOfStudy":["Engineering","Computer Science"],"publicationDate":"2008-09-01","authors":[{"authorId":"6296153","name":"G. Geerts"}]},{"paperId":"00096727b2786ed788eda99cb8564d664856d983","title":"A Decision-making Format for the Semantic Web","abstract":"This paper describes the work of the W3C Decisions and Decision-making Incubator, with the goal to identify requirements for a standard decision format, through a set of use cases, and to develop a first version of a potential standard format for representing decisions, fulfilling the requirements of the use cases and exploiting semantic web standards. Ongoing efforts include the identification and modelling of 'decision patterns' and development of proof-of-concept applications to validate assumptions and patterns.","venue":"WOP","year":2010.0,"referenceCount":8,"citationCount":4,"fieldsOfStudy":["Computer Science"],"publicationDate":"2010-11-08","authors":[{"authorId":"2456849","name":"E. Blomqvist"},{"authorId":"34683863","name":"M. Ceruti"},{"authorId":"10123406","name":"J. Waters"},{"authorId":"2268927","name":"D. McGarry"}]},{"paperId":"0009a571564087323a898b3288e3a7195a7f4bee","title":"Best Practice in Advanced Enterprise Knowledge Engineering","abstract":null,"venue":"International Conference on Information Technology & Systems","year":2018.0,"referenceCount":13,"citationCount":1,"fieldsOfStudy":["Computer Science"],"publicationDate":"2018-01-10","authors":[{"authorId":"3470935","name":"M. Sagratella"},{"authorId":"3331240","name":"A. Polzonetti"}]},{"paperId":"0009adbb06a843d9bfe2d0f21ad2d0ba5631ef75","title":"Metadatenmanagement mit einem Semantischen Wiki","abstract":"Das Semantic Web kann ein konzernweites Metadatenmanagement unterstutzen und somit zur Schaffung benotigter Transparenz beitragen. Eine Kombination von Semantic Web und Wiki-Technologie kann den Aufwand der Metadatenerfassung reduzieren und gleichzeitig die Nutzbarkeit erfasster Informationen erhohen.","venue":"","year":2008.0,"referenceCount":0,"citationCount":3,"fieldsOfStudy":["Computer Science"],"publicationDate":"2008-06-01","authors":[{"authorId":"2095398983","name":"Kai M. H\u00fcner"},{"authorId":"2060834356","name":"Boris Otto"},{"authorId":"121113523","name":"H. Oesterle"}]},{"paperId":"000c017e2542a98c44e19fbbd48079825ebf2d85","title":"The Relation Extraction Problem 3.1. Approach","abstract":"This chapter first defines the problem of relation extraction and then present the solution proposed. Section 4.1 gives a formal description of the approach applied in this dissertation. Then, Section 4.2 states the formal definition of the problem discussed in this dissertation. Finally, Section 4.3 discusses the features used to build the multi-class classifier for relation extraction. The approach we propose is based on that used by Mintz et al. (2009). This approach, called distant supervision, is a heuristic that automatically labels the relation between annotated entities on sentences based on a database relation. In this dissertation, the heuristically labeled dataset is used for the computation of relation extractors. Our approach uses a dataset T containing triples ti = (e1, ri, e2), where e1 and e2 are entities and ri is a relation. In our architecture, this dataset is extracted from Semantic Web resources. Consider an ontology O defined by a set of triples. We define the set T \u2286 O such that a triple ti =(e1, ri, e2) is in T iff ri is an object property and (e1, rdf:type, K1) and (e2, rdf:type, K2) are triples in O, where K1 and K2 are classes of O. In our approach, we use triples from T to heuristically label sentences based on the annotated entities. Consider a text corpus C = (s1, ... ,sn) constituted by n sentences. We also consider that every sentence is annotated with two entities defined in O. Suppose that a sentence sj is annotated with entities e1 and e2. If there is a triple (e1, ri, e2) in T, the sentence sj is heuristically labeled as an example of the relation ri.","venue":"","year":null,"referenceCount":0,"citationCount":0,"fieldsOfStudy":null,"publicationDate":null,"authors":[]},{"paperId":"000d6c6b8cdc4cc6bdea30df6fcd5fa075a3fe25","title":"A New Approach to Model OWL-S Services Operational Semantic with Petri Nets","abstract":"Putting forward a new approach to model OWL-S based semantic web services operational semantic with petri nets,selecting dynamic description logic actions theory as the logical foundation of semantic web services. Firstly,a OWL-S atomic process can be modeled as a dynamic description logic action,which combines the dynamic execution and static reasoning of related execution conditions of services;and then,using petri nets and dynamic description logic actions theory to model operational semantics of OWL-S services processes,especially composite processes,provides a more effective logical approach to study auto-composition and dynamic properties analysis of semantic web services.","venue":"","year":2007.0,"referenceCount":0,"citationCount":1,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"9290340","name":"Du Yu-yue"}]},{"paperId":"000da535ae7b8f02ee718d781a369ba33197b9fd","title":"ICCNIT 2011","abstract":"ICCNIT 2011 is the first effort by the Department of Computer Science, University of Peshawar, to provide a platform for discussion from different but related fields of computer science. ICCNIT has attracted researchers from diverse communities such as Computer Networks, Wireless Networks, Computer Engineering, Image Processing, Multimedia Contents, Databases, Natural Language Processing, Semantic Web and Software Engineering to facilitate a close coordinated interaction and knowledge sharing among them.","venue":"International Conference on Computer Networks and Information Technology","year":2011.0,"referenceCount":0,"citationCount":0,"fieldsOfStudy":null,"publicationDate":null,"authors":[]},{"paperId":"000e8fb99816b33640724a383fb37a60b6fee691","title":"Living in a Transparent Future: Search in a Wired World","abstract":"A BSTRACT . We present and discuss a likely future world in which advances in search and the wiring of our environment would provide us with ready access to much information. We outline the current status of search and the goals of the semantic web. We argue that much of the information already in electronic format will likely be made accessible through the web. We present a likely future scenario of a wired world, a world in which entities as simple as a bottle of pills to as complex as the human body are wired to the web. This adds much additional information to the web, information that by-and-large is currently not gathered in electronic format. We present and discuss three representative cases which highlight the benefits and drawbacks of ready access to information pertaining to individuals. We suggest that the future scenarios are not too far off in the making and suggest that a dialogue be started, attempting to develop enforceable privacy policies.","venue":"","year":2014.0,"referenceCount":16,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"2787228","name":"M. Wollowski"}]},{"paperId":"00112addbb19d89e1a354ea3c1356f6e2a0c7a29","title":"Image Annotation with Weak Labels","abstract":null,"venue":"Interational Conference on Web-Age Information Management","year":2013.0,"referenceCount":10,"citationCount":6,"fieldsOfStudy":["Computer Science"],"publicationDate":"2013-06-14","authors":[{"authorId":"2052643446","name":"Feng Tian"},{"authorId":"1749881","name":"Xukun Shen"}]},{"paperId":"001206eff933e814c05c15fa831e275635b934ed","title":"Web Mining: From Web to Semantic Web, First European Web Mining Forum, EMWF 2003, Cavtat-Dubrovnik, Croatia, September 22, 2003, Revised Selected and Invited Papers","abstract":"Reading a book is also kind of better solution when you have no enough money or time to get your own adventure. This is one of the reasons we show the web mining from web to semantic web first european web mining forum emwf 2003 cavtat dubrovnik croatia september 22 2003 revised selected and invited papers as your friend in spending the time. For more representative collections, this book not only offers it's strategically book resource. It can be a good friend, really good friend with much knowledge.","venue":"","year":2004.0,"referenceCount":0,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[]},{"paperId":"00132a74aab8cd355de1dfe2c5138ca2e43e1194","title":"Formal Descriptive Mechanism of the Ontology Language RDF","abstract":"This work illustrates the architecture of semantic Web and data model of RDF, and elaborates on RDF's formal system, whose descriptive mechanism is demonstrated with two examples, including the formalization of relational calculus and logic inference. In the end, it concludes that RDF is a formal specification method, which is a binary relation.","venue":"International Conference on Management of e-Commerce and e-Government","year":2008.0,"referenceCount":9,"citationCount":1,"fieldsOfStudy":["Computer Science"],"publicationDate":"2008-10-17","authors":[{"authorId":"2072822133","name":"Zhongsheng Qian"}]},{"paperId":"00138e9ad0ad20f05a476b2c70cabfade169cff3","title":"Gera\u00e7\u00e3o autom\u00e1tica de ontologias para a web sem\u00e2ntica","abstract":"The current Semantic Web specifications provide the necessary support for a broad range of applications. Most of these applications require direct or indirect ontology handling. Therefore the ontologies play a crucial role in the universe of the Semantic Web, working trustful sources of knowledge, from which one can establish and validate relationships between conceptual elements related to applications. The task of developing an ontology is not trivial, as it requires the work of people with reasonable degree of knowledge in the considered application field. In the Web \u0301s context, this task becomes more difficult due to the large dynamism in the generation of content related to the applications. This work describes a process and a prototype to automatically obtain ontologies through the combination of grammatical elements present in texts written in Portuguese language, allowing the merge to preexisting ontologies. The idea is to start from the syntactic analysis of Web texts, where the tool structures the elements using a syntactical analyser (PALAVRAS) and a basic Portuguese language ontology to associate to definitions found in preexisting ontologies. The resulting ontology is a useful artifact to the Semantic Web, once it reflects the original syntactic structure of the texts from different perspectives of concept relationships, which are allowed by the preexisting ontologies merged to the preliminar ontology.","venue":"","year":2010.0,"referenceCount":91,"citationCount":2,"fieldsOfStudy":["Philosophy"],"publicationDate":"2010-03-05","authors":[{"authorId":"2064658457","name":"Carlos de Oliveira Bravo"}]},{"paperId":"0016fa2c28aeb98abd725103284513099adae970","title":"Semantic Integration of Power Information System Based on Ontology","abstract":"Based on semantic web and ontology, a new information integration system named EOSIS is proposed for the semantic link- ing and inference of power enterprise information, involving business requirements, integration methods and system architecture of EOSIS. Compared to current integration systems, this system supports multi-dimensional information association of conceptions or ob-jects, inference of tacit knowledge based on ontology conception, dynamic insertion of new concepts or facts coming with business change.","venue":"","year":2007.0,"referenceCount":0,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"2196937","name":"Z. Yang"}]},{"paperId":"00175a4e9077058e6a4432050e3acbcdd3bacc94","title":"Research on Chinese-English Hybrid Rhetorical Question Recognition Model and Corpus Construction of Intelligent Web Text","abstract":"With the popularity of English in China, Chinese-English mixed rhetorical question has become a common expression in China. Mixed Chinese-English rhetorical questions have rich emotional overtones, and if they can be correctly identified, they improve the results of sentiment analysis and other tasks. Using semi-supervised learning and active learning methods, a semi-automatic collection of the rhetorical corpus is proposed to construct a Chinese-English rhetorical corpus of web text. Based on the corpus, the characteristics of Chinese-English mixed rhetorical questions are analyzed from the aspects of semantic features, positional features, and syntactic path features to carry out a rhetorical question recognition experiment. Experimental results show that the rhetorical question corpus constructed from online texts trains a rhetorical question recognition model with high performance, and the accuracy, recall, and F1 values of the model are higher than 90%. At the same time, the experimental results verify the effectiveness of syntactic path features and location features in identifying rhetorical questions.","venue":"2022 IEEE 4th Eurasia Conference on IOT, Communication and Engineering (ECICE)","year":2022.0,"referenceCount":14,"citationCount":0,"fieldsOfStudy":null,"publicationDate":"2022-10-28","authors":[{"authorId":"119117781","name":"Y. Zu"}]},{"paperId":"0017ba8219f44d288fd7e66c169ce145f089b1e4","title":"Navigators for the Digital Ocean","abstract":"Purpose \u2013 The purpose of this column is to explore methods in which information professionals can contribute to the intelligence of open discovery systems.Design\/methodology\/approach \u2013 This is a conceptual column based on experience in this field and a review of the relevant literature.Findings \u2013 There are several ways in which information professionals can contribute to make their discovery systems more robust through careful semantic analysis.Originality\/value \u2013 This column explores ways in which the fields of linguistics, semantic analysis, semiotics, and web ontologies can assist information professionals in building responsive and robust back end indexing systems that can be coupled to front end open discovery frameworks.","venue":"OCLC Systems & Services","year":2012.0,"referenceCount":8,"citationCount":7,"fieldsOfStudy":["Computer Science"],"publicationDate":"2012-05-25","authors":[{"authorId":"2052404240","name":"Robert Fox"}]},{"paperId":"0017e5611c222663b2eaa7e2ea1a8ff65e922960","title":"Semantic Analyzing Technology of Web Document","abstract":"Semantic technology can improve the analyzing accuracy of the Web documents.Two semantic technologies are introduced in this paper: concept semantic technology and formalization semantic technology.The concept semanteme based on non-negative matrix factorization is a novel method,which can consider the concept semantic accuracy and the complexity of algorithm.Ontology is a current formalization semantic technology.Ontology-based information systems suffer from the problem of ontology heterogeneity.It introduces the definitions of simplified multielement bounds to find the best approximations of the concepts,and presents the idea for searching the simplified multielement bounds.","venue":"","year":2007.0,"referenceCount":7,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"2055886731","name":"Guo Yong"}]},{"paperId":"00182c9a825db9ffef2cb3358ba54424c3d87d03","title":"Automating metadata Web service deployment for problem solving environments","abstract":null,"venue":"Future generations computer systems","year":2003.0,"referenceCount":60,"citationCount":6,"fieldsOfStudy":["Computer Science"],"publicationDate":"2003-06-02","authors":[{"authorId":"1774360","name":"Ozgur Balsoy"},{"authorId":"48932561","name":"Ying Jin"},{"authorId":"34705643","name":"G. Aydin"},{"authorId":"1748875","name":"M. Pierce"},{"authorId":"145943292","name":"G. Fox"}]},{"paperId":"00192014ff412bc2e68728b9b083177ba7bb8097","title":"Corpus-based Semantic Class Mining: Distributional vs. Pattern-Based Approaches","abstract":"Main approaches to corpus-based semantic class mining include distributional similarity (DS) and pattern-based (PB). In this paper, we perform an empirical comparison of them, based on a publicly available dataset containing 500 million web pages, using various categories of queries. We further propose a frequency-based rule to select appropriate approaches for different types of terms.","venue":"International Conference on Computational Linguistics","year":2010.0,"referenceCount":28,"citationCount":62,"fieldsOfStudy":["Computer Science"],"publicationDate":"2010-08-23","authors":[{"authorId":"34720053","name":"Shuming Shi"},{"authorId":"2111012883","name":"Huibin Zhang"},{"authorId":"1721029","name":"Xiaojie Yuan"},{"authorId":"2259699","name":"Ji-Rong Wen"}]},{"paperId":"0019dc70fc63fcbcee233422cb8121828bcc4b8a","title":"Triple-based Computing","abstract":null,"venue":"SWS@ISWC","year":2004.0,"referenceCount":12,"citationCount":115,"fieldsOfStudy":["Computer Science"],"publicationDate":"2004-11-23","authors":[{"authorId":"1766239","name":"D. Fensel"}]},{"paperId":"001a3d6d6b64f5952b35fbc718a69d3f51619009","title":"An optimization for query answering on ALC database","abstract":"Query answering over OWLs and RDFs on the Semantic Web is, in general, a deductive process. To this end, OWL, a family of web ontology languages based on description logic, has been proposed as the language for the Semantic Web. However, reasoning even on ALC, a description logic weaker than OWL, faces efficiency problem. To obviate this problem, at least for ALC, we propose a partition approach that improves the efficiency by splitting the search space into independent Aboxes. Each partition class, i.e., an Abox, can be queried independently. The answer to a query is the simple combination of the answers from each Abox. We prove the correctness of this approach and we outline how to represent compactly the content of each independent Abox. This work can be seen as an optimization for querying a deductive semi-structured database.","venue":"Australasian Database Conference","year":2006.0,"referenceCount":32,"citationCount":1,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"3279384","name":"Pakornpong Pothipruk"},{"authorId":"1712534","name":"Guido Governatori"}]},{"paperId":"001a47fdd15eb869ca5d0a2ed3116fc6664a81fb","title":"Trends in Parsing Technology, Dependency Parsing, Domain Adaptation, and Deep Parsing","abstract":null,"venue":"","year":2010.0,"referenceCount":0,"citationCount":7,"fieldsOfStudy":["Computer Science"],"publicationDate":"2010-10-13","authors":[{"authorId":"1786202","name":"H. Bunt"},{"authorId":"143939590","name":"Paola Merlo"},{"authorId":"1720988","name":"Joakim Nivre"}]},{"paperId":"001a6102e7fcd9ac0304a4e5df212d7f7170dd0c","title":"Framework of Semantic Web Service Discovery Based on Fuzzy Logic and Multi-phase Matching \u22c6","abstract":"Web service discovery has become increasingly more important as the prevailing use of web service. According to the inadequateness of current discovery methods to deal with the vague information of web service, a framework of semantic web service discovery based on fuzzy logic and multi-phase matching is proposed in this paper, which exploits domain ontology, fuzzy logic and linguistic variable to present web service capability and vague information in formal description and implements approximately reasoning. Firstly, an abstract level-based service description model is given to describe web service information. Then, multi-phase matching process, including two-stage filtering and two-level matching, is detailed expressed. A case study is conducted to describe the process details of the proposed method, and the results show that it can manage web service vague information and improve the efficiency of web service discovery.","venue":"","year":2012.0,"referenceCount":11,"citationCount":10,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"2447230","name":"Zhenglian Su"},{"authorId":"3042553","name":"Haisong Chen"},{"authorId":"2112509330","name":"Liang Zhu"},{"authorId":"2058469142","name":"Zeng Yonghua"}]},{"paperId":"001bcd6b1be2ae71260d6e31f957ca5231cda8e3","title":"Information organization and retrieval with collaboratively generated content","abstract":"Proliferation of ubiquitous access to the Internet enables millions of Web users to collaborate online on a variety of activities. Many of these activities result in the construction of large repositories of knowledge, either as their primary aim (e.g., Wikipedia) or as a by-product (e.g., Yahoo! Answers). In this tutorial, we will discuss organizing and exploiting Collaboratively Generated Content (CGC) for information organization and retrieval. Specifically, we intend to cover two complementary areas of the problem: (1) using such content as a powerful enabling resource for knowledge-enriched, intelligent representations and new information retrieval algorithms, and (2) development of supporting technologies for extracting, filtering, and organizing collaboratively created content. The unprecedented amounts of information in CGC enable new, knowledge-rich approaches to information access, which are significantly more powerful than the conventional word-based methods. Considerable progress has been made in this direction over the last few years. Examples include explicit manipulation of human-defined concepts and their use to augment the bag of words (cf. Explicit Semantic Analysis), using large-scale taxonomies of topics from Wikipedia or the Open Directory Project to construct additional class-based features, or using Wikipedia for better word sense disambiguation. However, the quality and comprehensiveness of collaboratively created content vary widely, and in order for this resource to be useful, a significant amount of preprocessing, filtering, and organization is necessary. Consequently, new methods for analyzing CGC and corresponding user interactions are required to effectively harness the resulting knowledge. Thus, not only the content repositories can be used to improve IR methods, but the reverse pollination is also possible, as better information extraction methods can be used for automatically collecting more knowledge, or verifying the contributed content. This natural connection between modeling the generation process of CGC and effectively using the accumulated knowledge suggests covering both areas together in a single tutorial. The intended audience of the tutorial includes IR researchers and graduate students, who would like to learn about the recent advances and research opportunities in working with collaboratively generated content. The emphasis of the tutorial is on comparing the existing approaches and presenting practical techniques that IR practitioners can use in their research. We also cover open research challenges, as well as survey available resources (software tools and data) for getting started in this research field.","venue":"Annual International ACM SIGIR Conference on Research and Development in Information Retrieval","year":2011.0,"referenceCount":0,"citationCount":2,"fieldsOfStudy":["Computer Science"],"publicationDate":"2011-07-24","authors":[{"authorId":"1685296","name":"Eugene Agichtein"},{"authorId":"1718798","name":"E. Gabrilovich"}]},{"paperId":"001c5b2b24e23abf9f4ca0daf994d85b110a86bb","title":"Novel method for dynamic web service selection and composition using hypergraph decomposition","abstract":"Today, there is a growing need for user to be able to express, and get answers to more complex requests, those including multiple functionalities, conditions, constraints and objectives. Complex requests including multiple functionalities only cannot usually be answered with one single Web service. As multiple services are needed, the problem is then to find good combination using the available services. This paper contributes to answering this issue. It focuses on the problem of semantic Web services composition to answer such requests. We propose an automatic composition algorithm designing the answering composition. The set of answering composition is modeled as a hypergraph, which supports the selection of the best composition according to the request constraints and objectives.","venue":"IPAC","year":2015.0,"referenceCount":12,"citationCount":1,"fieldsOfStudy":["Computer Science"],"publicationDate":"2015-11-23","authors":[{"authorId":"1399547099","name":"Samah Benmerbi"},{"authorId":"3111598","name":"Kamal Amroun"},{"authorId":"144458815","name":"A. Tari"}]},{"paperId":"001cd7991fe2c8cd78e5263ad2a29ebd75c671e6","title":"Role of semantic web in health informatics","abstract":"Leveraging the rapidly increasing amount of health care data to demonstrably enhance quality of clinical research and patient care has become a critical challenge for health care providers, researchers, and informaticians. In addition to the sheer volume of the data, the large disparity in storage formats, distributed locations, and variable quality of data, is exacerbating data management issues. There is an urgent need to address these issues to enable multi-center clinical studies, comply with new health care policies that encourage adoption of Electronic Health Records (EHR), and effectively move towards the National Institutes of Health (NIH) roadmap of translational research.\n The Semantic Web initiative by the World Wide Web Consortium (W3C) has defined a set of standards and technologies for representing, integration, and querying large-scale data with increasing use in health care, exemplified by the W3C Health Care and Life Sciences (HCLS) Interest Group. Ontologies are a core feature of the Semantic Web and are being increasingly adopted by the biomedical community, which is demonstrated by the more than 260 ontologies listed at the National Center for Biomedical Ontologies (NCBO). This tutorial will weave together three themes and the associated topics: Semantic Web and Biomedical Ontologies Key Technologies - Semantic Provenance and Data Integration Real World Use Cases and In-Use Tools","venue":"International Health Informatics Symposium","year":2012.0,"referenceCount":13,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":"2012-01-28","authors":[{"authorId":"2628266","name":"S. Sahoo"},{"authorId":"144463965","name":"A. Sheth"},{"authorId":"144107657","name":"Guo-Qiang Zhang"}]},{"paperId":"001d52c0f8e274c3c47b998b8800673118bd12cb","title":"Multi-level, Viewpoint-Oriented Engineering of Cyber-Physical Production Systems: An Approach Based on Industry 4.0, System Architecture and Semantic Web Standards","abstract":"This paper presents initial results of the industry-led research project \"SICHTEN 4.0\" that aims to develop a method for viewpoint-oriented engineering of CPS for production (Industry 4.0). The approach allows different stakeholders to model their own views of the CPS application and establish alignment with the views of other stakeholders. Specifically, a multi-level method for modelling CPS is proposed that includes the creation of viewpoints and views according to the ISO\/IEC\/IEEE 42010:2011 standard for system architecture. They are defined using the Reference Architecture Model Industrie 4.0 and Semantic Web standards. The paper describes and illustrates the foundations of this approach.","venue":"EUROMICRO Conference on Software Engineering and Advanced Applications","year":2018.0,"referenceCount":15,"citationCount":11,"fieldsOfStudy":["Computer Science"],"publicationDate":"2018-08-01","authors":[{"authorId":"2464245","name":"U. Kannengiesser"},{"authorId":"2093434590","name":"Harald M\u00fcller"}]},{"paperId":"001d958fabe47d40b09811722aa9296f25a81428","title":"Visualization of Web Site Information with Semantic Weights","abstract":null,"venue":"International Conference on Internet Computing","year":2000.0,"referenceCount":0,"citationCount":1,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"1728685","name":"Wookey Lee"},{"authorId":"2116515479","name":"Jinho Kim"}]},{"paperId":"001f24dcb9eff581de33e82fab175e745cb4ae0b","title":"Self\u2010organizing maps for latent semantic analysis of free\u2010form text in support of public policy analysis","abstract":"The huge amount of free\u2010form unstructured text in the blogosphere, its increasing rate of production, and its shrinking window of relevance, present serious challenges to the public policy analyst who seeks to take public opinion into account. Most of the tools which address this problem use XML tagging and other Web 3.0 approaches, which do not address the actual content of blog posts and the associated commentary. We give a tutorial review of latent semantic analysis and the self\u2010organizing maps, as considered in this context, and show how to apply the self\u2010organizing map over a probabilistic latent semantic space to the problem of completely unsupervised clustering of unstructured text in such a way as to be entirely independent of spelling, grammar, and even source language. This provides an algorithm suitable for clustering free\u2010form commentary with a well\u2010structured test environment. The algorithm is applied to academic paper abstracts instead, treated as unstructured text as though they were blog posts, because this set of documents has a known ground truth. The algorithm constructs a word category map and a document map in which words with similar meaning and documents with similar content are clustered together. WIREs Data Mining Knowl Discov 2014, 4:71\u201386. doi: 10.1002\/widm.1112","venue":"WIREs Data Mining Knowl. Discov.","year":2014.0,"referenceCount":79,"citationCount":6,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"38523439","name":"B. Till"},{"authorId":"39870836","name":"Justin Longo"},{"authorId":"143869473","name":"A. Dobell"},{"authorId":"2213697774","name":"Peter F. Driessen"}]},{"paperId":"0020ddc1ceaee6878f988fbf7af996264295eae9","title":"Towards a Universal Notification System","abstract":"As the world is getting more and more connected, a requirement for a connected notification system has emerged. In this paper a universal notification system namely UNS based on stream reasoning is described that not only meets the requirement of knowledge sharing among applications but can cater to different varying and custom scenarios, is flexible and semantic web compliant. Experimentation was done considering a meeting use case in a simulated condition on real data of smart city, and the experimental results were found to be promising.","venue":"2013 IEEE\/WIC\/ACM International Joint Conferences on Web Intelligence (WI) and Intelligent Agent Technologies (IAT)","year":2013.0,"referenceCount":4,"citationCount":3,"fieldsOfStudy":["Computer Science"],"publicationDate":"2013-11-17","authors":[{"authorId":"153564586","name":"Snehasish Banerjee"},{"authorId":"39064791","name":"D. Mukherjee"}]},{"paperId":"0020f7e38af671c0837ac86dac2297f1c8508c7d","title":"Hera presentation generator (Poster)","abstract":"Semantic Web Information Systems (SWIS) are Web Information Systems that use Semantic Web technologies. Hera is a model-driven design methodology for SWIS. In Hera, models are represented in RDFS and model instances in RDF. The Hera Presentation Generator (HPG) is an integrated development environment that supports the presentation generation layer of the Hera methodology. The HPG is based on a pipeline of data transformations driven by different Hera models.","venue":"","year":2005.0,"referenceCount":0,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"1729599","name":"Flavius Frasincar"},{"authorId":"143779489","name":"G. Houben"},{"authorId":"1746460","name":"P. Barna"}]},{"paperId":"002287d1fc855b601a9942f6a2aba20eaa428c5e","title":"\u201dCITYJSON2RDF\u201d A CONVERTER FOR PRODUCING 3D CITY KNOWLEDGE GRAPHS","abstract":"Abstract. The increasing prevalence of 3D city models (3DCMs) in various applications, such as mixed reality and navigation, highlights the need for efficient data exchange. CityGML serves as a standard model for this purpose, encompassing geometric and semantic information in 3DCM data. To enhance interoperability, a compatible transfer mechanism is essential. This study introduces a conversion tool that transforms CityGML data into RDF, a knowledge graph (KG) format. Utilizing semantic web technologies, this conversion ensures the data\u2019s seamless integration across applications. The RDF model facilitates linking to open ontologies, promoting data circulation without loss. The tool employs CityJSON encoding for its mappable JSON structure, enabling straight-forward conversion to RDF using Python components. While existing XML to RDF tools exist, this tool distinguishes itself by addressing accessibility and user intervention challenges. Linking is established by matching subject classes with relevant ontology definitions, a process dependent on developers\u2019 understanding of the CityGML data model. The tool, accessible through URL-2, is still in development, offering a promising solution for achieving effective 3DCM data interoperability.\n","venue":"The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences","year":2024.0,"referenceCount":0,"citationCount":0,"fieldsOfStudy":null,"publicationDate":"2024-03-08","authors":[{"authorId":"2290551385","name":"A. T. Ak\u0131n"},{"authorId":"2290548779","name":"\u00c7. C\u00f6mert"}]},{"paperId":"00232bb757a9b39b29af211ffaece112db606151","title":"Semantic event processing in ENVISION","abstract":"The Semantic Sensor Web provides a framework for the interoperable exchange and processing of observation data from heterogeneous sensor networks. Environmental monitoring applications deal with change detection in a spatio-temporal context. Here it is required to analyze vast amounts of sensor data in order to react to specific situations. In the ENVISION project, we explore how to enhance this process of sense&respond by using Complex Event Processing (CEP) techniques. CEP allows defining situations of change in observable variables using event patterns. By combining event processing and semantic technologies we are able to process time-series of observations from different sources and communicate the inferred events to interested communities in near real-time.","venue":"Web Intelligence, Mining and Semantics","year":2012.0,"referenceCount":27,"citationCount":7,"fieldsOfStudy":["Computer Science"],"publicationDate":"2012-06-13","authors":[{"authorId":"3233351","name":"Alejandro Llaves"},{"authorId":"2808471","name":"H. Michels"},{"authorId":"2257114","name":"P. Mau\u00e9"},{"authorId":"40141757","name":"Marcell Roth"}]},{"paperId":"0023bca2000f3245db1a9a6593e51c8fefe8ffb4","title":"Uma investiga\u00e7\u00e3o de STI que emprega a PBL de forma individual","abstract":"Resumo: Este trabalho tem como proposito interpretar resultados de uso de um STI pela Internet que emprega como modelo pedagogico a Aprendizagem Baseada em Problemas (PBL). A arquitetura de STI empregada se apoiou na tecnologia de Web Sem\u00e2ntica. O uso dessa abordagem permitiu uma clara separacao de interesses de cada modulo do sistema, uma vez que cada componente pode ser representado por uma ontologia propria. Embora para o estudo nao tenha sido utilizado um grande numero de aprendizes, os resultados indicam que o STI que utilizou a PBL tem potencial de uso pratico para proporcionar experiencias de aprendizagem significativas. Abstract: This paper aims at analyzing the results of use of an Internet based ITS that uses Problem based Learning (PBL) as a pedagogical model. The ITS\u2019s architecture has been based on the Semantic Web Technology. Such an architectural approach provided a clear concern separation of each system component, once each component has been represented by a specific ontology. Though for the analysis the number of participant learners has not been high, the obtained results indicate that the implemented ITS with the PBL approach may provide meaningful learning experiences.","venue":"","year":2007.0,"referenceCount":5,"citationCount":1,"fieldsOfStudy":["Art"],"publicationDate":"2007-11-01","authors":[{"authorId":"2078859630","name":"Adriana da Silva Jacinto"},{"authorId":"150156521","name":"Jos\u00e9 Maria Parente de Oliveira"}]},{"paperId":"0024e30b101f10864e2f318777a2aaad8962929c","title":"Designing learning management system interoperability in semantic web","abstract":"The extensive adoption of learning management system (LMS) has set the focus on the interoperability requirement. Interoperability is the ability of different computer systems, applications or services to communicate, share and exchange data, information, and knowledge in a precise, effective and consistent way. Semantic web technology and the use of ontologies are able to provide the required computational semantics and interoperability for the automation of tasks in LMS. The purpose of this study is to design learning management system interoperability in the semantic web which currently has not been investigated deeply. Moodle is utilized to design the interoperability. Several database tables of Moodle are enhanced and some features are added. The semantic web interoperability is provided by exploited ontology in content materials. The ontology is further utilized as a searching tool to match user\u2019s queries and available courses. It is concluded that LMS interoperability in Semantic Web is possible to be performed.","venue":"","year":2018.0,"referenceCount":12,"citationCount":8,"fieldsOfStudy":["Computer Science","Physics"],"publicationDate":null,"authors":[{"authorId":"48289815","name":"Y. Anistyasari"},{"authorId":"2803317","name":"R. Sarno"},{"authorId":"70647034","name":"N. Rochmawati"}]},{"paperId":"00250fc7fe665bdb5af3e895a18d1c94db3a7c8e","title":"Relational Database to RDF Mapping Patterns","abstract":"In order to integrate relational databases into Semantic Web applications, relational databases need to be mapped to RDF. The W3C RDB2RDF Working Group is in the process of ratifying two standards to map relational databases to RDF: Direct Mapping and R2RML mapping language. Through our experience as implementors of two RDB2RDF systems: Ultrawrap and Morph, and as authors of R2RML mappings, we have observed mappings that are reusable in order to solve a commonly occurring problem. In this paper, we have compiled these mappings and present a non-exhaustive list of RDB2RDF Mapping Patterns. We aspire that the mapping patterns in this paper are considered as a starting point for new mapping patterns.","venue":"WOP","year":2012.0,"referenceCount":12,"citationCount":34,"fieldsOfStudy":["Computer Science"],"publicationDate":"2012-11-12","authors":[{"authorId":"1703204","name":"Juan Sequeda"},{"authorId":"2787942","name":"Freddy Priyatna"},{"authorId":"1398348791","name":"B. Villaz\u00f3n-Terrazas"}]},{"paperId":"0025ba722bb69bbd92a961b56773daecd9ade5cf","title":"Applications of Big Data in Media Organizations","abstract":"The exploitation of data in the media industry has always played a significant role. This is especially evident today, since data (and in many cases big data) are generated through various activities that relate to the production and also consumption of news. This paper attempts to highlight the importance of big data utilization in the media industry. Specifically, it discusses cases of big data exploitation, such as media content consumption and management, data journalism production, social content utilization, and participatory journalism applications. The study also examines the changes that big data has introduced in all stages of the journalism practice, from news production to news distribution, by utilizing the available tools. Finally, it discusses new developments that relate to semantic web (Web 3.0) technologies, which have already started to be adopted by media organizations around the world.","venue":"The social science","year":2022.0,"referenceCount":0,"citationCount":7,"fieldsOfStudy":null,"publicationDate":"2022-09-08","authors":[{"authorId":"3199137","name":"A. Veglis"},{"authorId":"80638385","name":"Theodora Saridou"},{"authorId":"31426920","name":"Kosmas Panagiotidis"},{"authorId":"1486385829","name":"Christina Karypidou"},{"authorId":"2121109177","name":"Efthimis Kotenidis"}]},{"paperId":"00287bcf14e1d6ae002c438d31d0ae3bff7f7d62","title":"OpenInfRA \u2013 Storing and retrieving information in a heterogeneous documentation system (Long Paper)","abstract":"OpenInfRA is a new system for the scientific documentation and publication of worldwide conducted projects in archaeology. It is based on two older applications developed by the German Archaeological Institute (DAI) in Berlin (iDAI.field + CISAR) and thematically will support not only excavations with their finds but also extensive\/intensive surveys, building studies, stratigraphical drillings, restoration works and geophysical prospections. In technical terms it will focus in particular on open interfaces to publish and share its content for re-use and interoperability scenarios. It will consequently provide tools for the communication with online-systems like web-databases, geo-services or library catalogues (e. g. OPACs) on the one hand, and on the other hand, with specific professional (desktop) applications (like GIS, 3D, statistical, CAD, image processing, harris-matrices) for further evaluation and analysis of research results. Due to the aim of the developers to provide functionalities for editing and storing primary data from various field projects with different methodological approaches and scientific questions, the information within OpenInfRA is going to be very heterogeneous in respect to data quality, data formats, data types, languages, accuracy and fuzziness. Against this background, the search queries and the visualisation of the results become a technical and semantical challenge as there is a need for incorporating impreciseness and proximity into a logic based query language. The approach taken is to integrate special retrieval algorithms that combine the power of Boolean logic with vague and uncertain conditions. Therefore, a calculus query language named CQQL (commuting quantum query language) has been introduced by the chair of Database and Information Systems at Brandenburg University of Technology. Its underlying unifying theory is based on the mathematical formalism of quantum mechanics and quantum logic. The first part of the presentation will give a short overview of the main characteristics and issues of OpenInfRA. The second part will present the information retrieval strategies which are going to be implemented within this system. Related URLs: http:\/\/www.dainst.org\/de\/project\/idaifield http:\/\/www.tu-cottbus.de\/cisar\/ http:\/\/www.tu-cottbus.de\/fakultaet2\/de\/vermessung\/forschung\/projekte\/openinfra.html","venue":"","year":2011.0,"referenceCount":0,"citationCount":3,"fieldsOfStudy":["Computer Science"],"publicationDate":"2011-12-18","authors":[{"authorId":"1393240421","name":"F. Scha\u0308fer"},{"authorId":"2059541307","name":"Alexander Schulze"}]},{"paperId":"0028bad464a21f5499b04f69ee8c5d3716f77c7c","title":"Using Semantic Web for Information Retrieval Based on Clonal Selection Strategy","abstract":"It is well known that information retrieval systems based entirely on syntactic contents have serious limitations. In order to achieve high precision and recall on IR systems, the incorporation of natural language processing techniques that provide semantic information is needed. For this reason, by determining the semantic for the constituents of documents, a clustering method is presented in this paper. The goal is to find the conjoined point which can combine the advantages of both textual part and visual part, and to use for IR systems. It can help to well extract the meaning of a term. Thus, we can take the formalized meaning, instead of the lexical term, and consequently resolve the word sense ambiguity. Experimental results show that the proposed SWCSM model significantly improves the average precision and recall and reduces the overall search time.","venue":"2009 Second International Symposium on Computational Intelligence and Design","year":2009.0,"referenceCount":14,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":"2009-12-12","authors":[{"authorId":"2108172940","name":"Jianming Zhang"},{"authorId":"2112782788","name":"Xinliang Tan"},{"authorId":"32631081","name":"Xuehua Huang"},{"authorId":"2152548627","name":"Yan Wang"}]},{"paperId":"0028d9997ed87045744d6288e4d13ea81f26f176","title":"Memetic EDA-Based Approaches to QoS-Aware Fully Automated Semantic Web Service Composition","abstract":"Quality-of-service (QoS)-aware automated semantic Web service composition aims to find a composite service with optimized or near-optimized QoS and quality of semantic matchmaking within polynomial time. To cope with this NP-hard problem with high complexity, a variety of evolutionary computation (EC) techniques has been developed. To improve the effectiveness and efficiency of these techniques, in this article, we proposed a novel memetic estimation of the distribution algorithm-based approach, namely, MEEDA, to tackle this problem. In particular, MEEDA explores four different domain-dependent local search methods that search for effective composite services by utilizing several neighborhood structures. Apart from that, to significantly reduce the computational time of MEEDA, an efficient local search strategy is introduced by combining a uniform fitness distribution scheme for selecting suitable solutions and stochastic local search operators for effectively and efficiently exploiting neighbors. To better demonstrate MEEDA\u2019s effectiveness and scalability, we create a more challenging, augmented version of the service composition benchmark dataset. Experimental results on this benchmark show that MEEDA with newly developed domain-dependent local search operator, i.e., layer-based constrained one-point swaps, significantly outperforms existing state-of-the-art algorithms in finding high-quality composite services.","venue":"IEEE Transactions on Evolutionary Computation","year":2019.0,"referenceCount":45,"citationCount":8,"fieldsOfStudy":["Computer Science"],"publicationDate":"2019-06-19","authors":[{"authorId":"2109115644","name":"Chen Wang"},{"authorId":"144258297","name":"Hui Ma"},{"authorId":"6183863","name":"Gang Chen"},{"authorId":"1682323","name":"Sven Hartmann"}]},{"paperId":"0028fb5576b16abc6f1dae5e05ab9c8d09d8e9e5","title":"Semantic web's hidden meanings","abstract":"Can the Semantic Web ideal prevail in the face of critics and rival approaches to organising information on tomorrow's Internet?The paper reports the hidden meanings of semantic Web.","venue":"","year":2010.0,"referenceCount":0,"citationCount":4,"fieldsOfStudy":["Computer Science"],"publicationDate":"2010-11-11","authors":[{"authorId":"145493291","name":"C. J. Edwards"}]},{"paperId":"0029fa0bce24b758155748aacdb68d61d862874d","title":"HAKE: an Unsupervised Approach to Automatic Keyphrase Extraction for Multiple Domains","abstract":null,"venue":"Cognitive Computation","year":2022.0,"referenceCount":113,"citationCount":3,"fieldsOfStudy":["Computer Science"],"publicationDate":"2022-01-21","authors":[{"authorId":"8682540","name":"Zakariae Alami Merrouni"},{"authorId":"2040835","name":"B. Frikh"},{"authorId":"1819670","name":"B. Ouhbi"}]},{"paperId":"002aad7875d5f0a221e587de3314c7d9f1f73ad7","title":"Une interface de programmation visuelle pour la composition de services de visualisation d'information","abstract":"In this article, we are interested in information visualisations creation and sharing. Our approach is to consider information visualisation as a dataflow, issued from web services compositions which held both syntaxic and semantic rules. To ease service composition, we introduce mashviz, a visual programming interface aimed to both designers and users, to share and annote visualisations. We discuss our early created visualisations, and give clues about our next steps, such as evaluation by usage.","venue":"Interaction Homme-Machine","year":2009.0,"referenceCount":16,"citationCount":2,"fieldsOfStudy":["Computer Science"],"publicationDate":"2009-10-13","authors":[{"authorId":"1683275","name":"Romain Vuillemot"},{"authorId":"1775465","name":"B. Rumpler"}]},{"paperId":"002b6dfe458abe56ee8b9a53352a5dbb690e5984","title":"Degrees of adverbialization. A cross-linguistic corpus study of 'far from X' constructions","abstract":"In language change, parallel source constructions can undergo cross-linguistically divergent developments. The focus of this paper is on one such case, the development of degree modifiers from markers of physical distance. Specifically, we will compare the semantic and syntactic properties of FAR FROM constructions in three Germanic languages and one Romance language: English [far from X], Dutch [ver(re) van X], Swedish [langt ifran X] and French [loin de X]. In all four languages, the spatial construction consists of an adjective or adverb and a preposition, followed by an NP. Further, in all four languages, the construction tends to develop adverbial degree modifying uses (as a downtoner), as illustrated for English in (1), and for Swedish in (2). Its X-slot then tends to open up to other phrase types (VP, AP, PP). (1) Nutty was far from sure, and Biddy looked doubtful. (BNC) (2) de langt ifran marginella forandringar landet genomgar. (SECOW2014) \u2018the far from marginal changes the country is going through.\u2019 However, the four languages differ in the extent to which their [FAR FROM X] construction has grammaticalized into a full-blown adverbial degree modifier. The central purpose of our study is to analyze the differences between the languages and to account for them. It is shown that, semantically, degree modifying senses develop from metaphorical extensions of spatial senses, as in (3-4). (3) Nous voila loin de la mondialisation heureuse! (FRCOW2011) \u2018Here we are far from happy globalization!\u2019 (4) men det ar sa langt ifran sanningen man kan komma. (SECOW2014) \u2019but it is as far from the truth as one can get\u2019 The availability of the same metaphorical senses supports a gradient of meanings that continue to integrate degree modifying senses and spatial senses into a single semantic network. In French and English, this appears to hinder the development of full-blown adverbial uses. In French, loin de combines spatial, metaphorical and downtoner uses, but does not develop into an adverb. In English, it is found that new adverbial uses appear around the time metaphorical senses decline. In Swedish, by contrast, langt ifran is always adverbial (as evidenced by the adverbial suffix t in langt), but as in the other languages, it occurs in both spatial, metaphorical and downtoner constructions. Formally, variation is found to facilitate form-meaning realignment. In Dutch, the variation between ver van and verre van licensed functional specialization of ver van as a spatial expression and verre van as a degree modifying adverb (5). The fact that the -e ending in verre van is an opaque relic obscured its relation to the adjective\/adverb ver and as such further disrupted form-meaning unity. (5) Dit was een verre van marginaal verschijnsel. (NLCOW2012) \u2018This was a far from marginal phenomenon.\u2019 The comparison of the respective fates of FAR FROM constructions in four different languages highlights the structural preconditions that favour or hinder syntactic change. Differences between the languages, then, are not explained by the random character of change, but by unevenly spread favouring conditions. Corpora BNC = British National Corpus: http:\/\/corpus2.byu.edu\/bnc\/ COW = Corpora from the Web: http:\/\/hpsg.fu-berlin.de\/cow\/colibri\/ Cf. Schafer, R. & F. Bildhauer. (2012). Building large corpora from the web using a new efficient tool chain. N. Calzolari, K. Choukri, T. Declerck et al. (Eds), Proceedings of the Eight International Conference on Language Resources and Evaluation, Istanbul, 486-493.","venue":"","year":2015.0,"referenceCount":5,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":"2015-04-12","authors":[{"authorId":"52311360","name":"H. D. Smet"},{"authorId":"66030070","name":"M. Norde"},{"authorId":"52115015","name":"K. Goethem"},{"authorId":"69842233","name":"G. Vanderbauwhede"}]},{"paperId":"002e5b146ea112459d215072a5cd541eb0818dda","title":"Reconsidering Universal Bibliographic Control in Light of the Semantic Web","abstract":"The article discusses the future of universal bibliographic control in the context of the Semantic Web. Resource Description Framework RDF), the basis of the Semantic Web, allows the replacement of attempts at one-size-fits-all schema, rules and other international\/global standards with what might be termed an all-sizes-fit-one approach, as shown by the example of VIAF (Virtual International Authority File). This approach can support a much richer ecology of bibliographic communities and their standards, achieved by establishing the semantic mapping of individual properties, and sets of properties (or RDF graphs), to form a connected web into which legacy metadata and newly-minted statements can be deposited. Such deposits are made at the natural level of the source standard, preserving local granularity, semantic focus, context, and the data itself, using one-to-one RDF representations of the standard. The web of semantic links then allows this data to be readily assimilated into a universal, web-scale environment which connects all bibliographic metadata as \u201clibrary linked data\u201d. The article is illustrated with examples drawn from IFLA standards such as FRBR and ISBD, and other international standards such as Dublin Core and RDA.","venue":"","year":2012.0,"referenceCount":9,"citationCount":27,"fieldsOfStudy":["Computer Science"],"publicationDate":"2012-04-01","authors":[{"authorId":"2058642","name":"G. Dunsire"},{"authorId":"2497581","name":"Diane Hillmann"},{"authorId":"46988478","name":"Jon Phipps"}]},{"paperId":"002ff24294ee5f628d2473602b5c6e87d88d6aff","title":"Identification as a Service: Large-Scale Cloud Service Discovery over the World Wide Web","abstract":"Cloud computing is provisioned with high flexibility with regard to on demand infrastructures, platforms and software as services through the Internet. The unique characteristics of cloud services such as dynamic and diverse services offering at different levels, as well as the lack of standardized description, are becoming important challenges in efficiently discovering cloud services for customers. In this paper, we propose a cloud service search engine that has the capability to automatically identify cloud services aiming at improving the accuracy when searching cloud services in real environments. Our search engine can detect cloud services effectively from the Web sources. Furthermore, we focus on learning the cloud service features, such as similarity function, semantic ontology and cloud service components to identify the cloud services. We use a real cloud service dataset to build an identifier. Our cloud service identifier can be used to automatically determine whether a given Web source is a cloud service with high accuracy.","venue":"BigData Congress [Services Society]","year":2016.0,"referenceCount":24,"citationCount":6,"fieldsOfStudy":["Computer Science"],"publicationDate":"2016-06-01","authors":[{"authorId":"3166196","name":"Abdullah Alfazi"},{"authorId":"1713128","name":"Quan Z. Sheng"},{"authorId":"32794831","name":"W. Zhang"},{"authorId":"2082966","name":"Lina Yao"},{"authorId":"1827750","name":"Talal H. Noor"}]},{"paperId":"00300aabb8d92b9edc03c2ff2208d2817796f1ad","title":"Proceedings of the First International Conference on New Forms of Reasoning for the Semantic Web: Scalable, Tolerant and Dynamic - Volume 291","abstract":null,"venue":"","year":2007.0,"referenceCount":0,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":"2007-11-11","authors":[{"authorId":"2869954","name":"R. Piskac"},{"authorId":"1725286","name":"F. V. Harmelen"},{"authorId":"144729286","name":"N. Zhong"}]},{"paperId":"0030709a26cd87b32438e5c656a2f0bffede507a","title":"Open Domain Question Answering via Semantic Enrichment","abstract":"Most recent question answering (QA) systems query large-scale knowledge bases (KBs) to answer a question, after parsing and transforming natural language questions to KBs-executable forms (e.g., logical forms). As a well-known fact, KBs are far from complete, so that information required to answer questions may not always exist in KBs. In this paper, we develop a new QA system that mines answers directly from the Web, and meanwhile employs KBs as a significant auxiliary to further boost the QA performance. Specifically, to the best of our knowledge, we make the first attempt to link answer candidates to entities in Freebase, during answer candidate generation. Several remarkable advantages follow: (1) Redundancy among answer candidates is automatically reduced. (2) The types of an answer candidate can be effortlessly determined by those of its corresponding entity in Freebase. (3) Capitalizing on the rich information about entities in Freebase, we can develop semantic features for each answer candidate after linking them to Freebase. Particularly, we construct answer-type related features with two novel probabilistic models, which directly evaluate the appropriateness of an answer candidate's types under a given question. Overall, such semantic features turn out to play significant roles in determining the true answers from the large answer candidate pool. The experimental results show that across two testing datasets, our QA system achieves an 18%~54% improvement under F_1 metric, compared with various existing QA systems.","venue":"The Web Conference","year":2015.0,"referenceCount":50,"citationCount":115,"fieldsOfStudy":["Computer Science"],"publicationDate":"2015-05-18","authors":[{"authorId":"11121990","name":"Huan Sun"},{"authorId":"144988795","name":"Hao Ma"},{"authorId":"144105277","name":"Wen-tau Yih"},{"authorId":"2927704","name":"Chen-Tse Tsai"},{"authorId":"46700348","name":"Jingjing Liu"},{"authorId":"1744179","name":"Ming-Wei Chang"}]},{"paperId":"0030b00f86a1ca925677c3b5297d82a7813a1344","title":"Sementic Retrieval Research Based on Ontology","abstract":"The rapid growth and diversities of Web information bring a lot of difficulties to the efficient information-retrieval. The current information retrieval tools just offers keywords-based searching, but ignores the semantic content of the keywords itself. The author's library information retrieval system takes advantage of ontology, it expands the requirement of users to the sementic words sets and provides the document analyzer that can filter the Web pages returned by the search agent according to the certain algorithm.Consequently it presents the most relavant documents to the users.","venue":"","year":2014.0,"referenceCount":0,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"2059473277","name":"Liu Cha"}]},{"paperId":"00325bc8ae55c2131e6b399da57e2db780112c1e","title":"A survey on text mining in social networks","abstract":"Abstract In this survey, we review different text mining techniques to discover various textual patterns from the social networking sites. Social network applications create opportunities to establish interaction among people leading to mutual learning and sharing of valuable knowledge, such as chat, comments, and discussion boards. Data in social networking websites is inherently unstructured and fuzzy in nature. In everyday life conversations, people do not care about the spellings and accurate grammatical construction of a sentence that may lead to different types of ambiguities, such as lexical, syntactic, and semantic. Therefore, analyzing and extracting information patterns from such data sets are more complex. Several surveys have been conducted to analyze different methods for the information extraction. Most of the surveys emphasized on the application of different text mining techniques for unstructured data sets reside in the form of text documents, but do not specifically target the data sets in social networking website. This survey attempts to provide a thorough understanding of different text mining techniques as well as the application of these techniques in the social networking websites. This survey investigates the recent advancement in the field of text analysis and covers two basic approaches of text mining, such as classification and clustering that are widely used for the exploration of the unstructured text available on the Web.","venue":"Knowledge engineering review (Print)","year":2015.0,"referenceCount":74,"citationCount":131,"fieldsOfStudy":["Computer Science"],"publicationDate":"2015-03-01","authors":[{"authorId":"2286527","name":"Rizwana Irfan"},{"authorId":"2064654419","name":"Christine K. King"},{"authorId":"2306926","name":"Daniel Grages"},{"authorId":"46323024","name":"Sam J. Ewen"},{"authorId":"1740261","name":"S. Khan"},{"authorId":"145015786","name":"S. Madani"},{"authorId":"1737974","name":"J. Kolodziej"},{"authorId":"2108594650","name":"Lizhe Wang"},{"authorId":"145335171","name":"Dan Chen"},{"authorId":"9374356","name":"A. Rayes"},{"authorId":"3282372","name":"Nikos Tziritas"},{"authorId":"144486540","name":"Chengzhong Xu"},{"authorId":"9392149","name":"Albert Y. Zomaya"},{"authorId":"123782728","name":"A. Alzahrani"},{"authorId":"2469932","name":"Hongxiang Li"}]},{"paperId":"0033c6755a3dd3e80397a24aa0055a90a132e85d","title":"A Novel Approach of Table Detection and Analysis for Semantic Annotation","abstract":"Semantic web mining is getting more attention in intelligent web applications. Many web sites, especially those dynamically generate HTML pages to display the results of user queries, present information in the form of lists or tables. It is very useful to extract concept instances from these tables for many web applications such as intelligent agent systems for on-line product recommendations. This paper describes a technique for extracting data from tables in two steps, namely table detection and table analysis. The table detection step identifies the existence of a table and extracts its contents, and the table analysis step discovers the semantic meanings embedded in the table and associates them with the concepts described in the domain ontology that are used for semantic annotation on these tables. Our algorithm has been tested based on real-life web documents and the experimental results are encouraging.","venue":"Int. J. Artif. Intell. Tools","year":2006.0,"referenceCount":19,"citationCount":2,"fieldsOfStudy":["Computer Science"],"publicationDate":"2006-06-01","authors":[{"authorId":"2227868312","name":"Enhong Chen"},{"authorId":"2116932329","name":"Shu Wang"},{"authorId":"6707682","name":"P. Sheu"}]},{"paperId":"00345c78b2bb842f8c0ac7a163e0c7d803dc45f7","title":"Diskursiv friktion mellan \u00f6ppenhet och auktoritet : en arkeologisk unders\u00f6kning av bibliotekspolicyer f\u00f6r delning av bibliografiska data p\u00e5 den semantiska webben","abstract":"In the last few years, we have seen an emerging activity among library institutions to release their catalogue data under the terms that are often referred to as \u201clinked, open data\u201d. The linked, open data concept brings some new features to the practice of bibliographic data exchange: It is done in a linked data environment following the technical principles of what is called the \u201csemantic web\u201d. It is also done through the explicit waiving of copyright over the data, through the invocation of \u201copen\u201d licenses that encourage free reuse with few or no restrictions. \n \nSince the body of literature within LIS that deals with cataloguing and metadata has been dominated by research from a technical or practice-oriented perspective, this study sets out to investigate the phenomenon of linked, open bibliographic data from a more socially or critically focused point of view. With inspiration from previous studies in classification and knowledge organisation, the theoretical and methodological framework of Michel Foucault is used to analyse policy documents from five national libraries and three large aggregated catalogues. The analysis also draws on the concepts of cognitive and institutional authority developed by Patrick Wilson. \n \nThe study finds some discursive regularities that in a way \u201cgovern\u201d the general discourse on linked, open bibliographic data, as well as the presence of friction between some rather contradictory discourses that exist side by side in the material. On the one hand, there is a strong \u201copenness discourse\u201d, framing the sharing practice as a social, ethical, and political issue as well as a question of technical access. On the other hand, there is a strong \u201cauthority discourse\u201d, which underlines the quality of the data and the institution\u2019s metadata production, and thus argues for some control or regulation over how the data can be used, usually in the form of requesting attribution. The release\/regulation practices are carried out with reference to either a \u201cgoodwill discourse\u201d or a \u201clegal discourse\u201d. Additionally, discourses of provenance, community and development are important regularities in the policy documents. \n \nThe study calls for an understanding of these recent releases of bibliographic data that regards them neither as simple altruistic actions for the benefit of us all, nor mere technical adjustments of the cataloguing departments to the growing semantic web. The study points to another important aspect, namely that library institutions can use linked, open data not only to distribute bibliographic information, but to position themselves as knowledge authorities or main nodes in a global, network society.","venue":"","year":2014.0,"referenceCount":41,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"123869736","name":"M. Persson"}]},{"paperId":"0037071e1a29c43a7076827aa35981d90941e1ca","title":"An Ontology to Support Context-Aware B2B Services","abstract":"In present day globalised trade, the ability to support collaboration through B2B (Business-to-Business) services is crucial. One of the key challenges is to pervasively connect partners across the entire value chain, with the appropriate service offerings. Thus, it is vital to quickly identify potential partners to form new B2B collaborations or to support formed collaborations with swift decision making abilities. This paper proposes the use of Description Logic (DL) based reasoning to ensure completeness and decidability in reasoning for context-aware B2B services. A B2B Context Model is realised through a DL-based representation language called OWL (Web Ontology Language). The expressivity of OWL was extended through the SWRL (Semantic Web Rule Language), to represent business rules identified in the model. The performance scalability of an ontology-based knowledge base using OWL was then investigated. Results showed that such a knowledge base is not scalable.","venue":"IEEE International Conference on Services Computing","year":2010.0,"referenceCount":21,"citationCount":7,"fieldsOfStudy":["Computer Science"],"publicationDate":"2010-07-05","authors":[{"authorId":"113072826","name":"P. Tan"},{"authorId":"144198409","name":"A. Goh"},{"authorId":"2108320885","name":"S. S. G. Lee"}]},{"paperId":"00371ff1c9487c4f95656322b4b4dd6f7d4f4349","title":"Organizing the concepts of science: Science ontologies and the semantic Web","abstract":"An ontology is an explicit, formal representation of the concepts, objects or other entities in a particular domain and the relationships among them. These advanced knowledge organization structures are increasing in number and relevance as computer to computer processing of information becomes more prevalent. They have been developed in many scientific disciplines where computer agents are being developed to support the scale of work, including bioinformatics, genetics, earth and space science, medical research, and engineering. Ontologies have been identified as a key technology for the advancement of the semantic web, which seeks to provide more precise and relevant information for human and computer use. The session focuses on ontologies in three science areas: aerospace and space science, cancer research, and agriculture. These case studies show how research is meeting practice. For each case study domain, sample ontologies and how they differ from other knowledge organization structures such as thesauri or topic maps are presented. Examples show the types of relationships expressed and how these relationships are manifested in real ontologies. The specific decisions made by a particular community regarding the tools selected for creating and","venue":"ASIS&T Annual Meeting","year":2006.0,"referenceCount":0,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":"2006-10-18","authors":[{"authorId":"34722955","name":"G. Hodge"},{"authorId":"145659115","name":"R. Hodgson"},{"authorId":"1782962","name":"H. Solbrig"},{"authorId":"1970116","name":"Johannes Keizer"}]},{"paperId":"003823795a81507d1a16dae20b6e1af57c49f802","title":"Supervised reranking for web image search","abstract":"Visual search reranking that aims to improve the text-based image search with the help from visual content analysis has rapidly grown into a hot research topic. The interestingness of the topic stems mainly from the fact that the search reranking is an unsupervised process and therefore has the potential to scale better than its main alternative, namely the search based on offline-learned semantic concepts. However, the unsupervised nature of the reranking paradigm also makes it suffer from problems, the main of which can be identified as the difficulty to optimally determine the role of visual modality over different application scenarios. Inspired by the success of the \"learning-to-rank\" idea proposed in the field of information retrieval, we propose in this paper the \"learning-to-rerank\" paradigm, which derives the reranking function in a supervised fashion from the human-labeled training data. Although supervised learning is introduced, our approach does not suffer from scalability issues since a unified reranking model is learned that can be applied to all queries. In other words, a query-independent reranking model will be learned for all queries using query-dependent reranking features. The query-dependent reranking feature extraction is challenging since the textual query and the visual documents have different representation. In this paper, 11 lightweight reranking features are proposed by representing the textual query using visual context and pseudo relevant images from the initial search result. The experiments performed on two representative Web image datasets demonstrate that the proposed learning-to-rerank algorithm outperforms the state-of-the-art unsupervised reranking methods, which makes the learning-to-rerank paradigm a promising alternative for robust and reliable Web-scale image search.","venue":"ACM Multimedia","year":2010.0,"referenceCount":29,"citationCount":128,"fieldsOfStudy":["Computer Science"],"publicationDate":"2010-10-25","authors":[{"authorId":"7866194","name":"Linjun Yang"},{"authorId":"1718099","name":"A. Hanjalic"}]},{"paperId":"003a21c9b435fc7c0e886a3b22857d66538e7472","title":"A Dynamic Ontology Management System for the Semantic Web","abstract":". The semantic web is an extension of the current web [1][2] and the data are well-defined based on those semantics for the agents to comprehend. Ontologies provide a solid base to represent metadata for the semantic web environment. Several web-compatible languages and technologies [4][5][6] have been developed to support the semantic knowledge management for ontologies. Current ontology management systems, such as Prot\u00d8g\u00d8 [12], allow only one relation type and thereby provide insufficient support for other web technologies. Overly simplified models lack the semantics expressions required. To solve these problems, we propose a dynamic ontology management system. The system implements a data model enclosing sufficient semantics, integrates the ontologies developed by different web-based technologies, and incorporates other data resources for the ontology refinements. The performance of the ontology management system is being enhanced to ensure less human involvement.","venue":"","year":2004.0,"referenceCount":23,"citationCount":0,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"2389366","name":"A. Chen"},{"authorId":"2112311523","name":"Shan Gao"},{"authorId":"144696534","name":"D. McLeod"}]},{"paperId":"003b0640c2f884806a36ab99af6d29c104f6d173","title":"ELN in the semantic era","abstract":"The importance of semantics in human-computer and computer-computer communications\nCapturing the laboratory processes and data in a semantically rich form at source.\nImplementing semantics - The use of the semantic web & grid\nThe importance of context in the use of ELNs\nPublication and dissemination - Using the information obtained with ELNs","venue":"","year":2006.0,"referenceCount":0,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":"2006-03-15","authors":[{"authorId":"32113616","name":"J. Frey"}]},{"paperId":"003c0ea8b2d58304c4524e9becf0eaa960ea6802","title":"NATURAL LANGUAGE BASED QUESTION ANSWERING USING DISTRIBUTIONAL SEMANTIC MODEL","abstract":": QA is a application or specific type of information Retrieval. Today\u2019s world of the web ,information is store with large repositories of information. The Big Problem we face is that large amount of information available that allow us to find what is relevant and cannot be managed without automatic Search. We solve this problem by using Question answering System(QAS). The main goal of QA system is able to answer users Question in Natural Language. The QA system can Fulfil the needs of user as they provide with faster and appropriate answers to user question.","venue":"","year":2015.0,"referenceCount":11,"citationCount":0,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"2073005783","name":"Toral Desai"}]},{"paperId":"003d73564da4a90eafd5f59c351966e8c708f755","title":"Exploratory Browsing in the Web of Data","abstract":"Thanks to the recent Linked Data initiative, the foundations of the Semantic Web have been built [2]. Shared, open and linked RDF datasets give us the possibility to exploit both the strong theoretical results and the robust technologies and tools developed since the seminal paper in the Semantic Web [1] appeared in 2001. In a simplistic way, we may think at the Semantic Web as a ultra large distributed database we can query to get information coming from different sources. In fact, every dataset exposes a SPARQL endpoint to make the data accessible through exact queries. If we know the URI of the famous actress Nicole Kidman in DBpedia [3] we may retrieve all the movies she acted with a simple SPARQL query. Eventually we may aggregate this information with users ratings and genres from IMDB. Even though these are very exciting results and applications, there is much more behind the curtains. Datasets come with the description of their schema structured in an ontological way. Resources refer to classes which are in turn organized in well structured and rich ontologies. Exploiting also this further feature we go beyond the notion of a distributed database and we can refer to the Semantic Web as a distributed knowledge base. If in our knowledge base we have that Paris is located in France (ontological level) and that Moulin Rouge! is set in Paris (data level) we may query the Semantic Web (interpreted as a set of interconnected datasets and related ontologies) to return all the movies starred by Nicole Kidman set in France and Moulin Rouge! will be in the final result set. The ontological level makes possible to infer new relations among data. The Linked Data initiative and the state of the art in semantic technologies led off all brand new search and mash-up applications. The basic idea is to have smarter lookup services for a huge, distributed and social knowledge base. All these applications catch and (re)propose, under a semantic data perspective, the view of the classical Web as a distributed collection of documents to retrieve. The interlinked nature of the Web, and consequently of the Semantic Web, is exploited (just) to collect and aggregate data coming from different sources. Of course, this is a big step forward in search and Web technologies, but if we limit our investigation to retrieval tasks, we miss another important feature of the current Web: browsing and in particular exploratory browsing (a.k.a. exploratory search) [7]. Thanks to its hyperlinked nature, the Web defined a new way of browsing documents and knowledge: selection by lookup, navigation and trial-and-error tactics [8] were, and still are, exploited by users to search for relevant information satisfying some initial requirements. The basic assumptions behind a lookup search,","venue":"","year":2010.0,"referenceCount":13,"citationCount":0,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"2499179","name":"R. Mirizzi"}]},{"paperId":"003e5e7d537f51c1371fe3428c6621f76bc35925","title":"Semantic based framework for dynamic customization of PLM-related information models. (Syst\u00e8me s\u00e9mantique pour la customisation dynamique des mod\u00e8les d'information de la PLM)","abstract":"We live in the information age. Data has become an essential asset for most everyday situations and business interactions. The need to share data, to generate information, and create new knowledge from that data is common to all fields of research and all economic activity. Managing data is a critical, and sometimes costly, process. When not properly defined, data might become incomplete, inconsistent or, even worse, unusable. Requirements for data evolve and we must define new data or update existing data over the entire data lifecycle. Evolving data requirements is an important issue and a technological challenge as it is not possible to define, in advance, information structures that meet requirements you do not yet know. Specifying information requirements is particularly challenging in domains such as manufacturing where information exchange involves many actors and sharing across multiple functions and software applications. As a result, it becomes hard to find a common information structure for representing data. The challenge is even bigger when a temporal aspect has to be considered since it requires the ability to extend the information structure dynamically over time. One area within the manufacturing domain that we have identified with these characteristics is Product Lifecycle Management (PLM). PLM involves many global actors using a myriad of software applications that perform a series of product management functions that can last from weeks to decades. Because the mechanism to extend models is static by its nature, requiring numerous updates of the initial information model, this operation is expensive in cost and time, and requires and understanding of the entire initial model to ensure correct extensions are developed. This research presents an alternative based on dynamic customization of information models in the context of PLM, by leveraging existing PLM standards and frameworks, and using emerging semantic web technologies such as OWL, SPARQL and SPIN. Following a state of the art in Chapter 2, Chapter 3 defines technical requirements used to evaluate existing PLM standards and frameworks. Based on the analysis of this evaluation, Chapter 4 presents new framework components for defining dynamically customizable information models for PLM. In chapter 5 these components are integrated together into a framework, and a use case demonstrates the efficiency of the framework. Chapter 6 concludes the research and introduces ideas for future research.","venue":"","year":2013.0,"referenceCount":6,"citationCount":1,"fieldsOfStudy":["Computer Science"],"publicationDate":"2013-07-05","authors":[{"authorId":"3420093","name":"Sylv\u00e8re Krima"}]},{"paperId":"003f5cb696ef6ebb74b790416339655eb4e78153","title":"From Patient Information Services to Patient Guidance Services-The iCare Approach","abstract":null,"venue":"Internet of Things and Inter-cooperative Computational Technologies for Collective Intelligence","year":2013.0,"referenceCount":30,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"2958215","name":"Dimitrios Tektonidis"},{"authorId":"1744974","name":"A. Bokma"},{"authorId":"1744789","name":"E. Kaldoudi"},{"authorId":"1746598","name":"A. Koumpis"}]},{"paperId":"003fe51f1227293af1a2fbc7ff54ad0f7caf7d7a","title":"Leveraging Pattern Semantics for Extracting Entities in Enterprises","abstract":"Entity Extraction is a process of identifying meaningful entities from text documents. In enterprises, extracting entities improves enterprise efficiency by facilitating numerous applications, including search, recommendation, etc. However, the problem is particularly challenging on enterprise domains due to several reasons. First, the lack of redundancy of enterprise entities makes previous web-based systems like NELL and OpenIE not effective, since using only high-precision\/low-recall patterns like those systems would miss the majority of sparse enterprise entities, while using more low-precision patterns in sparse setting also introduces noise drastically. Second, semantic drift is common in enterprises (\"Blue\" refers to \"Windows Blue\"), such that public signals from the web cannot be directly applied on entities. Moreover, many internal entities never appear on the web. Sparse internal signals are the only source for discovering them. To address these challenges, we propose an end-to-end framework for extracting entities in enterprises, taking the input of enterprise corpus and limited seeds to generate a high-quality entity collection as output. We introduce the novel concept of Semantic Pattern Graph to leverage public signals to understand the underlying semantics of lexical patterns, reinforce pattern evaluation using mined semantics, and yield more accurate and complete entities. Experiments on Microsoft enterprise data show the effectiveness of our approach.","venue":"The Web Conference","year":2015.0,"referenceCount":33,"citationCount":13,"fieldsOfStudy":["Medicine","Computer Science"],"publicationDate":"2015-05-18","authors":[{"authorId":"3180064","name":"Fangbo Tao"},{"authorId":"2143736767","name":"Bo Zhao"},{"authorId":"2290016457","name":"Ariel Fuxman"},{"authorId":"2153493977","name":"Yang Li"},{"authorId":"145325584","name":"Jiawei Han"}]},{"paperId":"004146f1f494350173b6c6090938cb87195eb6ea","title":"SPATIAL DATA ACCESSIBILITY AND THE SEMANTIC WEB","abstract":". As the volume of spatial data increases and the number of spatial data web portals proliferates, new approaches to searching across multiple sites are needed to enhance knowledge discovery. The Semantic Web provides such an opportunity for automated retrieval of spatial data, presenting a general solution for standard access and querying for spatial data. The advantages of applying the concepts of the Semantic Web are explored in the first steps towards an implementation using NASA\u2019s Global Change Master Directory\u2019s (GCMD) metadata holdings.","venue":"","year":2003.0,"referenceCount":9,"citationCount":3,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"2217998","name":"F. Reitsma"}]},{"paperId":"0042a05b95f3faa4dc27aa56df906df0bd602e31","title":"Ontologies-Based Platform for Sociocultural Knowledge Management","abstract":null,"venue":"Journal on Data Semantics","year":2016.0,"referenceCount":53,"citationCount":1,"fieldsOfStudy":["Computer Science"],"publicationDate":"2016-06-20","authors":[{"authorId":"2468880","name":"Papa Fary Diallo"},{"authorId":"1773317","name":"O. Corby"},{"authorId":"1763647","name":"I. Mirbel"},{"authorId":"3178243","name":"Moussa Lo"},{"authorId":"153781289","name":"Seydina M. Ndiaye"}]},{"paperId":"004349d80dd8c43759b68eb45f319e7fdde23693","title":"Investigating a Plausible Reasoning Approach for Performing Semantics-based Health Data Analytics","abstract":". In the development of data-driven models for clinical decision support, incompleteness of the data is always a consideration. Plausible reasoning is the manifestation of the \u201cplasticity\u201d element of humans\u2019 reasoning capability to reason over incomplete data and discover new relationships. Hence, plausible reasoning can provide a practical approach to extend the coverage of knowledge-base of a clinical decision support system by abstracting plausible associations from heath data. However, an effective implementation of plausible reasoning relies on fine-grained conceptual relationships expressing how different concepts are semantically related. The Semantic Web offers effective formalisms to represent semantically annotated knowledge at various levels of expressivity, and to automatically reason over the knowledge and perform semantic analytics based on data. In our research, we investigate the potential of implementing plausible reasoning within the Semantic Web framework to handle the missing knowledge, especially when working with the open-world assumption. We propose a semantics-based data analytics framework, an innovative semantic reasoning method, to investigate certain Description Logic-based reasoning capabilities in the Semantic Web to discover hidden associations. We will evaluate the efficacy of the proposed framework in healthcare to perform effective semantic analytics using partial health data to make better decisions in disease diagnosis and long-term care. We demonstrate the efficiency of SeDan by answering intelligent medical questions posed by BioASQ challenges using Disease ontology, DrugBank and Semantic MEDLINE databases.","venue":"","year":2017.0,"referenceCount":14,"citationCount":0,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"40441600","name":"Hossein Mohammadhassanzadeh"}]},{"paperId":"004369a3fddb26d7a6c0c95f6a14127b831c4815","title":"Semantically Annotating RESTful Services with SWEET","abstract":"This paper presents SWEET: Semantic Web sErvices Editing Tool, the first tool developed for the semi-automatic acquisition of semantic RESTful service descriptions, aiming to support a higher level of automation of common RESTful service tasks, such as discovery and composition.","venue":"","year":2009.0,"referenceCount":10,"citationCount":10,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"2298633","name":"M. Maleshkova"},{"authorId":"1791113","name":"C. Pedrinaci"},{"authorId":"145543299","name":"J. Domingue"}]},{"paperId":"00447a714d2e6da2dd4be16edfa6cd036404b355","title":"INTRODUCTION TO THE SPECIAL ISSUE ON CANADIAN SEMANTIC WEB","abstract":"Since its creation a number of years ago, the World Wide Web has revolutionized the way entertainment, research, and business are conducted in modern society. However, most of the current Web is conceived for human understanding and software applications or agents cannot easily infer the meaning of its content. The Semantic Web, as an extension of the current Web, aims to bring structured data for computer programs to \u201cunderstand\u201d and process. According to Tim Berners-Lee, in this vision, humans and machines will be able to work, reason, and solve complex tasks in cooperation. The Semantic Web is an extension of the current Web which will contain most of human knowledge in a form allowing some automated reasoning services (Berners-Lee, Hendler, and Lassila 2001). It has been described by enthusiasts as the creation of a distributed brain (Fensel and Musen 2001). It is to be based on the Resource Description Framework (RDF) (Lassila and Swick 1999) which grants each possible object a unique identifier: \u201cThe Semantic Web, in naming every concept simply by a Uniform Resource Identifier (URI), lets anyone express new concepts that they invent with minimal effort\u201d (Berners-Lee et al. 2001, 43). RDF further organizes these URIs to allow at least some automated reasoning. Berners-Lee et al. (2001) believe that instead of turning HTML pages into indexes of words, as is currently done, we will turn them into indexes of RDF objects, making the Web \u201cone giant database, rather than one giant book\u201d (Berners-Lee n.d.). This special issue of Computational Intelligence stems from the first Canadian Semantic Web Working symposium held in June 2006 in Qu\u00e9bec City, Qu\u00e9bec, Canada. From this event, a number of expanded and improved versions of papers been selected on the topics of languages, tools, and methodologies for the Semantic Web; Semantic Web-based ontology management and engineering; and practical applications of Semantic Web techniques.","venue":"International Conference on Climate Informatics","year":2007.0,"referenceCount":10,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":"2007-08-01","authors":[{"authorId":"2627440","name":"M. Kone"},{"authorId":"145013136","name":"D. Lemire"}]},{"paperId":"0045b7539ff0c8cece9252f8638339b7e7c17b1d","title":"Retrieval of Semantic Concepts Based on Analysis of Texts for Automatic Construction of Ontology","abstract":null,"venue":"International Conference on Neural Information Processing","year":2012.0,"referenceCount":12,"citationCount":6,"fieldsOfStudy":["Computer Science"],"publicationDate":"2012-11-12","authors":[{"authorId":"1792620","name":"R. Krishnan"},{"authorId":"144664815","name":"A. Hussain"},{"authorId":"1760060","name":"P. Sherimon"}]},{"paperId":"004795752c8d975ccf07c32de6413b38fa75c202","title":"Web s\u00e9mantique et M\u00e9moire d exp\u00e9riences sur l analyse du transcriptome. (Semantic web and experiments memory for the transcriptome analysis)","abstract":"Cette these rentre dans le cadre du projet MEAT (Memoire d\u00b4Experiences pour l\u00b4Analyse du Transcriptome) dont le but est d\u00b4assister les biologistes travaillant dans le domaine des puces a ADN, pour l\u00b4interpretation et la validation de leurs resultats. Nous proposons une aide methodologique et logicielle pour construire une memoire d\u00b4experiences pour ce domaine. Notre approche, basee sur les technologies du web semantique, repose sur l\u00b4utilisation des ontologies et des annotations semantiques sur des articles scientifiques et d\u00b4autres sources de connaissances du domaine. Dans une premiere partie, nous proposons une ontologie modulaire pour la description des connaissances du domaine des puces a ADN (base de donnees d\u00b4experiences, articles scientifiques, entites biomedicales...). Cette ontologie integre entre autres, le reseau semantique deja existant d\u00b4UMLS, ce qui nous a permis d\u00b4approfondir le probleme de reutilisation de ressources termino-ontologiques et leur adaptation a une nouvelle application. Ensuite, nous proposons une methodologie generique pour la generation d\u00b4annotations semantiques basees sur cette ontologie en exploitant les connaissances contenues dans les textes. Cette methodologie a l\u00b4originalite d\u00b4utiliser des techniques de traitement automatique de la langue et des grammaires d\u00b4extraction de relations pour extraire automatiquement des articles scientifiques les relations reliant des termes d\u00b4UMLS reconnus dans le texte. Un systeme supportant cette methodologie a ete implemente et valide par nos collegues biologistes. Enfin, pour faciliter la diffusion des connaissances contenues dans la memoire, nous proposons un prototype qui se base sur un moteur de recherche semantique (Corese) et qui exploite la base d\u00b4annotations que nous avons constituee. Cette partie du travail a permis d\u00b4ameliorer la t\u00e2che de recherche d\u00b4informations en la rendant plus efficace et en offrant des mecanismes de raisonnement sur les connaissances du domaine.","venue":"","year":2006.0,"referenceCount":85,"citationCount":5,"fieldsOfStudy":["Computer Science","Philosophy"],"publicationDate":"2006-04-04","authors":[{"authorId":"2102123003","name":"Khaled Khelif"}]},{"paperId":"0047a6037303cb8507506c260a79bec99d280f21","title":"A survey of ontology learning techniques and applications","abstract":"Abstract Ontologies have gained a lot of popularity and recognition in the semantic web because of their extensive use in Internet-based applications. Ontologies are often considered a fine source of semantics and interoperability in all artificially smart systems. Exponential increase in unstructured data on the web has made automated acquisition of ontology from unstructured text a most prominent research area. Several methodologies exploiting numerous techniques of various fields (machine learning, text mining, knowledge representation and reasoning, information retrieval and natural language processing) are being proposed to bring some level of automation in the process of ontology acquisition from unstructured text. This paper describes the process of ontology learning and further classification of ontology learning techniques into three classes (linguistics, statistical and logical) and discusses many algorithms under each category. This paper also explores ontology evaluation techniques by highlighting their pros and cons. Moreover, it describes the scope and use of ontology learning in several industries. Finally, the paper discusses challenges of ontology learning along with their corresponding future directions.","venue":"Database J. Biol. Databases Curation","year":2018.0,"referenceCount":163,"citationCount":167,"fieldsOfStudy":["Medicine","Computer Science"],"publicationDate":"2018-10-05","authors":[{"authorId":"35637737","name":"M. Asim"},{"authorId":"2113948864","name":"Muhammad Wasim"},{"authorId":"120684987","name":"Muhammad Usman Ghani Khan"},{"authorId":"1768113","name":"Waqar Mahmood"},{"authorId":"79389263","name":"Hafiza Mahnoor Abbasi"}]},{"paperId":"0047ddc07b58512af88d83cccda0f6eb360e0f6f","title":"Exploiting Knowledge Graphs for Facilitating Product\/Service Discovery","abstract":"Most of the existing techniques to product discovery rely on syntactic approaches, thus ignoring valuable and specific semantic information of the underlying standards during the process. The product data comes from different heterogeneous sources and formats giving rise to the problem of interoperability. Above all, due to the continuously increasing influx of data, the manual labeling is getting costlier. Integrating the descriptions of different products into a single representation requires organizing all the products across vendors in a single taxonomy. Practically relevant and quality product categorization standards are still limited in number; and that too in academic research projects where we can majorly see only prototypes as compared to industry. This work presents a cost-effective solution for e-commerce on the Data Web by employing an unsupervised approach for data classification and exploiting the knowledge graphs for matching. The proposed architecture describes available products in web ontology language OWL and stores them in a triple store. User input specifications for certain products are matched against the available product categories to generate a knowledge graph. This mullti-phased top-down approach to develop and improve existing, if any, tailored product recommendations will be able to connect users with the exact product\/service of their choice.","venue":"arXiv.org","year":2020.0,"referenceCount":35,"citationCount":5,"fieldsOfStudy":["Computer Science"],"publicationDate":"2020-10-11","authors":[{"authorId":"152703817","name":"Sarika Jain"}]},{"paperId":"0049d9eecbf5128a1350cf1da5bbd94365ae2302","title":"Fuzzy Taxonomies for Creative Knowledge Discovery","abstract":"A systematic form of creative knowledge discovery is outlined, requiring taxonomies to generalise knowledge structures and mappings between taxonomies to find parallels between knowledge structures from different domains. These share many of the features needed to handle uncertainty in the semantic web, and results will be relevant to the URSW community.","venue":"Uncertainty Reasoning for the Semantic Web","year":2009.0,"referenceCount":12,"citationCount":3,"fieldsOfStudy":["Computer Science"],"publicationDate":"2009-10-26","authors":[{"authorId":"39801345","name":"T. Martin"},{"authorId":"2371847","name":"Siyao Zheng"},{"authorId":"3125072","name":"A. Majidian"}]},{"paperId":"004a3fb49e1fe2e7a05da6b64d54f01afa354c0a","title":"Group matrix factorization for scalable topic modeling","abstract":"Topic modeling can reveal the latent structure of text data and is useful for knowledge discovery, search relevance ranking, document classification, and so on. One of the major challenges in topic modeling is to deal with large datasets and large numbers of topics in real-world applications. In this paper, we investigate techniques for scaling up the non-probabilistic topic modeling approaches such as RLSI and NMF. We propose a general topic modeling method, referred to as Group Matrix Factorization (GMF), to enhance the scalability and efficiency of the non-probabilistic approaches. GMF assumes that the text documents have already been categorized into multiple semantic classes, and there exist class-specific topics for each of the classes as well as shared topics across all classes. Topic modeling is then formalized as a problem of minimizing a general objective function with regularizations and\/or constraints on the class-specific topics and shared topics. In this way, the learning of class-specific topics can be conducted in parallel, and thus the scalability and efficiency can be greatly improved. We apply GMF to RLSI and NMF, obtaining Group RLSI (GRLSI) and Group NMF (GNMF) respectively. Experiments on a Wikipedia dataset and a real-world web dataset, each containing about 3 million documents, show that GRLSI and GNMF can greatly improve RLSI and NMF in terms of scalability and efficiency. The topics discovered by GRLSI and GNMF are coherent and have good readability. Further experiments on a search relevance dataset, containing 30,000 labeled queries, show that the use of topics learned by GRLSI and GNMF can significantly improve search relevance.","venue":"Annual International ACM SIGIR Conference on Research and Development in Information Retrieval","year":2012.0,"referenceCount":29,"citationCount":28,"fieldsOfStudy":["Computer Science"],"publicationDate":"2012-08-12","authors":[{"authorId":"2117951053","name":"Quan Wang"},{"authorId":"2113997965","name":"Zheng Cao"},{"authorId":"2150635498","name":"Jun Xu"},{"authorId":"49404233","name":"Hang Li"}]},{"paperId":"004af9a19a1a2782b3347d161b06b7142799e230","title":"AI approaches to the complexity of legal systems : complex systems, the semantic web, ontologies, argumentation, and dialogue : International Workshops AICOL-I\/IVR-XXIV, Beijing, China, September 19, 2009 and AICOL-II\/JURIX 2009, Rotterdam, the Netherlands, December 16, 2009 : revised selected paper","abstract":"AI Approaches to the Complexity of Legal Systems.- Introduction: Complex Systems and Six Challenges for the Development of Law and the Semantic Web.- I Language and Complex Systems in Law.- As Law Goes By: Topology, Ontology, Evolution.- Sailing the Semantic Seas by Structural Vessels: Problems and Perspectives for the Identification of Implicit Knowledge in the Legal Domain.- Network Analysis of the French Environmental Code.- Model Regularity of Legal Language in Active Modifications.- II Ontologies and the Representation of Legal Knowledge.- Traceability and Change in Legal Requirements Engineering.- When a FrameNet-Style Knowledge Description Meets an Ontological Characterization of Fundamental Legal Concepts.- Application of an Ontology-Based Model to a Selected Fraudulent Disbursement Economic Crime.- Multi-layer Markup and Ontological Structures in Akoma Ntoso.- III Argumentation and Logics.- Prescriptive and Descriptive Obligations in Dynamic Epistemic Deontic Logic.- Lex Minus Dixit Quam Voluit, Lex Magis Dixit Quam Voluit: A Formal Study on Legal Compliance and Interpretation.- IV Dialogue and Legal Multimedia.- Legal Electronic Institutions and ONTOMEDIA: Dialogue, Inventio, and Relational Justice Scenarios.- Mediation, ODR, and the Web 2.0: A Case for Relational Justice.- Legal \"Neutral Dialogue\", Implementing the Work of Bruce Ackerman in the Field of Law.- Legal Multimedia Management through JPEG2000 Framework.","venue":"","year":2010.0,"referenceCount":0,"citationCount":1,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"2084859","name":"Pompeu Casanovas"}]},{"paperId":"004b15441368d39657624e2dc725b1c4781c7352","title":"Approach in High Precision Topic-Specific Resource Discovery on the Web","abstract":"The Internet presents numerous sources of useful information nowadays. However, these resources are drowning under the dynamic Web, so accurate finding userspecific information is very difficult. In this paper we discuss a Semantic Graph Web Search (SGWS) algorithm in topicspecific resource discovery on the Web. This method combines the use of hyperlinks, characteristics of Web graph and semantic term weights. We implement the algorithm to find Chinese medical information from the Internet. Our study showed that it has better precision than traditional IR (Information Retrieval) methods and traditional search engines.","venue":"","year":2004.0,"referenceCount":0,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"1405525367","name":"YeWei-guo"},{"authorId":"1403987387","name":"LuZheng-ding"}]},{"paperId":"004bc337f0a58beebf08519f97023d942dfc05d3","title":"Contemporary Folklore, Internet and Communities at the beginning of the 21st Century","abstract":"Estonian folklorists first became interested in folklore online and archiving that material in the period 1996\u20132002. On the one hand, internet studies were a logical continuation of working with bringing folklore materials online, on the other hand these people were personally interested in following the fast onslaught of internet in Estonia. In the late 1990s, many of the researchers as well as assistants working in the department of folkloristics were actively creators of web interfaces for publishing, learning and teaching folklore (cf K\u00f5iva 2000, 2002, 2003, 2005; K\u00f5iva & Vesik 2002, 2005; K\u00f5iva & Kuperjanov & Vesik 2007). They were aware of what was happening in the web in Estonia. Some of us belonged to an internet community, participated in a chatroom, moderated or posted to a mailing list, was a recognised contributor. For some, work and personal interest coincided.1 The internet has been, from the start, the ideal fieldwork location for folklorists because of the multitude of heritage genres that it carries. Cyberspace was simply an instrument for transmitting the traditions as they stand and it created a lot of new genres or mutations of the old genres. Collective Intelligenceoriented Semantic Web, based on a universal ontology, expressed by an ideographic language, as dreamed P. Levy (2007) was a distant future as well as term like Collective Intelligence Oriented Cyberspace.","venue":"","year":2010.0,"referenceCount":50,"citationCount":6,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"8895288","name":"M. K\u00f5iva"},{"authorId":"2104955649","name":"Liisa Vesik"}]},{"paperId":"004e3292885463f97a70e1f511dc476289451ed5","title":"Quadruplet-Wise Image Similarity Learning","abstract":"This paper introduces a novel similarity learning framework. Working with inequality constraints involving quadruplets of images, our approach aims at efficiently modeling similarity from rich or complex semantic label relationships. From these quadruplet-wise constraints, we propose a similarity learning framework relying on a convex optimization scheme. We then study how our metric learning scheme can exploit specific class relationships, such as class ranking (relative attributes), and class taxonomy. We show that classification using the learned metrics gets improved performance over state-of-the-art methods on several datasets. We also evaluate our approach in a new application to learn similarities between web page screenshots in a fully unsupervised way.","venue":"IEEE International Conference on Computer Vision","year":2013.0,"referenceCount":30,"citationCount":95,"fieldsOfStudy":["Mathematics","Computer Science"],"publicationDate":"2013-12-01","authors":[{"authorId":"2065543878","name":"M. Law"},{"authorId":"1728523","name":"Nicolas Thome"},{"authorId":"51021910","name":"M. Cord"}]},{"paperId":"004f0a9719972c8c104ee4f40c690e14b64bbcc2","title":"Sentiment retrieval on web reviews using spontaneous natural speech","abstract":"This paper addresses the problem of document retrieval based on sentiment polarity criteria. A query based on natural spontaneous speech, expressing an opinion about a certain topic, is used to search a repository of documents containing favorable or unfavorable opinions. The goal is to retrieve documents whose opinions more closely resemble the one in the query. A semantic system based on speech transcripts is augmented with information from full-length text articles. Posterior probabilities extracted from the articles are used to regularize their transcription counterparts. This paper makes three important contributions. First, we introduce a framework for polarity analysis of sentiments that can accommodate combinations of different modalities capable of dealing with the absence of any modality. Second, we show that it is possible to improve average precision on speech transcriptions' sentiment retrieval by means of regularization. Third, we demonstrate the robustness of our approach by training regularizers on one dataset, while performing sentiment retrieval experiments, with substantial gains, on another dataset.","venue":"IEEE International Conference on Acoustics, Speech, and Signal Processing","year":2014.0,"referenceCount":24,"citationCount":11,"fieldsOfStudy":["Computer Science"],"publicationDate":"2014-05-04","authors":[{"authorId":"2107117025","name":"Jose Costa Pereira"},{"authorId":"145114663","name":"J. Luque"},{"authorId":"1727017","name":"Xavier Anguera Mir\u00f3"}]},{"paperId":"00521420b2b354a3225ea4e94d65cd4ed3a8e2b8","title":"Semantic Web may be cancer information's next step forward.","abstract":null,"venue":"Journal of the National Cancer Institute","year":2011.0,"referenceCount":0,"citationCount":5,"fieldsOfStudy":["Medicine","Biology"],"publicationDate":"2011-08-17","authors":[{"authorId":"2110607880","name":"Mike Martin"}]},{"paperId":"00534b22ebd224c6c416883d155bc45633f15dd5","title":"OWL-S and Agent-Based Systems","abstract":null,"venue":"","year":2004.0,"referenceCount":37,"citationCount":11,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"144891293","name":"David L. Martin"},{"authorId":"46607986","name":"M. Burstein"},{"authorId":"1683896","name":"Sheila A. McIlraith"},{"authorId":"2103681682","name":"M. Paolucci"},{"authorId":"9076478","name":"K. Sycara"}]},{"paperId":"005398dc5c19ffe22ca4628778d6da5b8203d243","title":"Querying and Updating a Context-Aware Service Directory in Mobile Environments","abstract":"Several interesting research directions materialize through the convergence of mobile computing and service-oriented computing. As mobile devices keep getting smaller, cheaper and more sophisticated, their use is becoming a commodity. We envision future scenarios that involve mobile devices acting not only as requestors, but as providers of data as well. In order to hide the heterogeneous nature of web data, service-oriented architectures are adopted. Nevertheless, existing service discovery mechanisms usually focus on exact or semantic matching of static attributes, thus ignoring contextual parameters. We argue that context for mobile web services plays an important role in service discovery by increasing the precision and efficiency of the search. We explain our notion of context regarding mobile services and describe query evaluation, updating and merging of context-aware service directories.","venue":"International Conference on Wirtschaftsinformatik","year":2004.0,"referenceCount":15,"citationCount":35,"fieldsOfStudy":["Computer Science"],"publicationDate":"2004-09-20","authors":[{"authorId":"3290035","name":"C. Doulkeridis"},{"authorId":"1690383","name":"M. Vazirgiannis"}]},{"paperId":"0054a554b42d912ce0c7ee457f98367ec383b3c8","title":"Using TRIPLE for business agents on the Semantic Web","abstract":null,"venue":"Electronic Commerce Research and Applications","year":2003.0,"referenceCount":14,"citationCount":9,"fieldsOfStudy":["Computer Science"],"publicationDate":"2003-12-01","authors":[{"authorId":"1681568","name":"Michael Sintek"},{"authorId":"1685642","name":"S. Decker"}]},{"paperId":"005780cb016042cbe335817537b491ef553e609b","title":"The NEPOMUK Semantic Desktop","abstract":null,"venue":"Context and Semantics for Knowledge Management","year":2011.0,"referenceCount":8,"citationCount":13,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"39749950","name":"A. Bernardi"},{"authorId":"35014685","name":"G. Grimnes"},{"authorId":"1778643","name":"T. Groza"},{"authorId":"1705658","name":"S. Scerri"}]},{"paperId":"0057ecf5f1760a048adb3f025e205757e191bf8c","title":"Publishing and consuming geo-spatial and government data on the semantic web","abstract":null,"venue":"","year":2015.0,"referenceCount":0,"citationCount":5,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"1750062","name":"G. Atemezing"}]},{"paperId":"0057fc4d8d95fc04b852a76fa01ba9179a052b4a","title":"Personalized Semantic Resources - The SemComp Project Presentation and Preliminary Works","abstract":"This paper presents the computational aspects of the SemComp project, a multidisciplinary collaboration aiming at observing how interacting with documents acts on knowledge acquisition. It is based on a model for personalized semantic resources inspired from componential linguistics. The paper describes the advances in both the computational model\u2019s definition as well as its implementation in a Web oriented application. Functionalities and technical choices are presented with regards to the expected experiments.","venue":"International Conference on Knowledge Engineering and Ontology Development","year":2013.0,"referenceCount":10,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"1805206","name":"A. Labadi\u00e9"},{"authorId":"36769773","name":"S. Ferrari"},{"authorId":"2061597631","name":"Thibault Roy"}]},{"paperId":"0058dd55cc857ab9990043ce13263ab077365186","title":"Semantics-aware open information extraction in the biomedical domain","abstract":"The increasing amount of biomedical scientific literature published on the Web is demanding new tools and methods to automatically process and extract relevant information. Traditional information extraction has focused on recognizing well-defined entities such as genes or proteins, which constitutes the basis for extracting the relations between the recognized entities. Most of the work has focused on harvesting domain-specific, pre-specified relations, which usually requires manual labor and heavy machinery. The intrinsic features and scale of the Web demand new approaches able to cope with the diversity of documents, where the number of relations is unbounded and not known in advance. This paper presents a scalable method for the extraction of biomedical relations from text. The method is not geared to any specific sub-domain (e.g. protein-protein interactions, drug-drug interactions, etc.) and does not require any manual input or deep processing. Even better, the method uses the extracted relations to infer a set of abstract semantic relations and their signature types, which constitutes a valuable source of knowledge when constructing formal knowledge bases. We enable seamless integration of the extracted relations with the available biomedical resources through the process of semantic annotation. The proposed approach has successfully been applied to the CALBC corpus (i.e. almost a million text documents) and UMLS has been used as knowledge resource for semantic annotation.","venue":"Workshop on Semantic Web Applications and Tools for Life Sciences","year":2011.0,"referenceCount":26,"citationCount":13,"fieldsOfStudy":["Computer Science"],"publicationDate":"2011-12-07","authors":[{"authorId":"143633410","name":"V. Nebot"},{"authorId":"1730216","name":"Rafael Berlanga Llavori"}]},{"paperId":"0059630ed02ae2ad97bcbd59f0fad69ddd721dcf","title":"Was CIMI too early? Dublin Core and Museum Information: metadata as cultural heritage data","abstract":"In 2000, CIMI reported on the use of Dublin Core metadata in the museum context and proposed a broader set of elements for museums. This paper examines that decision in the light of developments in the DCMES and reaches a different conclusion. \n \nThe conclusion is based on experience with a virtual museum of Indigenous culture when metadata application profiles and schema cross-walks were available, unlike when CIMI investigated the same issue. In particular, it is now possible to use rich descriptions (data) and Semantic Web technologies and maintain the interoperability of Dublin Core metadata.","venue":"Dublin Core Conference","year":2005.0,"referenceCount":35,"citationCount":5,"fieldsOfStudy":["Computer Science"],"publicationDate":"2005-09-12","authors":[{"authorId":"1679632","name":"L. Nevile"},{"authorId":"2649817","name":"Sophie Lissonnet"}]},{"paperId":"005a08524e309ef170161fd7f072d10c6c692efe","title":"IMPROVING WEB SERVICE CLUSTERING THROUGH POST FILTERING TO BOOTSTRAP THE SERVICE DISCOVERY","abstract":"Web service clustering is one of a very efficient approach to discover Web services efficiently. Current approaches use similarity-distance measurement methods such as string-based, corpus-based, knowledge-based and hybrid methods. These approaches have problems that include discovering semantic characteristics, loss of semantic information, shortage of high-quality ontologies and encoding fine-grained information . Thus, the approaches couldn\u2019t identify the correct clusters for some services and placed them in wrong clusters. As a result of this, cluster performance is reduced. This paper proposes post-filtering approach to increase the performance of clusters by rearranging services incorrectly clustered. Our approach uses context aware similarity method that learns domain context by machine learning to produce models of context for terms retrieved from the Web in the filtering process to calculate the service similarity. We applied post filtering approach to hybrid term similarity based clustering approach that we proposed in our previous work. Experimental results show that our post-filtering approach works efficiently.","venue":"","year":2014.0,"referenceCount":37,"citationCount":3,"fieldsOfStudy":["Computer Science"],"publicationDate":"2014-07-01","authors":[{"authorId":"2336961","name":"B. Kumara"},{"authorId":"1714346","name":"Incheon Paik"},{"authorId":"2526308","name":"K. Koswatte"},{"authorId":"2111704521","name":"Wuhui Chen"}]},{"paperId":"005a27c882de0957499e7273304cd39581aff740","title":"SPEWS: A Framework for the Performance Analysis of Web Services Orchestrated with BPEL4WS","abstract":"This paper addresses quality of service aspects of Web Services (WS) orchestrations created using the Business Process Execution Language for Web Services (BPEL4WS). BPEL4WS is a promising language describing the WS orchestrations in form of Business Processes, but it lacks of a sound formal semantic, which hinders the formal analysis and verification of business processes specified in it. Formal methods, like Petri Nets (PN), may provide a means to analyse BPEL4WS processes, evaluating its performance, detecting weaknesses and errors in the process model already at design-time. A framework for transformation of BPEL4WS into Generalized Stochastic Petri Nets (GSPN) is proposed to analyse the performance and throughput of WS, based on the execution of orchestrated processes.","venue":"2009 Fourth International Conference on Internet and Web Applications and Services","year":2009.0,"referenceCount":7,"citationCount":7,"fieldsOfStudy":["Computer Science"],"publicationDate":"2009-05-24","authors":[{"authorId":"2725500","name":"Henrique Jorge A. Holanda"},{"authorId":"47519840","name":"G. Barroso"},{"authorId":"3353794","name":"A. Serra"}]},{"paperId":"005ac3b7d37f19b7192284f8d4765985deb51a94","title":"HPL ALGORITHM FOR SEMANTIC INFORMATION RETRIEVAL WITH RDFAND SPARQL","abstract":"As the web composed with lots of unstructured data, retrieving the accurate information for the user's posed query from it is a critical issue. Most of the search engines are fails to achieve the accurate outcomes for the users. In order to overcome this and to obtain efficient results, SPARQL query language is used to convert users\u2019 posed natural language queries to machine understandable format. Semantic web technology based on SPARQL is used to acquire useful information from the RDF knowledge base, which gives beneficial information to the user. In this paper, HPL algorithm is effectively utilized to aware of querying the semantic web. It also makes use of Linked Open Data Quality Assessment (LODQA) system to perform a semantic search that converts normal user defined queries into machine understandable formal logic. By combining both these systems, the interpretation of a natural language query into SPARQL queries is made easy that grabs knowledge from ontological database that are stored in Resource Description Framework. Accordingly, technologies and data storage possibilities are analyzed and evaluated to retrieve accurate results and a test case for the career opportunities for students.","venue":"","year":2017.0,"referenceCount":17,"citationCount":2,"fieldsOfStudy":["Computer Science"],"publicationDate":"2017-10-16","authors":[{"authorId":"9311011","name":"Prathyusha Kanakam"},{"authorId":"35753614","name":"S. M. Hussain"},{"authorId":"143941313","name":"D. Suryanarayana"}]},{"paperId":"005b30ffad30050181b0be07ba27a7f8c2be301c","title":"What is your Web 5.0 strategy","abstract":"Purpose \u2013 The worldwide web continues to evolve as a key capability for commercial and human interactions. This paper lays out how the web is likely to evolve and key capabilities businesses must harness to realize the future value of the web.Design\/methodology\/approach \u2013 The article defines five stages of evolution of the web. Web 1.0 was primarily a publishing and transactional environment. Web 2.0 as a space where users co\u2010create value. Web 3.0 as a semantic space where machine intelligence combines with human intelligence to create new insights. Web 4.0 as a mobile space where users and real and virtual objects are integrated together to create value. Web 5.0 a sensory emotive space where we are able to move the web from an emotionally flat environment to a space of rich interactions. The article outlines how companies must adapt to each stage.Findings \u2013 The article presents clear reasons for why the web might evolve across these five stages and what businesses must focus on to harness the web.Origina...","venue":"","year":2008.0,"referenceCount":3,"citationCount":55,"fieldsOfStudy":["Computer Science"],"publicationDate":"2008-10-31","authors":[{"authorId":"1723259","name":"A. Kambil"}]},{"paperId":"005e58c00a4b965f94576807f1cd336f59a607b6","title":"ALAN MODEL\u0130N\u0130N POL\u0130T\u0130KA KULLANILARAK K\u0130\u015e\u0130SELLE\u015eT\u0130R\u0130LMES\u0130 PERSONALIZING DOMAIN MODEL BY USING POLICY","abstract":"Gunumuzde, cevrimici olarak erisilen bilgi ustsel olarak artmaktadir. Bilgi miktarindaki bu artis, kullanicilarin tercihleri ile uyumlu bilgiye etkin bir sekilde erismesini zorlastirmaktadir. Bu zorluklar, kisisellestirme yaklasimi kullanilarak, bireye ozel bilginin ya da servisin sunulmasi ile asilabilir. Kisisellestirme yaklasiminin temeli, kisiye ozel bilgiyi temsil eden profil yapisidir. Kullanici-uyarlanabilir bir sistemde, profil tipine ozgu bir aramanin sonucunda, kullanici ihtiyaclarina gore kisisellestirilmis sonuclara ulasilacaktir. Bu calismada, kisisel icerigin sunulmasi amaci ile anlamsal olarak zengin profiller olusturulmakta ve gelistirilen kullanici profilleri, politikalar ile entegre edilerek kural-tabanli bir kisisellestirme saglanmaktadir. Boylelikle, profili temel alan kisitlar yardimi ile kisisellestirilmis bilgiye erisim etkin bir sekilde gerceklestirilecektir. Nowadays, the information that can be accessed online is increasing exponentially. However, this increase in the amount of information brings difficulties to users to access information relevant with their preferences in an effective way. These difficulties could be overcomed with providing customized information or service to an individual by using personalization approach. Profiling is the basis of personalization approach and the representation of person specific information. In a user-adaptive system, personalized results will be reached according to the user's needs after a profile specific search. In this work, semantically rich profiles are created to present personal context and developed user profiles are integrated with policies to provide a rule-based personalization. Thus, personalized information will be achieved in an effective way through profile based constraints. Anahtar kelimeler: Kisisellestirme, Kullanici modelleme, Profil, Politika yonetimi, Ontoloji, Anlamsal web","venue":"","year":2015.0,"referenceCount":28,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"2944393","name":"\u00d6zg\u00fc Can"},{"authorId":"2598690","name":"Okan Bursa"},{"authorId":"2963862","name":"M. \u00dcnalir"}]},{"paperId":"005f40afd9b882fd09acfe42a4480e2536f521fd","title":"Semantic Tools for Workflow Construction","abstract":null,"venue":"International Conference on Conceptual Structures","year":2006.0,"referenceCount":13,"citationCount":4,"fieldsOfStudy":["Computer Science"],"publicationDate":"2006-05-28","authors":[{"authorId":"1865626","name":"O. Habala"},{"authorId":"2673727","name":"M. Babik"},{"authorId":"1744707","name":"L. Hluch\u00fd"},{"authorId":"1751605","name":"M. Laclavik"},{"authorId":"145092163","name":"Z. Balogh"}]},{"paperId":"005f931cdb46e75ed18b98f6e925981b34b577dc","title":"Rough Set Theory and Granular Computing","abstract":null,"venue":"","year":2003.0,"referenceCount":3,"citationCount":112,"fieldsOfStudy":["Mathematics"],"publicationDate":"2003-05-01","authors":[{"authorId":"1681731","name":"M. Inuiguchi"},{"authorId":"1724805","name":"S. Tsumoto"},{"authorId":"1732173","name":"S. Hirano"}]},{"paperId":"005fe3df9608742b2a82ea387c727374365e05dd","title":"An Information Retrieval-Based Approach to Table-Based Question Answering","abstract":null,"venue":"Natural Language Processing and Chinese Computing","year":2017.0,"referenceCount":18,"citationCount":3,"fieldsOfStudy":["Computer Science"],"publicationDate":"2017-11-08","authors":[{"authorId":"3299718","name":"Junwei Bao"},{"authorId":"46429989","name":"Nan Duan"},{"authorId":"143849609","name":"M. Zhou"},{"authorId":"145382463","name":"T. Zhao"}]},{"paperId":"00600fab364b5c12dcae7e5e77981aad6ad5d741","title":"Quantitative analysis concerning the Relationships and Roles of Pronouns in Movie and Theater Critiques","abstract":"\u8a55\u5224\u5206\u6790\u306a\u3069\u304c\u81ea\u7136\u8a00\u8a9e\u51e6\u7406\u6280\u8853\u306b\u3088\u3063\u3066\u9032\u3081\u3089\u308c\u3066\u3044\u308b\u304c,\u5bfe\u8c61\u306f\u4e3b\u306bWeb\u4e0a\u306e\u30c6\u30ad\u30b9\u30c8\u3067\u3042\u308a,\u4eba\u6587 \u5b66\u7684\u306a\u6279\u8a55\u6587\u306f\u305d\u306e\u4e3b\u305f\u308b\u5bfe\u8c61\u3068\u306a\u3063\u3066\u3044\u306a\u3044.\u672c\u7814\u7a76\u3067\u306f\u4eba\u6587\u7684\u306a\u6279\u8a55\u6587\u306e\u5177\u4f53\u7684\u6279\u8a55\u5bfe\u8c61\u3092\u8a08\u91cf\u5316 \u3059\u308b\u3053\u3068\u3067,\u6279\u8a55\u884c\u70ba\u306e\u3088\u308a\u6df1\u3044\u610f\u5473\u5206\u6790\u306b\u5411\u3051\u3066\u306e\u57fa\u790e\u56fa\u3081\u3092\u884c\u3046.\u7dcf\u5408\u7684\u82b8\u8853\u4f5c\u54c1\u3067\u3042\u308b\u6620\u753b\u3068\u6f14\u5287\u306e \u6279\u8a55\u6587\u3092\u5bfe\u8c61\u3068\u3057\u3066,\u62bd\u51fa\u5bfe\u8c61\u3092\u4eba\u540d\u3068\u4f5c\u54c1\u540d\u306b\u7d5e\u308a\u5206\u6790\u3092\u884c\u3063\u305f.\u7d50\u679c\u3068\u3057\u3066\u983b\u5ea6\u5206\u6790\u3068\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u5206\u6790 \u3067\u6279\u8a55\u306b\u304a\u3051\u308b\u4eba\u7269\u306e\u91cd\u8981\u6027\u3084\u30b0\u30eb\u30fc\u30d7\u306e\u50be\u5411,\u4ed6\u5206\u91ce\u3068\u306e\u95a2\u308f\u308a\u306e\u76f8\u9055\u304c\u660e\u3089\u304b\u3068\u306a\u3063\u305f.\u307e\u305f\u30b9\u30bf\u30c3\u30d5 \u306e\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u306e\u5229\u7528\u306b\u3088\u308a,\u8a9e\u3089\u308c\u308b\u56fa\u6709\u540d\u8a5e\u306e\u6279\u8a55\u6587\u4e2d\u3067\u306e\u610f\u5473\u3068\u6a5f\u80fd\u306e\u50be\u5411\u304c\u62bd\u51fa\u3055\u308c\u305f. Although reputation analyses have been developed utilizing NLP technology, such studies have focused on web texts. Critiques with the humanities have not been regarded as primary targets for such analyses. The purpose of this study is to establish a basis for the deep semantic analysis of critiques. Movie and theater critiques, which are complete pieces of artistic output, were targeted, and all names, both for individuals and works, were extracted for analysis. As a result, the influence of certain individuals, the trends of certain factions and relationships to other genres were revealed through frequency and network analyses. Moreover, the semantic and functional characteristics of pronouns within the critiques were extracted by using a database of personnel.","venue":"","year":2012.0,"referenceCount":1,"citationCount":1,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"3302331","name":"H. Murai"},{"authorId":"32857584","name":"Takanori Kawashima"},{"authorId":"70284414","name":"Akira Kudou"}]},{"paperId":"00619fb2eddb6d68fb49b4add17979a82d40b7ba","title":"A Chinese Framework of Semantic Taxonomy and Description: Preliminary Experimental Evaluation Using Web Information Extraction","abstract":null,"venue":"Knowledge Science, Engineering and Management","year":2015.0,"referenceCount":10,"citationCount":1,"fieldsOfStudy":["Computer Science"],"publicationDate":"2015-10-28","authors":[{"authorId":"3162795","name":"Liangjun Zang"},{"authorId":"2116104066","name":"Weimin Wang"},{"authorId":"2115809864","name":"Ya Wang"},{"authorId":"36595248","name":"Fang Fang"},{"authorId":"48319843","name":"Cong Cao"},{"authorId":"2109210733","name":"Xiaolong Wu"},{"authorId":"2118294240","name":"Qi Zhou"},{"authorId":"2115686471","name":"Ye Lu"},{"authorId":"2118549996","name":"Tingyu Li"},{"authorId":"1712626","name":"C. Cao"}]},{"paperId":"00625d5a14ed086b21be7477f8be41d436039fdb","title":"Supply Chain Risk Management: Annotation of Knowledge Using a Semi-Structured Knowledge Model","abstract":null,"venue":"","year":2009.0,"referenceCount":25,"citationCount":2,"fieldsOfStudy":["Computer Science"],"publicationDate":"2009-12-01","authors":[{"authorId":"1678775","name":"Chun-Che Huang"},{"authorId":"5025994","name":"T. Tseng"}]},{"paperId":"0062b049a0e601c3cf77b3ed3755a50bdf1647f4","title":"Semantic Web Based Relational Database Access With Conflict Resolution","abstract":"SEMANTIC WEB BASED RELATIONAL DATABASE ACCESS WITH CONFLICT RESOLUTION. by FAYEZ KHAZALAH August 2015 Advisor: Dr. Zaki Malik Major: Computer Science Degree: Doctor of Philosophy This thesis focuses on (1) accessing relational databases through Semantic Web technologies and (2) resolving conflicts that usually arises when integrating data from heterogeneous source schemas and\/or instances. In the first part of the thesis, we present an approach to access relational databases using Semantic Web technologies. Our approach is built on top of Ontop framework for Ontology Based Data Access. It extracts both Ontop mappings and an equivalent OWL ontology from an existing database schema. The end users can then access the underlying data source through SPARQL queries. The proposed approach takes into consideration the different relationships between the entities of the database schema when it extracts the mapping and the equivalent ontology. Instead of extracting a flat ontology that is an exact copy of the database schema, it extracts a rich ontology. The extracted ontology can also be used as an intermediary between a domain ontology and the underlying database schema. Our approach covers independent or master entities that do not have foreign references, dependent or detailed entities that have some foreign keys that reference other entities, recursive entities that contain some self references, binary join entities that relate two entities","venue":"","year":2015.0,"referenceCount":104,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"3338551","name":"Fayez Khazalah"}]},{"paperId":"0063058aa8c1667e4933270e0f0d428e06324e8c","title":"Towards Semantic Data Mining","abstract":". Incorporating domain knowledge is one of the most challenging problems in data mining. The Semantic Web technologies are promising to o\ufb00er solutions to formally capture and e\ufb03ciently use the domain knowledge. We call data mining technologies powered by the Semantic Web, capable of systematically incorporating domain knowledge, the semantic data mining . In this paper, we identify the importance of semantic annotation \u2014a crucial step towards realizing semantic data mining by bringing meaning to data, and propose a learning-based semantic search algorithm for annotating (semi-) structured data.","venue":"","year":2010.0,"referenceCount":10,"citationCount":29,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"2109501657","name":"Haishan Liu"}]},{"paperId":"00644f39c068816334ad69f975438d006502efaa","title":"Ontology-driven mindmapping","abstract":"Mindmaps have been a popular means for intuitive and user-friendly conceptual modeling for several years. This paper proposes a mindmapping tool driven by semantic web ontologies that allows to assign meanings to the mindmap nodes and, even more importantly, guide the user through mindmap creation by proposing ontological concepts and roles relevant to each mindmap node. The tool is backed by OWL ontologies that allow to capture domain knowledge semantics precisely and rigorously. The tool is being developed as a part of the MONDIS project aimed at efficient knowledge management of immovable cultural heritage failures records. As such, the tool is currently used by civil engineering experts for collaborative authoring of structural damage records.","venue":"International Conference on Semantic Systems","year":2012.0,"referenceCount":15,"citationCount":7,"fieldsOfStudy":["Engineering","Computer Science"],"publicationDate":"2012-09-05","authors":[{"authorId":"1796645","name":"P. Kremen"},{"authorId":"2016330","name":"Pavel Micka"},{"authorId":"2109247","name":"Miroslav Blasko"},{"authorId":"2105765407","name":"M. Sm\u00edd"}]},{"paperId":"00645cc9af10eddcaac48e2f04b04fe24aa0766d","title":"Abstracts","abstract":"Intuitionistic fuzzy information aggregation theory and applications, by Zeshui Xu and Xiaoqiang Cai, Beijing, Science Press, 2012, xi + 309 pp., ISBN 978-7-03-033321-6 and Heidelberg, Springer, ISBN 978-3-642-29583-6 This is the first monograph that contains a thorough and systematic introduction to intuitionistic fuzzy aggregation methods, the correlation, distance and similarity measures of intuitionistic fuzzy sets, and various decision-making models and approaches based on the above-mentioned information processing tools. Through numerous practical examples, it offers researchers and professional in the field of fuzzy mathematics, information fusion and decision analysis, the most recent research results developed by the authors. Possibility theory and the risk, by Irina Georgescu, Berlin, Springer, 2012, xii + 124 pp., ISBN 978-3-642-24739-2 This rather small monograph deals with risk analysis in the context of economic and business activities. Its focus is on using theory of graded possibilities. However, an extensive comparison of the various features of the possibilistic formalization with their traditional probabilistic counterparts is also covered. A special attention is given to possibilistic formalization of risk aversion, an important feature of risk analysis in the areas of economics and business. Fuzzy knowledge management for the semantic web, by Zongmin Ma, Fu Zhang, Li Yan, and Jingwei Cheng, Heidelberg, Springer, 2014, xi + 275 pp., ISBN 978-3-642-39282-5 This book goes to great depth concerning the fast growing topic of technologies and approaches of fuzzy logic in the Semantic Web. The topics of this book include fuzzy description logics and fuzzy ontologies, queries of fuzzy description logics and fuzzy ontology knowledge bases, extraction of fuzzy description logics and ontologies from fuzzy data models, storage of fuzzy ontology knowledge bases in fuzzy databases, fuzzy Semantic Web ontology mapping, and fuzzy rules and their interchange in the Semantic Web. The book aims to provide a single record of current research in the fuzzy knowledge representation and reasoning for the Semantic Web. The objective of the book is to provide the state of the art information to researchers, practitioners and graduate students of the Web intelligence and at the same time serve the knowledge and data engineering professional faced with non-traditional applications that make the application of conventional approaches difficult or impossible. Fuzzy social choice theory, edited by Michael B. Gibilisco, Annie M. Gowen, Karen E. Albert, John Mordeson, Mark J. Wierman, and Terry D. Clark, Cham, Springer, 2014, xviii + 185 pp., ISBN 978-3-319-05175-8 This book offers a comprehensive analysis of the social choice literature and shows, by applying fuzzy sets, how the use of fuzzy preferences, rather than that of strict ones, may affect the social choice theorems. To do this, the book explores the presupposition of rationality within the fuzzy framework and shows that the two conditions for rationality, completeness and transitivity, do exist with fuzzy preferences. Specifically, this book examines: the conditions under which a maximal set exists; Arrow\u2019s theorem; the Gibbard\u2013Satterthwaite International Journal of General Systems 121","venue":"","year":2015.0,"referenceCount":0,"citationCount":0,"fieldsOfStudy":null,"publicationDate":"2015-01-02","authors":[]},{"paperId":"006512c1962036196ef51f8170aa324fa82f909c","title":"KQA: A Knowledge Quality Assessment Model for Clinical Decision Support Systems","abstract":"Informatics researchers have developed many methods for using computers to utilize knowledge in decision making in the form of clinical decision support systems (CDSSs). These systems can enhance human decision making in the healthcare domain. The knowledge acquisition bottleneck is one of the well-known issues in developing knowledge-based systems such as CDSS. It can be considered as a flow of knowledge from different knowledge sources to the main system. Most existing methods for extracting knowledge from knowledge resources suffer from the lack of a proper mechanism for extracting high-quality knowledge. In this paper, we propose a framework to discover high-quality knowledge by utilizing Semantic Web technologies.","venue":"Medinfo","year":2018.0,"referenceCount":29,"citationCount":3,"fieldsOfStudy":["Computer Science","Medicine","Business"],"publicationDate":"2018-01-06","authors":[{"authorId":"8671965","name":"S. Zolhavarieh"},{"authorId":"47522124","name":"D. Parry"}]},{"paperId":"0068ab13d8db151d38c42a864ecfc5211ddab122","title":"COPOMBOCY: A COVID-19 Pandemic Ontology Model of Bogor City","abstract":"Coronavirus Disease of 2019 (COVID-19) has become a global health problem along with a declaration by the World Health Organization (WHO) on March 11, 2020, which declared it a pandemic. COVID-19 has spread to almost all countries, including Indonesia. Data related to the COVID-19 pandemic is complex and heterogeneous. To generate and maintain knowledge that is semantically stored in it, knowledge modeling is necessary to be done. This study aims to develop a model of knowledge about the COVID-19 pandemic in Bogor City in the form of ontology. The scope of knowledge includes the distribution of agents, close contact tracing, COVID-19 transmission, diagnosis, disease, type of illness, location, Large-Scale Social Restrictions (Pembatasan Sosial Berskala Besar [PSBB]) implementation, PSBB sanctions, statistics, status, symptoms, test processes, test results, and color zones. Data were obtained from the Bogor City COVID-19 Task Force, COVID-19 Information & Coordination Center of West Java Province (Pusat Informasi & Koordinasi COVID-19 Provinsi Jawa Barat [PIKOBAR]), Covid19.go.id, literature review, interview with epidemiologist, and reuse of knowledge from existing ontologies. The result of this study is an ontology in the Web Ontology Language (OWL) format consisting of 88 classes, 29 object properties, 48 property data, 2103 axioms, and 229 individuals. The test results on the built ontology were successful in answering 85.7% of non-expert questions and 71.4% of expert questions. Overall, the ontology built successfully answered 78.6% of the questions about the COVID-19 pandemic in Bogor City. The ontology has been published so that it is publicly available and is still being developed to accommodate the latest data.","venue":"International Conference on Computer, Control, Informatics and its Applications","year":2021.0,"referenceCount":11,"citationCount":0,"fieldsOfStudy":["Medicine"],"publicationDate":"2021-10-05","authors":[{"authorId":"40809120","name":"F. A. Setiawan"},{"authorId":"2154316855","name":"Dendy Murdani"},{"authorId":"2075636991","name":"Freza Riana"},{"authorId":"2091008787","name":"Eny Dwimawati"}]},{"paperId":"0068d995285a5b34f789f4ce75a24158eb504ee5","title":"Proceedings of the International Workshop on Enterprise Interoperability (IWEI 2008)","abstract":"One of the trends in the global market is the increasing collaboration among enterprises. Constant changes in inter- and intra-organizational environment will persist in the future. Organizations have to flexibly and continuously react to (imminent) changes in markets and trading partners. Large companies but also SMEs have to cope with internal changes from both a technical (e.g. new information, communication, software and hardware technologies) and an organizational point of view (e.g. merging, re-organization, virtual organizations, etc.). In this context, the competitiveness of an enterprise depends not only on its internal performance to produce products and services but also on its ability to seamlessly interoperate with other enterprises. External and internal collaborative work needs more interoperable solutions. \n \nThe International Workshop on Enterprise Interoperability, IWEI, aims at identifying and discussing challenges and solutions with respect to enterprise interoperability, both at the business and the technical level. The workshop promotes the development of a scientific foundation for specifying, analyzing and validating interoperability solutions; an architectural framework for addressing interoperability problems from different viewpoints and at different levels of abstraction; a maturity model to evaluate and rank interoperability solutions with respect to distinguished quality criteria; and a working set of practical solutions and tools that can be applied to interoperability problems to date. \n \nIWEI organized by the IFIP Working Group 5.2 on Enterprise Interoperability. The aim of IFIP WG5.2 is to progress and disseminate research and development results in the area of enterprise interoperability. The IWEI workshop is therefore also a platform where ideas emerged from IFIP WG5.2 meetings can be discussed, or reversely, where issues raised at the workshop can be taken to the IFIP community for further contemplation and investigation. \n \nThis volume contains the proceedings of the first edition of the workshop, IWEI 2008, held on September 18, 2008, in Munich, Germany, in conjunction with the 12th IEEE International EDOC Conference \u2013 The Enterprise Computing Conference (EDOC 2008). Nine papers were selected for oral presentation and publication, based on a thorough review process, in which each paper was reviewed by several experts in the field. The papers are representative for the current research activities in the area of enterprise interoperability. For convenience, the papers were grouped in 4 sessions, reflecting some of the major topics related to enterprise interoperability, namely Session 1 - Ontologies and the semantic web; Session 2 - Service-orientation; Session 3 - Inter-organizational interoperability; and Session 4 - Maturity models.","venue":"","year":2008.0,"referenceCount":0,"citationCount":0,"fieldsOfStudy":["Engineering"],"publicationDate":null,"authors":[{"authorId":"1679024","name":"M. V. Sinderen"},{"authorId":"49368775","name":"Pontus Johnson"},{"authorId":"2826277","name":"L. Kutvonen"}]},{"paperId":"00691bc506661ca932509f9ef012ee5d98d8bd3c","title":"Large scale link based latent Dirichlet allocation for web document classification","abstract":"In this paper we demonstrate the applicability of latent Dirichlet allocation (LDA) for classifying large Web document collections. One of our main results is a novel influence model that gives a fully generative model of the document content taking linkage into account. In our setup, topics propagate along links in such a way that linked documents directly influence the words in the linking document. As another main contribution we develop LDA specific boosting of Gibbs samplers resulting in a significant speedup in our experiments. The inferred LDA model can be applied for classification as dimensionality reduction similarly to latent semantic indexing. In addition, the model yields link weights that can be applied in algorithms to process the Web graph; as an example we deploy LDA link weights in stacked graphical learning. By using Weka\u2019s BayesNet classifier, in terms of the AUC of classification, we achieve 4% improvement over plain LDA with BayesNet and 18% over tf.idf with SVM. Our Gibbs sampling strategies yield about 5-10 times speedup with less than 1% decrease in accuracy in terms of likelihood and AUC of classification.","venue":"arXiv.org","year":2010.0,"referenceCount":35,"citationCount":8,"fieldsOfStudy":["Computer Science"],"publicationDate":"2010-06-25","authors":[{"authorId":"2085585799","name":"Istv\u00e1n B\u00edr\u00f3"},{"authorId":"17104318","name":"J. Szab\u00f3"}]},{"paperId":"006a5deac992bdeeeaea793d4f65edf53f5c776f","title":"Proceedings of the 8th International Workshop on Ontology Matching co-located with the 12th International Semantic Web Conference (ISWC 2013), Sydney, Australia, October 21, 2013","abstract":null,"venue":"Organizational Memories","year":2013.0,"referenceCount":0,"citationCount":2,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[]},{"paperId":"006bcc388ed59cf74a5622a43be4c9fb5fa2098a","title":"Web People Search via Connection Analysis","abstract":"Nowadays, searches for Webpages of a person with a given name constitute a notable fraction of queries to web search engines. Such a query would normally return Webpages related to several namesakes, who happened to have the queried name, leaving the burden of disambiguating and collecting pages relevant to a particular person (from among the namesakes) on the user. In this article we develop a Web People Search approach that clusters Webpages based on their association to different people. Our method exploits a variety of semantic information extracted from Web pages, such as named entities and hyperlinks, to disambiguate among namesakes referred to on the Web pages. We demonstrate the effectiveness of our approach by testing the efficacy of the disambiguation algorithms and its impact on person search.","venue":"IEEE Transactions on Knowledge and Data Engineering","year":2008.0,"referenceCount":50,"citationCount":93,"fieldsOfStudy":["Computer Science"],"publicationDate":"2008-11-01","authors":[{"authorId":"1818681","name":"D. Kalashnikov"},{"authorId":"2144298585","name":"Zhaoqi Chen"},{"authorId":"144156242","name":"S. Mehrotra"},{"authorId":"1402921915","name":"Rabia Nuray-Turan"}]},{"paperId":"006d057bebbd4adabf31cc1ee1f732c446169b25","title":"Une approche orient\u00e9e service pour la recherche s\u00e9mantique de contenus multim\u00e9dias. (An oriented service approach for semantic search of multimedia contents)","abstract":"Les sources de donnees multimedias provenant de divers domaines (medical, tourisme, commerce, art et culture, etc.) sont devenues incontournables sur le web. L\u2019acces a ces sources multimedias dans les systemes distribues pose de nouveaux problemes en raison de nombreux parametres : volumetrie, diversite des interfaces, format de representation, localisation, etc. En outre, l\u2019exigence de plus en plus forte des utilisateurs et des applications a vouloir integrer la semantique dans la recherche d\u2019information pose de nouvelles questions a resoudre. Pour prendre en compte cette nouvelle complexite, nous nous interessons dans notre travail de recherche aux solutions d\u2019integration de donnees basees sur les services web. Dans cette these, nous proposons une approche orientee service pour la recherche semantique de contenus multimedia. Nous avons appele cette approche SeSaM (Semantic Search of Multimedia content). SeSaM repose sur la definition d\u2019un nouveau type de services accedant aux contenus multimedias, qui est les services MaaS (Multimedia as a Services). Elle est basee sur un processus en deux phases : description et decouverte des services MaaS. En ce qui concerne la description de services MaaS, nous avons defini le langage SA4MaaS (Semantic Annotation for MaaS services), qui est une extension de SAWSDL (recommandation W3C). L\u2019idee principale de ce langage est l\u2019integration, en plus de la semantique metier, de la semantique de l\u2019information multimedia dans la description des services MaaS. En ce qui concerne la decouverte de services MaaS, nous avons propose un nouveau matchmaker MaaS-MX (MaaS services Matchmaker) adapte au modele de description des MaaS. MaaS-MX est compose de deux etapes primordiales : appariement metier et appariement multimedia. L\u2019appariement metier consiste a comparer la description metier des services et de la requete, tandis que l\u2019appariement multimedia compare la description multimedia des services et de la requete. L\u2019approche a ete prototypee et evaluee dans deux domaines differents : medical et tourisme. Les resultats indiquent que l\u2019utilisation de l\u2019appariement metier et l\u2019appariement multimedia a considerablement ameliore les performances des systemes de recherche de donnees multimedias.","venue":"","year":2017.0,"referenceCount":73,"citationCount":0,"fieldsOfStudy":["Computer Science","Sociology"],"publicationDate":"2017-07-08","authors":[{"authorId":"52646068","name":"S. Midouni"}]},{"paperId":"006ea9bb7981201afe81b8850a77ceaed33c18ba","title":"WonderWeb: Ontology Infrastructure for the Semantic Web","abstract":null,"venue":"","year":2004.0,"referenceCount":29,"citationCount":68,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"1745369","name":"R. Volz"},{"authorId":"1789102","name":"S. Handschuh"},{"authorId":"1752093","name":"Steffen Staab"},{"authorId":"144446653","name":"R. Studer"}]},{"paperId":"006f4dc5072e65aa111b11132ea8a08c2a98091f","title":"Designing a Prototype Architecture for Crowdsourcing Language Resources","abstract":"We present an architecture for crowdsourcing language resources from language learners and a prototype implementation of it as a vocabulary trainer. The vocabulary trainer relies on lexical resources from the ConceptNet semantic network to generate exercises while using the learners\u2019 answers to improve the resources used for the exercise generation. 2012 ACM Subject Classi\ufb01cation Information systems \u2192 Web services","venue":"International Conference on Language, Data, and Knowledge","year":2019.0,"referenceCount":15,"citationCount":9,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"2701374","name":"Christos T. Rodosthenous"},{"authorId":"3277474","name":"V. Lyding"},{"authorId":"153745766","name":"Alexander Koenig"},{"authorId":"66095353","name":"J. Horba\u010dauskien\u0117"},{"authorId":"22287358","name":"Anisia Katinskaia"},{"authorId":"1798642","name":"U. Hassan"},{"authorId":"3449811","name":"Nicos Isaak"},{"authorId":"1764422","name":"Federico Sangati"},{"authorId":"2668168","name":"Lionel Nicolas"}]},{"paperId":"00703826e6f2dcdb36d9f4747680870a37fc1a5b","title":"Spatio-temporal Information Management Platform for Digital Agriculture","abstract":"Many spatio-temporal data in digital agriculture dispersedly loacated in isomerous systems which had different standards,terms,models and analytic methods.Based on spatio-temporal reasoning,ontologies,semantic Web and expert system technology,a spatio-temporal information management platform for digital agriculture was built.It was used for concentrated management of multi-source and isomerous agriculture spatio-temporal data and analytic methods.Building digital agriculture application systems becames more easier and expeditious with the platform.","venue":"","year":2007.0,"referenceCount":0,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"47472446","name":"Liu Jie"}]},{"paperId":"007053cdd01667e3579841fe6312b08cc55ada57","title":"IBM Research Report Service Oriented File Systems","abstract":"Service Oriented Architectures (SOAs) are a loose coupling of network services providing methods for systems development and integration. Interoperability be-tween different systems and programming languages is provided via communication protocols and well de\ufb01ned messages. The recent development trend has been to favor RESTful approaches for these interfaces, which encode relevant context and semantic metadata into the URL of an HTTP GET or PUT operation. We observe that this approach is essentially a sim-pli\ufb01ed web-instantiation of synthetic \ufb01le system based service interfaces, such as those originally pioneered by UNIX and later the Plan 9 and Inferno operating systems. In this paper we advocate the collapse of the software stack by abstracting the underlying transport and naming details, and accessing RESTful services via standard \ufb01le system interfaces. We explore the research challenges and opportunities presented by taking such an approach to building comprehensive dynamic distributed systems appropriate for large scale cloud computing.","venue":"","year":2009.0,"referenceCount":21,"citationCount":0,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"3160421","name":"E. V. Hensbergen"},{"authorId":"40258594","name":"N. Evans"},{"authorId":"1401754647","name":"Phillip Stanley-Marbell"}]},{"paperId":"007076440f62cf068abcf81b0ddf74beccdfdec6","title":"Semantic Attributes for Citation Relationships: Creation and Visualization","abstract":null,"venue":"International Conference on Metadata and Semantics Research","year":2017.0,"referenceCount":10,"citationCount":6,"fieldsOfStudy":["Computer Science"],"publicationDate":"2017-11-28","authors":[{"authorId":"145183217","name":"S. Parinov"}]},{"paperId":"0070eb5bf75933f35a6a0fcea67fcdaf7c489c06","title":"JTOWL: A JSON to OWL Converto","abstract":"JSON is a popular web data interchange format in Internet, especially for Social Network applications. To process these current JSON data sets using Semantic Web technologies, we should firstly convert them into well-defined semantic description languages, such as OWL. In this paper, we propose a method, which can automatically convert related JSON data sets into OWL ontology. This method can extend data semantics using semantic reasoning and combine multiple related resources into a unique ontology. The constructed semantic data contains concepts, properties, constrains and values which are implied in JSON object. We develop the method as a JSON to OWL convertor JTOWL that can process web data resources and create semantic data effectively.","venue":"Web-KR '14","year":2014.0,"referenceCount":4,"citationCount":8,"fieldsOfStudy":["Computer Science"],"publicationDate":"2014-11-03","authors":[{"authorId":"2065767","name":"Yuangang Yao"},{"authorId":"3077661","name":"R. Wu"},{"authorId":"49957841","name":"Hui Liu"}]},{"paperId":"0072df95da657b5aaed776564a1b11269699aecd","title":"Use of Ontologies in Pervasive Computing Environments","abstract":"Pervasive Computing Environments consist of a large number of independent entities that help transform physical spaces into computationally active and intelligent spaces. These entities could be devices, applications, services or users. In recent years, advances in middleware have enabled the different entities to interact with each other. However, it is still difficult to assure that independent entities can understand the \u201csemantics\u201d of the environment and other entities when they interact with each other. To tackle this problem, we have used semantic web technologies to attach semantics to various concepts in Pervasive Environments. We have developed ontologies to describe different aspects of these environments. Ontologies have been used to make information systems more usable. They allow different entities to have a common understanding of various terms and concepts and smoothen their interaction. They enable semantic discovery of entities, allowing requests to be semantically matched with advertisements. The ontologies also describe the different kinds of operations an entity supports like asking queries and sending commands. This makes it easier for autonomous entities to interact with one another. It also allows the generation of intelligent user interfaces that allow humans to interact with these entities easily. The ontologies also allow external agents (such as new entities that enter the environment or entities that access the environment over the web) to easily interact with the environment. Finally, we use ontologies coupled with description logic to ensure that the system is always in a consistent state. This helps the system meet various security and safety constraints. We have incorporated the use of ontologies in our framework for pervasive computing, GAIA [63]. While we have used ontologies in the pervasive computing scenario, many of the issues tackled are applicable to any distributed system or multi-agent system.","venue":"","year":2003.0,"referenceCount":72,"citationCount":7,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"1866054","name":"R. McGrath"},{"authorId":"1751349","name":"A. Ranganathan"},{"authorId":"143775101","name":"R. Campbell"},{"authorId":"145211762","name":"M. D. Mickunas"}]},{"paperId":"00746adbd0f26db995ed3ee4cffe2e9ac15d516f","title":"6S: Adding a Semantic Model to 5S Framework","abstract":"\u2014in this paper we proposed new model for digital library which is an extension for the 5S Model to include the semantic web layer in the structure of digital library to be 6S model for digital library. We also discuss the important role of semantic web in digital library and how are semantic web technologies affect the information retrieval accuracy. We represent the semantic layer in 6S Model by adding ontology to a digital library that satisfies the 5S model and enhance ontology by updating it automatically. This ontology is used in books classification and retrieval according to concepts in ontology .","venue":"","year":2016.0,"referenceCount":13,"citationCount":0,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"2286173956","name":"Heba Mahmoud"},{"authorId":"2286353488","name":"Neama Mathematics"},{"authorId":"51249763","name":"Computer Science"},{"authorId":"2286353472","name":"Yasser. F. Hassan Mathematics"},{"authorId":"2286368558","name":"Mohamed Kholef"}]},{"paperId":"00759347f6d5dd633eeb7e85af699846b6c3a98f","title":"Expectation and Layer Model of Semantic Web","abstract":null,"venue":"","year":2005.0,"referenceCount":0,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":"2005-10-26","authors":[{"authorId":"34636567","name":"T. Hagino"}]},{"paperId":"007642c5eb38143a67317c10e81fceefd2ad5fe2","title":"Large-scale Evaluation of Context Matching","abstract":"Context matching algorithms automatically discover semantic relations between two autonomously developed conceptual representations of two overlapping domains. Although significant work has been carried on the theoretical ground, the empirical evaluation of matching algorithms is still an open area for research. In this paper we introduce CTXMATCH, a matching algorithm which applies to symbolic based conceptual representations organized as a hierarchy of concepts. Typical examples of such conceptualizations are electronic market catalogs (e.g., UNSPSC and eCl@ss) and web directories (e.g., Google and Yahoo!). Then, we report on different evaluation experiments, that have been carried out with two main purposes: we wanted to evaluate the CTXMATCH algorithm in real, large scale scenarios and to test different evaluation methodologies. Results are to be considered as a first contribution toward shared evaluation practices and resources for context matching algorithms.","venue":"","year":2007.0,"referenceCount":13,"citationCount":3,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"1712352","name":"B. Magnini"},{"authorId":"145077583","name":"Manuela Speranza"}]},{"paperId":"00765152e922f9618504c6146cb77395d335adca","title":"On Enterprise Information System Research Trend\u2014Based on the Keywords Frequency Analysis of Journal EIS 2007-2015","abstract":"The journal of Enterprise Information Systems (EIS) was founded in 2007 by Taylor & Francis, selected by the Web of Science Citation Index Expanded in 2008, and included in EI. The research collects 219 papers published in the EIS from 2007 to 2015, and explores valuable information such as the present situation and hotspot trends in the research of the enterprise information systems by extracting and analyzing the keyword of those papers. Finally, we analyze and comment on 9 related papers with considering the trends: enterprise architecture, cloud computing services, ontology and semantic, data science and social networking, enterprise integration and systems science. The research can help relevant scholars to understand EIS research situation, and have a mind to EIS research trends.","venue":"","year":2016.0,"referenceCount":10,"citationCount":2,"fieldsOfStudy":["Computer Science"],"publicationDate":"2016-04-13","authors":[{"authorId":"40557054","name":"Jiangping Wan"},{"authorId":"6704844","name":"Qiaowen Jiang"}]},{"paperId":"00771221dc5b782c04667ef82ab261693880f11f","title":"Modeling semantic information in engineering applications: a review","abstract":null,"venue":"Artificial Intelligence Review","year":2011.0,"referenceCount":88,"citationCount":9,"fieldsOfStudy":["Computer Science"],"publicationDate":"2011-05-04","authors":[{"authorId":"1759237","name":"Kunmei Wen"},{"authorId":"144498187","name":"Yong Zeng"},{"authorId":"1773599","name":"Ruixuan Li"},{"authorId":"2144906481","name":"J. Lin"}]},{"paperId":"007739c20a84a60f69c4973c5d3c505de4d25dbc","title":"Reliable Semantic Systems for Decision Making: Defining a Business Rules Ontology for a Survey Decision System","abstract":null,"venue":"","year":2016.0,"referenceCount":17,"citationCount":3,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"69901669","name":"Pavani Akundi"}]},{"paperId":"00775a8dc1ed51cd4b4624284ec424a784312d8b","title":"Ontology Evaluation \u2013 Comprising Verification and Validation","abstract":"As ontologies became widely used methodology for knowledge representation, as well as foundation for Semantic Web, a question of their evaluation increased even more. Various methods and techniques for ontology evaluation have been already proposed, some concerned with their taxonomy and others with their content. In this paper several ontology evaluation methods are used together with purpose of showing how both important parts of evaluation, verification and validation, can be comprised. The usage of multiple independent evaluation methods ensures development of a consistent and usable ontology.","venue":"","year":2008.0,"referenceCount":17,"citationCount":33,"fieldsOfStudy":["Computer Science"],"publicationDate":"2008-07-23","authors":[{"authorId":"2632643","name":"S. Lovren\u010di\u0107"},{"authorId":"2811164","name":"M. Cubrilo"}]},{"paperId":"00775b89200e27fa81072aa03bc01b521a45d1dd","title":"Semantic Web Search System Founded on Case-Based Reasoning and Ontology Learning","abstract":null,"venue":"International Joint Conference on Knowledge Discovery, Knowledge Engineering and Knowledge Management","year":2010.0,"referenceCount":24,"citationCount":1,"fieldsOfStudy":["Computer Science"],"publicationDate":"2010-10-25","authors":[{"authorId":"1878146","name":"H. B. Zghal"},{"authorId":"2670687","name":"Nesrine Ben Mustapha"},{"authorId":"1403825873","name":"Manel Elloumi-Chaabene"},{"authorId":"115149242","name":"Antonio Moreno"},{"authorId":"50714906","name":"D. S\u00e1nchez"}]},{"paperId":"0077ac14726ad3218e194e6f1983ffd28acdf5d7","title":"The architecture and industry applications of web security in static and dynamic analysis","abstract":"Purpose \u2013 The purpose of this paper is to propose a metadata\u2010driven approach and the associated technologies to deal with ever\u2010rising web security issue. The approach applies metadata techniques to envision semantic validation for new types of vulnerability.Design\/methodology\/approach \u2013 Token decomposition design was applied to move analysis work into abstract level. This novel approach can solve the issues by using a dual control method to perform vulnerability validation.Findings \u2013 Current analysis has been lack in metadata foundation, the vulnerability is invisible due to semantic obfuscation. This paper reflects the limitation of existing methods. It applies metadata\u2010driven approach to move physical and syntax analysis into semantic validation.Research limitations\/implications \u2013 Currently, certain difficulties may be encountered in preparing benchmarking for dual control process before completing development work. However, this paper tries to create scenarios which can be a reference, to evaluate the ...","venue":"Journal of Systems and Information Technology","year":2010.0,"referenceCount":18,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":"2010-05-04","authors":[{"authorId":"2257407092","name":"Raymond Wu"},{"authorId":"48960563","name":"M. Hisada"}]},{"paperId":"00786223a23b7ac0221878c0204a1f830d51a273","title":"A Survey on Integrating Wireless Body Area Network Sensor Data with Semantic Web Technologies","abstract":". Wireless body area network (WBAN) is a subset of the wireless sensor network (WSN). WBAN has a vital role in technology for remotely monitoring human physiological changes in healthcare. Many applications for wearable and plantable devices have used WBAN. Most wearable devices are designed with several sensors to monitor various aspects of the body. A problem of interoperability in WBAN sensor data arises from the many sensing devices from several manufacturers, which may be operating at different frequencies and generating data in various types of formats. The heterogeneous nature of the WBAN sensor data limits the sharing and integration of other clinical data. There are several proposed approaches to address the challenges of the interoperability of the WBAN sensor. This paper presents a systematic review of some of the sensor data interoperability approaches using semantic web technology. The knowledge in this paper is to provide a background for further investigations in the use of semantic web technologies for WBAN data integration.","venue":"","year":null,"referenceCount":47,"citationCount":0,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"2121831469","name":"Joy Alatta"},{"authorId":"2169699256","name":"Joseph Cann"}]},{"paperId":"00787a55d5e71b7596fd426b3b96ef46e22350a6","title":"Virtual, augmented, and mixed reality-based learning systems: personalisation framework","abstract":"The paper is aimed to analyse the problem of personalisation of Virtual Reality\/Augmented Reality\/Mixed Reality (VR\/AR\/MR) based learning systems. Research results are two-fold: first, the results of systematic literature review are presented, and, second, VR\/AR\/MR-based learning systems personalisation framework is proposed. First of all, systematic literature review on research topic was conducted in Thomson Reuters Web of Science database and applying Semantic Scholarsearch tool. The review revealed that strides are being made in education using VR\/AR\/MR, although much needs to be done. The possibilities of VR\/AR\/MR application in education seem to be endless and bring many advantages to students of all ages. Few are creating content that may be used for educational purposes, with most advances being made in the entertainment industry, but many understand and realise the future and importance of education applying VR\/AR\/MR. Manystudies argue that new VR\/AR\/MR-based learning systems are more effective in comparison with traditional ones. Teachers and students like learning content and activities provided by VR\/AR\/MR technologies. On the other hand, although the concept of VR\/AR\/MR has already been proposed more than 20 years ago, most applications are still limited to simple visualisation of virtual objects onto spatially limited scenes, and the developed systems did not pass the barrier of\u00a0 demonstration prototypes. Many authors agree that personalisation of VR\/AR\/MR-based learning platforms should be further analysed. Original personalisation framework of VR\/AR\/MR-based learning systems is also presented in the paper. According to the framework, personalisation of VR\/AR\/MR learning systems should be based on applying learners models and intelligent technologies e.g. expert evaluation, ontologies, recommender systems, software agents etc. This pedagogically sound personalisation framework is aimed to improve learning quality and effectiveness.","venue":"","year":2016.0,"referenceCount":0,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":"2016-12-20","authors":[{"authorId":"1997294614","name":"Viktorija Dvareckien\u0117"},{"authorId":"1881181","name":"E. Kurilovas"},{"authorId":"2773215","name":"T. Jevsikova"}]},{"paperId":"00793996726e5f898b54d7a10c11956c638becb9","title":"Aero: An Evidence-based Semantic Web Knowledge Base of Cancer Behavioral Risk Factors","abstract":". The general public\u2019s awareness of cancer behavioral risk factors (CBRFs) is poor; and even when they are aware, they lack the necessary knowledge towards a healthy lifestyle. Given that 72% adult internet users in the United States searched online for health information, the Internet is a great venue to disseminate CBRF information. However, existing CBRF information online is poorly organized, not evidenced-based, and confusing to health information consumers. In this paper, we present a prototype semantic web c A ncer b E hav-ioral R isk kn O wledgebase\u2014 Aero to (1) better organize and provide evidence-based CBRF knowledge extracted from scientific literature (i.e., PubMed), and (2) provide users with access to high-quality scientific knowledge, yet easy to understand answers for their frequently encountered CBRF questions. Our current prototype focuses on the top 4 types of CBRFs: smoking, alcohol drinking, physical activity, and overweight. We manually annotated 59 high-quality Pub-Med abstracts (i.e., review articles with impact factor >= 8) and created a prelim-inary version of Aero with 787 triples. We built an interactive user interface with graph-based visualization of the KB, where users can explore answers to commonly asked CBRF questions according to the cancer risk factor fact sheet of National Cancer Institute. A preliminary evaluation of Aero was also conducted.","venue":"SEPDA@ISWC","year":2019.0,"referenceCount":16,"citationCount":3,"fieldsOfStudy":["Computer Science","Psychology"],"publicationDate":null,"authors":[{"authorId":"2119077928","name":"Hansi Zhang"},{"authorId":"153003061","name":"Xing He"},{"authorId":"28172175","name":"Tyler R. Harrison"},{"authorId":"152441499","name":"J. Bian"}]},{"paperId":"0079e0a8d2cd652faaf7bd8a5308dc819869e030","title":"Supporting application development in the semantic web","abstract":"The Semantic Web augments the current WWW by giving information a well-defined meaning, better enabling computers and people to work in cooperation. This is done by adding machine understandable content to Web resources. Such added content is called metadata, whose semantics is provided by referring to an ontology---a domain's conceptualization agreed upon by a community. The Semantic Web relies on the complex interaction of several technologies involving ontologies. Therefore, sophisticated Semantic Web applications typically comprise more than one software module. Instead of coming up with proprietary solutions, developers should be able to rely on a generic infrastructure for application development in this context. We call such an infrastructure Application Server for the Semantic Web whose design and development are based on existing Application Servers. However, we apply and augment their underlying concepts for use in the Semantic Web and integrate semantic technology within the server itself. The article discusses requirements and design issues of such a server, presents our implementation KAON SERVER and demonstrates its usefulness by a detailed scenario.","venue":"TOIT","year":2005.0,"referenceCount":63,"citationCount":74,"fieldsOfStudy":["Computer Science"],"publicationDate":"2005-05-01","authors":[{"authorId":"3101108","name":"Daniel Oberle"},{"authorId":"1752093","name":"Steffen Staab"},{"authorId":"144446653","name":"R. Studer"},{"authorId":"1745369","name":"R. Volz"}]},{"paperId":"0079f00acce0fcab9acc617b8b78202c2aaaa3b1","title":"User Web Usage Mining for navigation improvisation using semantic related frequent patterns","abstract":"Web sites have abundant web usage log which provides useful information that can be used for user navigation improvisation. Traditional web site does not use this rich web usage data for any investigation. It can be used to generate efficient frequent patterns which can support in user navigation improvisation. It can also be help in re-organizing web site for efficient navigation. In this paper we propose a frequent pattern generation approach using semantic relations with user web usage data. The quality of web usage pattern generated is measured with standards methods for evaluation. Experiment results show that more precise presentation using user pattern generation can improve user navigation measures.","venue":"International Conference on Computing and Communication Technologies","year":2014.0,"referenceCount":21,"citationCount":1,"fieldsOfStudy":["Computer Science"],"publicationDate":"2014-12-01","authors":[{"authorId":"2285384351","name":"Mr. N.P.Jilhedar"},{"authorId":"2285372832","name":"M. E. Student"},{"authorId":"2285318696","name":"Dr. S. K. Shirgave"}]},{"paperId":"007af8c8851f2d141cb0c02fc982f3dde5ac2ff0","title":"Fusing Textual and Visual Ontology with \u201cK-means Algorithm\u201d for Improving Retrieval Accuracy using Voting Annotation Technique","abstract":"Now a days the popularity of digital images increases due to the improving digital imaging technologies and convenient availability facilitated by the internet. So to find user intended images from internet is very difficult. It is an important issue that how to retrieve the images accurately on the world-wide web. This paper presents an advanced framework for web image retrieval search engine which relay not only on ontology to discover the semantic relationship between different keywords inside the web page but also propose a new voting annotation technique extract the shared semantically related keywords from different web pages to eliminate and solve the problem of subjectivity of image annotation of traditional approaches and enhance the performance of the retrieval results by taking the semantic of the correlated data into consideration. The proposed approach is not used only to enhance the retrieval accuracy of web images; but also able to annotated the unlabelled images and try to narrow the semantic gap problem and enhance the retrieval by fusing two basic modalities of web images.","venue":"","year":2013.0,"referenceCount":23,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":"2013-02-28","authors":[{"authorId":"70041791","name":"Miss. Pallavi H. Dhole"},{"authorId":"69966639","name":"A. B. Gadicha"}]},{"paperId":"007b0cc6fd20bf1b01fb1350f4d7cdb262bc076e","title":"Mining large amount of short text data in your desktop","abstract":"This work describes the classification of texts as being either crime-related or non-crime-related. Given the spontaneity and popularity of Twitter, we collected some posts related to crime and criminology, in the state of Sao Paulo-SP Brazil. However, this data set is not a collection of crime reports. As the web language is characterized by diversity including flexibility, spontaneity and informality we need a classification rule to filter the documents which really are in the context. The proposed methodology works in a two-step framework. In the first step, we partition the text database into smaller data sets which define text collections with characteristics (not necessarily directly observable) which allow a better classification process. This enables the usage of parallel computing which decreases the time process required for the technique execution. Later on, each subset of the data induces a distinct classification rule with a Supervised Machine Learning technique. For the sake of simplicity, we work with KMeans and KMedoids and linear SVM. We will present our results in terms of speed and classification accuracy using various feature sets, including semantic codes. Analysis with distinct classifier induction techniques as Random Forest, Logistic Regression, and Boosting is also provided. An application with a huge data set of 1,600,000 tweets written in English proofs the method's efficiency.","venue":"","year":2019.0,"referenceCount":51,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":"2019-06-27","authors":[{"authorId":"2107384634","name":"L. Santos"}]},{"paperId":"007b4421e0bdf6d55f022a9a107053410714d012","title":"Syntactico-Semantic Reasoning using PCFG, MEBN & PP Attachment Ambiguity","abstract":"Probabilistic context free grammars (PCFG) have been the core of the probabilistic reasoning based parsers for several years especially in the context of the NLP. Multi entity Bayesian networks (MEBN) a First Order Logic probabilistic reasoning methodology is widely adopted and used method for uncertainty reasoning. Further upper ontology like Probabilistic Ontology Web Language (PR-OWL) built using MEBN takes care of probabilistic ontologies which model and capture the uncertainties inherent in the domain's semantic information. The paper attempts to establish a link between probabilistic reasoning in PCFG and MEBN by proposing a formal description of PCFG driven by MEBN leading to the usage of PR-OWL modeled ontologies in PCFG parsers. Furthermore, the paper outlines an approach to resolve the prepositional phrase (PP) attachment ambiguity using the proposed mapping between PCFG and MEBN.","venue":"International Congress on Information and Communication Technology","year":2018.0,"referenceCount":16,"citationCount":3,"fieldsOfStudy":["Computer Science"],"publicationDate":"2018-09-20","authors":[{"authorId":"51309749","name":"Shrinivasan Patnaikuni"},{"authorId":"1892846","name":"S. Gengaje"}]},{"paperId":"007b9649f040bd8f9f67f3688c1726f4a8b008bb","title":"Extending OWL for QoS-based Web Service Description and Discovery","abstract":"1 Main Theme of Thesis Web Services (WSs) are modular, self-describing, loosely-coupled, platform and programming language-agnostic software applications that can be advertised , located and used across the Internet. They are viewed as one of the promising technologies that could help business entities to automate their operations on the web on a large scale by automatic discovery and consumption of services. Based on the above reasons, the WS paradigm is being adopted by many companies and individuals and many WSs are being deployed and running. However, as all of these WSs are advertised in a UDDI-based repository, an unavoidable fact as UDDI is a de-facto standard, the problem of discovering them based on a requester's functional needs becomes crucial. UDDI uses a syntax-based approach for WS description leading to purely syntactic discovery efforts returning imprecise and inaccurate results. OWLS [OWL-S Coalition 2003] and similar joint Semantic Web and WS efforts solve the problem of syntactic WS description by using ontologies for describing WSs. Ontologies provide meaning to concepts and relationships between them, leading to semantic WS Discovery algorithms, which provide more precise and accurate results. But even if all the advertised WSs satisfying a requester's functional needs are returned, many results may be produced. So a non-functional concept is needed that will differentiate between the functionally equivalent WS advertisements. This concept is quality of service (QoS). QoS is closely related with the performance of a WS as well as with other features of a WS that bear on its ability to satisfy stated or implied needs. Therefore it has a substantial impact on users' expectations from a service. Thus WS descriptions must be enhanced with QoS descriptions. Additionally, WS discovery algorithms should perform QoS-based matchmaking and selection in order to produce fewer ranked results. Unfortunately, all the current research efforts fail in correctly describing QoS for WSs. Semantics seems to be missing from the QoS description of a WS leading to purely syntactic QoS-based WS matchmaking and selection algorithms. But even if semantics is introduced, QoS description is not rich enough and not quite extensible. So the main issue of this PhD thesis is the rich, extensible, and semantic description of QoS for WSs. Additionally, new QoS-based WS matchmaking and selection algorithms must be devised or the current best should be extended in order to take advantage of this enhanced semantic QoS description.","venue":"","year":2005.0,"referenceCount":12,"citationCount":4,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"1718383","name":"K. Kritikos"}]},{"paperId":"007bad53bdb294a5c597e9ce5c5d1297a9b29392","title":"QoS Driven Service Discovery Method Based on Extended UDDI","abstract":"The inclusion of QoS in Web service has been pointed out in previous work in both academia and industry. Challenge in this area addresses importance of QoS. This paper proposes a QoS driven service discovery method based on extended UDDI with the help of Semantic Web. First, a Extending UDDI Model based on QoS driven is proposed, QoS ontology is analyzed to reduce misunderstanding. Second, a matching algorithm based on fuzzy correlation calculate is proposed to filter the unqualified service to improve the discovery accuracy. Third, a discovery process based on policy is build based on Semantic Web technology. The experience results show the QoS driven Web service discovery method possesses high discovery accuracy.","venue":"International Conference on Computing, Networking and Communications","year":2007.0,"referenceCount":12,"citationCount":16,"fieldsOfStudy":["Computer Science"],"publicationDate":"2007-08-24","authors":[{"authorId":"50702712","name":"Wenli Dong"}]},{"paperId":"007ef8592d179865b66089b1281cec5bcc2d049d","title":"A Survey on Ontology-Based Systems to Support the Prospection, Diagnosis and Treatment of Breast Cancer","abstract":"In a scenario where there is a huge amount of available data sources, the Semantic Web has played a key role in sharing, retrieval, selection, and combination of data organized in various formats. The storage and retrieval of medical images manipulated by systems that support breast cancer detection can take great advantage from the use of such technology. In this paper we present a comprehensive study on ontology-based systems that support the manipulation of medical images related to breast cancer, identifying the main features of each approach.","venue":"Brazilian Symposium on Information Systems","year":2016.0,"referenceCount":45,"citationCount":1,"fieldsOfStudy":["Computer Science"],"publicationDate":"2016-05-17","authors":[{"authorId":"73300162","name":"Cassia Isac"},{"authorId":"41192458","name":"J. Viterbo"},{"authorId":"144889626","name":"A. Conci"}]},{"paperId":"007f4dab7f33597586df19482f3098a08562bea9","title":"Semiotic Web for Translational Medicine","abstract":"The semiotic web for translational medicine generalizes the concept of the semantic web. We present the functions of the semiotic web as a simple ontology with three dimensions, namely: (a) the four steps of semiotics, (b) the two processes in semiotics, and (c) the four types of research. The resulting 32 combinations represent all its functions.","venue":"AMIA ... Annual Symposium proceedings. AMIA Symposium","year":2008.0,"referenceCount":3,"citationCount":4,"fieldsOfStudy":["Medicine","Computer Science"],"publicationDate":"2008-11-01","authors":[{"authorId":"144718518","name":"A. Ramaprasad"},{"authorId":"144293352","name":"V. Kashyap"}]},{"paperId":"007fd13d71372400a692c509d478bef62953ba06","title":"Text-Mining-Methoden im Semantic Web","abstract":null,"venue":"HMD Praxis der Wirtschaftsinformatik","year":2010.0,"referenceCount":16,"citationCount":1,"fieldsOfStudy":["Political Science","Computer Science"],"publicationDate":"2010-02-01","authors":[{"authorId":"145353908","name":"Gerold Schneider"},{"authorId":"2057211643","name":"Heinrich Zimmermann"}]},{"paperId":"00818b8d642ae8f338d20a03239b59d0bc1198f2","title":"for Chemical Genomics","abstract":"Semantic Web has been often suggested as the information technology solution to the growing problem in managing the millions of data points generated by modern science such as nanotechnology and high through-put screening for drugs. However, the progress towards this vision envisaged by the W3C has been very limited. Here we discuss \u2013some of the obstacles to the realization of this vision and we make some suggestions as to how one may overcome some of these hurdles? Here we discuss some of these issues and present thoughts on an alternative method to Semantic Web that is less drastic in requirements. This method does not require the use of RDF and Protege, and it works in an environment currently used by the chemical and biological database providers. In our method one attempts to use as many components as possible from the tools already used by the database providers and one brings in far fewer new tools and techniques compared to the method that use RDF or Prot\u00e9g\u00e9. Our method uses a standard database environment and web tools rather than the RDF and Prot\u00e9g\u00e9 to manage user interface and the data is held in a database rather than using RDF. This method shifts the task of building Semantic knowledge-base and ontology from RDF and Prot\u00e9g\u00e9 to a SQL based database environment.","venue":"","year":2013.0,"referenceCount":11,"citationCount":1,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"145506090","name":"T. Bhat"}]},{"paperId":"0082de4e035ec24f49c05ed9832d263f4801e903","title":"Multimedia ontology population through semantic analysis and hierarchical deep features extraction techniques","abstract":null,"venue":"Knowledge and Information Systems","year":2022.0,"referenceCount":67,"citationCount":7,"fieldsOfStudy":["Computer Science"],"publicationDate":"2022-04-25","authors":[{"authorId":"2166065656","name":"Michela Muscetti"},{"authorId":"33163897","name":"A. Rinaldi"},{"authorId":"47565094","name":"Cristiano Russo"},{"authorId":"34832112","name":"C. Tommasino"}]},{"paperId":"0082f40592206093d88eb523aa05d84abe3caae4","title":"In Search of a Semantic Book Search Engine on the Web: Are We There Yet?","abstract":null,"venue":"Computer Science On-line Conference","year":2016.0,"referenceCount":28,"citationCount":8,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"51453868","name":"Irfan Ullah"},{"authorId":"3351931","name":"Shah Khusro"}]},{"paperId":"0083321e8dca5363f7f14c19ccd817d9d346366c","title":"Conceptual Dynamism in Terminological Knowledge Bases: The Case of Ecolexicon","abstract":"The new conceptual-linguistic shift in terminology has given rise to a new approach, focused on discourse and the real use of terms in texts. This change of paradigm has led to a significant improvement in the content of terminolo\u00adgical knowledge bases. However, the most innovative aspect of knowledge modeling lies in the wide-ranging use of ontologies. This provides ter\u00adminology with greater semantic expressiveness. The presentation of the environmental knowledge base, EcoLexicon, developed at the Universi\u00addad de Granada, by the research group, EcoLexicon. In order to obtain the maximum benefit from the application of ontologies, a closed inventory of conceptual relations is proposed along with their combinatorial poten\u00adtial. Accordingly, the result is a domain-specific representation, restricted by context. The method is based on data extracted from a corpus of texts compiled for this research, the concepts in the domain are classified accor\u00adding to their typology and relational potential. The characteristics applied are those of the Web Ontology Language (OWL) to make inferences (e.g. the transitivity of metonymy). The definition of conceptual relations, de\u00adpending on the nature of the concepts, offers a quantitative solution that limits excess information, and at the same time, offers a qualitative solution for knowledge acquisition. EcoLexicon successfully combines terminology with the expressive capacity of ontologies, which in the future will help to define search systems adapted to different user groups. \nReceived: 03-03-10 \/ Accepted: 30-04-10 \nHow to reference this article: \nHien, A. (2010). Dinamismo conceptual en las bases de conocimiento terminol\u00f3gico: el caso de EcoLexicon. \u00cdkala, 15(2), 43 \u2013 72.","venue":"Ikala: Revista de Lenguaje y Cultura","year":2010.0,"referenceCount":0,"citationCount":1,"fieldsOfStudy":["Computer Science"],"publicationDate":"2010-09-09","authors":[{"authorId":"2176862","name":"P. Faber"},{"authorId":"2061115401","name":"P. Le\u00f3n"}]},{"paperId":"0084dd13fdee7d4df4b5ec9a68e023e77e5ca3b0","title":"Time-Related Patient Data Retrieval for the Case Studies from the Pharmacogenomics Research Network","abstract":null,"venue":"Journal of medical systems","year":2012.0,"referenceCount":16,"citationCount":3,"fieldsOfStudy":["Medicine","Computer Science"],"publicationDate":"2012-02-01","authors":[{"authorId":"144307126","name":"Qian Zhu"},{"authorId":"145723023","name":"C. Tao"},{"authorId":"144481316","name":"Ying Ding"},{"authorId":"1792682","name":"C. Chute"}]},{"paperId":"0085e943cbc0cd47c4b50db8a4df2a75030b13dc","title":"\u201cIs This A Joke?\u201d: A Large Humor Classification Dataset","abstract":"Humor is an essential characteristic of language. It has been a topic of research in linguistics and philosophy from historical times. In computer science, computational humor, as a part of Natural Language Processing, is a growing area of research. Social Media is rapidly growing as a platform for communication but processing of social media, owing to its semantic perplexity, is still a challenge. These two facts lead us to present a novel dataset for humor classi\ufb01cation which captures diversity in humor on web resources. The large size of this dataset is to meet the data requirements for modern machine learning algorithms. This paper also deals with creating a model for detecting and analyzing humor in social media text extracted from eclectic sources on the Internet.","venue":"ICON","year":2018.0,"referenceCount":41,"citationCount":1,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"72664146","name":"Faraz Faruqi"},{"authorId":"2254294009","name":"Manish Shrivastava"}]},{"paperId":"008635aa10ab40a0dbe2c6f5f03891906a7dad23","title":"Grounding Web Services Semantically: Why and How?","abstract":"Recent modeling frameworks for semantically enriched web services propose a layered architecture of different functionalities and representations. For discovery, selection, and composition of web services, an adequate semantic representation and a transport layer are (among others) necessary elements [1]. The semantic layer takes care of a shared understanding between requester and provider in order to enable automatic service provisioning. The most current approaches propose to utilize ontologies for this task [2]. The far end with respect to semantics is the transport layer, which specifies the details of how to access and communicate with the service implementation on a technical level. In order to invoke a service both layers need to be connected for data hand over between each other. This requires a mapping from an abstract semantical model to a concrete service specification in terms of a particular protocol, message format, data types, and serialization. We argue, that this bi-directional mapping, also called grounding, cannot be done syntactically as proposed by the OWL-S [3] service framework for example. This problem of linking declaratively specified parameter descriptions with primitive types (XML Schema in case of WSDL [4]) largely has been neglected in current semantic web services frameworks. In order not to limit the portability and practicability of current framework specifications we aim to bring this issue to the fore. In the following we will describe the mismatch of syntax-based groundings and propose a semantic mapping framework for which we refer to an existing algorithm and shortly describe our mapping editor","venue":"","year":2005.0,"referenceCount":5,"citationCount":5,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"2104685149","name":"Konstantin Pantschenko"},{"authorId":"1759117","name":"Olaf Noppens"},{"authorId":"2476801","name":"Thorsten Liebig"}]},{"paperId":"0086a768df2d1a43a9d145b8a720bae9956faef1","title":"Research on Converged Service Composition Based on Extending CSTA Services with OWL-S","abstract":"Automatic service composition converging these two services in telecom and web realm can hardly achieved by far inasmuch as the absent semantic services interface defined with WSDL. In this paper, after analyzing the shortcoming of these existing description technologies of web services and telecommunication services, we put forward an extending method via enriching the content of OWL-S Profile document with OWL-S to CSTA services specified in ECMA specifications, and an improved algorithm of forward chaining automatic service composition to facilitate the converged service composition between network services and telecommunication services. The proposed technique is applied to an automatic stock quote scenario and composition results are presented demonstrating the rationality of these proposed ideas.","venue":"International Conference on Wireless Communications, Networking and Mobile Computing","year":2009.0,"referenceCount":11,"citationCount":1,"fieldsOfStudy":["Computer Science"],"publicationDate":"2009-09-24","authors":[{"authorId":"2295738","name":"Rongqun Peng"},{"authorId":"37116752","name":"Zhengkun Mi"},{"authorId":"2308213","name":"Lingjiao Wang"}]},{"paperId":"0088005d1f0ecd8e33a6bfe2962f9932d414dd00","title":"The Application Research of Ontology Parsing and Inquiring Based on Jena","abstract":"th , 2012; revised: Jul. 19 th , 2012; accepted: Jul. 27 th , 2012 Abstract: As the next generation of the Internet, the semantic web provides strong capabilities of data organization and effective information retrieval. How to parse and inquire the ontology is the key technique for the semantic web to achieve intelligent semantic retrieval. The paper gives a deeply research of the ontology parse and inquire method based on Jena, and be used in the compiler principle course ontology.","venue":"","year":2012.0,"referenceCount":5,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"2116292938","name":"Li Zhu"},{"authorId":"2149535368","name":"Qing Yang"}]},{"paperId":"0088ec15aad7947b13ccbed263d0394e044f1ebf","title":"Web and Document Databases: An Effective Way to Explore the Internet","abstract":"In this paper, we discuss the architecture of a system, the so-called Web and Document Databases (WDDBS for short), designed to explore the Internet effectively and efficiently. Abstractly, a WDDBS can be defined as a triple, where (1) D stands for a local docu\u00acment database to store XML documents, (2) P for a subsystem responsible for remote query evaluation, including resolution of semantic conflicts among heterogeneous databases, and (3) W for a Web crawler which should be able to find information sources related to the local database in some way. Then, each information source can be organized into a WDDB distributed over the Internet, which may be con\u00acnected to others through URLs. A query submitted to a WDDBS will first be evaluated against the local document database, and then possibly switched over to some remote document databases if necessary, which is controlled by the \u2018knowledge\u2019 on how local WDDBSs are connected. In this way, the load of traffic over the Internet can effectively be decreased, but the information explored is more relevant.","venue":"International Conference on Interaction Sciences","year":2010.0,"referenceCount":26,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":"2010-08-18","authors":[{"authorId":"2157242842","name":"Yanjung Chen"}]},{"paperId":"0089fadf1f8a75529cda497decb5664f7b12980a","title":"Theory of Ontological Engineering","abstract":": Ontology research has embarked in knowledge base community, spread over the web technology community by semantic web movement. Ontological engineering is the discipline that deals with development and maintenance of ontologies. It was introduced in computer science in early nineties; as a result immense content of this discipline is available in literature. But, because of its huge extent and specialization, an exhaustive effort should be made to understand the said area. Some studies are available that are for comparative reasons or for review of the state of the art, but these address one or other aspect like comparison of methodologies or evaluation approaches. So the current study, after a comprehensive review and analysis, presents the compilation, as theory of ontological engineering that addresses all aspects from definition to evaluation, but in a concise manner with all-inclusive contents.","venue":"","year":2017.0,"referenceCount":73,"citationCount":1,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"2980930","name":"A. Verma"},{"authorId":"2286465288","name":"Amardeep Kaur"},{"authorId":"49577371","name":"Kamaljeet Kaur"}]},{"paperId":"008bdd81359b1c0faa21770530d2d4843fdca6a7","title":"Voluntary Contributions of Unaware Internet Users? On Automatic Knowledge Retrieval from the WWW","abstract":"This paper presents the method of automatic knowledge retrieval from the Web. In this approach, millions of Internet users who naturally and constantly create and update the content of the Web are treated as the \u201cvoluntary contributors\u201d who provide knowledge concepts without any need for additional motivation or coordination of their efforts. Obviously, only a small part of the statements accessible on the Web are valid knowledge axioms. Below, the \u201cweb knowledge concepts\u201d filtering and verification methods are described, based on the similarity measurements with the concepts found in the manually created knowledge database. The results obtained with the system demonstrated that it is able to automatically retrieve semantic equivalents of several concepts submitted by the volunteer contributors, as well as the concepts that while being valid entries to a knowledge database, provide more details compared to the ones found in the manually developed database.","venue":"AAAI Spring Symposium: Knowledge Collection from Volunteer Contributors","year":2005.0,"referenceCount":19,"citationCount":2,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"1735402","name":"M. Skowron"},{"authorId":"144710424","name":"K. Araki"}]},{"paperId":"008c690f6e0ffb68e4430c532aa25f702246399b","title":"The Development of Semantic Web to Search Student Final Study Collections (Work Practice and Final Project)","abstract":"This research aims to implement semantic web on student final study domain (work practice and final project ). Implementation of semantic web utilizing RAP library as RDF API, SPARQL as a query to RDF access, and PHP as the server-side scripting language. The result of this research is semantic web which can store knowledge of final study report collections. General Terms Semantic web, ontology, semantic search.","venue":"","year":2016.0,"referenceCount":10,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":"2016-02-17","authors":[{"authorId":"2260734183","name":"Ahmad Ashari"},{"authorId":"2289006899","name":"D. W. Jo"},{"authorId":"2286113844","name":"A. Gali"},{"authorId":"2286145573","name":"C. X. Chen"},{"authorId":"2289006466","name":"K. T. Claypool"}]},{"paperId":"008c95e3b26739afadfa97020f417ba212ed792d","title":"A review and comparison of rule languages and rule-based inference engines for the Semantic Web","abstract":"With the Semantic Web data standards defined, more applications demand inference engines in providing support for intelligent processing of the Semantic Web data. Rule-based inference engines or rule-based reasoners are used in many domains such as supporting clinical decision support system, e-commerce recommender system, access control mechanism. In order to allow rule reuse and interoperation, several rule languages have been designed for the Web. In this paper, we review and compare some rule languages designed for the Web including FOL-RuleML, SWRL, Notation3, Jena rules and RIF. Some of the comparison criteria include rule expressiveness, syntax, production operations, and built-in functions. In addition, we review and compare some free and public domain rule-based reasoners including Jena inference engine, EYE, OWLIM-lite, BaseVISor and FuXi. Some of the comparison criteria include inference algorithms, supported programming languages, RDFS\/OWL reasoning, rule languages and functions. The review and comparison results will provide some guideline for researchers and developers in choosing the rule languages and systems that match the application requirements.","venue":"International Computer Science and Engineering Conference","year":2013.0,"referenceCount":23,"citationCount":34,"fieldsOfStudy":["Computer Science"],"publicationDate":"2013-09-01","authors":[{"authorId":"3392182","name":"Thanyalak Rattanasawad"},{"authorId":"2698073","name":"K. Saikaew"},{"authorId":"3320746","name":"M. Buranarach"},{"authorId":"1936779","name":"T. Supnithi"}]},{"paperId":"008cc3dff5a169ed2a6fe9b1402ab3f1bd68f157","title":"Combining information extraction and data integration in the estest system","abstract":null,"venue":"International Conference on Software and Data Technologies","year":2006.0,"referenceCount":24,"citationCount":4,"fieldsOfStudy":["Computer Science"],"publicationDate":"2006-09-11","authors":[{"authorId":"2115971955","name":"Dean Williams"},{"authorId":"1747099","name":"A. Poulovassilis"}]},{"paperId":"008cc609a0f708a17a6dfa175cb294e496555ebe","title":"Building Domain Ontology: Experiences in Developing the Prophetic Ontology Form Quran and Hadith","abstract":"Ontologies have been designed for the purpose of representing a domain of knowledge in a way that makes it understandable by machines and humans. Ontologies have been used in many areas in computer sciences such as knowledge engineering, semantic web, and information retrieval. Religious studies is one of the areas were ontologies are in demand. In this paper, we present the design of domain ontology about prophets and messengers in Islam from trustworthy resources: the Quran and Hadith. The ontology can be used to better understanding all life aspects of prophets and messengers in Islam. The classes, relations and properties of this special domain ontology were gathered and integrated to help researchers to identify and explore knowledge about prophets in Islam such as their lives, books and teachings, the nature of the messages they brought to their nations and tribes and much more.","venue":"Italian Conference on Theoretical Computer Science","year":2017.0,"referenceCount":28,"citationCount":11,"fieldsOfStudy":["Computer Science"],"publicationDate":"2017-10-01","authors":[{"authorId":"1414226682","name":"Hanan A. Al-Sanasleh"},{"authorId":"2248595","name":"B. Hammo"}]},{"paperId":"008e72f4dae9da10708be165d4133c7bc05b4021","title":"W3C MMI WORKSHOP POSITION PAPER","abstract":"In the user interface adaptation project, we focused on the device independent representation and adaptation of web application UIs. The project was conducted together with SAP Global Research & Innovation. Based on the findings of our research, we have successfully developed the Dialog Description Language (DDL, [1]) that allows device independent authoring of web content based on the single source approach. It supports semantic adaptation through inline meta-information provided at authoring time. A modular adaptation engine applies semantic and syntactic transformations to DDL dialogs to generate device-specific dialog representations at runtime. The experience and knowledge we gained in this project also influenced the EU FP5 CONSENSUS [2] project. Within this project a Render Independent Markup language (RIML) was developed, which is based on several W3C standards (e. g. XHTML, XForms and SMIL). The project also the single source approach and adopted several adaptation concepts from our DDL research. Recently, SAP has indicated a strong interest in extending the concepts and scope of further research towards the support for multiple input and output channels. These extensions shall cover dynamic interaction channel selection, the mapping of content to different I\/O channels as well as technologies for the synchronization and fusion of parallel interaction events. While we already have experiences in supporting mixed text-andspeech interfaces based on the X+V, we want to gear our research activities towards more generic scenarios of multimodal user interaction. Furthermore, we participate in the preparation of a project proposal to the EUREKA-ITEA [3] cluster. The proposed project, ENABLE, will encompass the integration of context-awareness, adaptation and multimodality into software engineering and application platforms. One of the project\u2019s focal points will be to provide the prototype of an application platform for ambient applications that supports multimodal interaction.","venue":"","year":2004.0,"referenceCount":1,"citationCount":0,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"1974151","name":"Gerald H\u00fcbsch"},{"authorId":"145152861","name":"T. Springer"}]},{"paperId":"009011e3f37b122226c16660c18261e865c59133","title":"Knowledge graph matching with inter-service information transfer","abstract":". Knowledge graph matching is an approach to create entity mappings of structured data with linked data sources. As an automated approach, this paper explains a sparql query based matching engine developed during the Columns-Property Annotation (CPA) Challenge under ISWC 2020 SemTab challenge (Semantic Web Challenge on Tabular Data to Knowledge Graph Matching). The proposed approach utilizes a text correction via different knowledge base services\/libraries as well as numeric interval definitions to identify negligible numeric differences. The approach (submitted as TeamTR) achived, in the CPA task, F1-scores of 0.916. 0.873 and 0.837 in Rounds 1, 2 and 3, respectively.","venue":"SemTab@ISWC","year":2020.0,"referenceCount":4,"citationCount":3,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"2839817","name":"Semih Yumu\u015fak"}]},{"paperId":"0090ef235b9c1d623e16426d55a7ca3c8080eb7c","title":"A Categorization Scheme for Semantic Web Search Engines","abstract":"\u2014 Semantic web search engines are evolving and manyprototype systems and some implementation have been developed.However, there are some different views on what a semanticsearch engine should do. In this paper, a categorization schemefor semantic web search engines are introduced and elaborated.For each category, its components are described according to a proposed general architecture and various approaches employedin these components are discussed. We also propose some factorsto evaluate systems in each category .","venue":"","year":2017.0,"referenceCount":11,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"72067043","name":"Haresh R. Parmar"}]},{"paperId":"0091c121010249d18a735a7ee464fee9c5fb80a7","title":"Profile-based Datas and Recommendation for RDF Data Linking. (La recommandation des jeux de donn\u00e9es bas\u00e9e sur le profilage pour le liage des donn\u00e9es RDF)","abstract":"With the emergence of the Web of Data, most notably Linked Open Data (LOD), an abundance of data has become available on the web. However, LOD datasets and their inherent subgraphs vary heavily with respect to their size, topic and domain coverage, the schemas and their data dynamicity (respectively schemas and metadata) over the time. To this extent, identifying suitable datasets, which meet specific criteria, has become an increasingly important, yet challenging task to supportissues such as entity retrieval or semantic search and data linking. Particularlywith respect to the interlinking issue, the current topology of the LOD cloud underlines the need for practical and efficient means to recommend suitable datasets: currently, only well-known reference graphs such as DBpedia (the most obvious target), YAGO or Freebase show a high amount of in-links, while there exists a long tail of potentially suitable yet under-recognized datasets. This problem is due to the semantic web tradition in dealing with \"finding candidate datasets to link to\", where data publishers are used to identify target datasets for interlinking.While an understanding of the nature of the content of specific datasets is a crucial prerequisite for the mentioned issues, we adopt in this dissertation the notion of \"dataset profile\" - a set of features that describe a dataset and allow the comparison of different datasets with regard to their represented characteristics. Our first research direction was to implement a collaborative filtering-like dataset recommendation approach, which exploits both existing dataset topic proles, as well as traditional dataset connectivity measures, in order to link LOD datasets into a global dataset-topic-graph. This approach relies on the LOD graph in order to learn the connectivity behaviour between LOD datasets. However, experiments have shown that the current topology of the LOD cloud group is far from being complete to be considered as a ground truth and consequently as learning data.Facing the limits the current topology of LOD (as learning data), our research has led to break away from the topic proles representation of \"learn to rank\" approach and to adopt a new approach for candidate datasets identication where the recommendation is based on the intensional profiles overlap between differentdatasets. By intensional profile, we understand the formal representation of a set of schema concept labels that best describe a dataset and can be potentially enriched by retrieving the corresponding textual descriptions. This representation provides richer contextual and semantic information and allows to compute efficiently and inexpensively similarities between proles. We identify schema overlap by the help of a semantico-frequential concept similarity measure and a ranking criterion based on the tf*idf cosine similarity. The experiments, conducted over all available linked datasets on the LOD cloud, show that our method achieves an average precision of up to 53% for a recall of 100%. Furthermore, our method returns the mappings between the schema concepts across datasets, a particularly useful input for the data linking step.In order to ensure a high quality representative datasets schema profiles, we introduce Datavore| a tool oriented towards metadata designers that provides rankedlists of vocabulary terms to reuse in data modeling process, together with additional metadata and cross-terms relations. The tool relies on the Linked Open Vocabulary (LOV) ecosystem for acquiring vocabularies and metadata and is made available for the community.","venue":"","year":2016.0,"referenceCount":140,"citationCount":0,"fieldsOfStudy":["Computer Science","Philosophy"],"publicationDate":"2016-12-01","authors":[{"authorId":"2066366471","name":"M. Ellefi"}]},{"paperId":"0092a72252aed5e8b94499db0018d22fee99ba70","title":"Interoperability Issues, Ontology Matching and MOMA","abstract":": Thought interoperability has been gaining in importance and become an essential issue within the Semantic Web community, the main challenge of interoperability and data integration is still ontology matching. With this in mind, we wish to contribute to the enhancement of (semantic) interoperability by supporting the ontology matching issue; we propose an evaluation framework for matching approaches that contributes to the resolution of the data integration and interoperability issue by creating and maintaining awareness of the link between matchers and various ontologies","venue":"","year":2008.0,"referenceCount":25,"citationCount":0,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"2668115","name":"Malgorzata Moch\u00f3l"}]},{"paperId":"00952f0bba7fbcd904f0fb3dcccc6daeabf15461","title":"Mining the Human Phenome using Semantic Web Technologies: A Case Study for Type 2 Diabetes","abstract":"The ability to conduct genome-wide association studies (GWAS) has enabled new exploration of how genetic variations contribute to health and disease etiology. However, historically GWAS have been limited by inadequate sample size due to associated costs for genotyping and phenotyping of study subjects. This has prompted several academic medical centers to form \"biobanks\" where biospecimens linked to personal health information, typically in electronic health records (EHRs), are collected and stored on large number of subjects. This provides tremendous opportunities to discover novel genotype-phenotype associations and foster hypothesis generation. In this work, we study how emerging Semantic Web technologies can be applied in conjunction with clinical and genotype data stored at the Mayo Clinic Biobank to mine the phenotype data for genetic associations. In particular, we demonstrate the role of using Resource Description Framework (RDF) for representing EHR diagnoses and procedure data, and enable federated querying via standardized Web protocols to identify subjects genotyped with Type 2 Diabetes for discovering gene-disease associations. Our study highlights the potential of Web-scale data federation techniques to execute complex queries.","venue":"American Medical Informatics Association Annual Symposium","year":2012.0,"referenceCount":29,"citationCount":18,"fieldsOfStudy":["Computer Science","Medicine"],"publicationDate":null,"authors":[{"authorId":"145236681","name":"Jyotishman Pathak"},{"authorId":"28136435","name":"Richard C. Kiefer"},{"authorId":"3192702","name":"S. Bielinski"},{"authorId":"1792682","name":"C. Chute"}]},{"paperId":"00959de1b1cd410a14bc494f3f5a42417b2dce7c","title":"Analysing Student Programs in the PHP Intelligent Tutoring System","abstract":null,"venue":"International Journal of Artificial Intelligence in Education","year":2014.0,"referenceCount":35,"citationCount":28,"fieldsOfStudy":["Computer Science"],"publicationDate":"2014-02-04","authors":[{"authorId":"2731700","name":"Dinesha Weragama"},{"authorId":"145311016","name":"J. Reye"}]},{"paperId":"00963cfb2e3ed1b3a8aabf78fb687d1d54b8c15a","title":"OntoShare: a knowledge management environment for virtual communities of practice","abstract":"An ontology-based knowledge sharing system OntoShare and its evaluation as part of a case study is described. RDF(S) is are used to specify and populate an ontology, based on information shared between users in virtual communities. We begin by discussing the advantages that use of Semantic Web technology afford in the area of knowledge management tools. The way in which OntoShare supports WWW-based communities of practice is described. Usage of OntoShare semi-automatically builds an RDF-annotated information resource for the community (and potentially for others also). Observing that in practice the meanings of and relationships between concepts evolve over time, OntoShare supports a degree of ontology evolution based on usage of the system - that is, based on the kinds of information users are sharing and the concepts (ontological classes) to which they assign this information. A case study involving OntoShare was carried out. The evaluation exercise for this case study and its results are described. We conclude by describing avenues of ongoing and future research.","venue":"International Conference on Knowledge Capture","year":2003.0,"referenceCount":28,"citationCount":56,"fieldsOfStudy":["Computer Science"],"publicationDate":"2003-10-23","authors":[{"authorId":"145628594","name":"J. Davies"},{"authorId":"144734985","name":"A. Duke"},{"authorId":"1401813995","name":"York Sure-Vetter"}]},{"paperId":"00981bf1d952b99c86a39cdde4b6dff39016e31d","title":"Content MathML(CMML) conversion using LATEX Math Grammar (LMG)","abstract":"Abstract Syntax Tree (AST) is one of the main requirements to extract semantic information from a mathematical expression given in LATEX format and to make it machine readable for its interoperability in heterogeneous environments. In this paper, a grammar-based algorithm is proposed that converts LATEX math expression into Content MathML (CMML) to produce semantic enrichment in web documents. Initially, the conversion algorithm is tested on 20 equations used in NTCIR-12 math competition, later the algorithm is tested on NTCIR-12 Wikipedia-MathIR data-set. The results show that our algorithm is capable of converting LATEX complex equations into CMML extensively as compared to the existing ones.","venue":"2019 7th International Conference on Smart Computing & Communications (ICSCC)","year":2019.0,"referenceCount":23,"citationCount":1,"fieldsOfStudy":["Mathematics"],"publicationDate":"2019-06-01","authors":[{"authorId":"2129965","name":"Sharaf Hussain"},{"authorId":"2558292","name":"Samita Bai"},{"authorId":"145182839","name":"S. Khoja"}]},{"paperId":"009a9571ac64499a03ad01a970da87c1d88147d1","title":"Semantic Web Workshop (SWWS) Update Semantics for Cooperative Ontologies","abstract":"An assumption of theSemantic Webis that knowledge producers will generate knowledge (as meta-data or content descriptors) that can be automatically compared. A domain ontology system must aim at helping knowledge consumers and producers to use unambiguous descriptors. For example, when I use the term \u201cswitch\u201d, a domain ontology system should know about the various meanings of \u201cswitch\u201d: (i) a mechanical, electrical device; (ii) a flexible instrument for punishment; (iii) a substitute (iv) a basketball maneuver, etc. The domain ontology server intervenes to help refine the term until it is classified to a category with its intended meaning. The category can then be compared with other identical categories of \u201cswitch\u201d used as meta-data descriptors associated with documents. Often when terms are used in context, they can be disambiguated automatically. \u201cSwitch on a wall\u201d is enough context to discount a number of meanings of switch since the signature of the spatial relation \u201con\u201d provides a restriction on the category type1. Furthermore, a domain ontology system needs facilities for individuals or teams to work together, to create and refine categories, maintain meaningful views and give access security of the categories that they own. The number of categories for \u201cswitch\u201d (and their intended meanings) for a company (or industry) that manufactures switches, will need to complement the more general meanings given earlier. For this reason a mechanism to describe categories and their place in a type hierarchy is necessary, as are filters to accommodate multiple views. To experiment with a ontology that is meaningful and large enough to simulate the difficulties of an ontology server for the World Wide Web we knowledge engineered the natural language ontology WordNet and our own top-level ontology into a objectrelational database called F ASTDB2. We call the resulting ontology server and inference system WEBKB-2[4, 5]. Our ontology contains 94,500 nouns, 66,000 categories referred to by nouns, 21,000 adjectives and 7,900 categories referred to by adjectives. WEBKB-2 is an ontology server but also a inference engine in the classic knowledge base sense. It can also be used to store and retrieve conceptual graphs [6, 7].","venue":"","year":2001.0,"referenceCount":4,"citationCount":0,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"5319749","name":"P. Eklund"},{"authorId":"144676271","name":"P. Becker"},{"authorId":"152981775","name":"Philippe A. Martin"}]},{"paperId":"009b70177dd7b413dd320098266373e4dd3dd11f","title":"XSD To OWL: A Case Study","abstract":"This paper addresses the challenge of applying Semantic Web technologies like OWL-DL reasoners to XML documents to find implied relationships not stated directly in the documents. The challenge comes because the structure of XML schema often contains implicit assumptions about taxonomy and relationships. This makes it difficult to implement a completely general and automated mechanism to transform XML schemas to OWL ontologies. We describe our efforts to transform XML schemas to OWL ontologies and discuss our rationale for particular mappings. This work contributes to this area of research by providing new interpretations of XSD terminology in the context of OWL and shows how to map XSD structures to more complex OWL structures.","venue":"","year":2011.0,"referenceCount":19,"citationCount":0,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"145589620","name":"Aaron Wheeler"},{"authorId":"47983607","name":"James Dike"},{"authorId":"3086371","name":"M. Winburn"}]},{"paperId":"009dbd3e740040f93c9fe64488b6c299baa73e7b","title":"The Semantic Web \u2013 ISWC 2016","abstract":null,"venue":"Lecture Notes in Computer Science","year":2016.0,"referenceCount":503,"citationCount":10,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"143772714","name":"Paul Groth"},{"authorId":"2927032","name":"E. Simperl"},{"authorId":"34071005","name":"A. Gray"},{"authorId":"3122192","name":"M. Sabou"},{"authorId":"2849472","name":"M. Kr\u00f6tzsch"},{"authorId":"1863173","name":"F. L\u00e9cu\u00e9"},{"authorId":"1724463","name":"Fabian Fl\u00f6ck"},{"authorId":"103712910","name":"Yolanda Gil"}]},{"paperId":"009f26f4a9ec4370c6a55132cd01fdd4965cf868","title":"Exploiting semantic association to answer \u2019vague","abstract":"Although today\u2019s web search engines are very powerful, they still fail to provide intuitively relevant results for many types of queries, especially ones that are vaguely-formed in the user\u2019s own mind. We argue that associations between terms in a search query can reveal the underlying information needs in the users\u2019 mind and should be taken into account in search. We propose a multi-faceted approach to detect and exploit such associations. The CORDER method measures the association strength between query terms, and queries consisting of terms having low association strength with each other are seen as \u2018vague queries\u2019. For a vague query, we use WordNet to find related terms of the query terms to compose extended queries, relying especially on the role of least common subsumers (LCS). We use relation strength between terms calculated by the CORDER method to refine these extended queries. Finally, we use the Hyperspace Analogue to Language (HAL) model and information flow (IF) method to expand these refined queries. Our initial experimental results on a corpus of 500 books from Amazon shows that our approach can find the right books for users given authentic vague queries, even in those cases where Google and Amazon\u2019s own book search fail.","venue":"","year":2016.0,"referenceCount":6,"citationCount":0,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"145963104","name":"Queries\u2019Jianhan Zhu"},{"authorId":"2962215","name":"M. Eisenstadt"},{"authorId":"48437245","name":"D. Song"},{"authorId":"1967533","name":"C. Denham"}]},{"paperId":"009f3cdee1decf5c6f019e57afcd5f89a5465753","title":"Anonymizing bag-valued sparse data by semantic similarity-based clustering","abstract":null,"venue":"Knowledge and Information Systems","year":2012.0,"referenceCount":76,"citationCount":10,"fieldsOfStudy":["Computer Science"],"publicationDate":"2012-06-19","authors":[{"authorId":"1767200","name":"Junqiang Liu"},{"authorId":"1751643","name":"Ke Wang"}]},{"paperId":"009f644069f694d08549b30684628fd7e9ffd03f","title":"The Decentralization of Knowledge","abstract":": Does the centralization of the Web change both the diffusion of knowledge and the philosophical definition of knowledge itself? By exploring the origins of the Semantic Web in the philosophy of Carnap and of Google\u2019s machine learning approach in Heidegger, we demonstrate that competing philosophical schools are deeply embedded in artificial intelligence and its evolution in the Web. Finally, we conclude that a decentralized approach to knowledge is necessary in order to bring the Web to its full potential as project for the spread of human autonomy","venue":"","year":null,"referenceCount":1,"citationCount":0,"fieldsOfStudy":null,"publicationDate":null,"authors":[]},{"paperId":"00a044e1b502276e87976055ed384dd12a67b2e5","title":"Invasive Software Composition Operators for the Semantic Web","abstract":"Descriptions of data in the Semantic Web easily grow larger and more complex than the descriptions of traditional web pages and are thus more difficult to handle. The problem of how to structure complex systems has been addressed in traditional software engineering for decades and is commonly solved by splitting systems into components using different techniques. Recently, new techniques, like Aspect-Oriented Programming or the more generic Invasive Software Composition, were developed to fulfill newly emerging composition needs. These gray-box composition approaches access components through a well-defined interface, but modify internal parts of components during composition. This book investigates in transferring composition techniques from the software engineering to the semantic web domain using the concepts of Invasive Software Composition. It shows how composition operators can be defined for software, query and ontology composition alike and how they can be tailored for specific needs of the Semantic Web domain. This book targets software engineers, researchers and students interested in modern software composition techniques and the emerging challenges of the Semantic Web.","venue":"","year":2008.0,"referenceCount":0,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":"2008-02-26","authors":[{"authorId":"1808492","name":"Jendrik Johannes"}]},{"paperId":"00a1100b02ca059fad55a2e075cd3463fe0ecede","title":"Transforming Between UML Conceptual Models and OWL 2 Ontologies","abstract":". The ISO 19103 standard\u2014de\ufb01ning rules and guidelines for conceptual modeling in the geographic domain\u2014has deliberately chosen the Uni\ufb01ed Modeling Language (UML) as \u201cconceptual schema language\u201d for geographic information systems. From today\u2019s perspective\u2014i.e. when taking into account today\u2019s mature semantic web technology\u2014another language might also be envisioned as language for specifying application-oriented conceptual models, namely the Web Ontology Language OWL 2. Both language de\ufb01nitions refer to comparable meta-models laid down in terms of OMG\u2019s Meta Object Facility, but in contrast to UML, OWL 2 is fully built upon formal logic which allows logical reasoning on OWL 2 ontologies. In this paper, we investigate language similarities and di\ufb00erences by specifying and implementing the transformation on the meta-model level using the QVT transformation language.","venue":"Terra Cognita@ISWC","year":2012.0,"referenceCount":17,"citationCount":21,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"2061809","name":"Jesper Zedlitz"},{"authorId":"2741957","name":"N. Luttenberger"}]},{"paperId":"00a1525173514e1ec2c29ba034247eca34486beb","title":"Education and Learning in the Semantic Web","abstract":"Web 3.0, also known as the Semantic Web, promises to revolutionize the way learning is delivered over the internet. In this paper, we discuss how the underlying technological elements of the semantic web combine to add intelligence to web-based, desktop or mobile, education and learning. We moreover present three types of semantic web applications for education, namely learning objects, learning object repositories and pedagogical agents, and critically appraise their contribution to learners and instructors alike. Our work offers a systematic taxonomy of the current state-of-the-art along with the relevant future research challenges in the field and an objective assessment of the critical aspects for the successful integration of semantic web applications in learning, aiming to assist researchers in positioning their future work and contribution in the area.","venue":"Panhellenic Conference on Informatics","year":2011.0,"referenceCount":40,"citationCount":11,"fieldsOfStudy":["Computer Science"],"publicationDate":"2011-09-30","authors":[{"authorId":"1836197","name":"Anna E. Kasimati"},{"authorId":"2798252","name":"E. Zamani"}]},{"paperId":"00a39a68d5f55f53b1e4fa0eab9b6596a4631ce1","title":"etecting interaction links in a collaborating group using manually nnotated data","abstract":"Identification of network linkages through direct observation of human interaction has long been a staple of network analysis. It is, however, time consuming and labor intensive when undertaken by human observers. This paper describes the development and validation of a two-stage methodology for automating the identification of network links from direct observation of groups in which members are free to move around a space. The initial manual annotation stage utilizes a web-based interface to support manual coding of physical location, posture, and gaze direction of group members from snapshots taken from video recordings of groups. The second stage uses the manually annotated data as input for machine learning to automate the inference of links among group members. The manual codings were treated as observed variables and the theory of turn taking in conversation was used to model temporal dependencies among interaction links, forming a Dynamic Bayesian Network (DBN). The DBN was modeled using the Bayes Net Toolkit and parameters were learned using Expectation Maximization (EM) algorithm. The Viterbi algorithm was adapted to perform the inference in DBN. The result is a time series of linkages for arbitrarily long segments that utilizes statistical distributions to estimate linkages. The validity of the method was assessed through comparing the accuracy of automatically detected links to manually identified links. Results show adequate validity and suggest routes for improvement of the method. Network data come from a variety of sources, including sureys, email depositories, analysis of documents and archives, and irect observation. Direct observation of networks has a long hisory, stretching back to the original sociometric studies (Moreno, 951), the Bank Wiring Room studies conducted by Hawthorne esearchers and analyzed by Homans (1951), and early anthropoogical work (e.g., Kapferer, 1969). In recent years, gathering of network data through direct bservation is less common than collecting data via surveys, recontructing links from archival or media documents, and analysis f digital data on connections. Direct observation is extremely Please cite this article in press as: Mathur, S., et al., Detecting interaction lin (2012), http:\/\/dx.doi.org\/10.1016\/j.socnet.2012.04.002 ime and resource-intensive, and the expense becomes almost proibitive if we want to study network dynamics over time. \u2217 Corresponding author. E-mail addresses: shomat@gmail.com (S. Mathur), mspoole@illinois.edu M.S. Poole), feniosky@columbia.edu (F. Pe\u00f1a-Mora), jhasegaw@illinois.edu M. Hasegawa-Johnson), nosh@northwestern.edu (N. Contractor). 378-8733\/$ \u2013 see front matter \u00a9 2012 Elsevier B.V. All rights reserved. ttp:\/\/dx.doi.org\/10.1016\/j.socnet.2012.04.002 \u00a9 2012 Elsevier B.V. All rights reserved. However, there are compelling reasons for using direct observation to study networks. It offers a useful complement to self-reports of ties, especially if investigators can collect both types of data. If a permanent record of the observation can be made, for example by video or audio recording the observations, then additional facets of meaning can be adduced and used to supplement the network data. For example, semantic networks derived from transcriptions of interaction can be related to social or communication networks. One important barrier to direct observation of networks is the time and effort it takes. For even small networks, coding links observationally requires multiple coders to watch different subsets of subjects in real time. For larger networks, such as networks of emergency responders who may number in the hundreds, the task becomes truly formidable and forbidding. One way to reduce the time and effort required for direct observation of networks is to automate the process of link detection ks in a collaborating group using manually annotated data. Soc. Netw. as much as possible. This manuscript reports on the development of an algorithm for detection of network links from video data that is amenable to automation. The algorithm utilizes visual cues which current automated computing systems can detect. It","venue":"","year":2012.0,"referenceCount":34,"citationCount":5,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"2085226746","name":"hobhit Mathura"},{"authorId":"2103744739","name":"Marshall Scott Poolec"},{"authorId":"2083783965","name":"Feniosky Pe\u00f1a-Morab"},{"authorId":"2105447821","name":"Mark Hasegawa-Johnsond"},{"authorId":"2104202221","name":"oshir Contractore"}]},{"paperId":"00a45e8e9842585a2137c045b10ba3555ec64db4","title":"Model and data engineering for advanced data-intensive systems and applications","abstract":null,"venue":"Computing","year":2019.0,"referenceCount":0,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":"2019-10-01","authors":[{"authorId":"2827155","name":"Yassine Ouhammou"},{"authorId":"1684379","name":"Ladjel Bellatreche"},{"authorId":"144395551","name":"M. Ivanovi\u0107"},{"authorId":"48843545","name":"A. Abell\u00f3"}]},{"paperId":"00a4728e314ff57551071d3c204eaa09b5a00f05","title":"Effect of Semantic Web technologies on Distance Education","abstract":null,"venue":"","year":2011.0,"referenceCount":0,"citationCount":3,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"2146913","name":"Yaqing Shi"},{"authorId":"2118663214","name":"Meijuan Wang"},{"authorId":"9082887","name":"Zhenghong Qiao"},{"authorId":"97822916","name":"L. Mao"}]},{"paperId":"00a48707fbd92b0ed167a70f144a12b042d1d70c","title":"PROPIEDADES PSICOM\u00c9TRICAS DE LA BATER\u00cdA DE EVALUACI\u00d3N DE PROCESOS COGNITIVOS Y DE LECTURA EN ADULTOS CON DISLEXIA (BEDA) PSYCHOMETRIC PROPERTIES OF ASSESSMENT BATTERY OF DYSLEXIA IN ADULTS (BEDA)","abstract":"This study analyzed the psychometric properties of the Assessment Battery of Dyslexia in Adults (BEDA). Dyslexia persists into adulthood and the assessment should focus also on the underlying cognitive processes involved in dyslexia. Therefore, valid and reliable instruments tools to detect and assess adults with dyslexia are needed. BEDA was designed as a computer-assisted tool developed with web-based technology for the assessment of cognitive processes involved in university students with dyslexia (i.e., phonological awareness, orthographic processing, processing speed, lexical access, working memory and semantic processing). The standardization of BEDA has been conducted with undergraduate degree, master and PhD students from three Spanish universities (University of La Laguna, University of Girona and University of Las Palmas de Gran Canaria). Finally, we propose that BEDA is part of an e-learning platform (Platform for Assistance and Intervention Dyslexia in Adults: PIADA), along with other identification and assistance tools, with the aim that can be used by teachers and university students, and thus help to meet the challenge to provide university students a resource that enables the identification of dyslexia and provide information to teachers on strategies and guidelines with students with reading disabilities.","venue":"","year":2014.0,"referenceCount":25,"citationCount":0,"fieldsOfStudy":["Psychology"],"publicationDate":null,"authors":[{"authorId":"81334556","name":"Psicolog\u00eda Del Desarrollo"},{"authorId":"145711203","name":"Alicia D\u00edaz"},{"authorId":"143710905","name":"J. Jim\u00e9nez"},{"authorId":"120980546","name":"C. Mej\u00eda"},{"authorId":"2097633402","name":"Ram\u00f3n Fabregat"},{"authorId":"114941738","name":"Santa Juana de Arco"}]},{"paperId":"00a5ede00e08b3d21347a161501ca3ae462d778f","title":"Navigation in medical Internet image databases","abstract":"The world wide web (WWW) changes common ideas of database access. Hypertext Markup Language allows the simultaneous presentation of information from different sources such as static pages, results of queries from databases or dynamically generated pages. Therefore, the metaphor of the WWW itself as a database was proposed by Mendelzon and Milo in 1998. Against this background the techniques of navigation within WWW-databases and the semantic types of their queries have been analysed. Forty eight image repositories of different types and content, but all concerning medical essence, have been found by search-engines. Many different techniques are offered to enable navigation ranging from simple HTML-link-lists to complex applets. The applets in particular promise an improvement for navigation. Within the meta-information for querying, only ACR- and UMLS-encoding were found, but not standardized vocabularies like ICD10 or Terminologia Anatomica. UMLS especially shows that a well defined thesaurus can improve navigation. However, of the analysed databases only the UMLS 'metathesaurus'is currently implemented without providing additionalnavigation support based on the UMLS 'semantic network'. Including the information about relationships between the concepts of the metathesaurus or using the UMLS semantic network could provide a much easier navigation within a network of concepts pointing to multimedia files stored somewhere in the WWW.","venue":"Medical informatics and the Internet in medicine (Print)","year":2001.0,"referenceCount":38,"citationCount":23,"fieldsOfStudy":["Computer Science","Medicine"],"publicationDate":"2001-01-01","authors":[{"authorId":"1958791927","name":"T. Prokosch"}]},{"paperId":"00a670bae8c6b6de47e8b4c679c6dc0291690a92","title":"Semantic Web for Business","abstract":null,"venue":"","year":2016.0,"referenceCount":0,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":"2016-01-29","authors":[{"authorId":"98430769","name":"Jeremy Daniel Knee"}]},{"paperId":"00a74e36475030ab682f4de9c3156d79ccbe7ebe","title":"Context-explication in conceptual ontologies: PLIB ontologies and their use for industrial data","abstract":"A number of computer science problems, including heterogeneous database integration, natural language processing, document intelligent retrieval would benefit from the capability to model the absolute meaning of things, independently of any particular use of these things. Such models, termed ontologies, have been heavily investigated over the last ten years, with various purposes and within various contexts. The goal of this paper is to investigate the role of ontologies for data integration and to present an ontology model that was developed to allow neutral exchange and automatic integration of industrialComponent catalogues and of technical data. We first present a taxonomy of ontologies into linguistic ontologies, based on words and usable for intelligent document processing, and concept ontologies, multilingual and usable for structured data management. We then discuss differences between ontologies and usual conceptual models. We claim that the main difference is the consensual nature of ontologies when conceptual models are specifically designed for one particular target system. Reaching consensus, in turn, needs specific models of which context sensitivity has been minimized. We identify four requirements for making ontologies less contextual than models and suitable for data integration, and we present how these requirements have been fulfilled in the PLIB ontology model developed to give meaning to technical data. Finally, we outline the use of PLIB-based ontologies in various domains including database integration, engineering component database development, electronic catalogues of industrial components generation and the semantic Web.","venue":"","year":2004.0,"referenceCount":32,"citationCount":10,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"1748676","name":"G. Pierra"}]},{"paperId":"00a8df5b46c95278efc92a7218adcc1f7465ac2b","title":"Semantic Interpretation of Tweets: A Contextual Knowledge-Based Approach for Tweet Analysis","abstract":null,"venue":"","year":2018.0,"referenceCount":39,"citationCount":2,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"70075438","name":"Nazura Javed"},{"authorId":"35623006","name":"B. L. Muralidhara"}]},{"paperId":"00aa684a1f76e44122bc78131910108c2063640b","title":"Semantic Annotation of Web Services","abstract":"Web services are the latest attempt to revolutionize large scale distributed computing. They are based on standards which operate at the syntactic level and lack semantic representation capabilities. Semantics provide better qualitative and scalable solutions to the areas of service interoperation, service discovery, service composition, and process orchestration. SAWSDL defines a mechanism to associate semantic annotations with Web services that are described using Web Service Description Language (WSDL). In this paper we propose an approach for semi-automatically annotating WSDL Web services descriptions. This allows SAWSDL Semantic Web Service Engineering. The annotation approach consists of two main processes: Categorization and Matching. Categorization process consists in classifying WSDL service description to its corresponding domain. Matching process consists in mapping WSDL entities to pre-existing domain ontology. Both categorization and matching rely on ontology matching techniques. A tool has been developed and some experiments have been carried out to evaluate the proposed approach.","venue":"International Conference on Web and Information Technologies","year":2012.0,"referenceCount":28,"citationCount":14,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"3200744","name":"D. Bouchiha"},{"authorId":"1716183","name":"M. Malki"}]},{"paperId":"00ab3dc529fc421172c0e55a9d239297af96397d","title":"An Ontology-Based Multimedia Annotator for the Semantic Web of Language Engineering","abstract":"The development of the Semantic Web, the next-generation Web, greatly relies on the availability of ontologies and powerful annotation tools. However, there is a lack of ontology-based annotation tools for linguistic multimedia data. Existing tools either lack ontology support or provide limited support for multimedia. To fill the gap, we present an ontology-based linguistic multimedia annotation tool, OntoELAN, which features: (1) the support for OWL ontologies; (2) the management of language profiles, which allow the user to choose a subset of ontological terms for annotation; (3) the management of ontological tiers, which can be annotated with language profile terms and, therefore, corresponding ontological terms; and (4) storing OntoELAN annotation documents in XML format based on multimedia and domain ontologies. To our best knowledge, OntoELAN is the first audio\/video annotation tool in the linguistic domain that provides support for ontology-based annotation. It is expected that the availability of such a tool will greatly facilitate the creation of linguistic multimedia repositories as islands of the Semantic Web of language engineering.","venue":"International Journal on Semantic Web and Information Systems (IJSWIS)","year":2005.0,"referenceCount":21,"citationCount":26,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"2493336","name":"Artem Chebotko"},{"authorId":"2111233122","name":"Yu Deng"},{"authorId":"1700537","name":"Shiyong Lu"},{"authorId":"9517808","name":"F. Fotouhi"},{"authorId":"2128107","name":"A. Aristar"}]},{"paperId":"00ab7987eba9bb5279e7ec081400bea73bd7f25c","title":"Towards emergency vehicle routing using Geolinked Open Data: the case study of the Municipality of Catania","abstract":"Linked Open Data (LOD) has gained significant momentum over the past years as a best practice of promoting the sharing and publi- cation of structured data on the semantic Web. Currently LOD is reach- ing significant adoption also in Public Administrations (PAs), where it is often required to be connected to existing platforms, such as GIS-based data management systems. Bearing on previous experience with the pi- oneering data.cnr.it, through Semantic Scout, as well as the Agency for Digital Italy recommendations for LOD in Italian PA, we are working on the extraction, publication, and exploitation of data from the Geographic Information System of the Municipality of Catania, referred to as SIT (\"Sistema Informativo Territoriale\"). The goal is to boost the metropolis towards the route of a modern Smart City by providing prototype inte- grated solutions supporting transport, public health, urban decor, and social services, to improve urban life. In particular a mobile application focused on real-time road traffic and public transport management is currently under development to support sustainable mobility and, espe- cially, to aid the response to urban emergencies, from small accidents to more serious disasters. This paper describes the results and lessons learnt from the first work campaign, aiming at analyzing, reengineering, linking, and formalizing the Shape-based geo-data from the SIT.","venue":"","year":2014.0,"referenceCount":25,"citationCount":3,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"1748453","name":"S. Consoli"},{"authorId":"2420171","name":"Aldo Gangemi"},{"authorId":"3198185","name":"Andrea Giovanni Nuzzolese"},{"authorId":"2382525","name":"S. Peroni"},{"authorId":"2280600","name":"V. Presutti"},{"authorId":"3349721","name":"D. Recupero"},{"authorId":"15131325","name":"D. Spampinato"}]},{"paperId":"00abf4088317468fd8f6d9b2487fbf0db6e05b43","title":"L'automatitzaci\u00f3 de tesaurus i la seva utilitzaci\u00f3 en el web sem\u00e0ntic","abstract":"Es presenta una proposta basica d'automatitzacio i utilitzacio de tesaurus documentals en entorns distribuits de recuperacio d'informacio mitjancant serveis web basats en l'arquitectura RDF (resource description framework o marc de descripcio de recursos). Per aquest motiu, es revisen, en primer lloc, les propostes d'etiquetatge descriptiu aparegudes en els ultims quatre anys per a la codificacio de tesaurus documentals. A continuacio, es mostra una arquitectura basica d'un servidor de tesaurus implementat en Java. I, finalment, es repassen els diversos protocols de comunicacio i d'intercanvi de dades entre aplicacions que es poden usar per implementar aquest servei. El text s'acompanya de l'aplicacio informatica que s'ha desenvolupat.","venue":"","year":2004.0,"referenceCount":0,"citationCount":2,"fieldsOfStudy":["Computer Science"],"publicationDate":"2004-12-01","authors":[{"authorId":"2101835577","name":"P\u00e9rez Ag\u00fcera"},{"authorId":"2057990414","name":"Josep Ramon"}]},{"paperId":"00ac367b9470d1b706ee0bd4ff43f38a8f006846","title":"A Novel Rubric and Feature-based Appraisaland Comparison Framework for the Evaluationof Semantic Web Services Composition Approaches","abstract":"Background\/Objectives: This article proposes a novel methodology based on rubrics and feature-based schemes for the appraisal and comparison of approaches to semantic Web services composition and discovery. Methods\/Statistical analysis: In order to evaluate the Semantic Web services composition and discovery approaches we created a new framework called RFSWS. This framework is the combination of traditional feature-based evaluation schemes and newly developed analytic rubrics tables. Five recently introduced prominent Semantic Web services composition approaches were identified, explained, and then evaluated\/compared using RFSWS. Findings: In this work we determined aspects of Semantic Web services composition and discovery processes that can be evaluated as performance criteria in rubric tables. This is a novel application of rubrics, which have traditionally been used for grading student performance by teachers. We created a novel framework called RFSWS consisting of rubric tables and a feature-based evaluation scheme for the evaluation and comparison of Semantic Web service discovery and composition approaches, and applied it in the evaluation of five recently introduced prominent Semantic Web services composition approaches. Considering the shortcomings of existing Semantic Web services composition approaches that were discovered through this evaluation, we proposed an idealized dynamic Semantic Web service discovery and composition method, a yardstick by which all future Semantic Web services composition approaches can be evaluated. Application\/ Improvements: Our novel RFSWS framework can be applied in the comprehensive and systematic evaluation\/comparison of Semantic Web services discovery and composition approaches.","venue":"","year":2016.0,"referenceCount":54,"citationCount":4,"fieldsOfStudy":["Computer Science"],"publicationDate":"2016-02-10","authors":[{"authorId":"3255545","name":"S. Ghayekhloo"},{"authorId":"2669420","name":"Z. Bayram"}]},{"paperId":"00ad0a8eaf781a140203bc2db066252b75b34175","title":"LarKC Plug-In Annotation Language","abstract":"The aim of the Large Knowledge Collider (LarKC) project is to develop a platform for massive distributed incomplete reasoning for the Semantic Web. The LarKC Plugins \u2013 services that can be used in the LarKC platform play a key role in the context of LarKC. They are the core elements that are composed in a concrete LarKC pipeline \u2013 a particular configuration of LarKC plug-ins that enables massive distributed reasoning under various configurations of reasoners and other elements. Since multiple providers are expected to contribute with various plug-ins to the LarKC community and a large number of available plug-ins are expected, there is a clear need for a mechanism to handle plug-ins in a flexible way and to enable discovery and composition of such plug-ins. A key requirement to enable such tasks is to have explicit specifications of the functional and non-functional properties of plug-ins. This paper describes an initial mechanism for specifying plug-ins as semantically enriched Web services. We propose WSMO-Lite as a basis for specifying the functionality of LarKC plug-ins, and describe a list of non-functional properties that characterize the quality of service of plug-ins. Finally, we show how plug-in descriptions are used in a typical concrete LarKC pipeline.","venue":"2009 Computation World: Future Computing, Service Computation, Cognitive, Adaptive, Content, Patterns","year":2009.0,"referenceCount":7,"citationCount":8,"fieldsOfStudy":["Computer Science"],"publicationDate":"2009-11-15","authors":[{"authorId":"66215591","name":"D. Roman"},{"authorId":"145530535","name":"Barry Bishop"},{"authorId":"1690555","name":"I. Toma"},{"authorId":"2730011","name":"Georgina Gallizo"},{"authorId":"1800870","name":"B. Fortuna"}]},{"paperId":"00ad44169e1654af7a35bd779b63ad4e7b16a9db","title":"Remote Sensing Image Fusion for Unsupervised Land Cover Classification","abstract":"1.1 Context With the development of new satellite systems and the accessibility of data from public through web services like Google Earth, remote sensing imagery, knows today an important growing which advanced and still advances researches in this area on different aspects. Especially in cartography, many studies have been conducted for multi-source satellite images classification. These studies aim to develop automatic tools in order to facilitate the interpretation and provide a semantic land cover classification. Classical tools based on satellite images deal essentially with one category of satellite images which allows a partial interpretation. Multi-sensor or multi-source image fusion have been applied in the field of remote sensing since 20 years and continues today to provide efficient solutions to problems related to detection and classification. The work presented in this chapter is a part of multi-source fusion research efforts to have reliable and automatic satellite image interpretation. We propose to apply the new fusion concepts and theories for multi-source satellite images. Our main motivation is to measure the real contribution of multi-source image fusion according to the exploitation of satellite images separately. Recent studies suggest that the combination of imagery from satellites with different spectral, spatial, and temporal information may improve land cover classification performance. The use of multi-source satellites images fully take into account the complementary and supplementary information provided by different data sources and considerably optimize the classification of cartographic objects. Particularly, combination of optical and radar remote sensing data may improve the classification results because of the complementarities of these two sources. Spectral features extracted form optical data may remove some difficulties faced when using only radar images. However, radar images present the following massive advantage: the possibility of penetrating the clouds. Thus, data fusion technique is applied to combine these two kinds of information.","venue":"","year":2011.0,"referenceCount":30,"citationCount":2,"fieldsOfStudy":["Computer Science"],"publicationDate":"2011-01-12","authors":[{"authorId":"9155710","name":"C. Ferdaous"}]},{"paperId":"00ae0e112e5c212b14bb87a364eecf4854979dab","title":"Class Association Structure Derived From Linked Objects","abstract":"The Web is being extended with more and more RDF data, especially the links between objects. Object links are critical to the semantic Web just as page links to the hypertext Web. Studying the macroscopic properties of object links can help people understand the semantic Web and build (semantic) Web applications in a better manner. To achieve this, we propose a notion of class association graph (CAG) based on the object links on the semantic Web, and report the results of analyzing the complex network characteristics of a CAG constructed from a real large data set collected by the Falcons search engine. The CAG observed has the scale-free nature and small-world characteristics. Then, vertex-importance graph synopsis approach is employed to depict a landscape of such class association structure.","venue":"","year":2009.0,"referenceCount":3,"citationCount":6,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"1887019","name":"Yuzhong Qu"},{"authorId":"1737743","name":"Weiyi Ge"},{"authorId":"144592996","name":"Gong Cheng"},{"authorId":"2116491209","name":"Zhiqiang Gao"}]},{"paperId":"00af5470ef6bdde4e048b155c2aed683e0c5a496","title":"Semantic Processing of the Semantic Web","abstract":null,"venue":"International Workshop on the Semantic Web","year":2003.0,"referenceCount":30,"citationCount":10,"fieldsOfStudy":["Computer Science"],"publicationDate":"2003-10-20","authors":[{"authorId":"2267504748","name":"Kunal Patel"},{"authorId":"2238214698","name":"Gopal Gupta"}]},{"paperId":"00b09c90cea89aa0d61728d1f25ce3be86a78f4f","title":"The MMI Ontology Registry and Repository: A portal for Marine Metadata Interoperability","abstract":"To address important marine research and application challenges, there is a critical need for ocean observatories to share data in a way that is easy to use and integrate. Fulfilling this interoperability requirement is greatly facilitated by several standards efforts and recent advancements in Web technology. Although these infrastructures provide a fundamental capability for data sharing, there remains a gap from mere syntactic interoperability toward a more powerful, semantic interoperability, in which the diversity of terminologies, vocabularies, and conceptualizations across multiple observatories can be more effectively harmonized, exchanged, and fully integrated. In this paper, we describe the MMI Ontology Registry and Repository and associated semantic services developed by the Marine Metadata Interoperability Project. We present the architecture and the suite of key functions that allow data providers and users to include, use, and exploit semantic information in representative real world scenarios. We show how OGC Sensor Web Enablement services describing sensor systems and data products can be enriched with semantic references that client applications can readily resolve in corresponding semantic descriptions. Data discovery mechanisms enhanced with the provided semantic services are demonstrated with a Web data portal for integrated ocean observing systems. Services for resolution of Web identifiers, along with query and inference mechanisms, which can be accessed in a programmatic way, enable better data integration capabilities. We also demonstrate the ability to relate data quality flags across agencies, to fully describe processing tests and methods, as well as the ability to link definitions to bibliographic references, also registered using the MMI semantic portal.","venue":"Oceans","year":2009.0,"referenceCount":30,"citationCount":45,"fieldsOfStudy":["Computer Science"],"publicationDate":"2009-10-01","authors":[{"authorId":"143624216","name":"C. Rueda"},{"authorId":"144980015","name":"L. Bermudez"},{"authorId":"49952732","name":"J. Fredericks"}]},{"paperId":"00b2960a3493cc65c7b9f09c95f821c34d2f47ee","title":"A Personalized Search System Fitted User Preference","abstract":"This paper Introduces optimization research on personalized web search system in the view of user preference,and provides a new query expansion algorithm based on semantic relation tree and intelligent frame of personalized search system fitted user preference.Semantic relation tree can effectively and neatly construct query expansion model.Personalized search system fitted user preference has self-learning ability of user preference.The experimental result shows that the accuracy of text retrieval can be improved efficiently.","venue":"","year":2008.0,"referenceCount":0,"citationCount":2,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"2072419742","name":"Liao Yong"}]},{"paperId":"00b3c98e8c3b7fca9da7bc8f0501d686794412c7","title":"Data of SemanticWeb as Unit of Knowledge","abstract":"In service to the state of the art, advances are required toward redesigning the framework over which web applications are built. The semantic web lies at the intersection of web and machine understandable meaningful data, turning it into intelligent \u2018web of data\u2019. The key requirement with any intelligent system has been to \ufb01nd a concrete knowledge representation that can make the inferences within time and space constraints; that is, reasoning effectively and ef\ufb01ciently within the resource constraints posed to the problem at one hand and with insuf\ufb01cient data as well as incomplete knowledge on the other hand. Various Knowledge representation schemes have been proposed in the literature, each having its limitation over the others. Ontology is the key component for semantic web engineering. Ontologies are conceptual knowledge bases providing a systematic and taxonomical description of the concepts and instances under consideration. Conceptual clarity in the computational representation of a concept is vital for holistic thinking and knowledge engineering. In order to meet the needs of an application\/enterprise, knowledge should be presented taking care of all possible perspectives; and represented in a hierarchical structure with differing levels of granularity. This paper discusses about bringing all the manifestations of an ontological Journal of Web Engineering, Vol. 17 8, 647\u2013","venue":"Journal of Web Engineering","year":2019.0,"referenceCount":39,"citationCount":9,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"1423403448","name":"Archana Patel"},{"authorId":"152703817","name":"Sarika Jain"},{"authorId":"35524046","name":"Shishir K. Shandilya"}]},{"paperId":"00b41ede36f397412cfe8170943ca769082d951c","title":"Visual Attention Metadata from Pictures Browsing","abstract":"Image browsing has become an indispensable feature for today's mobile devices. To overcome their limited display size, information systems may benefit from the abundant clickstream provided by mobile users. This implicit feedback turns out to be very informative providing hints on both the visual image content and the relevance of the query results when searching for images. Building on previous works on user attention models, we propose a practical, yet generic platform for web usage tracking. Implicit feedback from the clickstream makes it possible to generate visual attention metadata. These metadata are user interest maps (UIMs) in which regions of interest (ROIs) become highlighted. These UIMs are used to establish and reinforce keyword-to-image relations. A tentative application for semantic annotation is also presented.","venue":"2008 Ninth International Workshop on Image Analysis for Multimedia Interactive Services","year":2008.0,"referenceCount":16,"citationCount":6,"fieldsOfStudy":["Computer Science"],"publicationDate":"2008-05-07","authors":[{"authorId":"1977674","name":"Benoit Baccot"},{"authorId":"1747107","name":"Vincent Charvillat"},{"authorId":"1732283","name":"Romulus Grigoras"},{"authorId":"1934174","name":"Cezar Plesca"}]},{"paperId":"00b460f9a9eba2fd21c7b32200a027889f67716c","title":"Multilingual Evaluation of KnowNet","abstract":"This paper presents a new fully automatic method for building highly dense and accurate knowledge bases from existing semantic resources. Basically, the method uses a wide-coverage and accurate knowledge-based Word Sense Disambiguation algorithm to assign the most appropriate senses to large sets of topically related words acquired from the web. KnowNet, the resulting knowledge-base which connects large sets of semantically-related concepts is a major step towards the autonomous acquisition of knowledge from raw corpora. In fact, KnowNet is several times larger than any available knowledge resource encoding relations between synsets, and the knowledge KnowNet contains outperform any other resource when is empirically evaluated in a common multilingual framework.","venue":"Proces. del Leng. Natural","year":2008.0,"referenceCount":21,"citationCount":3,"fieldsOfStudy":["Computer Science"],"publicationDate":"2008-09-01","authors":[{"authorId":"1791107","name":"Montse Cuadros"},{"authorId":"1785173","name":"German Rigau"}]},{"paperId":"00b48096fece38d660fb822c1510aaac445e8a03","title":"Toward Introducing Semantic Capabilities for WSRP","abstract":"The emergence of web services technology has introduced a problem: how can we ensure that requests are successfully matched with advertisements when consumers and producers may use different terminology to describe the same service or the same terminology to describe different ones? Popular approaches to solving this problem are reviewed which involve the use of ontologies to improve the semantic content of the matchmaking process. When services are presentation-oriented rather than merely data-oriented, another layer of difficulty is introduced. The architecture of Web Services for Remote Portlets is discussed extensively, including the interaction cycle between the client and the producer to maintain state variables for each remote session of a portlet to provide sufficient background for readers. A comparison is made between the way concepts are implemented in two different portlet specifications \u2013 IBM Portlet API and JSR168 specification. Architecture is proposed to support the automated use of dynamic services for remote portlets, the motivation for which is the lack of expressivity of the current standards to represent the semantic requirements and capabilities of data and user-facing web services.","venue":"Int. J. Web Portals","year":2009.0,"referenceCount":16,"citationCount":1,"fieldsOfStudy":["Computer Science"],"publicationDate":"2009-04-01","authors":[{"authorId":"143796187","name":"K. Wilkinson"},{"authorId":"29530829","name":"Jana Polgar"}]},{"paperId":"00b49b1d975f4d10b4c89a250faafa05f3ac2f86","title":"University of Huddersfield Repository A Semantic-enabled Framework For Future Internet Of Things Applications","abstract":"\u2014While the challenge of connecting Internet of Things (IoT) devices at the lowest layer has been widely studied, integrating and interoperating huge amounts of sensed data of heterogeneous IoT devices is becoming increasingly important because of the possibility of consuming such data in supporting many potential novel IoT applications. A common approach to processing and consuming IoT data is a centralized paradigm: sensor data is sent over the network to a comparatively powerful central server or a cloud service, where all processing takes place. However, this approach has some limitations as it requires devices to interact directly with a cloud which is not cost effective. First, it has high demands on the device\u2019s storage and computational capabilities. Second, as devices grow rapidly in a deployment area, sending all the data to a centralized cloud server requires high network bandwidth. Moreover, this often creates data privacy concerns as all raw data will be sent to a centralized place. To address the above limitations for building future Internet of Things applications, we present an early design of a novel framework that combines Internet of Things, Semantic Web, and Big Data concepts. We not only present the core components to build an IoT system, but also list existing alternatives with their merits. This framework aims to incorporate open standards to address the potential challenges in building future IoT applica- tions. Therefore, our discussion revolves around open standards to build the framework, rather than proprietary standards.","venue":"","year":null,"referenceCount":35,"citationCount":0,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"2251091762","name":"Umesh Bellur"},{"authorId":"2287588402","name":"Pankesh Chauhan Saurabh Patel"},{"authorId":"2287945111","name":"Yongrui Qin"},{"authorId":"2286035531","name":"\u2020. PankeshPatel"},{"authorId":"2285957836","name":"Saurabh Chauhan"}]},{"paperId":"00b5f945b8667b7c8af34278873346e126c3c920","title":"A new approach for enhancing managing and querying Web services communities: health care case study","abstract":null,"venue":"Network Modeling Analysis in Health Informatics and Bioinformatics","year":2015.0,"referenceCount":23,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":"2015-05-01","authors":[{"authorId":"1776049","name":"Hela Limam"},{"authorId":"1778376","name":"J. Akaichi"}]},{"paperId":"00b76693979dc1e5612a97d308caff705baa9a50","title":"Modelling provenance in hydrologic science: a case study on streamflow forecasting","abstract":"The web, and more recently the concept and technology of the Semantic Web, has created a wealth of new ideas and innovative tools for data management, integration and computation in an open framework and at a very large scale. One area of particular interest to the science of hydrology is the capture, representation, inference and presentation of provenance information: information that helps to explain how data were computed and how they should be interpreted. This paper is among the first to bring recent developments in the management of provenance developed for e-science and the Semantic Web to the problems of hydrology. Our main result is a formal ontological model for the representation of provenance information driven by a hydrologic case study. Along the way, we support usability, extensibility and reusability for provenance representation, relying on the concept of modelling both domain-independent and domain-specific aspects of provenance. We evaluate our model with respect to its ability to satisfy identified requirements arising from the case study on streamflow forecasting for the South Esk River catchment in Tasmania, Australia.","venue":"","year":2012.0,"referenceCount":52,"citationCount":13,"fieldsOfStudy":["Computer Science"],"publicationDate":"2012-10-01","authors":[{"authorId":"2923064","name":"Y. Shu"},{"authorId":"145620556","name":"K. Taylor"},{"authorId":"71029686","name":"P. Hapuarachchi"},{"authorId":"2054648726","name":"C. Peters"}]},{"paperId":"00b8207ae4e79a0c32e2e424c03bcaf53e5518de","title":"Querying the Semantic Web with SWRL","abstract":null,"venue":"International Web Rule Symposium","year":2007.0,"referenceCount":10,"citationCount":39,"fieldsOfStudy":["Computer Science"],"publicationDate":"2007-10-25","authors":[{"authorId":"1397042086","name":"M. O'Connor"},{"authorId":"1702645","name":"S. Tu"},{"authorId":"3099253","name":"Csongor Nyulas"},{"authorId":"145521072","name":"Amar K. Das"},{"authorId":"1680938","name":"M. Musen"}]},{"paperId":"00bb125344ee16a5ccc955e2ba384a5b70629294","title":"Exploring Semantic Web Services Selection Method with Effectivity in Collaborative Environment","abstract":"There are more and more Web services used in collaborative design, hence it is becoming important to locate proper Web services in an accurate and efficient way. In our design, we give an annexed algorithm to improve the existing semantic-based matchmaking algorithm which is focused on Web services containing single input and output. The annexed algorithm arranges the result advertisements according to the clients' convenience to execute the Web services, specially it can efficiently deal with Web services which have multiple inputs and outputs. Moreover, we implemented the matching method in semantic Web services-based application integration framework (SWSAIF) which is used for collaborative design.","venue":"International Conference on Computer Supported Cooperative Work in Design","year":2007.0,"referenceCount":10,"citationCount":4,"fieldsOfStudy":["Computer Science"],"publicationDate":"2007-04-26","authors":[{"authorId":"2065276047","name":"Daolin Du"},{"authorId":"145260900","name":"Qingzhong Li"},{"authorId":"2645442","name":"Tiangang Dong"}]},{"paperId":"00bbca0bb50a994b539e5f4ffc5ca216a4e548e2","title":"Normalization of relations and ontologies","abstract":"Although few systems for normalization of relations are already in place to support schema refinement, they are rarely used be it by database practitioners, or as a teaching aid at universities. Meanwhile, the Semantic Web potential for novice implementations understood by both humans and machines Web-wide has just recently urged the need to reinterpret systems that are yet in the mainstream of standalone or traditional Web systems. That has motivated us to consider the design and implementation of a database normalization system as integral part of the machine-understandable knowledge base on the Web, as conceived by the Semantic Web. This paper presents the ontology layer of our normalization system, as well as the initial findings in building the rule layer of this system using Semantic Web technologies.","venue":"","year":2011.0,"referenceCount":26,"citationCount":2,"fieldsOfStudy":["Computer Science"],"publicationDate":"2011-02-20","authors":[{"authorId":"2001729","name":"L. Ahmedi"},{"authorId":"3268299","name":"Edmond Jajaga"}]},{"paperId":"00bc2d433fabf26e18d2bd549a267bac30d8644c","title":"Content Networks: Taxonomy and New Approaches","abstract":"In this article we describe a taxonomy for content networks and suggest new architectures for such networks. In recent years, many types of content networks have been developed in various contexts, including peer-to-peer networks [8][12][16][27][31][37][49], cooperative Web caching [3][47], content distribution networks [2][7][10], subscribe-publish networks [6][52], and content-based sensor networks [14][21][22]. For each context, there have been numerous architectural approaches with various design objectives. Our taxonomy attempts to formulate a design space for both existing and future content networks and to identify design points of interest. The proposed new content networks, called semantic content-sensitive networks, offer desirable features such as support for content-proximity searches and the use of small routing tables.","venue":"The Internet as a Large-Scale Complex System","year":2005.0,"referenceCount":55,"citationCount":27,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"144153715","name":"H. Kung"},{"authorId":"1735777","name":"Chun-Hsin Wu"}]},{"paperId":"00bd28c4e52a124bf89f9d721e2e7e524457638d","title":"Providing Smart Objects with Intelligent Tutoring Capabilities by Semantic Technologies","abstract":"Intelligent Tutoring Systems (ITS) are software systems for human learning and training. Promising works integrate ITS and game environments in order to use both the pedagogical soundness of traditional ITS and the engagement power of games. Such integration could be more effective embedding these systems into the Internet of Things. The main result of this work is the definition of an ontology-based framework supporting the construction of physical-digital game-based ITS implemented as smart objects. The overall framework relies on the paradigms of the Semantic Web technologies. The above capabilities allow to decouple the ITS from the specific characteristics of the used sensors (e.g., camera, capacitive touch, infrared). Such framework provides scalability (in terms of number and complexity of sensors) and good flexibility with respect to the changing of: environment, learning experience, interaction, narrative, game. Lastly, these features will be shown by implementing a case study on educational games for 5-6 years old children.","venue":"International Workshop on Intelligent Networking and Collaborative Systems","year":2016.0,"referenceCount":13,"citationCount":5,"fieldsOfStudy":["Computer Science"],"publicationDate":"2016-09-01","authors":[{"authorId":"2721973","name":"G. Fenza"},{"authorId":"1689838","name":"V. Loia"},{"authorId":"1750385","name":"F. Orciuoli"}]},{"paperId":"00bd6c32e8ed2b7ffb1c710ba528b3fe709c502a","title":"Ontology based framework for reverse engineering of conventional softwares","abstract":"In contemporary years, integration among research areas of semantic web technologies and software engineering took place due to the reason of developers being present at different virtual, cultural, and geographical locations. Due to this amalgamation, a new collaborated field has emerged known as Semantic Web Enabled Software Engineering. This field presents researchers ample opportunities to probe issues and challenges, which are originated due to their amalgamation. Among such issues, one is the reverse engineering of conventional softwares using ontologies. This research paper presents a framework and discusses the implementation approach to resolve to the above issue.","venue":"International Conference on Computing for Sustainable Global Development","year":2016.0,"referenceCount":18,"citationCount":4,"fieldsOfStudy":["Computer Science"],"publicationDate":"2016-03-16","authors":[{"authorId":"2057418010","name":"M. Bhatia"},{"authorId":"2116451265","name":"Akshi Kumar"},{"authorId":"35174037","name":"Rohit Beniwal"}]},{"paperId":"00c0328e54685f2c0406260e61db1228de881abd","title":"Closed World Reasoning in the Semantic Web through Epistemic Operators","abstract":"The open world assumption makes OWL principally suitable to handle incomplete knowledge in Semantic Web scenarios, however, some scenarios desire closed world reasoning. Autoepistemic description logics allow to realise closed world reasoning in open world settings through epistemic operators. An extension of OWL by epistemic operators therefore allows for non-monotonic features known from closed world systems, such as default rules, integrity constraints or epistemic querying. These features can be beneficially applied in Semantic Web scenarios, where OWL lacks expressiveness.","venue":"OWL: Experiences and Directions","year":2005.0,"referenceCount":12,"citationCount":87,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"4757313","name":"S. Grimm"},{"authorId":"1703160","name":"B. Motik"}]},{"paperId":"00c03c95a7e9ca00762af2fa10b3ef24658e66ed","title":"Towards a Semantics-Based, End-User-Centered Information Visualization Process","abstract":". Using and understanding Semantic Web data is almost impossible for lay-users as skills in Semantic Web technologies are required. The information visualization (InfoVis) of this data is one possible approach to address this problem. However, convenient solutions are missing as existing tools like Tableau do not support Semantic Web data or users necessitate programming and visualization skills. In this paper, we propose a novel approach towards a generic InfoVis workbench called VizBoard which enables users to visualize arbitrary Semantic Web data without expert skills in Semantic Web Technologies, programming, and visualization. More precisely, we de\ufb01ne a semantics-based,user-centered InfoVis work\ufb02ow and present a corresponding workbench architecture based on the mashup paradigm, which actively supports lay-users in gaining insights from Semantic Web data, thus proving the practicability and validity of our approach.","venue":"","year":2012.0,"referenceCount":21,"citationCount":10,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"1932158980","name":"M. Voigt"},{"authorId":"1848975","name":"S. Pietschmann"},{"authorId":"1771042","name":"Klaus Mei\u00dfner"}]},{"paperId":"00c12fe96404b3b7311cc2b079d6b6544eb53f30","title":"Granular Association Rules for Multiple Taxonomies: A Mass Assignment Approach","abstract":null,"venue":"Uncertainty Reasoning for the Semantic Web","year":2008.0,"referenceCount":29,"citationCount":9,"fieldsOfStudy":["Computer Science"],"publicationDate":"2008-11-30","authors":[{"authorId":"39801345","name":"T. Martin"},{"authorId":"48234901","name":"Yun Shen"},{"authorId":"144806488","name":"B. Azvine"}]},{"paperId":"00c1373c407b4b6be21d81fcdc24c0587830125b","title":"Digitometric Services for Open Archives Environments","abstract":null,"venue":"European Conference on Research and Advanced Technology for Digital Libraries","year":2003.0,"referenceCount":18,"citationCount":8,"fieldsOfStudy":["Computer Science"],"publicationDate":"2003-08-17","authors":[{"authorId":"36917308","name":"T. Brody"},{"authorId":"1693823","name":"Simon Kampa"},{"authorId":"2293327","name":"S. Harnad"},{"authorId":"1727183","name":"L. Carr"},{"authorId":"39187956","name":"S. Hitchcock"}]},{"paperId":"00c148bb68649a901ff44c13ea2d2f1513d4460a","title":"Logic-based Rule Learning for the Web of Data","abstract":". This tutorial introduces to Inductive Logic Programming (ILP), being it a major logic-based approach to rule learning, and surveys extensions of ILP that turn out to be suitable for applications to the emerging vision of the Semantic Web as a Web of Data.","venue":"RuleML+RR","year":2017.0,"referenceCount":59,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"145091756","name":"F. Lisi"}]},{"paperId":"00c398da1d7f5e876722ec28092831beada9d0cc","title":"DIGITAL LIBRARIES: THE SYSTEMS ANALYSIS PERSPECTIVE Cataloging our information architecture","abstract":"Purpose \u2013 To explore the potential impact of Shiyali Ramamrita Ranganathan\u2019s classi\ufb01cation theories on the accessibility and exposure of digital repository content. Design\/methodology\/approach \u2013 Conceptual analysis of: faceted classi\ufb01cation schemes; the symantic web; object-oriented analysis, design and programming; and digital repository content. Findings \u2013 With the rapid proliferation of digital repositories and digital archives comes the need for appropriate and \ufb02exible classi\ufb01cation schemes that can be implemented in conjunction with current technology such as object-oriented programming techniques. Shivali Ranganathan was a forerunner in the area of classi\ufb01cation systems, and developed a classi\ufb01cation system, which is very suited to the need at hand: faceted classi\ufb01cation. This column explores the relationship between Ranganathan\u2019s theories and their potential use in the contemporary digital library context (speci\ufb01cally digital repositories). Practical implications \u2013 Ranganathan\u2019s methodology may help libraries to expose digital repository content on a larger scale within a very \ufb02exible and forward-looking framework. This will allow libraries to anticipate the development of the semantic web and become key players in this environment. Originality\/value \u2013 Suggests a theoretical framework for describing and syndicating digital repository content, which is \ufb02exible and anticipatory in nature, based on the work of Shiyali Ranganathan.","venue":"","year":null,"referenceCount":5,"citationCount":10,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"2052404240","name":"Robert Fox"}]},{"paperId":"00c560b4dc70351796fb22189bf13f8f39e6c8ba","title":"Semantic Agent Systems","abstract":null,"venue":"Studies in Computational Intelligence","year":2011.0,"referenceCount":12,"citationCount":14,"fieldsOfStudy":["Computer Science"],"publicationDate":"2011-02-01","authors":[{"authorId":"1723633","name":"Atilla El\u00e7i"},{"authorId":"73523906","name":"Mamadou Tadiou Kon"},{"authorId":"145572420","name":"M. Orgun"}]},{"paperId":"00c62f9f663a3d01c816d4fe4cfdd4e766e256f9","title":"Data Quality Principles in the Semantic Web","abstract":"The increasing size and availability of web data make data quality a core challenge in many applications. Principles of data quality are recognized as essential to ensure that data fit for their intended use in operations, decision-making, and planning. However, with the rise of the Semantic Web, new data quality issues appear and require deeper consideration. In this paper, we propose to extend the data quality principles to the context of Semantic Web. Based on our extensive industrial experience in data integration, we identify five main classes suited for data quality in Semantic Web. For each class, we list the principles that are involved at all stages of the data management process. Following these principles will provide a sound basis for better decision-making within organizations and will maximize long-term data integration and interoperability.","venue":"2012 IEEE Sixth International Conference on Semantic Computing","year":2012.0,"referenceCount":25,"citationCount":15,"fieldsOfStudy":["Computer Science"],"publicationDate":"2012-09-19","authors":[{"authorId":"3140773","name":"Ahmad Assaf"},{"authorId":"1972207","name":"A. Senart"}]},{"paperId":"00c69ac3e46fce7013cda997e6c9a7c39714e890","title":"Context Sensitive Access Control in Smart Home Environments","abstract":"The rise in popularity of Internet of Things (IoT) devices has opened doors for privacy and security breaches in Cyber-Physical systems like smart homes, smart vehicles, and smart grids that affect our daily existence. IoT systems are also a source of big data that gets shared via cloud. IoT systems in a smart home environment have sensitive access control issues since they are deployed in a personal space. The collected data can also be of highly personal nature. Therefore, it is critical to build access control models that govern who, under what circumstances, can access which sensed data or actuate a physical system. Traditional access control mechanisms are not expressive enough to handle such complex access control needs, warranting the incorporation of new methodologies for privacy and security. In this paper, we propose the creation of the PALS system, that builds upon existing work in attribute based access control model, captures physical context collected from sensed data (attributes), and performs dynamic reasoning over these attributes and context driven policies using Semantic Web technologies to execute access control decisions. Reasoning over user context, details of information collected by cloud service provider and device type our mechanism generates as a consequent access control decisions. Our system\u2019s access control decisions are supplemented by another sub-system that detects intrusions into smart home systems based on both network and behavioral data. The combined approach serves to determine indicators that a smart home system is under attack, as well as limit what data breach such attacks can achieve.","venue":"2020 IEEE 6th Intl Conference on Big Data Security on Cloud (BigDataSecurity), IEEE Intl Conference on High Performance and Smart Computing, (HPSC) and IEEE Intl Conference on Intelligent Data and Security (IDS)","year":2020.0,"referenceCount":33,"citationCount":32,"fieldsOfStudy":["Computer Science"],"publicationDate":"2020-05-01","authors":[{"authorId":"1657432236","name":"Sofia Dutta"},{"authorId":"1500371242","name":"Sai Sree Laya Chukkapalli"},{"authorId":"1659178331","name":"Madhura Sulgekar"},{"authorId":"1659179347","name":"Swathi Krithivasan"},{"authorId":"2059710","name":"Prajit Kumar Das"},{"authorId":"2286265039","name":"A. Joshi"}]},{"paperId":"00c73efd336167c35a6058ef18822c9654a57074","title":"Heterogeneous Service Selection using Evolutionary Algorithm in SOA\u2019s Repository","abstract":"Ontology acts as a backbone for every semantic web applications. Service selection is a major constraint to discover and deliver services in a user friendly way. In this system, we are enhancing and evaluating reliability, availability and consistency of service discovery by adapting Genetic Algorithm (GA) in ontology repository to discover selected services .The proposed technique is useful for the normal search as well as semantic search according to the service request using ontology repository. In this system, the ontologies are reposited in ontology repository based on some set of concepts and their interrelationships relevant to domain knowledge. The knowledge provided by ontology repository helps service requestors\/user to find semantic service from heterogeneous database and improves interoperatability and user-centricity. The reliability of service discovery can be evaluated based on two parameters such as execution time and memory processing and graph also plotted by comparing the execution time and processing memory of server with ontology repository","venue":"","year":2016.0,"referenceCount":0,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":"2016-06-17","authors":[{"authorId":"122292941","name":"C. Jayaprakash"},{"authorId":"102771422","name":"V. Maheswari"}]},{"paperId":"00c9aa8732ddf9d8177c8851ab45c043d719cd0d","title":"Bayesian Networks for Inference and Discovery of Semantic Relations in a Never-Ending Learning System","abstract":"The first never-ending learning system reported in literature is named NELL (Never-Ending Language Learning). The main goal of the NELL system is to learn to read the web better each day, and to store the gathered knowledge in a never-ending growing knowledge base (KB). Since NELL's KB continuously grows each day, it does not contain all instances of every category, neither all instances of every relation described in the ontology. Thus, in this paper, we have investigated a methodology that can help NELL to populate its own KB using Bayesian networks (BN). To do so, we have applied two BN learning algorithms called DMBC and VOMOS to induce BN from facts (knowledge) already stored in the NELL's KB. The empirical results have showed that both algorithms are promising to solve the problem of representing semantic relations and extending the NELL's ontology. Besides, the BN induced by DMBC and VOMOS have presented good inference results, suggesting another alternative to learn new facts and assist to populate the NELL's KB.","venue":"Brazilian Conference on Intelligent Systems","year":2019.0,"referenceCount":26,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":"2019-10-01","authors":[{"authorId":"3159067","name":"E. B. D. Santos"},{"authorId":"1452345059","name":"Igor Henrique P. Rodrigues"},{"authorId":"1842532","name":"Estevam Hruschka"},{"authorId":"1481712224","name":"Lucas Rezende Bruno"}]},{"paperId":"00c9c8a970574dd80617c4d63493567d45f87888","title":"Querying Relational Databases with RDQL","abstract":"Most Semantic Web applications are still unable to query data stored in relational databases using their own built-in functionality. Hence, needing access to such data, they have to fall back on SQL and the relational model. In this paper we describe Relational.OWL, our technique to automatically extract the semantics of relational databases and transform this information into a machine processable and understandable representation. Since this data can now be queried using semantic query languages, it has to be analyzed whether this combination of Relational.OWL and e.g. RDQL can be a real alternative to the commonly used SQL access to relational data.","venue":"Berliner XML Tage","year":2005.0,"referenceCount":19,"citationCount":15,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"1751233","name":"C. Laborda"},{"authorId":"143966331","name":"Stefan Conrad"}]},{"paperId":"00ca9786ea5353901cc3ca4f2ab3d9d51e32aba3","title":"Comparison of Web Service Similarity- Assessment Methods","abstract":"Due to the advent of service oriented architecture, web services have gained popularity. The need for efficient web service discovery increases because of the enormous growth of the web services. The main concern of this paper is to addresses the challenge of automated web service discovery and service similarity assessment. It utilizes the WordNet and a traditional information retrieval method, combined with structure matching to identify potentially useful services and estimating their relevance. The objective of this paper is to find the best suitable web service assessment method by comparing the three web service similarity assessment methods namely WordNet-powered vector space model, Structure matching and Semantic structure matching.","venue":"","year":2014.0,"referenceCount":16,"citationCount":1,"fieldsOfStudy":["Computer Science"],"publicationDate":"2014-07-18","authors":[{"authorId":"94129262","name":"J. Maheswari"},{"authorId":"1719520","name":"G. R Karpagam"},{"authorId":"21748915","name":"S. Indhumathy"}]},{"paperId":"00cae42a20bf24a260cb1b1aeeb768ab73e4cc8b","title":"A survey of exploratory search systems based on LOD resources","abstract":"The fact that the existing Web allows people to effortlessly share data over the Internet has resulted in the accumulation of vast amounts \nof information available on the Web.Therefore, a powerful search technology that will allow retrieval of relevant information is one of the main requirements for the success of the Web which is complicated further due to use of many different formats for storing information. Semantic Web technology plays a major role in resolving this problem by permitting the search \nengines to retrieve meaningful information. Exploratory search system, a special information seeking and exploration approach, supports users who are unfamiliar with a topic or whose search goals are vague and unfocused to learn and investigate a topic through a set of activities. In order to achieve exploratory search goals Linked Open Data (LOD) can be used to help search systems in retrieving related data, so the investigation task runs smoothly.This paper provides an overview of the Semantic Web Technology, Linked Data and search strategies, followed by a survey of the state of the art Exploratory Search Systems based on LOD.Finally the systems are compared in various aspects such as algorithms, result rankings and explanations.","venue":"","year":2015.0,"referenceCount":24,"citationCount":28,"fieldsOfStudy":["Computer Science"],"publicationDate":"2015-08-11","authors":[{"authorId":"52133102","name":"Karwan Jacksi"},{"authorId":"3227831","name":"Nazife Dimililer"},{"authorId":"52132700","name":"Subhi R. M. Zeebaree"}]},{"paperId":"00ceb3a8607aac72a0c5bacd35fac28f6a2b7955","title":"Semantic Web Architecture and Its Implementation","abstract":"An architecture of semantic Web portal is designed. The concept of page agent is proposed and implemented in a homogeneous environment. The system employs a new Web query language CDQL, which is an extension of the well-known query language DQL with constraints and across-information-source querying. The system can be used to construct enterprise Web systems, which can automatically answer questions from users and user agents.","venue":"","year":2004.0,"referenceCount":0,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"30679110","name":"Li Shou-li"}]},{"paperId":"00d0161d5ec21ecae457fb94706bea17b477f19a","title":"Protocol Mediation for Adaptation in Semantic Web Services","abstract":null,"venue":"Extended Semantic Web Conference","year":2006.0,"referenceCount":35,"citationCount":51,"fieldsOfStudy":["Computer Science"],"publicationDate":"2006-06-11","authors":[{"authorId":"2108670891","name":"Stuart K. Williams"},{"authorId":"2194492","name":"S. Battle"},{"authorId":"3282533","name":"Javier Esplugas Cuadrado"}]},{"paperId":"00d10de8c8f0a1f3b923c0b569b3a6074f1d6407","title":"What is the Analogue for The Semantic Web, And Why is Finding One Important? 1","abstract":"This paper postulates that for the Semantic Web to grow, and gain input from fields that will surely benefit it, such as Information Retrieval, Design and Human Computer Interaction, it needs to develop an analogue that will help people not only understand what it is, but what the potential opportunities are that are enabled by this new technology. The model proposed in the paper takes the typical way that Web interaction has been framed as a baseline to inform a similar analogue for the Semantic Web. While the Web has been represented as a Page + Links, the paper presents the argument that the Semantic Web can be conceptualized as a Notebook + Memex. The argument considers how this model also presents new challenges for fundamental human interaction with computing, and that hypertext models have much to contribute to this new understanding for distributed information systems.","venue":"","year":2007.0,"referenceCount":36,"citationCount":0,"fieldsOfStudy":null,"publicationDate":null,"authors":[]},{"paperId":"00d227612e8b0363b71e6c9cb37ba09129cdeac1","title":"Syntactic and semantic interoperability: New approaches to knowledge and the semantic web","abstract":"La quete du Web semantique s'inscrit dans le prolongement de la recherche historique du sens dans le langage, avec notamment l'elaboration de systemes de classification et de catalogage. Dublin Core, en permettant la connexion de ressources heterogenes, constitue la reponse la plus elaboree aux nouveaux defis poses par l'internet. La realisation du Web semantique requiert une interoperabilite aux niveaux syntaxique et semantique. Mais l'interoperabilite semantique exige bien plus qu'un simple accord sur la signification d'un terme. Il s'agit de creer de nouveaux systemes d'organisation des connaissances pour identifier et connecter les differents niveaux d'accord requis (local, regional, national et international). L'utilisation de la logique propositionnelle, plutot que des systemes de concepts, et la reorganisation des connaissances ouvrent la voie au Web semantique en tenant compte de toute la richesse culturelle et historique et de toute la complexite du langage.","venue":"","year":2001.0,"referenceCount":71,"citationCount":90,"fieldsOfStudy":["Computer Science"],"publicationDate":"2001-01-01","authors":[{"authorId":"144955597","name":"K. Veltman"}]},{"paperId":"00d2670db794e411f0122332419fa011c08c4428","title":"Research Article Learning Support with Semantic Forum System","abstract":"Learning support is a service offers to assist learners learning process towards a desirable educational goal. Learning support is pertinent to fulfill the learning requirement and to complement the lack of interaction with tutors in e-learning education. However, there raise a concern that learning support provided is not effective enough to provide fast response to inquiries, relevant content of interest and reuse past discussion to resolve issues and difficulties in learning. Nevertheless, the ontological approach from semantic web technologies implementation offer certain affordance to enhance the learning support towards greater possibility as an effective e-learning facility. As such, it is the interest of this study to propose and introduce an ontological-based semantic forum by reusing the knowledge obtained from course modules and past forum discussion in order to enhance the learning support. Thus, a brief description of semantic forum development is presented in the acquisition and modelling the knowledge into an ontological structure. As well as evaluation conducted to ensure the effectiveness of the system use in enhancing learners' understanding of the subject. This study contributes to a new approach of learning support with new facilities designed to provide more meaningful and relevant learning materials that able to accomodate the desirable learning outcome.","venue":"","year":2015.0,"referenceCount":17,"citationCount":1,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"9224518","name":"Hazalina Hashim"},{"authorId":"2480890","name":"S. Noah"}]},{"paperId":"00d2af6068385f33f3ed90dab312591a26209e6e","title":"Aaron Swartz's The Programmable Web: An Unfinished Work","abstract":"Abstract This short work is the first draft of a book manuscript by Aaron Swartz written for the series \"Synthesis Lectures on the Semantic Web\" at the invitation of its editor, James Hendler. Unfortunately, the book wasn't completed before Aaron's death in January 2013. As a tribute, the editor and publisher are publishing the work digitally without cost. From the author's introduction: \" . . . we will begin by trying to understand the architecture of the Web -- what it got right and, occasionally, what it got wrong, but most importantly why it is the way it is. We will learn how it allows both users and search engines to co-exist peacefully while supporting everything from photo-sharing to financial transactions. We will continue by considering what it means to build a program on top of the Web -- how to write software that both fairly serves its immediate users as well as the developers who want to build on top of it. Too often, an API is bolted on top of an existing application, as an afterthought or ...","venue":"Aaron Swartz's The Programmable Web: An Unfinished Work","year":2013.0,"referenceCount":0,"citationCount":10,"fieldsOfStudy":["Computer Science","Engineering"],"publicationDate":"2013-03-08","authors":[{"authorId":"144541063","name":"A. Swartz"}]},{"paperId":"00d2c37eca0df21a10ac803ec6274f7a59804715","title":"From cultural islands to popular sites. Semantic sequences typifying museum descriptions on the Web: Christina Samson","abstract":null,"venue":"","year":2014.0,"referenceCount":0,"citationCount":0,"fieldsOfStudy":["Art"],"publicationDate":null,"authors":[{"authorId":"2057219958","name":"Giancarmine Bongo"},{"authorId":"66930383","name":"G. Caliendo"}]},{"paperId":"00d30de081afe8fc1c3bc373127d5591498e5a13","title":"Semantic Knowledge and Information Management in the Semantic Web","abstract":"Acknowledgements To my parents to whom I owe my education, my faith, my life. Thank you for teaching me that the best way to success is learning of your defeats. \" Vive \" lives in me because of you furpas. I shall never forget it. To the five I could never forget: Inge, Dayana, Katy, Alma and Abi. We have lived so many things together and conquered so many battles. Thank you for all these years, thank you for being my friends no matter what. To the friends I fortunately found here: Isaac, Ale, Lalo, Rochy, Erick and Rich. Thank you for all your help, your support, your company and your laughter. You all made my stay in the university the best time I have ever had. To Ale Bandala, for her understanding and patience, for her support and love. To Gennaro Bruno, for being more than an excellent guide, for being my friend. This work would not be possible without your help and advice. Je me rappellerai toujours du tigre mon ami, merci beaucoup. To Dr. Genoveva Vargas, for her infinite patience and advice, for her compromise and dedication. Thank you for your encouragement, for showing me that the only way to do something is doing it well.","venue":"","year":2004.0,"referenceCount":51,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"1405494312","name":"H\u00e9ctor P\u00e9rez-Urbina"}]},{"paperId":"00d3c00758b89a2d1bcf7a90fbf3e2b9259d8c44","title":"Smart Learning Management System Framework","abstract":"Thanks to modern networking technologies and advancement of social networks, people in the modern society need more and more information just to be in the game. With such environment, the importance of learning and information sharing cannot be overemphasized. Even though plethora of information is available on various sources such as the web, libraries, and any learning material repositories, if it is not readily available and meets the needs of the user, it may not be utilized. For that, we need a system that can help provide customized information \u2013 matches with user\u2019s level and interest to the user. Such system should understand what the user\u2019s interests are, what level the user belongs for the topic, and so on. In this paper, we are proposing a framework for smart learning management system (SLMS) that utilizes user profiles and semantically organized learning objects so only the relevant information can be delivered to the user. The SLMS maintains user profiles \u2013 continuously updating whenever there is a change \u2013 and learning objects that are organized by building ontology. Upon user\u2019s request, the system fetches relevant learning materials based on the user\u2019s profile. The delivered learning materials are suitable for the user\u2019s topic and the level for the requested topic sorted by relevancy ranking.","venue":"International Conference on Data Technologies and Applications","year":2016.0,"referenceCount":14,"citationCount":2,"fieldsOfStudy":["Computer Science"],"publicationDate":"2016-11-27","authors":[{"authorId":"37772679","name":"Yeong-Tae Song"},{"authorId":"31886918","name":"Yuanqiong Wang"},{"authorId":"4976095","name":"Sungchul Hong"},{"authorId":"2099330472","name":"Yongik Yoon"}]},{"paperId":"00d476026951cf2cd0442b024f86512f88491c0a","title":"Effect of Semantic Web Technologies on Distance Education","abstract":"Starting with the key technologies of the Semantic Web,we analyze the characteristics of the semantic web and the potential ef-fect on the model of distance education.The conclusion shows that the development of Semantic Web will leverage the ability of the re-sources fusion,knowledge discovery and the knowledge retrieval,and finally,the Semantic Web will transform the study mode of the learners,from pulling knowledge from the web to pushing knowledge out of the web.","venue":"","year":2010.0,"referenceCount":0,"citationCount":5,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"2093009734","name":"Shi Ya-qing"}]},{"paperId":"00d4c774e33e7462bf8ff1c2c86a7ae16391f019","title":"Final Report, T-Rex exchange between UIBK and NUIG","abstract":"Web Services promise a new level of functionality on top of the current Web. However, current Web Service technologies only provide syntactical descriptions of Web Services and, therefore, they are not amenable to automation. The efforts of WSMO aim at describing Web Services and their related aspects with well-defined, formal semantics, thus providing a basis for the automatization of various tasks in the Web Service usage process. During the exchange with NUIG, which has taken place from July 22nd to September 30th 2004, we have focused on the exploitation of semantic descriptions of Web Services and user goals to automatically discover i.e. locate Web Services that can fulfill a given goal. We have investigated a logical framework which, based on the WSMO conceptual model, provides such functionality. In addition, we have further investigated the distinction of capabilities and constraints in the Web Service context and their role in WSMO.","venue":"","year":2004.0,"referenceCount":3,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"144606408","name":"Rub\u00e9n Lara"},{"authorId":"2648624","name":"C. Bussler"}]},{"paperId":"00d7b725759c05bb7b9f763c174632d31f004397","title":"Contextual information retrieval in research articles: Semantic publishing tools for the research community","abstract":"In recent years, the dramatic increase in academic research publications has gained significant research attention. Research has been carried out exploring novel ways of providing information services using this research content. However, the task of extracting meaningful information from research documents remains a challenge. This paper presents our research work on developing intelligent information systems that exploit online article databases. We present in this paper, a linked data application which uses a new semantic publishing model for providing value added information services for the research community. The paper presents a conceptual framework for modelling contexts associated with sentences in research articles and discusses the Sentence Context Ontology, which is used to convert the information extracted from research documents into machine-understandable data. The paper reports supervised learning experiments carried out using conditional probabilistic models for achieving automatic context identification. The paper also describes a Semantic Web Application that provides various citation context based information services.","venue":"Semantic Web","year":2014.0,"referenceCount":62,"citationCount":12,"fieldsOfStudy":["Computer Science"],"publicationDate":"2014-10-01","authors":[{"authorId":"2291612","name":"M. A. Angrosh"},{"authorId":"1707051","name":"Stephen Cranefield"},{"authorId":"2665144","name":"N. Stanger"}]},{"paperId":"00d9306d348026fd78232a87e02445db10d58419","title":"Experiences of Exposing Semantics to Drive Transcoding","abstract":"The World Wide Web (Web) is a visually complex, dynamic, multimedia system that can be inaccessible to people with visual impairments. SADIe uses semantic annotations of a Web site's Cascading Style Sheet (CSS) to drive a transformation process that can improve access to content for visually impaired users. The original process of annotating the CSS involved the use of an upper ontology, extended by a site specific lower ontology. While this approach provided rich annotation of the CSS terms, experience suggests that components within the model were inappropriate for the interactive system we were developing. This experience has led to a more pragmatic approach that still provides the necessary semantics required to drive the SADIe transcoding tool, but in a more lightweight manner. This paper describes the lessons learnt from building the ontological models for the SADIe platform, highlighting pitfalls that developers of ontologies in interactive systems should be wary of.","venue":"2008 First International Workshop on Ontologies in Interactive Systems","year":2008.0,"referenceCount":21,"citationCount":2,"fieldsOfStudy":["Computer Science"],"publicationDate":"2008-09-01","authors":[{"authorId":"144522847","name":"D. Lunn"},{"authorId":"1709236","name":"S. Bechhofer"},{"authorId":"2240384938","name":"Simon Harper"}]},{"paperId":"00dc6df573f0211d5b319d8f976fbb0dc134605c","title":"Integration of Avian Influenza Virus Information Sources for Korea e-Science","abstract":"There are multiple data sources storing avian influenza virus information in Korea. Research on AI requires scientists to collect, integrate, share and analyze AI virus information from the data sources. Since the sources are heterogeneous, autonomously created and maintained by different institutions, it is very difficult for AI researchers to search their data sets from the sources. In this paper, we propose a mediator-based data integration system, which integrates such multiple heterogeneous AI virus information sources. Mediation approach to integrating the sources requires scientists to define the semantic mapping among them. Most AI researchers do not have enough knowledge on the sources to define the mapping. To alleviate their efforts, AVIS provides a visual administration tool to browse schema of data sources and easily define the semantic mapping for data integration. It also provides Web-based graphical interface to easily access and share data from multiple heterogeneous AI virus information sources.","venue":"2008 IEEE Fourth International Conference on eScience","year":2008.0,"referenceCount":4,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":"2008-12-07","authors":[{"authorId":"3075157","name":"Woo-Lam Kang"},{"authorId":"32476192","name":"D.-H. Choi"},{"authorId":"31192207","name":"Young-Kyun Suh"},{"authorId":"2110392249","name":"Yoon-Joon Lee"}]},{"paperId":"00dc75593b8a45f65837a99b68d28962ea516ff4","title":"\ud2b9\uc9d1\uba85 : \uc74c\uc131\/\uc5b8\uc5b4 \uc815\ubcf4\uc0b0\uc5c5 \uae30\uc220 \ub3d9\ud5a5 ; \ud2b9\uc9d1 : \uc9c0\uc2dd\uae30\ubc18(Knowledge Base)\uc73c\ub85c\uc11c\uc758 \uc628\ud1a8\ub85c\uc9c0(Ontology)\uc640 \uc2dc\uba58\ud2f1 \uc6f9(Semantic Web)","abstract":null,"venue":"","year":2004.0,"referenceCount":0,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"66552894","name":"\uc2e0\ud6a8\ud544"}]},{"paperId":"00de92bcaf85f8b8e626c2b5b4a9e1fe7d8e01c3","title":"Process Oriented Collaboration in Grid-Environments: A Case Study in the Construction Industry","abstract":"This paper addresses the process-oriented collaboration based on a grid-based platform for the support of virtual organizations (VO), illustrated on the example of the construction industry. Distributed, organizational and IT-structures of teams involved in vintage complex projects cannot be managed with conventional methods in an appropriate manner. Both using a grid platform and grid-based services, in conjunction with semantic methods for consistency saving and goal-oriented process management can increase the efficiency of collaboration processes in large-scale projects. A hybrid gridand web service-based architecture for the next generation of VO service and a gateway solution was developed integrating the process-oriented perspective and prototypically implemented. The problem, as well as the solution on the basis of the hybrid system architecture combing the benefits of the cutting-edge technologies, the methodical concept for modeling VO processes and their automated execution on a grid platform are discussed in detail.","venue":"Americas Conference on Information Systems","year":2009.0,"referenceCount":30,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"3108822","name":"T. Dollmann"},{"authorId":"1759200","name":"M. Fellmann"},{"authorId":"145589040","name":"Oliver Thomas"},{"authorId":"1741394","name":"P. Loos"},{"authorId":"1793330","name":"A. Hoheisel"},{"authorId":"1924301","name":"P. Katranuschkov"},{"authorId":"144867632","name":"R. Scherer"}]},{"paperId":"00dee9d96d4e6d5a281d2101203b86bb7e53e220","title":"Web Services Clustering Using a Bio-inspired Algorithm","abstract":"In this work we describe a bio-inspired algorithm for Web service clustering, in particular we present an adaptation of the Ant Colony Optimization (ACO) algorithm which is applied over a collection of Web service descriptions. The adapted ACO uses input and output parameter definitions to calculate semantic similarity measures between all the different Web services. A set of experiments were carried out with promising results that show the benefits of the ACO algorithm for Web services clustering.","venue":"International Conference on Database and Expert Systems Applications","year":2015.0,"referenceCount":15,"citationCount":1,"fieldsOfStudy":["Computer Science"],"publicationDate":"2015-09-01","authors":[{"authorId":"2055687615","name":"Roman Mora"},{"authorId":"1414014435","name":"Saul Santillan-Perez"},{"authorId":"145326879","name":"Maricela Claudia Bravo"}]},{"paperId":"00defc3e5ee576b80a23d7fc5cd7e08edf686cc9","title":"The MEKETREpository A Collaborative Web Database for Middle Kingdom Scene Descriptions","abstract":"Whilst representations, iconography and the development of scenes in private and royal tombs from the Old Kingdom have been studied extensively in the past, comparable research of Middle Kingdom (MK) representations and scene details is still underrepresented. The MEKETRE research project aims at closing this gap by systematic research of MK representations. In the course of this project, an online digital repository (the MEKETREpository) is being built that enables researchers to describe and annotate MK two-dimensional art at various levels of detail using images, free text, and controlled vocabularies. It further enables the collaborative development of semantic vocabularies for the description of these data. The MEKETREpository will publish the resulting data and vocabularies as Linked Data on the Web by utilizing Semantic Web technologies to enable their integration into other Linked Data sets such as DBpedia, Freebase or LIBRIS. The collected data is described using standardized and specialized vocabularies allowing for easy integration into existing databases and search engines. For the long-term preservation of the entered data, the MEKETREpository will make use of the University of Vienna's digital asset management system PHAIDRA. At its final stage the MEKETREpository will supply a platform that exposes collaboratively created, continuously evolving, and publicly available information about the MK on the Web.","venue":"","year":2010.0,"referenceCount":0,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":"2010-07-01","authors":[{"authorId":"6920421","name":"Christian Mader"},{"authorId":"1679379","name":"Bernhard Haslhofer"},{"authorId":"2549440","name":"N. Popitsch"}]},{"paperId":"00df5f1f8c9ac1f2010e5f48356f29088257241c","title":"The Biodiversity Knowledge Hub (BKH): a crosspoint and knowledge broker for FAIR and linked\u00a0biodiversity data","abstract":"The Biodiversity Knowledge Hub (BKH) is a web platform acting as an integration point and broker of an open, FAIR (Findable, Accessible, Interoperable, Reusable) and interlinked corpora of biodiversity data, services and knowledge. It serves the entire biodiversity research cycle, from specimens and observations to sequences, taxon names and finally to scientific publications. The strategic aim of the BKH is to support a functional and integrated biodiversity knowledge graph and an emerging new community of users. The BKH is aimed at biodiversity researchers in the widest sense, research infrastructures and publishers (Fig. 1).\n The BKH is the key product of the EU-funded Biodiversity Community Integrated Knowledge Library (BiCIKL) project (Penev et al. 2022). The four goals of BiCIKL and the BKH are:\n \n \n \n Improved access to open and FAIR biodiversity data;\n \n \n Establishing of bi-directional data linkages between infrastructures;\n \n \n Development of new methods and workflows for semantic publishing, harvesting, liberating, linking, accessing and re-using of data in literature (specimens, material citations, samples, sequences, taxonomic names, taxonomic treatments, figures, tables);\n \n \n Testing and implementation of services through use cases and open call projects for researchers outside the project.\n \n \n \n Improved access to open and FAIR biodiversity data;\n Establishing of bi-directional data linkages between infrastructures;\n Development of new methods and workflows for semantic publishing, harvesting, liberating, linking, accessing and re-using of data in literature (specimens, material citations, samples, sequences, taxonomic names, taxonomic treatments, figures, tables);\n Testing and implementation of services through use cases and open call projects for researchers outside the project.\n The BKH consists of several modules, such as the Home page that presents the main user groups and the benefits that the BKH provides to them. It has guidelines and protocols, such as various documents on the policies, functions, and recommendations for the users. And it has relevant projects, that use linked FAIR biodiversity data.\n In the core of the BKH is the FAIR Data Place (FDP), which presents novel services and tools developed over the course of BiCIKL. In the future, the FDP will also accept services for linked data provided by new contributors. The FDP consists of three sub-modules:\n \n \n \n Infrastructures and organisations: Lists the contributing organisations and research infrastructures with short descriptions and links to their data, tools and services. Research infrastructures are sorted by the main type of biodiversity data they aggregate and serve: specimens, sequences, taxon names and literature.\n \n \n Linked data services: A catalogue of novel services that deliver FAIR data linked between the participating research infrastructures. Examples of such services are: ChecklistBank, LifeBlock, OpenBiodiv, TreatmentBank, SIBiLS \u201cBiodiversityPMC\u201d, eBioDiv, SynoSpecies, PlutoF Curation Tool and others.\n \n \n Become a contributor application form: A formal questionnaire which serves as a basis to check the suitability of an organisation or research infrastructure to join the BKH. Part of the application form is a FAIR data checklist.\n \n \n \n Infrastructures and organisations: Lists the contributing organisations and research infrastructures with short descriptions and links to their data, tools and services. Research infrastructures are sorted by the main type of biodiversity data they aggregate and serve: specimens, sequences, taxon names and literature.\n Linked data services: A catalogue of novel services that deliver FAIR data linked between the participating research infrastructures. Examples of such services are: ChecklistBank, LifeBlock, OpenBiodiv, TreatmentBank, SIBiLS \u201cBiodiversityPMC\u201d, eBioDiv, SynoSpecies, PlutoF Curation Tool and others.\n Become a contributor application form: A formal questionnaire which serves as a basis to check the suitability of an organisation or research infrastructure to join the BKH. Part of the application form is a FAIR data checklist.\n The BKH serves as a navigation system in a universe of interconnected biodiversity research infrastructures and is open to new contributors and collaborators in accessing open data and knowledge by anybody, anywhere, at any time.","venue":"Biodiversity Information Science and Standards","year":2023.0,"referenceCount":1,"citationCount":0,"fieldsOfStudy":null,"publicationDate":"2023-08-24","authors":[{"authorId":"145178859","name":"L. Penev"},{"authorId":"66311675","name":"D. Koureas"},{"authorId":"5052291","name":"Q. Groom"},{"authorId":"46940450","name":"J. Lanfear"},{"authorId":"2945263","name":"D. Agosti"},{"authorId":"47585953","name":"Ana Casino"},{"authorId":"2138726249","name":"Joseph T. Miller"},{"authorId":"145077545","name":"G. Cochrane"},{"authorId":"3989937","name":"J. Paup\u00e9rio"},{"authorId":"2327449015","name":"O. B\u00e1nki"},{"authorId":"88132038","name":"W. Addink"},{"authorId":"2970211","name":"U. K\u00f5ljalg"},{"authorId":"1724346","name":"Patrick Ruch"},{"authorId":"2233628118","name":"Kristina Hristova"},{"authorId":"46661039","name":"Boris Barov"},{"authorId":"2233628013","name":"Madeira Madeira Scauri"},{"authorId":"87259408","name":"Sara Montinaro"},{"authorId":"1681950","name":"L. Vaira"},{"authorId":"2006799508","name":"N. Fiore"},{"authorId":"2233625832","name":"Elizabeth Bamford"},{"authorId":"2499267","name":"C. Arvanitidis"}]},{"paperId":"00e0c97ac55e41dc65e2aeeba8d4bf78817b3fa8","title":"Generating User Interfaces for Users with Disabilities Using Libraries of XSLT, UIML, and Stylesheet Files","abstract":null,"venue":"Interacci\u00f3n","year":2015.0,"referenceCount":7,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":"2015-08-02","authors":[{"authorId":"1780280","name":"L. Henschen"},{"authorId":"2108360143","name":"Julia C. Lee"},{"authorId":"2120048510","name":"Ning Li"},{"authorId":"50135067","name":"Xia Hou"}]},{"paperId":"00e132b3cb6b089d2ddcaf751ac57cdc07cf9f5c","title":"Interchanging discrete event simulation process-interaction models using the web ontology language - OWL","abstract":"Discrete event simulation development requires significant investments in time and resources. Descriptions of discrete event simulation models are associated with world views, including the process-interaction orientation. Historically, these models have been encoded using high-level programming languages or special purpose (typically vendor-specific) simulation languages. These approaches complicate simulation model reuse and interchange. The current document-centric World Wide Web is evolving into a Semantic Web that communicates information using ontologies. The Web Ontology Language - OWL, was used to encode an ontology for representing discrete event process-interaction models (DEPIM). The DEPIM ontology was developed using ontology engineering processes. The purpose of DEPIM is to provide a vendor-neutral open representation to support model interchange. Model interchange provides an opportunity to improve simulation quality, reduce development costs, and reduce development times.","venue":"Online World Conference on Soft Computing in Industrial Applications","year":2005.0,"referenceCount":149,"citationCount":29,"fieldsOfStudy":["Computer Science"],"publicationDate":"2005-12-04","authors":[{"authorId":"1682044","name":"L. Lacy"}]},{"paperId":"00e1645682437aca43b7ce3bb4dd8d042f87de17","title":"Semantic representation and enrichment of information retrieval experimental data","abstract":null,"venue":"International Journal on Digital Libraries","year":2016.0,"referenceCount":118,"citationCount":28,"fieldsOfStudy":["Computer Science"],"publicationDate":"2016-05-28","authors":[{"authorId":"1688094","name":"G. Silvello"},{"authorId":"2459957","name":"Georgeta Bordea"},{"authorId":"143612982","name":"N. Ferro"},{"authorId":"3338131","name":"P. Buitelaar"},{"authorId":"1742436","name":"Toine Bogers"}]},{"paperId":"00e2bcd5951ce8f489b7d705df1c9be504e9831a","title":"Symposium 1: Designs for learning with the Semantic Web","abstract":"This symposium aligns with the first conference theme of \u2018Theories, methodologies, perspectives and paradigms for Research in Networked Learning\u2019. Within this theme we have assembled three papers relating to designs for learning with the semantic web (Web 3.0). We plan to start the symposium with the presentation of each paper then follow with discussion of the key themes running through them. These are: 1) the emergent nature of semantic web technologies, 2) how participatory research practices like DBR are affected during the development of semantic web technologies and 3) how both of these concepts may find a new place as we move forward into increasingly complex and changeable educational environments. \nEach paper critically reflects on the experience of research and development of semantic web technologies in different educational settings. We specifically focus on methodologies for research in networked learning; linking the nature of an emergent networked learning technology like the semantic web to critical reflections on our participatory research practices across multiple disciplines. This process of reflection on design for learning is described by Jones and Asensio (2002) as critical to enable us to be aware of the influences of social and cultural change in education, our own assumptions about learning, design and development and to uncover any previously unspoken issues for the field of networked learning. We draw on empirical data and experience to contribute to a research field which is concerned with aligning practice with values (Hodgson, 2012). Interestingly, very few papers presented at past networked learning conferences have explicitly considered the role of semantic web technologies in this field and none have linked this to methodological considerations for their design and development. In many ways it could be argued that the semantic web expands the potential of Web 2.0 for ICT to \u2018promote connections\u2019 in learning, which is central to the definition of the networked learning process (Goodyear, Banks, Hodgson and McConnell, 2004, p1.). \nThe semantic web is not a new technology; Berners-Lee at al. brought the concept to public attention in 2001 as \u2018a new form of Web content that is meaningful to computers [which] will unleash a revolution of new possibilities\u2019. But the take up of this grand vision has been patchy and development activity has been disconnected (Carmichael and Jordan, 2012). Outside of specialist fields the notion of the semantic web or Web 3.0 is not well known and the researchers in this symposium are used to the challenge of explaining the concept without a familiar online technology to which it can be associated. Much of the work of the semantic web is hidden and described in the language of the information sciences. Never the less, the potential of the semantic web has been realised for acting as a framework offering advanced search tools, flexibility in visualising data and integration of digital repositories with user-generated content (Martinez-Garcia, et al., 2012). This potential can be exciting but the ethical implications of its use in educational environments should be considered at all times as an integral part of research and development (Tracy and Carmichael, 2011). The case can be made for describing semantic web technologies as \u2018emergent\u2019 in line with the definition by Stahl (2011:p364) of \u2018a technology that shows high potential but hasn\u2019t shown its value or settled down into any kind of consensus\u2019. However, a strict definition of emergent is hard to tie down due to the uncertainty and ambiguity of predicting future impact (Rotolo, Hicks and Martin, 2015). The impact of the emergent nature of the semantic web is considered in line with research methodologies in the papers for this symposium. Along with the challenges and responsibilities posed by developing a technology that is in continual transition and change come the possibilities for redefinition and configuration of the educational pedagogies and practices with which it can be associated. In line with participatory research methods like Design Based Research and in increasingly fractured educational systems this may have the capacity to empower staff and students in the work of knowledge management in Higher Education.The paper by Jesper Jensen & Nina Bonderup Dohn specifically considers a Design Based Research (DBR) project where semantic web technologies were developed for teaching Biology and Chemistry in an Upper Secondary School in Denmark. The case is made that the emergent nature of the technology posed methodological challenges to the implementation of a DBR approach but also created new opportunities for flexibility in the creation of unique solutions to suit the pedagogical practices of the educational environment. This encourages stronger involvement of practitioners in the development process. Furthermore, the paper argues that DBR projects like the one described in this paper, are actually paradigmatic for investigation of educational contexts in rapid technological and pedagogical change because they not only take this change into account, but fundamentally and significantly build on them. \nThe participatory nature of research and development of technologies is considered further in the paper by Fran Tracy, which problematizes participatory research for the development of semantic web technologies. Here the uncertainties and contingencies that are created in the use of participatory research methods are highlighted. Empirical data from an interdisciplinary, multi-institutional technology enhanced learning (TEL) research project is used to reconsider who or what was participating in the research and also when and where that participation took place. The case is made that uncertainty and contingency in technological solutions and methodological approaches allow for enrichment of the development process and subsequently the research outcomes. Through the process of participatory research for this project new teaching practices were developed, pedagogical reflection was inspired and new technologies were developed. \nThe third paper by Patrick Carmichael takes an alternative approach to the analysis of the design practices used in the research and development of semantic web technologies. The neglected tradition of operaismo or 'workers enquiry' is used to reframe some of the activities and findings of a research project which sought to explore the potential of semantic web technologies in Higher Education where case-based learning was the pedagogy of choice. Operaismo has recently begun to receive attention and its potential has begun once again to be recognised as a framework for exploring the experiences of \u2018precarious\u2019 workers, including those in high-tech industries and education. This paper explores some of the insights it might offer for the design of semantic web technologies, with design being seen as a particular kind of work-based enquiry that benefits from contextual understanding and participation of multiple stakeholders and user groups.","venue":"Proceedings of the International Conference on Networked Learning","year":2016.0,"referenceCount":0,"citationCount":0,"fieldsOfStudy":null,"publicationDate":"2016-05-09","authors":[{"authorId":"2323989557","name":"Frances Tracy"},{"authorId":"2324698051","name":"Jesper Jensen"}]},{"paperId":"00e4c28a2f13d87c96d4c28d7333d37777a85163","title":"Sailing the corpus sea: Visual exploration of news stories","abstract":"Rich information spaces like blogs or news are full of \u201cstories\u201d: sets of statements that evolve over time, made in fast-growing streams of documents. Even if one reads a specific source every day and\/or subscribes to a selection of feeds, one may easily lose track; in addition, it is difficult to reconstruct a story already in the past. In this paper, we present the STORIES methods and tool for (a) learning an abstracted story representation from a collection of time-indexed documents; (b) visualizing it in a way that encourages users to interact and explore in order to discover temporal \u201cstory stages\u201d depending on their interests; (c) supporting the search for documents and facts that pertain to the user-constructed story stages; (d) discovering the most important facts in the corpora; and (e) navigating in document space along multiple meaningful dimensions of document similarity and relatedness. This combination provides users with more control, progressing from \u201csurfing\u201d the Web to \u201csailing\u201d selected corpora of it, semantically in story space as well as between the underlying documents. An evaluation demonstrates that machine learning and interaction lead to representations that serve to retrieve coherent and relevant document subsets and that help users learn facts about the story.","venue":"2011 IEEE 9th International Symposium on Intelligent Systems and Informatics","year":2011.0,"referenceCount":17,"citationCount":3,"fieldsOfStudy":["Computer Science"],"publicationDate":"2011-10-03","authors":[{"authorId":"2448620","name":"Ilija Subasic"},{"authorId":"2990203","name":"Bettina Berendt"},{"authorId":"152772745","name":"Daniel Trumper"}]},{"paperId":"00e52a6544c3ac928c7307d0266898c89c02d2f0","title":"Prospective Terms Based Architecture for Migrating Crawler","abstract":"Search engines help users find information on WWW by making web pages related to their query available. Searches are factorized by using either terms or keywords or through short sentences. No matter how user specifies the search query, the results retrieved, organized & presented by search engines are in terms of millions of linked pages of which many of them might not be useful to the user. Due to lack of refinement & any meaningful classification of search result, user seldom find required information on the first page of the result page. Furthermore temporal quality of downloaded documents due to lack of automatic tracking of user trend & topic of current interest is not high. Thus providing accurate precise & high quality result to the end user has become major task for search engine. In this paper Prospective Terms Based Architecture for Migrating Crawler is being proposed that helps to retrieve web pages according to latest trend & updated information among various topics while working in parallel. A prospective table which relate semantically related keyword is being used at crawling, indexing and page ranking level so that search engine adopt a prospective view & user get full information within first few urls & need not go deeper into the results.","venue":"2012 Fourth International Conference on Computational Intelligence and Communication Networks","year":2012.0,"referenceCount":12,"citationCount":3,"fieldsOfStudy":["Computer Science"],"publicationDate":"2012-11-03","authors":[{"authorId":"2110031709","name":"Ashlesha Gupta"},{"authorId":"145871197","name":"A. Dixit"},{"authorId":"144839940","name":"A. Sharma"}]},{"paperId":"00e9398ad4f56bbb668234f319159b23e5338a24","title":"Context-aware Business Application Service Co-ordination in Mobile Computing Environments","abstract":"The research project CASCOM will implement, validate, and trial value-added support for business services for mobile workers and users across mobile and fixed networks. The vision of the CASCOM approach is that ubiquitous application services are flexibly co-ordinated and pervasively provided to the mobile users by intelligent agents in dynamically changing contexts of open, large-scale, pervasive environments. The essential approach of CASCOM is the innovative combination of intelligent agent technology, semantic Web services, peer-to-peer, and mobile computing for intelligent peer-to-peer (IP2P) service environments. The services are provided by software agents exploiting the co-ordination infrastructure to efficiently operate in highly dynamic environments.","venue":"","year":2005.0,"referenceCount":19,"citationCount":26,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"2072146429","name":"Heikki Helin"},{"authorId":"1798357","name":"M. Klusch"},{"authorId":"2110295197","name":"A. L\u00f3pez"},{"authorId":"144904155","name":"Alberto Fern\u00e1ndez"},{"authorId":"2055699661","name":"Schumacher Michael"},{"authorId":"2091542776","name":"Schuldt Heiko"},{"authorId":"115036345","name":"B. Federico"},{"authorId":"2092768138","name":"Kinnunen Ari"}]},{"paperId":"00e96acd9f295ed5dc1668247a2f52aff2be3f6c","title":"Automated interpretability of linked data ontologies: : an evaluation within the cultural heritage domain","abstract":"Publication and usage of linked data has been highly pursued by cultural heritage institutions and service providers in this domain. Much research and cooperation are taking place in adapting and improving cultural heritage data models for linked data and in defining ontologies and vocabularies, as well as the setting up of services based on linked data. This article presents an evaluation of ontologies and vocabularies published as liked data, which originate from the cultural heritage domain, or are frequently used and linked to in this domain. Our study aims to evaluate their usability by crawlers operating on the web of data, according to specifications and practices of linked data, the Semantic Web and ontology reasoning. We evaluate having in mind the use case of general data consumption applications based on RDF, RDF Schema, OWL, SKOS and linked data\u2019s guidelines. We have evaluated twelve ontologies and vocabularies and identified that four were not fully compliant, and that alignments between ontologies are not included in the definitions of the ontologies. This study contributes to the research of novel services consuming linked data. It also allows to better assess the automation that can be achieved to handle the variety and large volume of linked data, when assessing the viability of new services based on linked data in cultural heritage.","venue":"2019 IEEE International Conference on Big Data (Big Data)","year":2019.0,"referenceCount":19,"citationCount":8,"fieldsOfStudy":["Computer Science"],"publicationDate":"2019-12-01","authors":[{"authorId":"144913210","name":"Nuno Freire"},{"authorId":"67277779","name":"S. Valk"}]},{"paperId":"00e9e7f071b2d76a021ff0326e0ea8baa1c7d990","title":"Semantic and Logic Modeling of Disaster Simulation for Multi-agent Systems","abstract":"\u2014Disaster management is a complex collaborative process involving several stakeholders from different domains and requiring preparation for designing action plans. Computer simulation of such collaborative process allows globally assessing the efficiency of such preparation. Studies have shown that multi-agent systems (MAS) are well suited for identifying an optimal strategy or potential issues in the context of one or several action plans. Thus, our approach relies on a MAS for simulating action plans. We consider combining such an approach with Semantic Web technologies, in order to define the conceptual simulation model according to the preparation model of disaster management. The knowledge base is expressed through two different ontologies (semDM to model the preparation results and semMAS to model the simulation) that will be discussed in this paper. On top of these knowledge models, domain-specific constraints allow for checking consistency, and logic rules are used to define the semMAS modeling according to semDM.","venue":"International Journal of Modeling and Optimization","year":2019.0,"referenceCount":33,"citationCount":1,"fieldsOfStudy":["Computer Science"],"publicationDate":"2019-08-01","authors":[{"authorId":"37272923","name":"C. Prudhomme"},{"authorId":"145378327","name":"C. Cruz"},{"authorId":"2234423","name":"F. Boochs"}]},{"paperId":"00eccfcc29bfe2192d669dcc4138a80a29814e35","title":"Mining of Diverse Social Entities from Linked Data","abstract":"Nowadays, high volumes of valuable data can be easily generated or collected from various data sources at high velocity. As these data are often related or linked, they form a web of linked data. Examples include semantic web and social web. The social web captures social relationships that link people (i.e., social entities) through the World Wide Web. Due to the popularity of social networking sites, more people have joined and more online social interactions have taken place. With a huge number of social entities (e.g., users or friends in social networks), it becomes important to analyze high volumes of linked data and discover those diverse social entities. In this paper, we present (i) a tree-based mining algorithm calledDF-growth, along with (ii) its related data structure calledDF-tree ,w hich allow users to e\u21b5ectively and eciently mine diverse friends from social networks. Results of our experimental evaluation showed both the timeand space-eciency of our scalable DF-growth algorithm, which makes good use of the DF-tree structure.","venue":"EDBT\/ICDT Workshops","year":2014.0,"referenceCount":24,"citationCount":4,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"145046124","name":"A. Cuzzocrea"},{"authorId":"1726081","name":"C. Leung"},{"authorId":"2085610","name":"S. Tanbeer"}]},{"paperId":"00ed27d1ece6bd4405bd95ef819325e5ff1990b7","title":"Multi agent trust for belief combination on the Semantic Web","abstract":"Software agents that assess similarities between concepts on the semantic Web has to deal with scenarios where the beliefs in the assessed similarities becomes contradicting. The combination of these contradicting beliefs can easily worsen the mapping precision and recall, which leads to poor performance of any ontology mapping algorithm. Typically mapping algorithms, which use different similarities and combine them into a more reliable and coherent view can easily become unreliable when these contradictions are not managed effectively between the different sources. In this paper we propose a solution based on the fuzzy voting model for managing such situations by introducing trust and voting between software agents that resolve contradicting beliefs in the assessed similarities.","venue":"International Conference on Computational Photography","year":2008.0,"referenceCount":8,"citationCount":3,"fieldsOfStudy":["Computer Science"],"publicationDate":"2008-10-10","authors":[{"authorId":"33282232","name":"M. Nagy"},{"authorId":"1398824485","name":"M. Vargas-Vera"},{"authorId":"2054281562","name":"Enrico Motta"}]},{"paperId":"00eff49b93902a2ff3fa7ed93e0784b1028a6511","title":"Functionality-Driven Clustering of Web Service Registries","abstract":"Web service registries play an important role in service oriented applications. They constitute the market where service consumers and providers go to search and advertise Web services. With the proliferation of Web service registries, finding an adequate registry has become a complex task for a service requester. In this paper we propose a semantic model for Web services registry description (WSRD). WSRD descriptions depict the functionalities offered by services advertised by a given registry since they rely on these descriptions. We also propose a functionality-driven clustering approach for distributed Web service registries. This approach is based on a fuzzy clustering technique and allows structuring distributed registries based on their WSRD descriptions without any additional data. This clustering will be helpful for selecting an adequate registry for service requesters.","venue":"IEEE International Conference on Services Computing","year":2010.0,"referenceCount":13,"citationCount":22,"fieldsOfStudy":["Computer Science"],"publicationDate":"2010-07-05","authors":[{"authorId":"144087499","name":"M. Sellami"},{"authorId":"1762930","name":"Walid Gaaloul"},{"authorId":"3208164","name":"S. Tata"}]},{"paperId":"00f0bf26ee5cdc4d7a0f9794ffeeb343d4b7ce32","title":"A service selection method for improving integrated business processes","abstract":"Web services hold a great promise of implementing the B2B e-commerce by dynamically integrating business processes over the Internet. It is necessary to automatically and accurately select appropriate web services satisfying client requirements before and after integrating business processes. However, current web services standards do not well support it. We propose a formal method to select appropriate services satisfying client requirements as much as possible. Firstly, we make use of the semantic matching of service specifications based on service behavior to select the services that can be safely integrated with the existing services. Secondly, we evaluate the reliability of these services to select an appropriate integration satisfying the client requirement. Consequently, we can obtain high quality integrated business processes.","venue":"IEEE Asia-Pacific Services Computing Conference","year":2009.0,"referenceCount":12,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":"2009-12-01","authors":[{"authorId":"2583993","name":"Lihui Lei"}]},{"paperId":"00f9f2a96da4c206f0d8e5bf1ad706878cd8aeb0","title":"Short Text Classification via Knowledge powered Attention with Similarity Matrix based CNN","abstract":"Short text is becoming more and more popular on the web, such as Chat Message, SMS and Product Reviews. Accurately classifying short text is an important and challenging task. A number of studies have difficulties in addressing this problem because of the word ambiguity and data sparsity. To address this issue, we propose a knowledge powered attention with similarity matrix based convolutional neural network (KASM) model, which can compute comprehensive information by utilizing the knowledge and deep neural network. We use knowledge graph (KG) to enrich the semantic representation of short text, specially, the information of parent-entity is introduced in our model. Meanwhile, we consider the word interaction in the literal-level between short text and the representation of label, and utilize similarity matrix based convolutional neural network (CNN) to extract it. For the purpose of measuring the importance of knowledge, we introduce the attention mechanisms to choose the important information. Experimental results on five standard datasets show that our model significantly outperforms state-of-the-art methods.","venue":"arXiv.org","year":2020.0,"referenceCount":50,"citationCount":3,"fieldsOfStudy":["Computer Science"],"publicationDate":"2020-02-09","authors":[{"authorId":"47629178","name":"Mingchen Li"},{"authorId":"2150567605","name":"Gabtone.Clinton"},{"authorId":"93912397","name":"Yijia Miao"},{"authorId":"2153408839","name":"Feng Gao"}]},{"paperId":"00fa8be6f1e7ef2948a95d53c90a1789d43ee5ef","title":"A Novel Approach for Interacting with Linked Open Data","abstract":null,"venue":"WISE","year":2011.0,"referenceCount":5,"citationCount":3,"fieldsOfStudy":["Computer Science"],"publicationDate":"2011-10-13","authors":[{"authorId":"1712453","name":"A. Haller"},{"authorId":"1778643","name":"T. Groza"}]},{"paperId":"00fa98ee4bf598056237c0d8645d971ca9f8326a","title":"Enhanced web services collaboration in B2B context","abstract":"Web services are one of modern technologies used to perform collaboration and interactions between businesses in B2B-based ebXML contexts. In our study, we will focus on business registries-based ebXML because his two layers oriented architecture - registry and repository layers - will enable modularity and flexibility in our solution. In this paper, we expose an efficient approach to enhance the interpretation of the semantic by the business registry. This approach consists of storing semantic OWL - Web Ontology Language - constructs into the business repository and designing pre-stored functions for semantic interpretation of the business repository components. The designed pre-stored functions permit to web services to query repository semantic data following OWL DL - Description Language - reasoning.","venue":"","year":2015.0,"referenceCount":0,"citationCount":0,"fieldsOfStudy":["Business"],"publicationDate":null,"authors":[{"authorId":"120912849","name":"Salim Baroudi"},{"authorId":"2747412","name":"M. Bahaj"}]},{"paperId":"00fab71db3196836d5b6d8c72d20a9056fb182c0","title":"Proceedings of the 3rd Workshop on Knowledge Discovery and Data Mining Meets Linked Open Data co-located with 11th Extended Semantic Web Conference (ESWC 2014), Crete, Greece, May 25, 2014","abstract":null,"venue":"Know@LOD","year":2014.0,"referenceCount":0,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[]},{"paperId":"00fc8c5202b3ee746fa6eda973db8d572e33ad4b","title":"Integrating Metadata Development, XML, and DBMS Search and Query Techniques in a State of Wisconsin Land Information System","abstract":"In addition to Nancy Wiegand, the PIs on this project are Isabel Cruz at the University of Illinois at Chicago and Stephen Ventura at the University of Wisconsin-Madison. The goal of the project is to provide full Database Management System type querying over government-produced data in a distributed Web-based information system. Current research focuses on the major issue of integrating and querying heterogeneous statewide data. We are using a semantic approach to achieve interoperability.","venue":"Digital Government Research","year":2004.0,"referenceCount":6,"citationCount":1,"fieldsOfStudy":["Computer Science"],"publicationDate":"2004-05-24","authors":[{"authorId":"2285265","name":"N. Wiegand"}]},{"paperId":"00fc981cd9f9ce6c1141489a25d3636170a4f32d","title":"Using Semantic Web to Provide Intelligent Advice on University Admissions","abstract":"This paper describes a prototype application that investigates benefits of using Semantic Web to improve information access and provide intelligent advice to students in selecting the most appropriate universities and subjects to apply to. Without Semantic Web technology, students need to manually browse through pages and pages of information in Web sites of different Universities to find a list of universities, departments and programs that they qualify to apply for. Our prototype demonstrates that Semantic Web can automate and streamline this whole process. All the students need to do is enter their qualifications and a list will be generated automatically. Of course, this is assuming that most universities have the admissions requirements in RDF format. Fortunately, since there are only eight universities in Hong Kong, the use of a shared ontology based on RDF and DAML+OIL to describe admissions requirements is not totally impossible. One of the objectives of our research is to design such an ontology and to test its limits by encoding admission requirements for several of our local universities into our prototype. This paper also presents a new \"explore by class\" search algorithm we developed to optimize search performances in our university Semantic Web problem domain.","venue":"","year":2003.0,"referenceCount":28,"citationCount":0,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"2285044226","name":"Francis King"},{"authorId":"2285109074","name":"Hei Kwong"},{"authorId":"2285113276","name":"Hon Wai Chun"}]},{"paperId":"00fc9f2a0f6215f5352faf040275987bcef2ac2c","title":"Association Rule Interactive Post-processing using Rule Schemas and Ontologies - ARIPSO","abstract":"This thesis is concerned with the merging of two active research domains: Knowledge Discovery in Databases (KDD), more precisely the Association Rule Mining technique, and Knowledge Engineering (KE) with a main interest in knowledge representation languages developed around the Semantic Web. In Data Mining, the usefulness of association rule technique is strongly limited by the huge amount and the low quality of delivered rules. Experiments show that rules become almost impossible to use when their number exceeds 100. At the same time, nuggets are often represented by those rare (low support) unexpected association rules which are surprising to the user. Unfortunately, the lower the support is, the larger the volume of rules becomes. Thus, it is crucial to help the decision maker with an efficient technique to reduce the number of rules. To overcome this drawback, several methods have been proposed in the literature such as itemset concise representations, redundancy reduction, filtering, ranking and post-processing. Even though rule interestingness strongly depends on user knowledge and goals, most of the existing methods are generally based on data structure. For instance, if the user looks for unexpected rules, all the already known rules should be pruned. Or, if the user wants to focus on specific family of rules, only this subset of rules should be selected. In this context, we address two main issues: the integration of user knowledge in the discovery process and the interactivity with the user. The first issue requires defining an adapted formalism to express user knowledge with accuracy and flexibility such as ontologies in the Semantic Web. Second, the interactivity with the user allows a more iterative mining process where the user can successively test different hypotheses or preferences and focus on interesting rules. The main contributions of this work can be summarized as follows: (i) A model to represent user knowledge. First, we propose a new rule-like formalism, called Rule Schema, which allows the user to define his\/her expectations regarding the rules through ontology concepts. Second, ontologies allow the user to express his\/her domain knowledge by means of a high semantic model. Last, the user can choose among a set of Operators for interactive processing the one to be applied over each Rule Schema (i.e. pruning, conforming, unexpectedness, . . . ). (ii) A new post-processing approach, called ARIPSO (Association Rule Interactive Post-processing using rule Schemas and Ontologies), which helps the user to reduce the volume of the discovered rules and to improve their quality. It consists in an interactive process integrating user knowledge and expectations by means of the proposed model. At each step of ARIPSO, the interactive loop allows the user to change the provided information and to reiterate the post-processing phase which produces new results. (iii) The implementation in post-processing of the proposed approach. The developed tool is complete and operational, and it implements all the functionalities described in the approach. Also, it makes the connection between different elements like the set of rules and rule schemas stored in PMML\/XML files, and the ontologies stored in OWL files and inferred by the Pellet reasoner. (iv) An adapted implementation without post-processing, called ARLIUS (Association Rule Local mining Interactive Using rule Schemas), consisting in an interactive local mining process guided by the user. It allows the user to focus on interesting rules without the necessity to extract all of them, and without minimum support limit. In this way, the user may explore the rule space incrementally, a small amount at each step, starting from his\/her own expectations and discovering their related rules. (v) The experimental study analyzing the approach efficiency and the discovered rule quality. For this purpose, we used a real-life and large questionnaire database concerning customer satisfaction. For ARIPSO, the experimentation was carried out in complete cooperation with the domain expert. For different scenarios, from an input set of nearly 400 thousand association rules, ARIPSO filtered between 3 and 200 rules validated by the expert. Clearly, ARIPSO allows the user to significantly and efficiently reduce the input rule set. For ARLIUS, we experimented different scenarios over the same questionnaire database and we obtained reduced sets of rules (less than 100) with very low support.","venue":"","year":2010.0,"referenceCount":232,"citationCount":9,"fieldsOfStudy":["Computer Science"],"publicationDate":"2010-10-26","authors":[{"authorId":"3245150","name":"Claudia Marinica"}]},{"paperId":"00fce98c3fda59bcb84b6d0626fb3137d2fbb984","title":"Web-Scale Distributional Similarity and Entity Set Expansion","abstract":"Computing the pairwise semantic similarity between all words on the Web is a computationally challenging task. Parallelization and optimizations are necessary. We propose a highly scalable implementation based on distributional similarity, implemented in the MapReduce framework and deployed over a 200 billion word crawl of the Web. The pairwise similarity between 500 million terms is computed in 50 hours using 200 quad-core nodes. We apply the learned similarity matrix to the task of automatic set expansion and present a large empirical study to quantify the effect on expansion performance of corpus size, corpus quality, seed composition and seed size. We make public an experimental testbed for set expansion analysis that includes a large collection of diverse entity sets extracted from Wikipedia.","venue":"Conference on Empirical Methods in Natural Language Processing","year":2009.0,"referenceCount":51,"citationCount":307,"fieldsOfStudy":["Computer Science"],"publicationDate":"2009-08-06","authors":[{"authorId":"1990190","name":"Patrick Pantel"},{"authorId":"2019236","name":"E. Crestan"},{"authorId":"2647634","name":"A. Borkovsky"},{"authorId":"36445704","name":"Ana-Maria Popescu"},{"authorId":"2938286","name":"V. Vyas"}]},{"paperId":"00fd0bebd6ed789a064126123d016f49fba3b6e9","title":"The JUMP project: Domain Ontologies and Linguistic Knowledge @ Work","abstract":"The JUMP project aims at bringing together the knowledge stored in different information systems in order to satisfy information and training needs in knowledge-intensive organisations. Electronic Performance Support Systems provide help, advices, demonstrations, or any other informative support that a user needs to the accomplishment of job tasks in her day-to-day working environment. The paper describes the JUMP framework, which is designed to offer multiple ways for the user to query the knowledge base resulting from integration of autonomous legacy systems. Semantic Web languages and technologies are used throughout the framework to represent, exchange and query the knowledge, while Natural Language Processing Techniques are implemented to understand natural language queries formulated by the user and provide consistent and satisfying results.","venue":"Semantic Web Applications and Perspectives","year":2007.0,"referenceCount":12,"citationCount":9,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"1731651","name":"Pierpaolo Basile"},{"authorId":"1873109","name":"M. Degemmis"},{"authorId":"1953113","name":"Anna Lisa Gentile"},{"authorId":"2724704","name":"L. Iaquinta"},{"authorId":"1725519","name":"P. Lops"}]},{"paperId":"010068feb23ebf7d61095e83c3e0678aaee11d08","title":"Discourse-level relations for opinion analysis","abstract":"Opinion analysis deals with subjective phenomena such as judgments, evaluations, feelings, emotions, beliefs and stances. The availability of public opinion over the Internet and in face to face conversations, coupled with the need to understand and mine these for end applications, has motivated a great amount of research in this field in recent times. Researchers have explored a wide array of knowledge resources for opinion analysis, from words and phrases to syntactic dependencies and semantic relations. \nIn this thesis, we investigate a discourse-level treatment for opinion analysis. \nIn order to realize the discourse-level analysis, we propose a new linguistic representational scheme designed to support interdependent interpretations of opinions in the discourse. We adapt and extend an existing subjectivity annotation scheme to capture discourse-level relations in a multi-party meeting corpus. Human inter-annotator agreement studies show that trained human annotators can recognize the elements of our linguistic scheme. \nEmpirically, we test the impact of our discourse-level relations on fine-grained polarity classification. In this process, we also explore two different global inference models for incorporating discourse-based information to augment word-based information. Our results show that the discourse-level relations can augment and improve upon word-based methods for effective fine-grained opinion polarity classification. Further, in this thesis, we explore linguistically motivated features and a global inference paradigm for learning the discourse-level relations form the annotated data. \nWe employ the ideas from our linguistic scheme for recognizing stances in dual-sided debates from the product and political domains. For product debates, we use web mining and rules to learn and employ elements of our discourse-level relations in an unsupervised fashion. For political debates, on the other hand, we take a more exploratory, supervised approach, and encode the building blocks of our discourse-level relations as features for stance classification. Our results show that the ideas behind the discourse level relations can be learned and employed effectively to improve overall stance recognition in product debates. \nKeywords. Opinion analysis, sentiment, arguing, linguistic scheme, annotation scheme, computational modeling, fine-grained polarity analysis, stance recognition.","venue":"","year":2010.0,"referenceCount":147,"citationCount":43,"fieldsOfStudy":["Psychology"],"publicationDate":null,"authors":[{"authorId":"144120827","name":"Janyce Wiebe"},{"authorId":"2059584","name":"Swapna Somasundaran"}]},{"paperId":"010144e77177e48f65ac93773c219e85faa0c744","title":"Francisella tularensis novicida proteomic and transcriptomic data integration and annotation based on semantic web technologies","abstract":null,"venue":"BMC Bioinformatics","year":2009.0,"referenceCount":59,"citationCount":9,"fieldsOfStudy":["Medicine","Biology","Computer Science"],"publicationDate":"2009-10-01","authors":[{"authorId":"1944632","name":"Nadia Anwar"},{"authorId":"2425796","name":"Ela Pustulka-Hunt"}]},{"paperId":"0101859b2faf2c9c75b971238741576edeadb91a","title":"Challenges for Ontology Repositories and Applications to Biomedicine & Agronomy","abstract":"The explosion of the number of ontologies and vocabularies available in the Semantic Web makes ontology libraries and repositories mandatory to find and use them. Their functionalities span from simple on-tology listing with more or less of metada-ta description to portals with advanced on-tology-based services: browse, search, vis-ualization, metrics, annotation, etc. Ontol-ogy libraries and repositories are usually developed to address certain needs and communities. BioPortal, the ontology repository built by the US National Center for Biomedical Ontologies BioPortal relies on a domain independent technology already reused in several projects from bio-medicine to agronomy and earth sciences. In this position paper, we describe six high level challenges for ontology repositories: metadata & selection, multilingualism, alignment, new generic ontology-based services, annotations & linked data, and interoperability & scalability. Then, we present some propositions to address these challenges and point to our previously published work and results obtained within applications \u2013reusing NCBO technology\u2013 to biomedicine and agronomy in the context of the NCBO, SIFR and AgroPortal projects.","venue":"Symposium on Information Management and Big Data","year":2017.0,"referenceCount":62,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":"2017-09-04","authors":[{"authorId":"1800186","name":"C. Jonquet"}]},{"paperId":"010247fc8c09096fd6308f4d9bb6c1e6a8c6ea51","title":"Local Tableaux for Reasoning in Distributed Description Logics","abstract":"The last decade of basic research in the area of Description Logics (DL) has created a stable theory, efficient inference procedures, and has demonstrated a wide applicability of DL to knowledge representation and reasoning. The success of DL in the semantic web and the distributed nature of the last one inspired recently a proposal of Distributed DL framework (DDL). DDL is composed of a set of stand alone DLs pairwise interrelated with each other via collection of bridge rules. In this paper, we investigate the reasoning mechanisms in DDL and introduce a tableau-based reasoning algorithm for DDL, built on the top of the state of the art tableaux reasoners for DL. We also describe a first prototype implementation of the proposed algorithm.","venue":"Description Logics","year":2004.0,"referenceCount":12,"citationCount":52,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"144077615","name":"L. Serafini"},{"authorId":"3001648","name":"A. Tamilin"}]},{"paperId":"01026a74f9a7aaeda245e799211b556d94a7e1ad","title":"Semantic Complex Event Reasoning - Beyond Complex Event Processing","abstract":null,"venue":"Foundations for the Web of Information and Services","year":2011.0,"referenceCount":28,"citationCount":15,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"144200398","name":"N. Stojanovi\u0107"},{"authorId":"144395406","name":"Ljiljana Stojanovi\u0107"},{"authorId":"1777981","name":"Darko Anicic"},{"authorId":"2152610901","name":"Jun Ma"},{"authorId":"151746517","name":"Sinan Sen"},{"authorId":"1771776","name":"Roland St\u00fchmer"}]},{"paperId":"0103750f4a2291679cdee2d3c9607c837ea1637b","title":"Linked Data: The Glue Within Interoperable Information Systems","abstract":"Our Environmental Information Systems are exposing environmental features, their monitoring systems and the observation they generate in an interoperable way (technical and semantic) for years. In Europe, there is even a legal obligation to such practices via the INSPIRE directive. However, the practice inducing data providers to set up services in a \"Discovery > View > Download data\" pattern hides data behind the services. This hinders data discovery and reuse. Linked Data on the Web Best Practices put this stack upside down and data is now back in the first line. This completely revamp the design and capacities of our Information Systems. We'll highlight the new data frontiers opened by such practices taking examples on the French National Groundwater Information Network.\u201d","venue":"","year":2020.0,"referenceCount":0,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":"2020-01-13","authors":[{"authorId":"7798292","name":"Sylvain Grellet"},{"authorId":"3141219","name":"Abdelfettah Feliachi"}]},{"paperId":"01062f35dbb130e893c80c4c06b483a33a71c55e","title":"Semantic Web for e-Commerce","abstract":null,"venue":"ERCIM News","year":2009.0,"referenceCount":0,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"2060077315","name":"Bernd Gruber"}]},{"paperId":"01065b1da12415553b0fe225a017f00cd4055f85","title":"Web Stream Reasoning: From Data Streams to Actionable Knowledge","abstract":null,"venue":"Reasoning Web","year":2015.0,"referenceCount":34,"citationCount":5,"fieldsOfStudy":["Computer Science"],"publicationDate":"2015-07-31","authors":[{"authorId":"1758781","name":"A. Mileo"}]},{"paperId":"0106db2d2504abf3ccf823257e436ec4c7b14b75","title":"Mexican e-government ontologies: an adaptation","abstract":"The Electronic Government is a new field of applica tions for the semantic web where ontologies are becoming an important research technology. The e-Government faces considerable challenges to achieve interoperability given the semantic differences of interpretation, complexity and width of scope. In t his paper we present the results obtained in an ongoing project commissioned by the Mexican government that seeks strategies for the e-Government to reduc e the problems encountered when delivering services to citizens. We also show an adaptation of e-Govern ment ontology model; within this model a set of government ontologies are devoted to representing t he Local Government processes.","venue":"","year":2006.0,"referenceCount":32,"citationCount":15,"fieldsOfStudy":["Engineering"],"publicationDate":null,"authors":[{"authorId":"2581068","name":"Fernando Ortiz-Rodr\u00edguez"}]},{"paperId":"010744bd748597e8abcc9b04c49fbb0ca1137d94","title":"Statistically-constrained shallow text marking: techniques, evaluation paradigm and results","abstract":"We present three natural language marking strategies based on fast and reliable shallow parsing techniques, and on widely available lexical resources: lexical substitution, adjective conjunction swaps, and relativiser switching. We test these techniques on a random sample of the British National Corpus. Individual candidate marks are checked for goodness of structural and semantic fit, using both lexical resources, and the web as a corpus. A representative sample of marks is given to 25 human judges to evaluate for acceptability and preservation of meaning. This establishes a correlation between corpus based felicity measures and perceived quality, and makes qualified predictions. Grammatical acceptability correlates with our automatic measure strongly (Pearson's r = 0.795, p = 0.001), allowing us to account for about two thirds of variability in human judgements. A moderate but statistically insignificant (Pearson's r = 0.422, p = 0.356) correlation is found with judgements of meaning preservation, indicating that the contextual window of five content words used for our automatic measure may need to be extended.","venue":"Electronic imaging","year":2007.0,"referenceCount":47,"citationCount":15,"fieldsOfStudy":["Engineering","Computer Science"],"publicationDate":null,"authors":[{"authorId":"2053393407","name":"Brian Murphy"},{"authorId":"144420027","name":"Carl Vogel"}]},{"paperId":"0109022cfde471bc217ef89c171e3039d7eca903","title":"Transforming unstructured query to mediated query for structured retrieval","abstract":"Recent years, the availability of public accessible structured resources like XML on the web has led to active developments of structural retrieval systems. With these systems, users will be able to query for information from structured resources on the web efficiently. When querying, it is obvious that usage of structural information in query increases the precision of retrieval system. However, general web users are more familiar with unstructured query such as natural language or keywords, which contains no structural information. This motivates us to find a retrieval method that supports querying which is simpler and familiar to user, i.e. unstructured query, but at the same time, does not overlook the usage of structural information in query. Hence, we propose a solution that automatically adds structural information to the unstructured query, and represents it as a Mediated Query. The mediated query is an intermediate query in structured form to bridge the gap of structural differences between unstructured query and structured resources. As the selection of correct structural information that reflects the query context is crucial for better retrieval performance, we develop a method to obtain this information by learning the semantics of a set of terms extracted from structured resources. The semantics of a term is defined by its concept and context. We represent the term and its semantics using the Semantic Prediction Model. The model will be used in reasoning the context of query and the process of creating mediated query. The mediated query is then matched against structured resources to obtain relevant results.","venue":"International Symposium on Information Theory","year":2010.0,"referenceCount":13,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":"2010-06-15","authors":[{"authorId":"3064135","name":"Gan Keng Hoon"},{"authorId":"2480682","name":"Phang Keat Keong"}]},{"paperId":"010950e846df26d3dea6e6e09b8eb958f99be183","title":"Decidable Reasoning in a Modified Situation Calculus","abstract":"We consider a modified version of the situation calculus built using a two-variable fragment of the first-order logic extended with counting quantifiers. We mention several additional groups of axioms that can be introduced to capture taxonomic reasoning. We show that the regression operator in this framework can be defined similarly to regression in the Reiter's version of the situation calculus. Using this new regression operator, we show that the projection and executability problems are decidable in the modified version even if an initial knowledge base is incomplete and open. For an incomplete knowledge base and for context-dependent actions, we consider a type of progression that is sound with respect to the classical progression. We show that the new knowledge base resulting after our progression is definable in our modified situation calculus if one allows actions with local effects only. We mention possible applications to formalization of Semantic Web services.","venue":"International Joint Conference on Artificial Intelligence","year":2007.0,"referenceCount":24,"citationCount":32,"fieldsOfStudy":["Computer Science","Mathematics"],"publicationDate":"2007-01-06","authors":[{"authorId":"2937364","name":"Yilan Gu"},{"authorId":"3141928","name":"M. Soutchanski"}]},{"paperId":"010b9c34c82f31530f4c7bc3b8be3bf270972341","title":"A Phishing-Attack-Detection Model Using Natural Language Processing and Deep Learning","abstract":"Phishing is a type of cyber-attack that aims to deceive users, usually using fraudulent web pages that appear legitimate. Currently, one of the most-common ways to detect these phishing pages according to their content is by entering words non-sequentially into Deep Learning (DL) algorithms, i.e., regardless of the order in which they have entered the algorithms. However, this approach causes the intrinsic richness of the relationship between words to be lost. In the field of cyber-security, the innovation of this study is to propose a model that detects phishing attacks based on the text of suspicious web pages and not on URL addresses, using Natural Language Processing (NLP) and DL algorithms. We used the Keras Embedding Layer with Global Vectors for Word Representation (GloVe) to exploit the web page content\u2019s semantic and syntactic features. We first performed an analysis using NLP and Word Embedding, and then, these data were introduced into a DL algorithm. In addition, to assess which DL algorithm works best, we evaluated four alternative algorithms: Long Short-Term Memory (LSTM), Bidirectional LSTM (BiLSTM), Gated Recurrent Unit (GRU), and Bidirectional GRU (BiGRU). As a result, it can be concluded that the proposed model is promising because the mean accuracy achieved by each of the four DL algorithms was at least 96.7%, while the best performer was BiGRU with 97.39%.","venue":"Applied Sciences","year":2023.0,"referenceCount":34,"citationCount":15,"fieldsOfStudy":null,"publicationDate":"2023-04-23","authors":[{"authorId":"2209219307","name":"Eduardo Benavides-Astudillo"},{"authorId":"144705186","name":"Walter Fuertes"},{"authorId":"1403353367","name":"Sandra Sanchez-Gordon"},{"authorId":"1742152091","name":"Daniel Nu\u00f1ez-Agurto"},{"authorId":"2215348585","name":"Germ\u00e1n Rodr\u00edguez-Gal\u00e1n"}]},{"paperId":"010c68c2a5808bc31fd2f383451efcf0af13acc3","title":"crowd: A Tool for Conceptual Modelling assisted by Automated Reasoning","abstract":"There is an increment on the complexity of the information systems derived from new paradigms, for example Semantic Web, Big Data, e-government, etc. which require high quality solutions to tackle complex problems such as information integration. This quality is widely determined by the conceptual level. In this work, we present crowd as a novel tool for designing both conceptual models and ontologies based on visual representations with assistance of logic-based reasoning services. The challenge and the intention behind this work is to de\ufb01ne graphical-logical methodologies as e\ufb00ective solutions for the description of interest domains at conceptual level. We detail the tool and demonstrate the usage of an initial prototype with some simple examples. Moreover, we identify limitations and potential issues about modelling and propose some partial solutions to tackle them. Currently, we are working to release the \ufb01rst beta version of crowd .","venue":"","year":2016.0,"referenceCount":34,"citationCount":13,"fieldsOfStudy":["Engineering"],"publicationDate":null,"authors":[{"authorId":"2070536522","name":"Christian Gimenez"},{"authorId":"3275243","name":"G. Braun"},{"authorId":"28138344","name":"L. Cecchi"},{"authorId":"1786561","name":"P. Fillottrani"}]},{"paperId":"010c9f0412d32a2b80c7dbd8baf2ce4d4adce436","title":"Prediction of class and property assertions on OWL ontologies through evidence combination","abstract":"In the line of our investigation of inductive methods for Semantic Web reasoning, we propose an alternative way for approximate ABox reasoning based on the evidence and the analogical principle of the nearest-neighbors. Once neighbors of a test individual are selected through some distance measures, a combination rule descending from the Dempster-Shafer theory can join together the evidence provided by the various neighbor individuals in order to predict unknown values in a learning problem. We show how to exploit the procedure in the problems of determining unknown class- and role-memberships or fillers for datatype properties which may be the basis for many further ABox inductive reasoning algorithms.","venue":"Web Intelligence, Mining and Semantics","year":2011.0,"referenceCount":29,"citationCount":6,"fieldsOfStudy":["Computer Science"],"publicationDate":"2011-05-25","authors":[{"authorId":"145971067","name":"Giuseppe Rizzo"},{"authorId":"1743194","name":"N. Fanizzi"},{"authorId":"8315951","name":"Claudia d\u2019Amato"},{"authorId":"1700821","name":"F. Esposito"}]},{"paperId":"010cf219bd0d42ddb53de29c7eff6ddbe8a45130","title":"A Novel Technique to Image Annotation using Neural Network","abstract":": Automatic annotation of digital pictures is a key technology for managing and retrieving images from large image collection. Traditional image semantics extraction and representation schemes were commonly divided into two categories, namely visual features and text annotations. However, visual feature scheme are difficult to extract and are often semantically inconsistent. On the other hand, the image semantics can be well represented by text annotations. It is also easier to retrieve images according to their annotations. Traditional image annotation techniques are time-consuming and requiring lots of human effort. In this paper we propose Neural Network based a novel approach to the problem of image annotation. These approaches are applied to the Image data set. Our main work is focused on the image annotation by using multilayer perceptron, which exhibits a clear-cut idea on application of multilayer perceptron with special features. MLP Algorithm helps us to discover the concealed relations between image data and annotation data, and annotate image according to such relations. By using this algorithm we can save more memory space, and in case of web applications, transferring of images and download should be fast. This paper reviews 50 image annotation systems using supervised machine learning Techniques to annotate images for image retrieval. Results obtained show that the multi layer perceptron Neural Network classifier outperforms conventional DST Technique.","venue":"","year":2013.0,"referenceCount":15,"citationCount":4,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"70030118","name":"Pankaj Savita"},{"authorId":"30265647","name":"Deepshikha Patel"},{"authorId":"47159874","name":"Amit Sinhal"}]},{"paperId":"010d57e188cbf9f40b47ff63b4616255271673e3","title":"Towards Open Data for Linguistics: Linguistic Linked Data","abstract":null,"venue":"New Trends of Research in Ontologies and Lexical Resources","year":2013.0,"referenceCount":63,"citationCount":94,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"1723161","name":"C. Chiarcos"},{"authorId":"1689974","name":"John P. McCrae"},{"authorId":"1748977","name":"P. Cimiano"},{"authorId":"1721801","name":"C. Fellbaum"}]},{"paperId":"010e807911373ddedb34d061f7c82837d755875b","title":"A Semantic Framework for Analyzing Web Services Composition","abstract":"Service oriented architecture (SOA) is an emergent paradigm that aims at building applications and components by assembling existing ones. Several works on composition aspects have been proposed by researchers and industrial practitioners. The overall observation about these works is that they only provide means for service composition and invocation; but, they offer little support for analysis, and formal checking of composite Web services. In this work, we exploit rewriting logic as a unique semantic formalism for well describing and checking Web services composition. Thanks to this formalization we lean on the category model to give precise and sufficient semantics to Web service behavior. Besides, this high level specification constitutes an executable one, it allows formal analysis using a particular wellfounded language Maude having a proof and prototyping environment. General Terms Formal Methods, Web Services.","venue":"","year":2010.0,"referenceCount":17,"citationCount":5,"fieldsOfStudy":["Computer Science"],"publicationDate":"2010-08-10","authors":[{"authorId":"1970466","name":"F. Latreche"},{"authorId":"2341722","name":"F. Belala"}]},{"paperId":"010ef989aaa8e6e1927887101cc0d746c1404fd3","title":"A Document Feature Extraction Method Based on Concept-Word List","abstract":"When describing a document in Vector Space Model (VSM), it often assumes that there is no semantic relationship between words or they are orthogonal to each other. In order to improve the inaccurate document description, a new document description method has been proposed in this paper by introducing a concept-word, which calculates the semantic similarity between words based on HowNet ontology database. Comparative experiments show that the new method can not only improve effectively the effect of document feature description in VSM, but also reduce significantly the dimension of a document vector. The research is very useful to document clustering, query word expansion in Web information retrieval and personalized service in e-business applications.","venue":"","year":2011.0,"referenceCount":6,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":"2011-06-01","authors":[{"authorId":"2109516367","name":"Zhengyu Zhu"},{"authorId":"2206632879","name":"Jie He"},{"authorId":"5222289","name":"S. J. Dong"},{"authorId":"2117821259","name":"C. Yu"}]},{"paperId":"010f87b41fcbbde2aa52415f4a4c2e7b08bae9c1","title":"Semantic Web based innovative design knowledge modeling for collaborative design","abstract":null,"venue":"Expert systems with applications","year":2012.0,"referenceCount":29,"citationCount":13,"fieldsOfStudy":["Computer Science"],"publicationDate":"2012-04-01","authors":[{"authorId":"2148895415","name":"Kai Wang"},{"authorId":"2070119827","name":"Akio Takahashi"}]},{"paperId":"0110739f6a2831725dd28ec9e29c762308e9b390","title":"Using Join Operation in Relational Database to Composite Web Services","abstract":null,"venue":"World Congress on Services","year":2018.0,"referenceCount":25,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":"2018-06-25","authors":[{"authorId":"2128659177","name":"Xuan Yang"},{"authorId":"2108393825","name":"Jianxiao Liu"}]},{"paperId":"0110ada284e807996ef8f1230b75a163a69c96be","title":"Semantic Web and Databases: Second International Workshop, SWDB 2004, Toronto, Canada, August 29-30, 2004, Revised Selected Papers (Lecture Notes in Computer Science)","abstract":null,"venue":"","year":2005.0,"referenceCount":0,"citationCount":3,"fieldsOfStudy":["Computer Science","History"],"publicationDate":"2005-04-01","authors":[{"authorId":"2648624","name":"C. Bussler"},{"authorId":"144879888","name":"V. Tannen"},{"authorId":"1791376","name":"I. Fundulaki"}]},{"paperId":"0112036170fc23f1fbd625f55e93e4e9fca00f82","title":"Using Fuzzy Logic to Relax Constraints in GA-Based Service Composition","abstract":"The rapid di(cid:11)usion of web services is changing the software engineering landscape. One of the most interesting features o(cid:11)ered by service{oriented systems is the possibility to perform dynamic binding, i.e. choosing, among sets of semantically equivalent services, those which better contribute to meet some constraints (e.g., related to the cost or to any other Quality of Service attributes) and optimize some other criteria (e.g., the response time). Solving this problem is NP{hard, and approaches to tackle it using Genetic Algorithms have been proposed. In some cases, especially when it is not possible to (cid:12)nd any solution to the aforementioned problem, it would be useful to relax constraints, in order to (cid:12)nd some alternative solutions that, while not meeting the initial constraints, at least o(cid:11)er a reasonable Quality of Service. This paper proposes the use of fuzzy logic to address the imprecision in specifying QoS constraints, estimating QoS values and expressing Service Level Agreements.","venue":"","year":2005.0,"referenceCount":11,"citationCount":7,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"1719962","name":"M. D. Penta"},{"authorId":"1959622","name":"L. Troiano"}]},{"paperId":"0112d8d984d990206b78bfb915e49f7c8ec221c3","title":"The Aberdeen Burgh Records of 1398\u20131531 and the Semantic Web","abstract":"Abstract This paper provides an overview of two text analytic projects on the Aberdeen burgh records, which are legal records of the city of Aberdeen, Scotland. These records contain detailed information about a range of activities in the city and their legal treatment. The projects cover the periods 1398\u20131511 (Law in the Aberdeen Council Registers project \u2013 LACR) and 1530\u20131531 (A Text Analytic Approach to Rural and Urban Legal Histories project \u2013 TAHL). The completed TAHL project annotated a selected corpus with rich semantic information for the purpose of facilitating historical research by querying and extracting data from across the corpus. The LACR project, which is ongoing, focuses on transcribing the first eight volumes of the Aberdeen burgh records (1398\u20131511) into the Text Encoding Initiative\u2019s standard, thus making the text machinereadable. This project lays the foundation for further analysis and enrichment of the corpus.","venue":"","year":2017.0,"referenceCount":4,"citationCount":0,"fieldsOfStudy":["History"],"publicationDate":"2017-10-01","authors":[{"authorId":"82025207","name":"Anna D. Havinga"},{"authorId":"1742189","name":"A. Wyner"}]},{"paperId":"011309d6cc3d888073373e8d833e520c0cc3a264","title":"Performance Evaluation of South Esk Hydrological Sensor Web: Unsupervised Machine Learning and Semantic Linked Data Approach","abstract":"Technological progress has lead the sensor network domain to an era where environmental and agricultural domain applications are completely dependent on hydrological sensor networks. Data from the sensor networks are being used for knowledge management and critical decision support system. The quality of data can, however, vary widely. Existing automated quality assurance approach based on simple threshold rulebase could potentially miss serious errors requiring robust and complex domain knowledge to identify. This paper proposes a linked data concept, unsupervised pattern recognition, and semantic ontologies based dynamic framework to assess the reliability of hydrological sensor network and evaluate the performance of the sensor network. Newly designed framework is used successfully to evaluate the South Esk hydrological sensor web in Tasmania, indicating that domain ontology based linked data approach could be a very useful methodology for quality assurance of the complex data.","venue":"IEEE Sensors Journal","year":2013.0,"referenceCount":32,"citationCount":17,"fieldsOfStudy":["Computer Science"],"publicationDate":"2013-05-29","authors":[{"authorId":"3287762","name":"R. Dutta"},{"authorId":"143990656","name":"Ahsan Morshed"}]},{"paperId":"01154dcc9e5cb513538afa315ac4b2e0a5c71e17","title":"Exploiting Semantic Web Datasets: A Graph Pattern Based Approach","abstract":null,"venue":"China Semantic Web Symposium","year":2014.0,"referenceCount":10,"citationCount":1,"fieldsOfStudy":["Computer Science"],"publicationDate":"2014-08-08","authors":[{"authorId":"1715859","name":"Honghan Wu"},{"authorId":"1398348791","name":"B. Villaz\u00f3n-Terrazas"},{"authorId":"9416872","name":"Jeff Z. Pan"},{"authorId":"2420472","name":"Jos\u00e9 Manu\u00e9l G\u00f3mez-P\u00e9rez"}]},{"paperId":"01170bf96bc0ef6b7f961d5ddf0917c93150b092","title":"Adding meaning negotiation skills in multiagent systems","abstract":"In order to perform its tasks on the semantic web, software agents must be able to communicate with other agents using domain ontologies, even when considering different ontologies. Thus, it's necessary to address the semantic interoperability issue to enable agents to recognize common concepts and misunderstandings. This work proposes the use of negotiation concepts in business scenarios for addressing concept compatibilization problems in communication between software agents. Negotiation techniques are suitable in this context by providing a formal communication protocol useful for reaching conceptualization consensus. An architecture is proposed, with modules that encapsulate these negotiation concepts.","venue":"2009 IEEE International Conference on Intelligent Computing and Intelligent Systems","year":2009.0,"referenceCount":24,"citationCount":4,"fieldsOfStudy":["Computer Science"],"publicationDate":"2009-12-28","authors":[{"authorId":"1753688958","name":"J. F. de Souza"},{"authorId":"7494930","name":"S. Siqueira"},{"authorId":"32072453","name":"R. Melo"}]},{"paperId":"01172224414211ba93b959ba227c12a9a6a2c1b8","title":"Semantic Web Standards and Ontologies for Legislative Drafting Support","abstract":null,"venue":"Electronic Participation","year":2010.0,"referenceCount":15,"citationCount":8,"fieldsOfStudy":["Computer Science"],"publicationDate":"2010-08-29","authors":[{"authorId":"3118503","name":"T. Agnoloni"},{"authorId":"2307749","name":"D. Tiscornia"}]},{"paperId":"01177810d1a7a9c69b44ceef645dd5330de69d37","title":"Supporting Ontology-Based Dynamic Property and Classification in WebSphere Metadata Server","abstract":null,"venue":"International Workshop on the Semantic Web","year":2008.0,"referenceCount":26,"citationCount":1,"fieldsOfStudy":["Computer Science"],"publicationDate":"2008-10-26","authors":[{"authorId":"2035396","name":"Shengping Liu"},{"authorId":"49308328","name":"Yang Yang"},{"authorId":"2052157756","name":"G. Xie"},{"authorId":"40614781","name":"Chen Wang"},{"authorId":"2061270345","name":"Feng Cao"},{"authorId":"35240742","name":"C. Santos"},{"authorId":"49139808","name":"Robert J. Schloss"},{"authorId":"144455843","name":"Yue Pan"},{"authorId":"38997068","name":"Kevin Shank"},{"authorId":"3347638","name":"John Colgrave"}]},{"paperId":"01177acfe57043104fd1e1d43c62ccd79e85ec3d","title":"Carbon Stock Estimation at Scale from Aerial and Satellite Imagery","abstract":"In the ongoing efforts to mitigate climate change effect, the capability to reliably estimate forest carbon stock on a global scale is vital to support sustainable development. This entails the investigation of tree coverage from diverse forest ecosystems worldwide, necessitating a substantial volume of high-resolution images. This paper integrates a variety of remote sensing data sources, from aerial to satellite imagery, for the training and development of our AI system. Given the heterogeneous nature of these data sources, we develop a standardization method to ensure consistent image size and resolution between source platforms. Our harmonized dataset includes 86,088 training images and 21,768 validation images, each with a high resolution of 1.194 m2 per pixel. We introduce a novel technique for tree semantic segmentation which offers a more effective alternative to traditional individual tree crown delineation for large-scale tree coverage estimation. To assess the adaptability of our AI models, we conducted experiments on a hand-annotated satellite image test set and achieved a High Vegetation IoU score of 45.73%. Building on these findings, we present an interactive web-based Geographic Information System for navigating high vegetation segmented satellite images and estimating carbon stock on a global scale.","venue":"Conference on Algebraic Informatics","year":2024.0,"referenceCount":53,"citationCount":0,"fieldsOfStudy":null,"publicationDate":"2024-06-25","authors":[{"authorId":"2060846593","name":"Alex To"},{"authorId":"2308691815","name":"Hoang Quoc"},{"authorId":"2271990808","name":"V. Pham"},{"authorId":"2308696050","name":"Quang H. Nguyen"},{"authorId":"2108999650","name":"Joseph G. Davis"},{"authorId":"2302798814","name":"Barry O\u2019Sullivan"},{"authorId":"2308808106","name":"S. L. Pan"},{"authorId":"2110609686","name":"Hoang D. Nguyen"}]},{"paperId":"011931ce6c88c19e67b970e385ac82e8b83b7c93","title":"Information Retrieval usingSemantic WebBrowser - Personalized andCategorical WebSearch","abstract":"The Semantic web browsingoffers several benefits fortheusers. Theresearchers havedonelotsof workinthis area. Theproposals specified bythemarenot usedmucheffectively foraccessing theinformation. The search engines built todayserveallusers, independent of thespecial needsofanyindividual user.Personalization ofweb searchforeachuserincorporating his\/her interests wouldgiveeffective information retrieval. A usermayassociate oneormorecategories totheir query manually. We haveimproved theexisting, Rocchio based algorithm toconstruct thegeneral profile anduserprofile forpersonalization. Inourproposed method, we have constructed awebbrowser; theinformation isretrieved through thebrowser withtheaidofcategory hierarchy. Thecategory hierarchy information willbefrequently updated andrankedaspertheuser's interest during his\/her websearch dynamically, theinformation retrieved isalsocachedontheclient sideusingsemantic cache mechanism whichimproves theresponse time. We have experimentally provedthatourtechnique personalizes thewebsearch andreduces thehitsmadebythesearch engine providing appropriate results andimproves the retrieval efficiency.","venue":"","year":2007.0,"referenceCount":0,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"73704518","name":"M. R. Sumalathal"},{"authorId":"145661109","name":"V. Vaidehi"},{"authorId":"153682997","name":"A. Kannan"}]},{"paperId":"011a0e2a97014e68de5496e830c800be28109c22","title":"Measuring Semantic Relatedness between Flickr Images: From a Social Tag Based View","abstract":"Relatedness measurement between multimedia such as images and videos plays an important role in computer vision, which is a base for many multimedia related applications including clustering, searching, recommendation, and annotation. Recently, with the explosion of social media, users can upload media data and annotate content with descriptive tags. In this paper, we aim at measuring the semantic relatedness of Flickr images. Firstly, four information theory based functions are used to measure the semantic relatedness of tags. Secondly, the integration of tags pair based on bipartite graph is proposed to remove the noise and redundancy. Thirdly, the order information of tags is added to measure the semantic relatedness, which emphasizes the tags with high positions. The data sets including 1000 images from Flickr are used to evaluate the proposed method. Two data mining tasks including clustering and searching are performed by the proposed method, which shows the effectiveness and robustness of the proposed method. Moreover, some applications such as searching and faceted exploration are introduced using the proposed method, which shows that the proposed method has broad prospects on web based tasks.","venue":"TheScientificWorldJournal","year":2014.0,"referenceCount":42,"citationCount":9,"fieldsOfStudy":["Computer Science","Medicine"],"publicationDate":"2014-02-23","authors":[{"authorId":"144755348","name":"Zheng Xu"},{"authorId":"2167614","name":"Xiangfeng Luo"},{"authorId":"2285714984","name":"Yunhuai Liu"},{"authorId":"46665820","name":"Lin Mei"},{"authorId":"2056289","name":"Chuanping Hu"}]},{"paperId":"011b2ba45a9caba6fa1841a76d0e9663cdeec0cc","title":"Natural Language Processing and Deep Learning Techniques to Improve Sentiment Analysis in Social Media Texts","abstract":"Sentiment analysis (SA) is a mechanized strategy for finding and understanding the feelings depicted in text. Over the most recent decade, SA has altogether expanded in ubiquity in the Natural Language Processing (NLP) people group. Because of the inescapable utilization of social media and web stages, SA is presently urgent for firms to get client info and shape their promoting approach. The motivation behind this study is to utilize a deep learning-based way to deal with natural language process to give an exhaustive investigation of the opinion of sentiment of social media content. The technique then builds a comparable model that may be applied to replicate the relevant social process. In instance, by dynamically choosing the most significant phrase in the current state depending on the information presented, the network can effectively recognize the significant material that is always changing. This prompts the semantic comprehension of the total sentence toward the finish of each phase of the interaction. Besides, an absence of context oriented data will prompt an incorrect and muddled semantic portrayal of natural language on the grounds that relevant data is fundamental for that portrayal. In this paper, we take a gander at the unimodal and multimodal social network sentiment analysis algorithms and foster two models for text sentiment investigation and picture-text multimodal sentiment examination.","venue":"International Conferences on Contemporary Computing and Informatics","year":2023.0,"referenceCount":13,"citationCount":2,"fieldsOfStudy":["Computer Science"],"publicationDate":"2023-09-14","authors":[{"authorId":"2281406646","name":"Dr. Sreenivas Mekala"},{"authorId":"2281397191","name":"Dr. Vinod Bhatt"},{"authorId":"2281399227","name":"Dr. M. Bhuvana"},{"authorId":"73674966","name":"Pankaj Kunekar"},{"authorId":"2281408570","name":"Dr. Dev Brat Gupta"},{"authorId":"2062985534","name":"Geetha Manoharan"}]},{"paperId":"011c062ac0972b5f568f1e59fa2127bc27af8212","title":"\uc774\uc9c8\uc801\uc778 \uc1fc\ud551\ubab0 \ud658\uacbd\uc744 \uc704\ud55c \uc628\ud1a8\ub85c\uc9c0 \uae30\ubc18 \uc0c1\ud488 \ub9e4\ud551 \ubc29\ubc95\ub860","abstract":"\uc758\ubbf8 \uc6f9(Semantic Web)\uacfc \uc774\uc5d0 \ub300\ud55c \uad00\ub828\uae30\uc220\ub4e4\uc740 \uc6f9\uc744 \ud1b5\ud574 \uc790\uc720\ub86d\uac8c \uc815\ubcf4\ub97c \uacf5\uc720\ud560 \uc218 \uc788\ub294 \uc0c8\ub85c\uc6b4 \uc9c0\ud3c9\uc744 \ub9c8\ub828\ud574 \uc8fc\uc5c8\ub2e4. \uc774\ub97c \ud1a0\ub300\ub85c \uc628\ud1a8\ub85c\uc9c0(Ontology)\uc5d0 \ub300\ud55c \uc5f0\uad6c \uc5ed\uc2dc \ud65c\ubc1c\ud788 \uc9c4\ud589\ub418\uc5b4 \uc654\uc73c\uba70, \uacb0\uacfc\uc801\uc73c\ub85c \uc628\ud1a8\ub85c\uc9c0\ub294 \uc5ec\ub7ec \uac00\uc9c0 \uce21\uba74\uc5d0\uc11c \uac00\uc2dc\uc801\uc778 \uc131\uacfc\ub4e4\uc744 \uc774\ub8e9\ud574 \ub0bc \uc218 \uc788\uc5c8\ub2e4. \uc758\ubbf8 \uc6f9\uc5d0 \ub300\ud55c \uae30\ub300\uac00 \uace0\uc870\ub418\uba74\uc11c, \uc628\ud1a8\ub85c\uc9c0\ub294 \ub9ce\uc740 \uc5f0\uad6c \ud559\uc790\ub4e4\ub85c\ubd80\ud130 \uac01\uad11\uc744 \ubc1b\ub294 \ubd84\uc57c\ub85c \ub5a0\uc624\ub97c \uc218 \uc788\uc5c8\uc73c\uba70, \uc624\ub298\ub0a0, \uc774\ub7ec\ud55c \uc628\ud1a8\ub85c\uc9c0\uc5d0 \ub300\ud55c \uc5f0\uad6c\ub294 \uc9c0\uc2dd\ud45c\ud604(Knowledge-Representation)\ub4f1\uacfc \uac19\uc740 \ud559\uc220\uc801\uc778 \ub2e8\uacc4\uc5d0\uc11c \ubc97\uc5b4\ub098 \uc804\uc790\uc0c1\uac70\ub798 \ubd84\uc57c\uae4c\uc9c0 \uadf8 \uc601\uc5ed\uc744 \ub113\ud600 \ub098\uac00\uace0 \uc788\ub2e4. \uadf8\ub7ec\ub098 \uc77c\ubd80\uc5d0\uc11c\ub294 \uc774\ub7ec\ud55c \uc628\ud1a8\ub85c\uc9c0\uc758 \uc591\uc0b0\uc73c\ub85c \uc778\ud574 \ubc1c\uc0dd\ud560 \ubb38\uc81c\ub4e4\uc5d0 \ub300\ud55c \uc6b0\ub824\uc758 \ubaa9\uc18c\ub9ac\uac00 \uc801\uc9c0 \uc54a\ub2e4. \uc989, \ud604\uc7ac \uc628\ud1a8\ub85c\uc9c0\ub4e4\uc740 \uc11c\ub85c\uac04\uc758 \uc774\uc9c8\uc131\uc73c\ub85c \uc778\ud574 \uadf8 \ud6a8\uc6a9 \uac00\uce58\ub97c \uc704\ud611\ubc1b\uace0 \uc788\ub2e4\ub294 \uac83\uc774\ub2e4. \uc608\ub97c \ub4e4\uc5b4, \ud604\uc7ac Yahoo\ub098 DMOZ Open Directory(www.dmoz.org)\ub4f1\uc73c\ub85c\ubd80\ud130 \uc81c\uacf5 \uc911\uc778 \uc0c1\ud488 \uce74\ud14c\uace0\ub9ac\uc758 \uacbd\uc6b0, \uc2dc\uac01\uc801\uc73c\ub85c\ub294 \uc720\uc0ac\ud574 \ubcf4\uc77c\uc9c0 \ubaa8\ub974\ub098 \uadf8\ub4e4\uc774 \uc9c0\ub2cc \uce74\ud14c\uace0\ub9ac \uad6c\uc870\ub77c\ub4e0\uc9c0 \uc0ac\uc6a9\ub41c \uc6a9\uc5b4 \ub4f1\uc744 \uc0b4\ud3b4\ubcf4\uba74 \uc0c1\ub2f9\ud55c \ucc28\uc774\uc810\uc774 \uc874\uc7ac\ud55c\ub2e4\ub294 \uc0ac\uc2e4\uc744 \ubc1c\uacac\ud574 \ub0bc \uc218 \uc788\ub2e4. \ub530\ub77c\uc11c \ud604\uc7ac \uc628\ud1a8\ub85c\uc9c0\uac00 \uc9c0\ud5a5\ud558\ub294 \ubcf8\ub798\uc758 \ud6a8\uc6a9 \uac00\uce58\ub97c \uadf9\ub300\ud654\uc2dc\ud0a4\uae30 \uc704\ud574\uc11c\ub294 \uc774\ub7ec\ud55c \uc774\uc9c8\uc131\uc744 \uadf9\ubcf5\ud560 \uc218 \uc788\ub294 \ubc29\ubc95\ub860\uc774 \ubc18\ub4dc\uc2dc \ud544\uc694\ud558\ub2e4\uace0 \ud560 \uc218 \uc788\ub2e4. \ubcf8 \uc5f0\uad6c\uc5d0\uc11c\ub294 \ud604\uc7ac \uc628\ud1a8\ub85c\uc9c0 \ubd84\uc57c\uc5d0\uc11c \uac00\uc7a5 \ucee4\ub2e4\ub780 \uc774\uc288\ub85c \ub5a0\uc624\ub974\uace0 \uc788\ub294 \uc815\ubcf4\ud1b5\ud569\uc5d0 \ub300\ud55c \ud574\uacb0\ucc45\uc744 \uc81c\uc2dc\ud574 \ubcf4\uace0\uc790 \ud55c\ub2e4. \uc815\ubcf4\ud1b5\ud569\uc774\ub780, \uc11c\ub85c \uc774\uc9c8\uc801\uc778 \ud504\ub85c\uadf8\ub798\ubc0d \uc5b8\uc5b4\ub098 \ud615\uc2dd\uc73c\ub85c \uc774\ub8e8\uc5b4\uc9c4 \ub370\uc774\ud130\ub4e4\uc744 \ud1b5\ud569\ud558\uc5ec \uc694\uc57d\ud55c \ud615\ud0dc\ub85c \uc81c\uacf5\ud558\ub294 \uae30\uc220\uc774\ub77c \uc815\uc758\ub0b4\ub9b4 \uc218 \uc788\ub2e4. \uc774\ub7ec\ud55c \uc815\ubcf4 \ud1b5\ud569\uc758 \ub300\ud45c\uc801\uc778 \ubd84\uc57c\ub85c Merging, Alignment, Translation, Articulation\uc744 \ub4e4 \uc218 \uc788\ub294\ub370, \uc774 \uac00\uc6b4\ub370, \ubcf8 \uc5f0\uad6c\uc5d0\uc11c\ub294\u201cOntology Alignment\u201d\uc5d0 \ub300\ud574 \uc9d1\uc911\uc801\uc73c\ub85c \ub2e4\ub8e8\uc5b4 \ubcf4\uace0\uc790 \ud55c\ub2e4. \uc774\uc640 \ub354\ubd88\uc5b4, \ud604\uc7ac \uc758\ubbf8 \uc6f9\uc774 \uc9c0\ud5a5\ud558\ub294 \ub300\ud45c\uc801\uc778 \ud2b9\uc131 \uc911 \ud558\ub098\ub85c\uc368 \uc0c1\ud638\uc6b4\uc601\uc131\uc744 \uaf3d\uc744 \uc218 \uc788\ub2e4. \uc628\ud1a8\ub85c\uc9c0 \ub9e4\ud551(Ontology mapping)\uc740 \uc774\ub7ec\ud55c \uc0c1\ud638\uc6b4\uc601\uc131\uc744 \uc9c0\uc6d0\ud558\uae30 \uc704\ud55c \ub300\ud45c\uc801\uc778 \uae30\uc220\ub85c\uc368 \uac01\uad11\uc744 \ubc1b\uace0 \uc788\ub2e4. \ub530\ub77c\uc11c \uc6b0\ub9ac\ub294 \uc774\ub7ec\ud55c \uc628\ud1a8\ub85c\uc9c0 \ub9e4\ud551\uc5d0 \ub300\ud55c \ubc29\ubc95\ub860\uc744 \uc1fc\ud551\ubab0 \ud658\uacbd\uc5d0 \uc801\uc6a9\ud568\uc73c\ub85c\uc368 \uc11c\ub85c \uc774\uc9c8\uc801\uc778 \uc0c1\ud488 \uce74\ud14c\uace0\ub9ac\ub85c \uad6c\uc131\ub41c \ub450 \uc1fc\ud551\ubab0\uac04\uc758 \uc0c1\ud488\uc5d0 \ub300\ud55c \ub9e4\ud551 \uc54c\uace0\ub9ac\uc998(Mapping Algorithm)\uc744 \uc81c\uc548\ud558\uace0\uc790 \ud55c\ub2e4. \ub610\ud55c, \ud6a8\uc6a9\uc131 \uac80\uc99d\uc744 \uc704\ud558\uc5ec \uc628\ud1a8\ub85c\uc9c0 \ub9e4\ud551\uc5d0 \uc788\uc5b4 \uc774\ubbf8 \ud6a8\uc6a9\uc131\uc744 \uac80\uc99d \ubc1b\uc740 PROMPT\uc640\uc758 \ube44\uad50 \ubd84\uc11d\ub3c4 \uc218\ud589\ud558\uc5ec \ubcf8\ub2e4.","venue":"","year":2006.0,"referenceCount":0,"citationCount":1,"fieldsOfStudy":["Computer Science"],"publicationDate":"2006-06-01","authors":[{"authorId":"52057086","name":"\uae40\uc6b0\uc8fc"},{"authorId":"70255690","name":"\ucd5c\ub0a8\ud601"},{"authorId":"52509571","name":"\ucd5c\ub300\uc6b0"}]},{"paperId":"011d9e0f9d60855a5099f096ae02f7ecec86c3a8","title":"Measurement of turkish word semantic similarity and text categorization application","abstract":"In literature, texts to be classified are generally represented in the large dimensional Bag of Words space in which every dimension equals to a word or ngram. In this study, firstly the words are placed in a semantic space. The word's coordinates in semantic spaces needs the similarity of the words according to their meanings. Harris states that two words' semantic similarity is related to the number of documents which the words are both in. We used his hypothesis for Turkish words. Firstly, we obtained word co-occurrence matrix from a web corpus. Then, the numerical coordinates of the words are calculated by using multi dimensional scaling. Texts coordinates are obtained from word coordinates which passes in the texts. In our experiments, Turkish news texts are classified into 5 classes. We get more successful results than the traditional Bag of Words space. Our approach is not for only Turkish words\/texts, but also for all other languages.","venue":"2009 IEEE 17th Signal Processing and Communications Applications Conference","year":2009.0,"referenceCount":16,"citationCount":17,"fieldsOfStudy":["Mathematics","Computer Science"],"publicationDate":"2009-04-09","authors":[{"authorId":"1775715","name":"M. Amasyal\u0131"},{"authorId":"9333928","name":"Aytunc Beken"}]},{"paperId":"011db7cf60bb4da2d38a54f393e0a47a2ae6e0e2","title":"A Novel Data Mining Algorithm for Semantic Web Based Data Cloud","abstract":"By a cloud, we mean an infrastructure that provides resources and\/or services over the Internet. A storage cloud provides storage services, while a compute cloud provides compute services. We describe the design of the Sector storage cloud and how it provides the storage services required by the Sphere compute cloud [14]. Different efforts have been made to address the problem of data mining in the cloud framework. In this paper we propose an algorithm to mine the data from the cloud using sector\/sphere framework and association rules. We also describe the programming paradigm supported by the Sphere compute cloud and Association rules. Sector and Sphere are discussed for analyzing large data sets using computer clusters connected with wide area high performance networks","venue":"","year":2010.0,"referenceCount":22,"citationCount":13,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"48023586","name":"K. Lal"},{"authorId":"2286739386","name":"Sr. Lecturer"},{"authorId":"2286943004","name":"N.C.Mahanti"}]},{"paperId":"011e3fc05a3ad8103189a519cccea003ff115db5","title":"Creating, Organising and Publishing Media on the Web","abstract":"htmlabstractCreating, organising and publishing findable media on the Web raises outstanding problems. While most applications that process multimedia assets make use of some form of metadata to describe the multimedia content, they are often based on diverse metadata standards. In the W3C Multimedia Semantics Incubator Group (XG), we have demonstrated, for various use cases, the added value of combining several of these into a single application. We have also shown how semantic Web technology can help in making these standards interoperable.","venue":"ERCIM News","year":2008.0,"referenceCount":2,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"1684267","name":"Raphael Troncy"}]},{"paperId":"011e6977fa2d4cd75a2b191c93d5981ace09906a","title":"Performance evaluation for semantic-based risk factors extraction from clinical narratives","abstract":"Precision medicine is the new perspective in healthcare that requires a personalized diagnosis and treatment plan for a patient. This new approach mandates that clinical decision support system (CDSS), an essential element of preventive and precision medicine processes, uses state-of-the-art technologies in terms of clinical knowledge extraction. To assist a physician's precise prognosis using CDSS, it is important that a patient's health data is properly and automatically analyzed. The unstructured part of the data in electronic health records (EHR) is critical, as it may contain hidden risk factors. We propose a new approach for CDSS to extract risk factors concepts from the clinical narratives using natural language processing techniques (NLP) and semantic web technologies (SWT). We evaluate our model using a case study dataset of patients\u2019 records with venous thromboembolism (VTE). Our model extracts risk factors of VTE to make a prognosis. Results of proposed technique yielded precision of 85% and recall of 84% to identify and extract risk factors concepts.","venue":"Computing and Communication Workshop and Conference","year":2018.0,"referenceCount":45,"citationCount":6,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"36253988","name":"S. Sabra"},{"authorId":"7576714","name":"Mazen Alobaidi"},{"authorId":"144444372","name":"K. Malik"},{"authorId":"35997957","name":"Vian Sabeeh"}]},{"paperId":"0120b9ea97a4b5b13049ed30dd204a1c9cf38234","title":"Real-world metadata registries; sharing concepts, schemas and semantics","abstract":"Our current metadata schema registry initiative, the IEMSR, has recently celebrated its third birthday. The IEMSR is based on the principle that semantic annotation of resources is precisely as accurate as the user performing the annotation, meaning that the best way to improve the quality and use of metadata is to provide a more supportive environment for metadata producers and consumers. A metadata registry is an environment within which users may discover existing schemas, or collaboratively develop an appropriate set of concepts. In this paper, we take a look at relevant research, describe the results of user testing, and fill out some of the gaps in our understanding in the practical use of schema registries. As a result of this review process, we provide a series of guidelines for those supporting schema or application profile development, and sketch out what the next generation of registries might resemble.Some of the arguments underlying schema development are modern manifestations of very classical issues and relate to deeply-held assumptions in various fields. There's a general multidisciplinary effort going on today that takes inspiration from all sorts of areas, from computer-supported collaborative work to philosophy to theories of construction of knowledge and understanding, in an attempt to comprehend and predict the result of user engagement with the semantic web and its lower-case or informal relatives. With the increasing popularity of self-consciously informal metadata creation and community-based Web 2.0 approaches to knowledge management, formalised processes are perceived by many as excessively long and complex. A well designed schema registry could support these processes by addressing some of the difficulties faced by users.Terms are created according to their authors understanding of the system, the resource and their own aims. But if the result is a socially situated artifact, grounded in the user's unique context, what does this mean for sustainability? How do we support schema evolution and development? How can we encourage visitors to take the time to populate the registry? This presentation provides an overview of issues and research trends; we hope to spark some interesting discussion and feedback","venue":"","year":2007.0,"referenceCount":0,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"144156942","name":"E. Tonkin"}]},{"paperId":"0122963f3b33dcaf6b469ba24c7850820c4a50f1","title":"Role of boundary objects in the coevolution of design and use: the KMP experimentation","abstract":"Nowadays, it is widely recognized that an ICT tool cannot be built without know ing who will use it and what they will do with. In this perspective, Human-Computer Interaction community (Carroll 1990; Jarke, Tung Bui and Carroll 1998; Young and Barnard 1987; Young et al. 1989) developed a scenario-based approach contrasting with the traditional information system design. The scenario describes an existing or envisioned system from the perspective of one or more users and included a narration of their goals, plans and reactions (Rosson and Carroll 2002). As a result, design is founde d on the use of scenarios as a central representation for analysis and design of use. The scenario-based design appeares to be a first step in the integration of users in the design of ICT tool. However, we would like to underline in this paper a more active role of users in the design process. According to Orlikowski (2000) while a technology can be seen to have been constructed with particular materials and inscribed with developersO assumptions and know ledge about the world at a point in time, it is only when this technology is used in recurrent social practices that it can be said to structure userOs action. The use of technology in recurrent social practices must be considered because how technological properties will be used or appropriate for the moment is not inherent or predetermined. This approach leads us to dissociate the designersO world from the usersO world. In this perspective, the design project is the result of the co-evolution and the convergence of both worlds: on the one hand, the world of design and a first integration of users by scenarios; on the other hand, the world of users where innova tion is the art of interesting an increasing number of allies who will make the world of design stronger and stronger (Akrich et al. 2002). The objective of this paper is to understand the mechanisms of interaction between the world of design and that of users i.e. between loops of co-design and loops of uses. In this perspective, the success of an innova tion may be explained by the co-evolution and the convergence of these two worlds. In this process, we suggest that bounda ry objects play a key role in the convergence of these two worlds. In order to demonstrate this proposal our article will lean on a specific design research conduc ted five years ago: the Knowledge Management Platform project (KMP project). The KMP project aimed to build a semantic web service of competencies in order to enhance exchange and combination dynamics of know ledge within the Telecom cluster of Sophia Antipolis (Alpes-Maritimes, France) thanks to an interactive mapping of competencies. Indeed, this cluster had to face two main problems due to its specific multi-technological halshs-00490453, version 1 - 8 Jun 2010","venue":"","year":2010.0,"referenceCount":38,"citationCount":4,"fieldsOfStudy":["Engineering"],"publicationDate":null,"authors":[{"authorId":"3217075","name":"Amandine Pascal"},{"authorId":"2148887925","name":"Catherine Thomas"}]},{"paperId":"012583ef404a48b2ab311369abf2effaa6e3071c","title":"Leveraging P2P Architecture and Semantic Web for Enhanced Resource Discovery","abstract":"Web 4.0, also known as the next generation, intelligent internet, possesses the potential to become a widely and universally used communication medium for various types of information. However, its decentralized architecture lacks strong semantic support, resulting in an internet that is disorganized. The current system lacks the capacity to facilitate users' effective information discovery, extraction, and integration from multiple sources. Additionally, it fails to give consumers efficient tools for manipulating and turning acquired data into knowledge that is useful. Peer-to-peer (P2P) overlay technologies have recently come to light as a way to improve resource discovery on the internet. In dynamic and large-scale situations, these technologies provide a scalable framework for allocating, sharing, and gaining access to resources. The purpose of this research is to discuss on semantically enabled web architecture that makes use of P2P overlay technology. This architecture aims to facilitate structured and precise access to internet resources and promote knowledge sharing among community members who share similar interests. The paper examines the core elements of the semantic web architecture, which encompass the services and protocols responsible for resource advertising, discovery, and management, methods and material. It then delve into the hybrid peer-to-peer (P2P) overlay structure, specifically focusing on indexing and resource location, and explores the mechanisms necessary to facilitate scalable routing within a distributed environment.","venue":"International Journal of Scientific Research in Science Engineering and Technology","year":2024.0,"referenceCount":3,"citationCount":0,"fieldsOfStudy":null,"publicationDate":"2024-05-15","authors":[{"authorId":"2302231737","name":"Leonard K. Kirui"},{"authorId":"2302233664","name":"Samuel M. Mbuguah"},{"authorId":"2302233658","name":"Richard K. Ronoh"}]},{"paperId":"0125e4fcc6db61be3a486e68b8b0c5d7914cc045","title":"Reasoning on a Semantic Web Based Context-Awareness Middleware","abstract":null,"venue":"Practical Applications of Agents and Multi-Agent Systems","year":2010.0,"referenceCount":10,"citationCount":1,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"1403850115","name":"A. Garc\u00eda-Sola"},{"authorId":"1398620986","name":"Teresa Garc\u00eda-Valverde"},{"authorId":"1742463","name":"J. A. Blaya"}]},{"paperId":"01265bab05d13cf4d1e12988bd1534ccae940bac","title":"AN ONTOLOGY-BASED APPROACH TO INCORPORATE USER-GENERATED GEO-CONTENT INTO SDI","abstract":"The Web is changing the way people share and communicate information because of emergence of various Web technologies, which enable people to contribute information on the Web. User-Generated Geo-Content (UGGC) is a potential resource of geographic information. Due to the different production methods, UGGC often cannot fit in geographic information model. There is a semantic gap between UGGC and formal geographic information. To integrate UGGC into geographic information, this study conducts an ontology-based process to bridge this semantic gap. This ontology-based process includes five steps: Collection, Extraction, Formalization, Mapping, and Deployment. In addition, this study implements this process on Twitter messages, which is relevant to Japan Earthquake disaster. By using this process, we extract disaster relief information from Twitter messages, and develop a knowledge base for GeoSPARQL queries in disaster relief information.","venue":"","year":2012.0,"referenceCount":18,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":"2012-08-30","authors":[{"authorId":"3023801","name":"D. Deng"},{"authorId":"2103957","name":"R. Lemmens"}]},{"paperId":"012b2271c755e47e9a51ad9d9c9b9ba7340935c2","title":"State of the Art of Community-Driven Software Engineering Ontology Evolution","abstract":"Ontology evolution becomes an interesting topic in the semantic web field and increasingly getting research momentum. However, there is still a lack of understanding and support in ontology evolution. In this paper, we focus on an approach for ontology evolution of Software Engineering Ontology (SE Ontology) in multi-site software development setting. An integration of agents with semantic web technology and recommender systems to address communication and co-ordination issues is proposed together with a use of social networks for the purpose of ontology evolution.","venue":"2011 IEEE Ninth International Conference on Dependable, Autonomic and Secure Computing","year":2011.0,"referenceCount":30,"citationCount":4,"fieldsOfStudy":["Computer Science"],"publicationDate":"2011-12-12","authors":[{"authorId":"145036570","name":"P. Wongthongtham"},{"authorId":"144306547","name":"T. Dillon"},{"authorId":"2288545212","name":"E. Chang"}]},{"paperId":"012cbae2be3a3d473b783177cbf891dbd39feb9a","title":"Ontology based file retrieval framework for resource limited mobile devices","abstract":"Recent advances in mobile technologies have emerged new challenges for researchers. File management and retrieval on resource-limited devices has become a challenging problem as these devices are now equipped with larger storage capacities. This paper presents an overview about the possibilities of implementing Semantic Web Technologies in order to facilitate the file retrieval on resource-limited devices. We have proposed a semantic based file retrieval framework which utilizes a generic ontology in file search process. The search module is implemented in Java ME platforms as a case study. Performance of the proposed search module is evaluated through experimental tests along with probabilistic evaluations. The implemented module not only automates file retrieval process but also shows significant improvement in file retrieval efficiency by utilizing the knowledge of employed ontology in the search module.","venue":"International Conference on Fuzzy Systems and Knowledge Discovery","year":2011.0,"referenceCount":20,"citationCount":1,"fieldsOfStudy":["Computer Science"],"publicationDate":"2011-07-26","authors":[{"authorId":"113986832","name":"S. Jan"},{"authorId":"1716059","name":"Maozhen Li"},{"authorId":"1403116069","name":"Ghaidaa Al-Sultany"},{"authorId":"1401400566","name":"H. Al-Raweshidy"}]},{"paperId":"012d667d814202291e7cf245e4c0aca30d9a9468","title":"Forecasting Technology Migrations by means of the Technology-Topic Framework","abstract":"Technologies such as algorithms, applications and formats usually originate in the context of a specific research area and then spread to several other fields, sometimes with transformative effects. However, this can be a slow and inefficient process, since it not easy for researchers to be aware of all interesting approaches produced by unfamiliar research communities. We address this issue by introducing the Technology-Topic Framework, a novel approach which uses a semantically enhanced technology-topic model and machine learning to forecast the propagation of technologies across research areas. The aim is to foster the knowledge flow by suggesting to scholars technologies that may become relevant to their research field. The system was evaluated on a manually curated set of 1,118 technologies in Semantic Web and Artificial Intelligence and the results of the evaluation confirmed the validity of our approach.","venue":"International Workshop on the Semantic Web","year":2017.0,"referenceCount":4,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"2052329","name":"Francesco Osborne"},{"authorId":"2043406","name":"Andrea Mannocci"},{"authorId":"1721851","name":"E. Motta"}]},{"paperId":"012d7b5e1d5461d6e1a7a6f58a0526fb30ae1c22","title":"Semantically Annotating a Web Service","abstract":"In the past few years, service-oriented architecture (SOA) has transitioned from a partially formed vision into a widely implemented paradigm, with Web services (WS) being the forerunners to implementing SOA-based solutions. But even though the current trend is to use Web services' standards-based nature to establish static connections between various components, businesses are starting to explore dynamic value-added propositions, such as reuse, interoperability, and agility","venue":"IEEE Internet Computing","year":2007.0,"referenceCount":11,"citationCount":125,"fieldsOfStudy":["Computer Science"],"publicationDate":"2007-03-01","authors":[{"authorId":"2065888927","name":"Kunal Verma"},{"authorId":"144463965","name":"A. Sheth"}]},{"paperId":"012e02fa9765dec50e6b534fe13578773fd8d6c7","title":"Discovering attribute and entity synonyms for knowledge integration and semantic web search","abstract":"We propose the <i>Context-aware Synonym Suggestion System<\/i> (<i>CS<\/i><sup>3<\/sup>) which learns synonyms from text by using our NLP-based text mining framework, called <i>SemScape<\/i>, and also from existing evidence in the current knowledge bases (KBs). Using <i>CS<\/i><sup>3<\/sup> and our previously proposed knowledge extraction system <i>IBminer<\/i>, we integrate some of the publicly available knowledge bases into one of the superior quality and coverage, called <i>IKBstore<\/i>.","venue":"SS@ '13","year":2013.0,"referenceCount":28,"citationCount":11,"fieldsOfStudy":["Computer Science"],"publicationDate":"2013-08-30","authors":[{"authorId":"3057145","name":"Hamid Mousavi"},{"authorId":"39111025","name":"Shi Gao"},{"authorId":"1712630","name":"C. Zaniolo"}]},{"paperId":"012f1c1d738fcb5f62791269b4944964b298789f","title":"Spiritual Care in Palliative Medicine and End of Life: A Bibliometric Network Analysis.","abstract":"Background and Objectives: Spiritual care is an essential component of care for the terminally ill, because of its potential to positively impact patient perception of quality of life and dignity. However, it continues to be the least cultivated or even most overlooked aspect of palliative care and end of life. We performed a methodological review using bibliometric analysis to provide a holistic view of the scientific output published on this topic in the literature at the same time outlining present perspectives and research trends. Methods: In accordance with the BIBLIO checklist for reporting the bibliometric reviews of the biomedical literature, pertinent articles were retrieved from the Web of Science (WOS) database. The search string included \"spiritual care,\" \"end of life,\" and their synonyms. The VOSviewer (version 1.6.17) software was used to conduct comprehensive analyses. Semantic and research networks, bibliographic coupling, and journal analysis were examined. Results: A total of 924 articles were identified in WOS, and 842 were retrieved. An increasing trend in the number of publications is observed from 1981 to date, with a peak in the 2019-2021 timeframe. Most articles focused on palliative care, spirituality, spiritual care, religion, end of life, and cancer. The Journal of Pain and Symptom Management contributed the highest number of published documents, while the Journal of Palliative Medicine was the top-cited journal. The highest number of publications originated from collaborations of authors from the United Kingdom, the United States, and Australia. Conclusion: The remarkable increase in the number of publications on spiritual care observed in the years of the COVID-19 pandemic likely reflected global concerns, reasserting the importance of prioritizing spiritual care for whole-person palliation. Spiritual care is integrated with palliative care, in line with the latter's holistic nature and the recognition of spirituality as a fundamental aspect of end-of-life care. Nurses and chaplains exhibited more involvement in palliative-spiritual care than physicians reflecting the belief that chaplains are perceived as specialized providers, and nurses, owing to their direct exposure to spiritual suffering and ethos, are deemed suitable for providing spiritual care.","venue":"Journal of Palliative Medicine","year":2024.0,"referenceCount":56,"citationCount":1,"fieldsOfStudy":["Medicine"],"publicationDate":"2024-08-02","authors":[{"authorId":"2219774984","name":"Jacopo D\u2019Andria Ursoleo"},{"authorId":"2314533475","name":"Cristiano Cal\u00ec"},{"authorId":"2132484437","name":"Rosario Losiggio"},{"authorId":"2314533746","name":"Vito Limone"},{"authorId":"2314540901","name":"Elena Mucci"},{"authorId":"2255389781","name":"Fabrizio Monaco"}]},{"paperId":"012f8848caa73455352b5f74d2b6e4ee5db7ec80","title":"Priorities for research during the Coronavirus SARS-CoV-2 (COVID-19) pandemic and beyond: a survey of nurses, midwives and health visitors in the United Kingdom","abstract":"Background The Coronavirus SARS-CoV-2 (COVID-19) pandemic has had a significant burden on global healthcare systems. Nurses, midwives and health visitors remain critical to the rapid responses and innovative solutions required. Their views, however, on priorities for research is mainly muted, necessitating greater clarity to inform research that benefits patients and families across the life course. Aims To identify priorities for research in relation to the COVID-19 pandemic and \u2018beyond\u2019, as recommended by nurses, midwives and health visitors across the four countries of the United Kingdom (UK). Methods A cross-sectional, web-based survey design was conducted (5th May-4th June 2020). In addition to the completion of demographic information, respondents identified up to three research areas important to their clinical care\/practice in the context of COVID-19 and beyond. Data were imported for analysis into NVivo 12 (QSR International). Descriptive analysis was used to summarise the demographic variables. Free text responses were analysed using a semantic, inductive thematic analysis approach. Results In total 1,296 responses were received from a self-selected sample of predominantly of female, registered nurses of white British ethnicity, located in England and working for acute care providers, providing 3,444 research priority recommendations. Four higher-order themes emerged, (1) New and unknown frontiers; (2) Care and treatment solutions; (3) Healthcare leadership and inclusive workforce; and (4) Emotional and mental health impact. Conclusions At a time of significant global uncertainty, the collective voice of nursing, midwifery and health visiting is never more important to inform clinical research. Whilst generalisability is limited by the homogeneity of the sample, this is the first survey to elicit the priorities for research in relation to the COVID-19 pandemic and beyond from nurses, midwives and health visitors in the UK. Novel findings developed through a rigorous analytical approach illuminate areas that require both urgent and long-term attention and provide a platform to direct priority refinement, future research and the basis for evidence translation.","venue":"Journal of Research in Nursing","year":2021.0,"referenceCount":50,"citationCount":4,"fieldsOfStudy":["Medicine"],"publicationDate":"2021-08-01","authors":[{"authorId":"35616869","name":"J. Manning"},{"authorId":"7613738","name":"L. Bramley"},{"authorId":"49404177","name":"J. Coad"},{"authorId":"145918274","name":"C. Evans"},{"authorId":"144867789","name":"K. Evans"},{"authorId":"46500474","name":"Linda Tinkler"},{"authorId":"7202530","name":"J. Cooper"}]},{"paperId":"0131cd9c21423dd5a5637f45c448c1d8d6cc598f","title":"Myths around Web Services","abstract":"Web services and the technology surrounding them have become the dominant trend in the electronic commerce arena. XML, SOAP, UDDI, and WSDL, as the foundation of Web services, are all attracting considerable attention as potential bridges between heterogeneous systems distributed acrass the Internet. The assumption seems to be that soon most applications will speak and understand XML, that all systems will support SOAP, that everybody will advertise their services in UDDI registers, and that all services will be described in WSDL. Once that stage is reached, application integration and business to business (B2B) e-commerce will be straightforward. Unfortunately, Web services are only the next step in the natural evolution of middleware. Therefore, by design, Web services are evolutionary rather than revolutionary. The most basic form of middleware are RPC engines. When such engines become transactional, they become TP-Monitors. Once object orientation aspects are inc1uded, TP-Monitors evolve into Object Monitors. Message oriented middleware (MOM) also originated fram TP-Monitors since persistent queuing was a feature of many TP-Monitors until they became systems on their own. In fact, many\u00b7 MOM platforms are RPC based. Web services are, primarily, an extension to middleware platforms to allow them to interact across the Internet. Only from this perspective do many of the developments in the Web services arena make sense, e.g., that one of the first protocols to be wrapped as SOAP messages was RPC (and, at the time of writing, almost the only one to have been completely specified). Of course, it is possible that Web services will trigger a radical change in the way we think about middleware, application integration or the way we use the Internet. In that case, Web services will evolve into something yet unforeseen. At this stage, however, this has yet to happen. In reality, and precisely because they were created with that purpose in mind, Web services are used today almost exc1usively for conventional enterprise application integration (which may or may not happen in a B2B setting). It is this experience as an extension to middleware platforms that will define and shape Web services in the short and medium termo There are nevertheless many proposals that take Web services well beyond their current capabilities: semantic web, dynamic marketplaces, automatic generation of B2B applications, seamless integration of IT infrastructures from different corporations, etc. These proposals are the basis for presenting Web services as revolutionary, rather than evolutionary. Such speculations are the province of long term research but they tend to ignore the exact nature of Web services and the underlying technology. Many of these ideas also ignore the current limitations of existing middleware platforms although most of these limitations appear again at the Web service level. In this regard, Web services have to a certain extent become an outlet for ideas that proved impractical in the","venue":"","year":2009.0,"referenceCount":11,"citationCount":7,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"144641551","name":"G. Alonso"}]},{"paperId":"013234c7af7babfae8d8a679b1ec59cd9e47e234","title":"Semantic Web Representation for Phytochemical Ontology Model","abstract":".","venue":"","year":2018.0,"referenceCount":14,"citationCount":3,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"2939169","name":"M. Hamiz"},{"authorId":"2222531","name":"H. Haron"},{"authorId":"66375892","name":"A. Sanusi"},{"authorId":"143880237","name":"M. Bakri"},{"authorId":"2286033497","name":"Nur Syamira"},{"authorId":"2286062089","name":"Mohd Nazaruddin"}]},{"paperId":"01329d92d9315a73f531c145472b692ab3c3bc59","title":"Advances in Knowledge Discovery and Management - Volume 4 [Best of EGC 2012, Bordeaux, France]","abstract":null,"venue":"European Grid Conference","year":2014.0,"referenceCount":0,"citationCount":2,"fieldsOfStudy":["Computer Science","Engineering"],"publicationDate":"2014-04-13","authors":[{"authorId":"1782804","name":"F. Guillet"},{"authorId":"2100834","name":"Bruno Pinaud"},{"authorId":"145839771","name":"G. Venturini"},{"authorId":"1678550","name":"D. Zighed"}]},{"paperId":"013337d3cbc63378c2bf41cee229611b7a20541e","title":"Semantic Service Alignment Using Concept Description Refinement","abstract":"Due to the heterogeneity of the semantic web, the integration of client applications and services using slightly different ontologies is a major challenge, shown by the significant research effort directed towards aligning ontologies and identifying matching concepts. A novel method for service selection by matching a query with services, represented by input and output parameters and a description, is presented. The query matching relies on a concept translation and mapping using bridge rules and by replacing a concept by an equivalent representation, a bag of concepts. By translating a concept description between ontologies we obtain the equivalent representation of the same concept using terms from the other ontology, used later to determine the mapped concept or verify existing mappings.","venue":"2010 12th International Symposium on Symbolic and Numeric Algorithms for Scientific Computing","year":2010.0,"referenceCount":8,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":"2010-09-23","authors":[{"authorId":"1728878","name":"I. A. Letia"},{"authorId":"2053665646","name":"Octavian Pop"}]},{"paperId":"01335cee959bf4ea1982d0f07d374b2ea84f5db9","title":"IWT: A Semantic Web-based Educational System","abstract":"The Semantic Web seems to be a challenge for educational system aiming to accomplish the AAAL: Anytime, Anywhere, Anybody Learning. In this scenario an innovative e-learning solution named IWT, Intelligent Web Teacher, coming from Italian and European research projects, actually employed in many Italian high schools, enterprises and university departments, started to do it some years ago. IWT is able to model educational domains knowledge, users' competences and preferences by a Semantic Web approach in order to create personalized and contextualized learning activities and to allow users to communicate, to cooperate, to dynamically create new content to deliver and information to share as well as enabling platform for e-learning 2.0.","venue":"","year":2009.0,"referenceCount":13,"citationCount":27,"fieldsOfStudy":["Engineering"],"publicationDate":null,"authors":[{"authorId":"1705430","name":"N. Capuano"},{"authorId":"144602007","name":"Sergio Miranda"},{"authorId":"1750385","name":"F. Orciuoli"}]},{"paperId":"0134598ddba28c396077020a11b74db311ecdf56","title":"Interoperability for the Semantic Web: A Loosely Coupled Mediation Approach. (Interop\u00e9rabilit\u00e9 pour le Web s\u00e9mantique : une approche par m\u00e9diation faiblement coupl\u00e9e)","abstract":null,"venue":"","year":2021.0,"referenceCount":0,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"2064068951","name":"A. Zimmermann"}]},{"paperId":"0134d7b7c5c57dc682555be65f04622a26d1f9b6","title":"A Robust Medical Speech-to-Speech\/Speech-to-Sign Phraselator","abstract":"We present BabelDr, a web-enabled spoken-input phraselator for medical domains, which has been developed at Geneva University in a collaboration between a human language technology group and a group at the University hospital. The current production version of the system translates French into Arabic, using exclusively rule-based methods, and has performed credibly in simulated triaging tests with standardised patients. We also present an experimental version which combines largevocabulary recognition with the main rule-based recogniser; offline tests on unseen data suggest that the new architecture adds robustness while more than halving the 2-best semantic error rate. The experimental version translates from spoken English into spoken French and also two sign languages.","venue":"Interspeech","year":2017.0,"referenceCount":10,"citationCount":2,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"23784509","name":"Farhia Ahmed"},{"authorId":"145141931","name":"P. Bouillon"},{"authorId":"27726255","name":"C. Destefano"},{"authorId":"39452145","name":"Johanna Gerlach"},{"authorId":"2755486","name":"Sonia Halimi"},{"authorId":"33652619","name":"A. Hooper"},{"authorId":"1761581","name":"Manny Rayner"},{"authorId":"5103177","name":"H. Spechbach"},{"authorId":"3179347","name":"Irene Strasly"},{"authorId":"3338503","name":"Nikos Tsourakis"}]},{"paperId":"01351e2ad983ebb4926040648f28052269e8a85c","title":"The Agronomic Linked Data (AgroLD) Project","abstract":"The drastic growth in data in the recent years, within the Agronomic sciences has brought the concept of knowledge management to the forefront. Some of the factors that contribute to this change include a) conducting high-throughput experiments have become affordable, the time spent in generating data through these experiments are minuscule when compared to its integration and analysis; b) publishing data over the web is fairly trivial and c) multiple databases exist for each type of data (i.e. \u2018omics\u2019 data) with a possible overlap or slight variation in its coverage. In most cases these sources remain autonomous and disconnected. Hence, efficiently managed data and the underlying knowledge in principle will make data analysis straightforward aiding in more efficient decision making. At the Institute of Computational Biology (IBC), we are involved in developing methods to aid data integration and knowledge management within the domain of Agronomic sciences to improve information accessibility and interoperability. To this end, we address the challenge by pursuing several complementary research directions towards: distributed, heterogeneous data integration. This talk will focus mainly on,Agronomic Linked Data (AgroLD) wich is a Semantic Web knowledge base designed to integrate data from various publically available plant centric data sources. These include Gramene, Oryzabase, TAIR and resources from the South Green platform among many others. The aim of AgroLD project is to provide a portal for bioinformaticians and domain experts to exploit the homogenized data towards enabling to bridge the knowledge.","venue":"","year":2016.0,"referenceCount":4,"citationCount":0,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"49767167","name":"P. Larmande"},{"authorId":"3353178","name":"C\u00e9lia Michotey"},{"authorId":"66480934","name":"C. Anger"},{"authorId":"49379050","name":"F. Ehrenmann"},{"authorId":"2242306101","name":"V\u00e9ronique V. Jorge"},{"authorId":"49351571","name":"Odile Rogier"},{"authorId":"2272149701","name":"Catherine Bastien"},{"authorId":"2243905380","name":"Christophe Plomion"},{"authorId":"2285804144","name":"Christian Pichot"},{"authorId":"3001968","name":"H. Quesneville"},{"authorId":"1403020925","name":"A. Adam-Blondon"},{"authorId":"37932793","name":"M. Moretto"},{"authorId":"49592684","name":"P. Sonego"},{"authorId":"37384037","name":"S. Pilati"},{"authorId":"2220580","name":"G. Malacarne"},{"authorId":"2285815543","name":"Laura Costantini"},{"authorId":"6181647","name":"L. Grzeskowiak"},{"authorId":"4946835","name":"Giorgia Bagagli"},{"authorId":"2285813100","name":"Claudio Moser"},{"authorId":"33613247","name":"M. S. Grando"},{"authorId":"7707308","name":"K. Engelen"},{"authorId":"2241456700","name":"Fondazione Edmund Mach"},{"authorId":"2285832066","name":"Computer Demo"},{"authorId":"2285803694","name":"Damien Leroux"},{"authorId":"2285811400","name":"Miat Sylvain Jasson"},{"authorId":"37912533","name":"C. Pommier"},{"authorId":"17697593","name":"Guillaume Cornut"},{"authorId":"2492914","name":"M. Alaux"},{"authorId":"8628692","name":"T. Letellier"},{"authorId":"49156076","name":"Erik Kimmel"},{"authorId":"152708202","name":"Sophie Durand"},{"authorId":"37456418","name":"Raphael Flores"},{"authorId":"2285803123","name":"Florian Philippe"},{"authorId":"2285803845","name":"Mathide Lain\u00e9"},{"authorId":"2284127904","name":"\u00c9ric Duch\u00eane"},{"authorId":"2285812128","name":"Thierry Lacombe"},{"authorId":"87937996","name":"F. Oury"},{"authorId":"2238026970","name":"Gilles Charmet"},{"authorId":"2272303618","name":"A. Gauffreteau"},{"authorId":"46296109","name":"R. Bruskiewich"},{"authorId":"1413466359","name":"Kenneth C. Huellas-Bruskiewicz"},{"authorId":"2285830895","name":"Chandan K. Mishra"},{"authorId":"1409254657","name":"Farzin Ahmed"},{"authorId":"2285776837","name":"Yinglun Colin Qiao"},{"authorId":"2285867238","name":"Jarielle D Lim"},{"authorId":"1627376174","name":"Lance M. Hannestad"},{"authorId":"2285768649","name":"Rudy Kong"},{"authorId":"2285832075","name":"Tin Lun"},{"authorId":"2285410334","name":"Benjamin M. Good"},{"authorId":"2262118849","name":"Clay Birkett"}]},{"paperId":"0136bee1baed9faae3ef6bcf671676f1bd0954ba","title":"Current Research and Practical Progress of Multi-domain Ontology Semantic Interconnection","abstract":"This article briefly introduced the status of semantic web and ontology mapping research at domestic and abroad,and analyzed and dissertation on the significant literature were given.By comparing and analyzing the research features between domestic and abroad fro several aspects:standardization formulation of semantic web,development tools and platform,related projects,the Methods and the system of the ontology mapping and so on,this paper discussed the different research features at home and abroad,finally,constructed to solve the problem in the Multi-domain Ontology Semantic interconnection by knowledge map technology.","venue":"","year":2010.0,"referenceCount":0,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"2056195023","name":"Zhao Na"}]},{"paperId":"013793b4e992c0e2d6b3e1d4fd916c7d210a31d5","title":"A New Approach to Answerer Recommendation in Community Question Answering Services","abstract":null,"venue":"European Conference on Information Retrieval","year":2012.0,"referenceCount":14,"citationCount":14,"fieldsOfStudy":["Computer Science"],"publicationDate":"2012-04-01","authors":[{"authorId":"2491081","name":"Zhenlei Yan"},{"authorId":"49640256","name":"Jie Zhou"}]},{"paperId":"0137cbf4bf119c6aa053940c2b4b1cb2275a5f1e","title":"Weaving the Web of Belief into the Semantic Web","abstract":"Collaboration, especially knowledge sharing, enables the advance of science as well as human society. In cyberspace, socializing the traditionally isolated intelligent software agents is an ultimate goal of the emerging Semantic Web activity. When making collaboration decisions, an agent usually needs explicitly represented facts about the agent world, such as ``who knows what' and ``who can do what'. However, the limited computation and storage resources forbid an agent to independently maintain rational beliefs on all facts about the agent world. So the full picture of the agent world has to be distributed in the knowledge sharing social network of those resident agents. In this paper, we propose a generic representation framework for this distributed knowledge network, which is also called the reminiscent of Quine's {\\it web of belief}. The framework includes: the RDF based {\\it semantic relation model}, which is a cognitive data model for the agent world; a general OWL ontology, which facilitates representing agent properties (such as knowledge and capability) and finer inter-agent trust relations; and the practical issues on maintaining the web of belief for distributed inference.","venue":"","year":2004.0,"referenceCount":44,"citationCount":9,"fieldsOfStudy":["Computer Science"],"publicationDate":"2004-05-22","authors":[{"authorId":"46572927","name":"Li Ding"}]},{"paperId":"01385d896a56fb8b7aac0203eaffb77bcabb1cfc","title":"Semantic Knowledge Management for Product Design Based on Product Engineering Ontologies","abstract":"This paper formulates an approach to use the semantic web for knowledge management in the product design domain to provide enhanced capabilities of authoring\/updating, querying\/reasoning, searching, and visualization of information. Engineering has unique challenges, due to the pervasive use of CAD models and underlying interoperability and integration issues. The authors propose a distributed model composed of a host hybrid-data repository, external public linked data sources, a semantic data management engine, and a web-based user interface layer. The hybrid-data repository consists of ontologies to preserve knowledge for the product design domain and a conventional product data base to utilize legacy design data. Near full integration with a web based environment is achieved. The importance of accessing product related CAD data that has been instantiated in ontology models, querying them, and then displaying the data on a web interface in real time with other legacy data, such as hand sketches and notes that have been scanned and relevant information from conventional rational databases public linked data sites, is a useful and transformational capability. The system clearly facilitates design and information management beyond traditional CAD capabilities and creates a foundation for important capability improvements in the domain.","venue":"","year":2012.0,"referenceCount":7,"citationCount":0,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"2218422759","name":"Lijuan Zhu"}]},{"paperId":"013a0f132454369093a86a716395e8eda6a139b9","title":"MyMemory: an ontology for privacy protection in external digital memories","abstract":"Every day, over one billion people actively use some social network or social media, sharing opinions, describing facts they believe, and detailing moments of their lives online. In some way, we are digitizing part of our lives and, thus, creating an external collective digital memory in which the issue of privacy is central. We propose to address the privacy issue of digital memories by applying conceptual modeling and semantic web technologies. For that, we built MyMemory, an ontology for the broad concept of digital memory that includes the concept and associated rules to address private memory associated to the context in which it was produced.","venue":"Americas Conference on Information Systems","year":2018.0,"referenceCount":18,"citationCount":1,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"25901321","name":"Bianca Rodrigues Teixeira"},{"authorId":"32870305","name":"F. Santoro"},{"authorId":"144023013","name":"F. Bai\u00e3o"}]},{"paperId":"013a57da61905781a8d10b98ddd8baa00d8c256e","title":"Web Mining through Semantic Similarity Measures between Words Using Page Counts","abstract":": Semantic Web Mining aims at combining the two fast-developing research areas Semantic Web and Web Mining. This survey analyzes the convergence of trends from both areas: More and more researchers are working on improving the results of Web Mining by exploiting semantic structures in the Web, and they make use of Web Mining techniques for building the Semantic Web. Last but not least, these techniques can be used for mining the Semantic Web itself. The Semantic Web is the second-generation WWW, enriched by machine-learning techniques which support the user in his tasks. Given the enormous size of even today\u2019s Web, it is impossible to manually enrich all of these resources. Therefore, automated schemes for learning the relevant information are increasingly being used. We argue that the two areas Web Mining and Semantic Web need each other to fulfill their goals, but that the full potential of this convergence is not yet realized. This paper gives an overview of where the two areas meet today, and sketches ways of how a closer integration could be profitable. By applying lexico-syntactic patterns to the process of ontology design\/evolution, we might derive ontology elements.","venue":"","year":2014.0,"referenceCount":5,"citationCount":0,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"41216523","name":"R. Paper"},{"authorId":"2286060127","name":"Ms. R. Kousalya"},{"authorId":"2285828500","name":"Arun Kumar"},{"authorId":"94207524","name":"Dr.V. Saravanan"}]},{"paperId":"013b0ae8439518c6bc21f67357a49da61868507a","title":"Testbeds II - Early Prototypes","abstract":"A3-D6 delivers demonstrators and prototypes of personalized information systems. In this ac- companying report we continue the documentation strategy developed in deliverable A3-D2, were we gave a detailed analysis on use cases of partners in the REWERSE network, and analyzed these use cases. This accompanying report provides an improved version of the ques- tionnaire developed in A3-D2, and gives an overview on current prototypes in both human- and machine-readable form. Guidelines for development of use cases have been incorperated in this documentation. During the development of the prototypes, some key issues on personalization for the Semantic Web have been identified during various discussions and meetings. We sum- marize these findings in a brief lessons-learnt section, and conclude the report with a roadmap of future work in A3.","venue":"","year":2006.0,"referenceCount":7,"citationCount":1,"fieldsOfStudy":["Engineering"],"publicationDate":null,"authors":[{"authorId":"1699110","name":"N. Henze"}]},{"paperId":"013c8d1c62bec8cdc692d3b5e9ffd908423ec41f","title":"Quality of an Ontology as a Dynamic Optimisation Problem","abstract":"The Semantic Web is a proposal from the World Wide Web Consortium aimed at solving problems like data integration and application interoperability. To reach these goals several languages for the representation of semantic data have been proposed. One of the essential concepts behind semantic data is that the data is according to a certain ontology. However, the goals of the semantic web seem challenged because it seems essential for its working that ontologies are agreed upon and shared. This work-in-progress paper describes a first step to solving these problems. When an ontology is missing or only partially known a system might try to make an approximation of the missing part of the ontology. The quality of this estimated ontology will depend on the context of the application. This paper proposes the solving of a dynamic multi-objective and context sensitive optimisation problem as a way to evalute the quality of the ontology.","venue":"International Conference on Information and Communication Technologies in Education, Research, and Industrial Applications","year":2012.0,"referenceCount":20,"citationCount":3,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"1708906","name":"Michael Cochez"},{"authorId":"1742755","name":"V. Terziyan"}]},{"paperId":"013ce40ab8b960911500ebe08cad208e53be7fb1","title":"A Semantic Approach for Fashion Recommendation Using Logistic Regression and Ontologies","abstract":"Due to the increased prevalence of web recommendation systems after years of research, it has unarguably become the ultimate solution for efficient functioning of any e-commerce or user supportive digital domain. Though a variety of algorithms have been tested to meet the expectations of users in order to be decision supportive, this paper proposes a potential framework for recommendation of men's clothing. The focus of the system is to improve the efficiency of the recommendation to cope up to the speed of the user's thought process and expectations at the same time generate only those options that have been validated closely to the user's style hunt trajectory. In the presented approach the user's historical click data and searches is preprocessed and converted into query words. The features are extracted from the on ontology of fashion with the help of query words. The ontology used in this paper is highly domain specific. External sources such as fashion reviews, fashion e-magazines, fashion blogs and fashion trends from e-commerce websites are converted into query words and used for feature enrichment. The dataset is provided for classification using logistic regression, and only the top 50% of results from the classification undergoes semantic similarity computation. Normalized google distance and SemantoSim measure are the methods used for emantic similarity computation, this happens mainly for the relevance of the results. The recommendations of fashion items and fashion brands are suggested to the user based on the results gotten from semantic similarity. The accuracy of the Onto infused recommendation system is 97.14% and average precision is 96.31%.","venue":"International Conference on Signals and Electronic Systems","year":2021.0,"referenceCount":12,"citationCount":8,"fieldsOfStudy":null,"publicationDate":"2021-09-24","authors":[{"authorId":"2145999782","name":"D. N. Yethindra"},{"authorId":"144292620","name":"G. Deepak"}]},{"paperId":"013f4339bd92ae4f331102bd00ebe0d0da0a801c","title":"Beyond \u201cAlt-Text\u201d: Creating Accessible Data Visualizations with Code","abstract":"Data visualization is a reliable tool for professional communication practitioners for synthesizing and presenting data to a variety of audiences. However, data visualizations have a range of accessibility concerns including: visual acuity, color\/contrast difficulties, color blindness and size\/scale issues. Alt-text is not enough to make these visuals accessible and therefore more advanced web coding techniques, such as the Scalable Vector Graphic (SVG) format should be used to create data visualizations for the web. The use of SVG allows for greater coded semantic and contextual information to be added to data visualizations resulting in graphics that can be better interacted with by users with a variety of accessibility software.","venue":"ACM International Conference on Design of Communication","year":2021.0,"referenceCount":18,"citationCount":3,"fieldsOfStudy":["Computer Science"],"publicationDate":"2021-10-12","authors":[{"authorId":"3272302","name":"Adam Strantz"}]},{"paperId":"013fde08eef840266f5305a6f2d021e1769e81a0","title":"Hierarchical Object-Oriented Petri Net Modeling Method Based on Ontology","abstract":"This paper presents a Hierarchical Object-Oriented Petri Net (HOOPN) modeling method based on Ontology that should not only enable sharing Petri nets models on the Semantic Web but also present a high level Petri net. Previous work on formal methods for representing Petri nets mainly focuses on modeling and analyzing aspects or formats for Petri net model interchange. However, such efforts do not provide a suitable model description for using Petri nets on the Semantic Web. This paper uses the HOOPN with the Ontology concepts as a starting point for implementing the Petri net ontology. Moreover this paper uses HOOPN as the Petri net model method. HOOPN supports a wide range of Object-Oriented features including abstract, encapsulated and modularized objects, object interaction by message passing, inheritance, and polymorphism.","venue":"2008 International Conference on Internet Computing in Science and Engineering","year":2008.0,"referenceCount":11,"citationCount":12,"fieldsOfStudy":["Computer Science"],"publicationDate":"2008-01-28","authors":[{"authorId":"2286992310","name":"Xiaoning Feng"},{"authorId":"38385213","name":"Wang Zhuo"},{"authorId":"2264314938","name":"Guisheng Yin"}]},{"paperId":"0140d0b9daf203dea48623251cdaa661bd342e5f","title":"KMIR - a Knowledge Management Implementation and Recommendation Framework using CBR and Semantic Web Technologies","abstract":". This document describes KMIR, a framework which supports organizations in the successful implementation of Knowledge Management (KM). It follows the holistic approach of a KM introduction by considering technological, organizational and human aspects, as well as organizational culture. The KMIR framework provides recommendations based on Case-Based Reasoning (CBR) and Semantic Web technology. The best practice cases for a successful KM implementation are structured by the use of an ontology.","venue":"","year":2006.0,"referenceCount":31,"citationCount":3,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"2648384","name":"Mark Hefke"},{"authorId":"1689856","name":"A. Abecker"}]},{"paperId":"0141c3455b6a7b1547335e3afcf984f835add136","title":"Semantic-Free Referencing in Linked Distributed Systems","abstract":null,"venue":"International Workshop on Peer-to-Peer Systems","year":2003.0,"referenceCount":10,"citationCount":22,"fieldsOfStudy":["Computer Science"],"publicationDate":"2003-02-21","authors":[{"authorId":"145034082","name":"H. Balakrishnan"},{"authorId":"143838343","name":"S. Shenker"},{"authorId":"1756078","name":"Michael Walfish"}]},{"paperId":"01423aa4e5fb50808ed31f1c877f3a548dd62346","title":"Correlated Multi-label Refinement for Semantic Noise Removal","abstract":null,"venue":"International Conference on Intelligent Computing","year":2010.0,"referenceCount":12,"citationCount":2,"fieldsOfStudy":["Computer Science"],"publicationDate":"2010-08-18","authors":[{"authorId":"21509844","name":"T. Zhou"},{"authorId":"2151976091","name":"Ling Wang"},{"authorId":"80325704","name":"H. Shon"},{"authorId":"2109315856","name":"Y. Lee"},{"authorId":"3080120","name":"K. Ryu"}]},{"paperId":"0142dbcc282e83930c01febaeaa82bfa9943bd57","title":"ARISTOTLE UNIVERSITY OF THESSALONIKI","abstract":"The Web Ontology Language (OWL) has become the standard for de\ufb01ning and sharing ontologies on the Web, based on formal and machine processable semantics. In the present work, we de\ufb01ne a framework for importing the (extensional) knowledge about OWL instances in Object-Oriented (OO) rule engines in order to develop practical, semantic web compliant, rule-based applications. We target at domains where ontologies are used as the means for exchanging knowledge among heterogeneous environments and serve as the back-end model of rule-based applications. To this end, we import the asserted and inferred OWL axioms of Description Logic (DL) reasoners in the KB of a native rule engine in order to be matched in the body of rules, acting as constraint model. The novelty of our approach is in the fact that, instead of the trivial mapping of DL reasoners\u2019 axioms into rule facts, we de\ufb01ne a methodology that exploits the OO capabilities of OO rule engines. The idea is to take advantage of OO principles, such as class and attribute inheritance, and to de\ufb01ne an OO model in such a way, so to preserve, in terms of OO relationships, the extensional semantics that have been inferred by the DL reasoner. In that way (a) the semantics of OWL ontologies are handled by sound and complete DL reasoners, and (b) instance constraints, such as instance class memberships or instance property values, are checked directly over the OO rule KB. We have implemented our methodology in the CLIPS-OWL library, an extension to the CLIPS production rule engine based on the Pellet DL reasoner that makes use of the COOL language in order to represent and check extensional OWL constraints.","venue":"","year":2009.0,"referenceCount":48,"citationCount":0,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"1696389","name":"G. Meditskos"},{"authorId":"1404583335","name":"N. Bassiliades"}]},{"paperId":"0142f669b79030461bba933648a1badc9578942d","title":"Is a Transformer Your Next Semantic Co-Author? Generating Semantic Web Paper Snippets with GPT-2","abstract":". The Semantic Web community has produced a large body of literature that is becoming increasingly di\ufb03cult to manage, browse, and use. Recent work on attention-based, sequence-to-sequence Transformer neural architecture has produced language models that generate surprisingly convincing synthetic conditional text samples. In this demonstration, we re-train the GPT-2 architecture using the complete corpus of proceedings of the International Semantic Web Conference since 2002 until 2019. We use an input text from a web service for conditionally sampling paper snippets, therefore illustrating cases where this model can help at addressing challenges in scienti\ufb01c paper writing, such as navigating extensive literature, explaining the Semantic Web core concepts, providing de\ufb01nitions, and even inspiring new research ideas.","venue":"","year":null,"referenceCount":7,"citationCount":0,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"1401909927","name":"Albert Mero\u00f1o-Pe\u00f1uela"},{"authorId":"2412667","name":"Dayana Spagnuelo"}]},{"paperId":"0142faefc3b83c3231526ab0005e1c01d63d0229","title":"Automatic blog classification using concept-category vectorization","abstract":"Blog classification is the system of classifying blogs based on pre-defined categories. This area \nis addressed by considering the textual content, or the surrounding features of the blogs. This \nthesis focuses on the textual content of the blogs which uses the blog title and posts for \nclassification. These blogs are categorised and maintained as a blog directory that serves the \ndemands of the users searching information online. Such online blog directories use human \nindexers to categorize blog pages. Manual classifications of blogs are tends to be labour \nintensive and time consuming. In related fields such as text mining and web mining, various \nclassification methods such as supervised, semi-supervised and unsupervised methods were \nproposed. These studies have used Bag-of-Words representation of text documents, and indexes \nusing term weighting scheme which does not capture the semantic relatedness.\nIn this thesis, we devise a novel framework for automatic topic based blog classification, \ndenoted as Terms-to-Concepts-to-Category framework. Our framework utilizes Wikipedia\u2019s \ncategorical index for blog classification task. Wikipedia article titles are treated as concepts, \nand are used for terms to concept substitution to compute a weighted-semantic path connecting \nconcepts to their main category. The n-gram based concept extraction technique is then used \nto extract concepts from the titles and posts from blogs. Our study improves upon previous \nstudies, by using concept based representation and concept weighting scheme that embeds \nsemantic information for blog classification.\nWe also propose clustering of blogs as an improvement to the Terms-to-Concepts-to-Category\nframework and show that clustering can improve the accuracy of blog classification by \nenhancing our framework with two clustering approaches: coarse clustering and fine \nclustering. The first approach is achieved by using tripartite spectral graph which uses three \nvertexes: Document context similarity, concept similarity and content similarity to categorize blog posts. \nIn the second approach, to achieve better classification and cluster multi categories, we \nenhance our framework using fuzzy c-means clustering and fuzzy similarity. Experimental \nresults show that our framework produces better accuracy in classifying multiple categories \nthan the existing tripartite and Fuzzy c-means clustering techniques.","venue":"","year":2017.0,"referenceCount":0,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"1955287","name":"R. Ayyasamy"}]},{"paperId":"01442a2278fad1a24db67748ddf9743035ae8544","title":"SD-Core: A Semantic Middleware Applied to Molecular Biology","abstract":null,"venue":"OTM Workshops","year":2008.0,"referenceCount":16,"citationCount":3,"fieldsOfStudy":["Computer Science"],"publicationDate":"2008-11-09","authors":[{"authorId":"1399149761","name":"Ismael Navas-Delgado"},{"authorId":"1814491","name":"Amine Kerzazi"},{"authorId":"2116977","name":"Othmane Chniber"},{"authorId":"1743835","name":"J. F. A. Montes"}]},{"paperId":"0144b25e06f4dedfebc588e039442a7417a6db02","title":"Index for Efficient Ontology Retrieval and Inference","abstract":"\ucd08 \ub85d\uadfc\ub798\uc5d0 \ub4e4\uc5b4\uc640\uc11c \uac01\uad11\ubc1b\uace0 \uc788\ub294 \uc2dc\ub9e8\ud2f1 \uc6f9\uacfc \uad00\ub828\uae30\uc220\uc758 \ubd80\uc0c1\uc73c\ub85c \uc628\ud1a8\ub85c\uc9c0\uc5d0 \ub300\ud55c \uad00\uc2ec\uc774 \uc99d\ub300\ub418\uc5c8\uc73c\uba70, \uadf8\uc911\uc5d0\uc11c\ub3c4 \uace0\ub09c\uc774\ub3c4\uc758 \ucd94\ub860\uc744 \uc694\uad6c\ud558\ub294 \uc758\ubbf8\uae30\ubc18 \uc2dc\ub9e8\ud2f1 \uac80\uc0c9\uc744 \uc704\ud574\uc11c \uc628\ud1a8\ub85c\uc9c0\ub97c \ud6a8\uc728\uc801\uc73c\ub85c \uc800\uc7a5\ud558\uace0 \uac80\uc0c9\ud558\ub294 \ub2e4\uc591\ud55c \uae30\ubc95\ub4e4\uc774 \ud65c\ubc1c\ud788 \uc5f0\uad6c\ub418\uc5b4\uc654\ub2e4. W3C\uc5d0\uc11c\uc758 \ud45c\uc900\uad8c\uace0\uc548\uc740 RDFS, OWL\uc744 \ud65c\uc6a9\ud558\ub3c4\ub85d \ud558\uace0 \uc788\ub2e4. \ud558\uc9c0\ub9cc \uba54\ubaa8\ub9ac \uae30\ubc18\uc73c\ub85c \uad6c\ud604\ub418\uc5b4 \uc788\ub294 \uc5d0\ub514\ud130\ub098 \ucd94\ub860\uc5d4\uc9c4\ub4e4, \uc628\ud1a8\ub85c\uc9c0\uc758 \uc6d0\ud615\uc744 \uadf8\ub300\ub85c \uc720\uc9c0\ud558\uc5ec \uc800\uc7a5\ud558\ub294 \ud2b8\ub9ac\ud50c \uc800\uc7a5\uc18c\ub97c \uc774\uc6a9\ud558\uc5ec \ub300\uc6a9\ub7c9 \uc628\ud1a8\ub85c\uc9c0\ub97c \ucc98\ub9ac\ud558\uae30\uc5d0\ub294 \uc131\ub2a5\uc0c1\uc758 \ud55c\uacc4\uac00 \uc788\ub2e4. \ub530\ub77c\uc11c \uc774\ub97c \ud574\uacb0\ud558\uae30 \uc704\ud574 \uad00\uacc4\ud615 \ub370\uc774\ud130\ubca0\uc774\uc2a4 \uc5d4\uc9c4\uc744 \uc774\uc6a9\ud558\uc5ec, \uc628\ud1a8\ub85c\uc9c0\ub97c \uc800\uc7a5\ud558\uace0 \ud6a8\uc728\uc801\uc73c\ub85c \ud65c\uc6a9\ud558\uae30 \uc704\ud55c \ub2e4\uc591\ud55c \ubc29\uc2dd\uc758 \ucd94\ub860\uc5d4\uc9c4\uacfc \uc9c8\uc758\ucc98\ub9ac \uc54c\uace0\ub9ac\uc998\ub4e4\uc774 \uc81c\uc548\ub418\uc5c8\uc73c\ub098, \uc628\ud1a8\ub85c\uc9c0 \ud504\ub85c\ud37c\ud2f0\uc758 \ub2e4\uc12f \uac00\uc9c0 \ud575\uc2ec\ud2b9\uc131\uc5d0 \ub530\ub978 \ucd94\ub860 \uacb0\uacfc\ub97c \uc644\uc804\ud558\uac8c \ud68d\ub4dd\ud558\uc9c0\ub294 \ubabb\ud558\uace0 \uc788\ub294 \uc2e4\uc815\uc774\ub2e4. \ubcf8 \ub17c\ubb38\uc5d0\uc11c\ub294 \ud558\uc774\ud37c \ud050\ube0c \uc778\ub371\uc2a4(Hyper Cube Index)\ub97c \uc81c\uc548\ud568\uc73c\ub85c\uc11c \uad00\uacc4\ud615 \ub370\uc774\ud130\ubca0\uc774\uc2a4\uc5d0 \uc800\uc7a5\ud55c \uc628\ud1a8\ub85c\uc9c0\ub97c \ud6a8\uc728\uc801\uc73c\ub85c \uac80\uc0c9\ud560 \uc218 \uc788\ub294 \ud658\uacbd\uc744 \uc81c\uacf5\ud558\ub294 \uac83\uc740 \ubb3c\ub860, \uc628\ud1a8\ub85c\uc9c0 \ud504\ub85c\ud37c\ud2f0\uc758 \ud575\uc2ec\ud2b9\uc131\uc744 \ube60\uc9d0\uc5c6\uc774 \ud22c\uc601\ud558\uc5ec \uc228\uaca8\uc9c4 \ucd94\ub860 \uacb0\uacfc\ub97c \ud68d\ub4dd\ud560 \uc218 \uc788\ub294 \ubc29\uc548\uc744 \uc81c\uc2dc\ud55c\ub2e4.ABSTRACTThe ontology has been gaining increasing interests by recent arise of the semantic web and related technologies. The focus is mostly on inference query processing that requires high-level techniques for storage and searching ontologies efficiently, and it has been actively studied in the area of semantic-based searching. W3C\u2019s recommendation is to use RDFS and OWL for representing ontologies. However memory-based editors, inference engines, and triple storages all store ontology as a simple set of triplets. Naturally the performance is limited, especially when a large-scale ontology needs to be processed. A variety of researches on proposing algorithms for efficient inference query processing has been conducted, and many of them are based on using proven relational database technology. However, none of them had been successful in obtaining the complete set of inference results which reflects the five characteristics of the ontology properties. In this paper, we propose a new index structure called hyper cube index to efficiently process inference queries. Our approach is based on an intuition that an index can speed up the query processing when extensive inferencing is required.","venue":"","year":2013.0,"referenceCount":31,"citationCount":1,"fieldsOfStudy":["Computer Science"],"publicationDate":"2013-05-31","authors":[{"authorId":"2110509169","name":"S. Song"},{"authorId":"2152585934","name":"Insung Kim"},{"authorId":"2113700745","name":"Jonghoon Chun"}]},{"paperId":"014716d5a3d4b6a13502cd9c1c01ba2e4f381b18","title":"The semantic web as a knowledge management environment","abstract":null,"venue":"","year":2013.0,"referenceCount":187,"citationCount":2,"fieldsOfStudy":["Computer Science"],"publicationDate":"2013-03-01","authors":[{"authorId":"72295822","name":"Aubrey James Livesey"}]},{"paperId":"014722151ee576e0361910b31f30902942f6a15a","title":"Towards a Programmable Semantic Extract-Transform-Load Framework for Semantic Data Warehouses","abstract":"In order to create better decisions for business analytics, organizations increasingly use external data, structured, semi-structured and unstructured, in addition to the (mostly structured) internal data. Current Extract-Transform-Load (ETL) tools are not suitable for this \"open world scenario\" because they do not consider semantic issues in the integration process. Also, current ETL tools neither support processing semantic-aware data nor create a Semantic Data Warehouse (DW) as a semantic repository of semantically integrated data. This paper describes SETL: a (Python-based) programmable Semantic ETL framework. SETL builds on Semantic Web (SW) standards and tools and supports developers by offering a number of powerful modules, classes and methods for (dimensional and semantic) DW constructs and tasks. Thus it supports semantic-aware data sources, semantic integration, and creating a semantic DW, composed of an ontology and its instances. A comprehensive experimental evaluation comparing SETL to a solution made with traditional tools (requiring much more hand-coding) on a concrete use case, shows that SETL provides better performance, knowledge base quality and programmer productivity.","venue":"International Workshop on Data Warehousing and OLAP","year":2015.0,"referenceCount":25,"citationCount":46,"fieldsOfStudy":["Computer Science"],"publicationDate":"2015-10-22","authors":[{"authorId":"3333643","name":"Rudra Pratap Deb Nath"},{"authorId":"1682407","name":"K. Hose"},{"authorId":"1731453","name":"T. Pedersen"}]},{"paperId":"0148527d8046a25b7d147d7d0edb56bb9cca2604","title":"Sharing Ancient Wisdoms across the Semantic Web using TEI and ontologies","abstract":"This paper explores the approach of the Sharing Ancient Wisdoms (SAWS) 1 project to the publication and analysis of the tradition of wisdom literatures in ancient Greek, Arabic, Spanish, and other languages. The SAWS project edits and presents the texts digitally, in a manner that enables linking and comparisons within and between anthologies, their source texts, and the texts that draw upon them (referred to here as (cid:212)recipient texts(cid:213)). It is also creating a framework through which other projects can link their own materials to these texts through the Semantic Web, thus providing a focal point for the development of scholarship on these texts and their related manuscripts. The project is funded by HERA (Humanities in the European Research Area) as part of their programme to investigate cultural dynamics in Europe, and constitutes teams at the Department of Digital Humanities and the Centre for e-Research at King\u2019s College London, the Newman Institute Uppsala in Sweden, and the University of Vienna. The wisdom literatures included in the SAWS project are a feature of the broader tendency in antiquity and the Middle Ages to take extracts from larger texts containing wise or useful sayings, and to circulate these anthologies widely. This was done in order to address the problem of the cost and rarity of full, original texts, and was a key method by which ideas and morals were circulated across different countries and languages","venue":"","year":2012.0,"referenceCount":6,"citationCount":2,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"3233178","name":"Charlotte Tupman"},{"authorId":"2324254","name":"Anna Jordanous"}]},{"paperId":"0149c5b8e35b27206a7329a341dd0bb0c6972f03","title":"TagFusion: A System for Integration and Leveraging of Collaborative Tags","abstract":null,"venue":"Web 2.0 & Semantic Web","year":2009.0,"referenceCount":15,"citationCount":3,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"31703347","name":"M. Stankovi\u0107"},{"authorId":"145103816","name":"J. Jovanovi\u0107"}]},{"paperId":"014ad70a1ef8c25a2edb1132ed871d73f3c0f60a","title":"An Approach to Construct Semantic Networks with Confidence Scores Based on Data Analysis - Case Study in Osaka Wholesale Market","abstract":"In recent years, several large-scale knowledge bases (KBs) have been constructed, such as YAGO, DBpedia, and Google Knowledge Graph. Although automatic extractio techniques that extract facts and rules from the Web is necessary for constructing such large-scale KBs, incorporation of noisy, unreliable knowledge cannot be unavoidable. Thus, Google Knowledge Vault assigns extracted knowledge with confidence scores based on consistency with the existing KBs. In this paper, we propose a new approach for associating confidence scores with knowledge based on a large amount of raw data for domains, where there is no existing KB. We first construct knowledge in a specific domain as a semantic network, and then design a probabilistic network, that corresponds to the semantic network. To associate the confidence scores with the semantic network, we train the probabilistic network with a large amount of open data, provided by the Osaka central wholesale market in Japan. We also confirm the validity of the confidence scores with the accuracy of reasoning on the probabilistic network. A semantic network associated with confidence scores, that is, a weighted labeled graph is advantageous not only for reducing the noisy, unreliable knowledge with low confidence, but also for making retrieval results ranking on the KB. In the future, probabilistic reasoning on semantic networks may also be possible.","venue":"IEEE International Conference on Tools with Artificial Intelligence","year":2015.0,"referenceCount":22,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":"2015-11-09","authors":[{"authorId":"1689972","name":"Takahiro Kawamura"},{"authorId":"1740433","name":"Akihiko Ohsuga"}]},{"paperId":"014cd6d4e8c5349ef271eb4dd9308d5ceb13e668","title":"Sentiment Analysis for Topics based on Interaction Chain Model","abstract":"With the rapid development of Internet and Web 2.0, online social networks, such as Facebook, Twitter, LinkedIn, have become valuable sources for public opinion mining and sentiment analysis. Millions of users are sharing their views and discussing current issues through social media every day. Microblog, as a convenient and easily access platform, also attracts more and more people to express their feelings about hot topics. However, as the maximum message length is only 140 characters in microblog, traditional sentiment analysis methods for topics cannot well performed due to the lack of information. In this paper, we propose a novel sentiment analysis methods based on interaction chain. Firstly, we organize messages as interaction-chains by taking advantages of the explicit interaction markers in microblog. Then, interaction-chains are clustered into different topics by comparing the similarity among them. After that, we perform sentiment analysis using semantic-based SBV polarity algorithm. We also proposed two heuristics according to the specificities of microblog. Experimental evaluations show that the proposed heuristic interaction-chain-based algorithm can extract discriminative and meaningful topics and could conduct sentiment analysis effectively.","venue":"European Intelligence and Security Informatics Conference","year":2015.0,"referenceCount":14,"citationCount":2,"fieldsOfStudy":["Computer Science"],"publicationDate":"2015-09-07","authors":[{"authorId":"2066078788","name":"Ning Gu"},{"authorId":"1984634","name":"Duoyong Sun"},{"authorId":"1713520","name":"Bo Li"},{"authorId":"46947189","name":"Ze Li"}]},{"paperId":"014d0dcd8867a9012b142d5f97af1a78b51eb785","title":"A Survey of Semantic Web Based Recommender Systems for E-Learning","abstract":null,"venue":"Communication Systems and Applications","year":2023.0,"referenceCount":0,"citationCount":2,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"3856771","name":"C. Aktas"},{"authorId":"2793245","name":"Birol Ciloglugil"}]},{"paperId":"014e9876a85e777c4ee1e291bf1bf784624b109b","title":"Learning Chinese Word Embeddings By Discovering Inherent Semantic Relevance in Sub-characters","abstract":"Learning Chinese word embeddings is important in many tasks of Chinese language information processing, such as entity linking, entity extraction, and knowledge graph. A Chinese word consists of Chinese characters, which can be decomposed into sub-characters (radical, component, stroke, etc). Similar to roots in English words, sub-characters also indicate the origins and basic semantics of Chinese characters. So, many researches follow the approaches designed for learning embeddings of English words to improve Chinese word embeddings. However, some Chinese characters sharing the same sub-characters have different meanings. Furthermore, with more cultural interaction and the popularization of the Internet and web, many neologisms, such as transliterated loanwords and network terms, are emerging, which are only close to the pronunciation of their characters, but far from their semantics. Here, a tripartite weighted graph is proposed to model the semantic relationship among words, characters, and sub-characters, in which the semantic relationship is evaluated according to the Chinese linguistic information. So, the semantic relevance hidden in lower components (sub-characters, characters) can be used to further distinguish the semantics of corresponding higher components (characters, words). Then, the tripartite weighted graph is fed into our Chinese word embedding modelinsideCC to reveal the semantic relationship among different language components, and learn the embeddings of words. Extensive experimental results on multiple corpora and datasets verify that our proposed methods outperform the state-of-the-art counterparts by a significant margin.","venue":"International Conference on Information and Knowledge Management","year":2022.0,"referenceCount":33,"citationCount":3,"fieldsOfStudy":["Computer Science"],"publicationDate":"2022-10-17","authors":[{"authorId":"143844110","name":"Wei Lu"},{"authorId":"2156123735","name":"Zhaobo Zhang"},{"authorId":"2881771","name":"Pingpeng Yuan"},{"authorId":"2118832510","name":"Hai-rong Jin"},{"authorId":"2187856151","name":"Qiangsheng Hua"}]},{"paperId":"014f0a7c3ad4aaf36160accd8eabaee85cb52a02","title":"Semantic Wonder Cloud: Exploratory Search in DBpedia","abstract":null,"venue":"ICWE Workshops","year":2010.0,"referenceCount":28,"citationCount":45,"fieldsOfStudy":["Computer Science"],"publicationDate":"2010-07-05","authors":[{"authorId":"2499179","name":"R. Mirizzi"},{"authorId":"1738932","name":"Azzurra Ragone"},{"authorId":"1737962","name":"T. D. Noia"},{"authorId":"1738818","name":"E. Sciascio"}]},{"paperId":"014fee68257f5e8fe39332082b446256afc0c61b","title":"A semantic web based personalized learning service for programming course in e-learning","abstract":"Many researches are concentrating on personalized strategies of e-learning, and many new strategies are put forward. This paper also tries to support a personalized strategy customized for programming course. Considering the demands for improvements later or application with new strategies, the realization should be flexible with new strategies. We designed a model for personalized learning. It included an information model and a process model. The model has great adaptability for strategy and strategy combination. Many strategies from other researches can also map and embed into the model. Based on the model, the strategy for programming course was designed, and a personalized service was provided. The service can adapt to the change of strategies, not only to a rule's change, but also to the change of entire strategy plan.","venue":"International Conference on Mechatronic Science, Electric Engineering and Computer","year":2011.0,"referenceCount":12,"citationCount":2,"fieldsOfStudy":["Computer Science"],"publicationDate":"2011-09-23","authors":[{"authorId":"2285586597","name":"Jinghua Zhang"}]},{"paperId":"015034dfd797414053cac54675835c63f87bfefa","title":"Secure and Intelligent Decision Making in Semantic Web Mining using XML, XSLT and Xquery","abstract":"Web mining is the application of data mining technologies to automatically interact and discover information from web documents, which can be in structured, unstructured or semi- structured form. The Semantic Web is an extension of the current web in which information is given well-defined meaning, better enabling computers and people to work in cooperation. We present an enterprise framework regarding semantic web mining in distance learning, which can be used to not only improve the quality of web mining results but also enhances the functions and services and the interoperability of long distance educational information systems and standards in the educational field. For on line distance education system we propose an Ontology-based approach to share online data and retrieve all relevant data about students and their courses. Thus semantic web ontology help build better web mining analysis in educational institute and web mining in-turns helps contract basis more powerful ontology in distance learning. Since the majority of the online data considered as private data we need various mechanism for privacy preservation and control over the online presence data. We propose privacy protection in semantic web mining using role back access control.","venue":"","year":2015.0,"referenceCount":16,"citationCount":3,"fieldsOfStudy":["Computer Science"],"publicationDate":"2015-12-30","authors":[{"authorId":"46237670","name":"R. Dubey"},{"authorId":"72819684","name":"N. Namdeo"}]},{"paperId":"0151b6c330933c07d170495ff62f27ca1e42414d","title":"On the Programming and System Integration of Robots in Flexible Manufacturing","abstract":"Advanced manufacturing technologies and programmable machines such as\nindustrial robots are used to increase productivity and quality for\ncompetitiveness on a global market. Development of increasingly\nflexible manufacturing systems has resulted in an increasing\nimportance of software aspects, both on a system level and for\nefficient interaction with human operators. Trends toward providing\ncustomized products increase the need for flexibility, which implies\na need to build modular systems that are flexible enough to handle\nfrequent changes in production operations and product designs.\n\nThe objective of the research presented in this thesis is to improve\nthe flexibility of industrial robot software when used as a component\nin flexible and reconfigurable industrial automation\nsolutions. Contributions are made in four areas; First, high\nperformance industrial motion control is enhanced to utilize arbitrary\nsensors in task definition and execution. Results include an\nextensible task programming language, allowing for flexible\nintegration of sensor motion in established robot languages. Second,\nflexibility of the robot structure itself is studied, with an emphasis\non software tool configuration support for a highly modular parallel\nkinematic robot featuring stiff motions and large workspace. Third,\nseveral operator interaction techniques are evaluted for fast and easy\nrobot setup. Novel interaction devices and use of sensors bring new\nopportunities to improve robot setup procedures. Finally, and also\npointing out future research directions, semantic web techniques are\nexplored for use within automatic generation of user interfaces from\nproduct and process data and for more efficient integration of\noff-line engineering tools in the workflow for online task generation.\n\nThe findings are based on a variety of industrial prototypes and case\nstudies, with novel software solutions ranging from low-level device\ninterfaces to high-level semantic integration. The experienced\nresulting enhancements of flexibility, usability and modularity are\nencouraging.","venue":"","year":2010.0,"referenceCount":118,"citationCount":1,"fieldsOfStudy":["Engineering"],"publicationDate":null,"authors":[{"authorId":"2728155","name":"M. Haage"}]},{"paperId":"015219fd99327e09cc86c2e8ae9f751f48656c1f","title":"Measuring the semantic headedness of English blends with token-based semantic vector space modeling: a corpus-based study","abstract":"\n This article analyzes the semantic headedness of English blends with distributional semantics methods. The semantic head of a blend is the source word that transfers its semantic information to the blend as a whole. For example, a sitcom is a kind of comedy. But is FedEx a kind of express, and is wi-fi a kind of fidelity? We use corpus data and token-based semantic vector space modeling in order to address these questions. Specifically, we investigate whether Plag\u2019s ternary division of endocentric, exocentric, and coordinative compounds based on semantic headedness can also be applied to English blends, and whether the general tendency of semantic right-headedness can be observed for all three subtypes. We analyze a dataset of fifty-five blends and their respective source words, using data from the Corpus of Contemporary American English and the English Web Corpus 2021. We measure the degree of semantic similarity between each blend and its two source words. The results show that for most endocentric blends, the hypothesis of semantic right-headedness holds true. At the same time, exocentric blends and coordinative blends are shown to behave differently. We conclude that Plag\u2019s classification offers a useful point of departure for the semantic analysis of blends and that distributional semantics methods can provide new insights into their semantic behavior.","venue":"Digital Scholarship in the Humanities","year":2024.0,"referenceCount":18,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":"2024-09-16","authors":[{"authorId":"2325568319","name":"Qingnan Meng"},{"authorId":"2325337530","name":"Martin Hilpert"}]},{"paperId":"01546c7ab159698702a6bce237f4ee7cb2832833","title":"Classical dictionary Al-Qamus in lemon","abstract":"In order to enrich the digital content of Classical Arabic, we aim to propose and represent the Arabic dictionary \u201c'Al-Qamiis Al-Muhit\u201d in the standard format LEMON. Printed transition to digital format requires various steps of work. This article describes the procedures that we followed to convert the dictionary in digitized and encoded format to apply automatic extractions and get the Lemon format used in semantic web. Furthermore, due to Arabic dictionary complexity, formalize lexical and semantic information involves morphosyntactic and derivational knowledge that we try to explain.","venue":"Colloquium in Information Science and Technology","year":2016.0,"referenceCount":19,"citationCount":10,"fieldsOfStudy":["Computer Science"],"publicationDate":"2016-10-01","authors":[{"authorId":"3449525","name":"Mustapha Khalfi"},{"authorId":"1697059","name":"Ouafae Nahli"},{"authorId":"3201840","name":"A. Zarghili"}]},{"paperId":"0154b8d8e8a8fe7c753956343eef80e693f30146","title":"Dependently Typed Knowledge Graphs","abstract":"Reasoning over knowledge graphs is traditionally built upon a hierarchy of languages in the Semantic Web Stack. Starting from the Resource Description Framework (RDF) for knowledge graphs, more advanced constructs have been introduced through various syntax extensions to add reasoning capabilities to knowledge graphs. In this paper, we show how standardized semantic web technologies (RDF and its query language SPARQL) can be reproduced in a unified manner with dependent type theory. In addition to providing the basic functionalities of knowledge graphs, dependent types add expressiveness in encoding both entities and queries, explainability in answers to queries through witnesses, and compositionality and automation in the construction of witnesses. Using the Coq proof assistant, we demonstrate how to build and query dependently typed knowledge graphs as a proof of concept for future works in this direction.","venue":"arXiv.org","year":2020.0,"referenceCount":32,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":"2020-03-08","authors":[{"authorId":"2072863482","name":"Zhangsheng Lai"},{"authorId":"1557327062","name":"Aik Beng Ng"},{"authorId":"2258720814","name":"Liang Ze Wong"},{"authorId":"144308998","name":"S. See"},{"authorId":"2115275324","name":"Shaowei Lin"}]},{"paperId":"01559d346a5a0460beec83b21526670381061ab3","title":"Complex Event Processing on Linked Stream Data","abstract":null,"venue":"Datenbank-Spektrum","year":2015.0,"referenceCount":24,"citationCount":11,"fieldsOfStudy":["Computer Science"],"publicationDate":"2015-06-23","authors":[{"authorId":"34884125","name":"Omran Saleh"},{"authorId":"2522511","name":"Stefan Hagedorn"},{"authorId":"1716839","name":"K. Sattler"}]},{"paperId":"0156b98a08340e31d1f348247797fd2332f1c907","title":"Mathematical modeling of the system for assessing students\u2019 assimilation level of the university educational portal material using neural network technolog","abstract":"\u0412 \u0441\u0442\u0430\u0442\u044c\u0435 \u043f\u0440\u043e\u0432\u0435\u0434\u0435\u043d \u0430\u043d\u0430\u043b\u0438\u0437 \u043c\u0435\u0442\u043e\u0434\u0438\u043a \u043e\u0446\u0435\u043d\u043a\u0438 \u044d\u0444\u0444\u0435\u043a\u0442\u0438\u0432\u043d\u043e\u0441\u0442\u0438 \u043e\u0431\u0440\u0430\u0437\u043e\u0432\u0430\u0442\u0435\u043b\u044c\u043d\u044b\u0445 \u043f\u043e\u0440\u0442\u0430\u043b\u043e\u0432 \u0432\u0443\u0437\u043e\u0432. \u0421\u0440\u0435\u0434\u0438 \u0440\u0430\u0441\u0441\u043c\u043e\u0442\u0440\u0435\u043d\u043d\u044b\u0445 \u043c\u0435\u0442\u043e\u0434\u0438\u043a \u0431\u044b\u043b\u0438 \u0432\u044b\u0434\u0435\u043b\u0435\u043d\u044b \u0441\u043b\u0435\u0434\u0443\u044e\u0449\u0438\u0435: \u043e\u0446\u0435\u043d\u043a\u0430 \u0444\u043e\u0440\u043c\u0430\u043b\u044c\u043d\u043e\u0433\u043e \u0441\u043e\u043e\u0442\u0432\u0435\u0442\u0441\u0442\u0432\u0438\u044f \u043e\u0431\u0440\u0430\u0437\u043e\u0432\u0430\u0442\u0435\u043b\u044c\u043d\u044b\u0445 \u043c\u0430\u0442\u0435\u0440\u0438\u0430\u043b\u043e\u0432 \u043d\u043e\u0440\u043c\u0430\u0442\u0438\u0432\u043d\u044b\u043c \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0430\u043c; \u043c\u0435\u0442\u043e\u0434 \u044d\u043a\u0441\u043f\u0435\u0440\u0442\u043d\u044b\u0445 \u043e\u0446\u0435\u043d\u043e\u043a; \u0412\u0435\u0431-\u0430\u043d\u0430\u043b\u0438\u0442\u0438\u0447\u0435\u0441\u043a\u0438\u0439 \u043f\u043e\u0434\u0445\u043e\u0434 \u0441 \u043f\u0440\u0438\u043c\u0435\u043d\u0435\u043d\u0438\u0435\u043c SEO-\u0430\u0443\u0434\u0438\u0442\u0430; \u043a\u043e\u043c\u0431\u0438\u043d\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u044b\u0439 \u043f\u043e\u0434\u0445\u043e\u0434; \u043c\u0435\u0442\u043e\u0434 \u0438\u043d\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u043e\u043d\u043d\u043e-\u0441\u0435\u043c\u0430\u043d\u0442\u0438\u0447\u0435\u0441\u043a\u0438\u0445 \u0441\u0438\u0441\u0442\u0435\u043c ISS \u0438 \u0433\u0440\u0430\u0444\u0438\u0447\u0435\u0441\u043a\u0438\u0439 \u043c\u0435\u0442\u043e\u0434 \u0434\u0438\u0430\u0433\u0440\u0430\u043c\u043c \u042d\u0439\u043b\u0435\u0440\u0430-\u0412\u0435\u043d\u043d\u0430. \u0412 \u0441\u0442\u0430\u0442\u044c\u0435 \u043f\u0440\u0435\u0434\u043b\u043e\u0436\u0435\u043d \u043f\u043e\u0434\u0445\u043e\u0434 \u043a \u043f\u0440\u0435\u0434\u0441\u0442\u0430\u0432\u043b\u0435\u043d\u0438\u044e \u0441\u0442\u0440\u0443\u043a\u0442\u0443\u0440\u044b \u043e\u0431\u0440\u0430\u0437\u043e\u0432\u0430\u0442\u0435\u043b\u044c\u043d\u043e\u0433\u043e \u043f\u043e\u0440\u0442\u0430\u043b\u0430 \u0432\u0443\u0437\u0430 \u0432 \u0432\u0438\u0434\u0435 \u043e\u0440\u0438\u0435\u043d\u0442\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u043e\u0433\u043e \u0433\u0440\u0430\u0444\u0430. \u0412 \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u0435 \u043a\u0440\u0438\u0442\u0435\u0440\u0438\u044f \u044d\u0444\u0444\u0435\u043a\u0442\u0438\u0432\u043d\u043e\u0441\u0442\u0438 \u043e\u0440\u0433\u0430\u043d\u0438\u0437\u0430\u0446\u0438\u0438 \u043e\u0431\u0440\u0430\u0437\u043e\u0432\u0430\u0442\u0435\u043b\u044c\u043d\u043e\u0433\u043e \u043f\u043e\u0440\u0442\u0430\u043b\u0430 \u0432\u0443\u0437\u0430 \u043f\u0440\u0435\u0434\u043b\u043e\u0436\u0435\u043d\u043e \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u044c \u0441\u0443\u043c\u043c\u0430\u0440\u043d\u043e\u0435 \u0432\u0440\u0435\u043c\u044f \u043d\u0430\u0445\u043e\u0436\u0434\u0435\u043d\u0438\u044f \u043e\u0431\u0443\u0447\u0430\u044e\u0449\u0435\u0433\u043e\u0441\u044f \u043d\u0430 \u043a\u0430\u0436\u0434\u043e\u0439 \u0438\u0437 \u0441\u0442\u0440\u0430\u043d\u0438\u0446 \u043e\u0431\u0440\u0430\u0437\u043e\u0432\u0430\u0442\u0435\u043b\u044c\u043d\u043e\u0433\u043e \u043f\u043e\u0440\u0442\u0430\u043b\u0430 \u0437\u0430 \u043e\u0434\u0438\u043d \u0441\u0435\u0430\u043d\u0441 \u0440\u0430\u0431\u043e\u0442\u044b. \u041f\u0440\u0438 \u044d\u0442\u043e\u043c \u0441\u0443\u043c\u043c\u0430\u0440\u043d\u043e\u0435 \u0432\u0440\u0435\u043c\u044f \u043f\u0440\u0435\u0434\u0441\u0442\u0430\u0432\u043b\u0435\u043d\u043e \u0432 \u0432\u0438\u0434\u0435 \u0444\u0443\u043d\u043a\u0446\u0438\u0438 \u043f\u043e\u0441\u043b\u0435\u0434\u043e\u0432\u0430\u0442\u0435\u043b\u044c\u043d\u043e\u0441\u0442\u0438 \u043f\u0440\u043e\u0441\u043c\u043e\u0442\u0440\u0430 \u0441\u0442\u0440\u0430\u043d\u0438\u0446 \u0438 \u0432\u0440\u0435\u043c\u0435\u043d\u0438 \u043f\u0440\u043e\u0441\u043c\u043e\u0442\u0440\u0430 \u043a\u0430\u0436\u0434\u043e\u0439 \u0441\u0442\u0440\u0430\u043d\u0438\u0446\u044b. \u0412 \u0441\u0442\u0430\u0442\u044c\u0435 \u043f\u0440\u0435\u0434\u043b\u043e\u0436\u0435\u043d \u043f\u043e\u0434\u0445\u043e\u0434 \u043a \u043e\u043f\u0440\u0435\u0434\u0435\u043b\u0435\u043d\u0438\u044e \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u0430 \u043f\u043e\u0434\u0430\u0447\u0438 \u043e\u0431\u0440\u0430\u0437\u043e\u0432\u0430\u0442\u0435\u043b\u044c\u043d\u043e\u0439 \u0438\u043d\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u0438 \u0438 \u044d\u0444\u0444\u0435\u043a\u0442\u0438\u0432\u043d\u043e\u0441\u0442\u0438 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f \u0437\u0430 \u0441\u0447\u0435\u0442 \u043e\u0446\u0435\u043d\u043a\u0438 \u0432\u0440\u0435\u043c\u0435\u043d\u0438 \u043f\u0440\u0435\u0431\u044b\u0432\u0430\u043d\u0438\u044f \u0441\u0442\u0443\u0434\u0435\u043d\u0442\u043e\u0432 \u043d\u0430 \u043a\u0430\u0436\u0434\u043e\u0439 \u0438\u0437 \u0441\u0442\u0440\u0430\u043d\u0438\u0446 \u043e\u0431\u0440\u0430\u0437\u043e\u0432\u0430\u0442\u0435\u043b\u044c\u043d\u043e\u0433\u043e \u043f\u043e\u0440\u0442\u0430\u043b\u0430. \u0412 \u0441\u0442\u0430\u0442\u044c\u0435 \u043f\u0440\u0435\u0434\u043b\u043e\u0436\u0435\u043d\u043e \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d\u0438\u0435 \u0438\u0441\u043a\u0443\u0441\u0441\u0442\u0432\u0435\u043d\u043d\u043e\u0439 \u043d\u0435\u0439\u0440\u043e\u043d\u043d\u043e\u0439 \u0441\u0435\u0442\u0438 \u0434\u043b\u044f \u043e\u0431\u0440\u0430\u0431\u043e\u0442\u043a\u0438 \u0434\u0430\u043d\u043d\u044b\u0445 \u043e \u0432\u0440\u0435\u043c\u0435\u043d\u0438 \u043f\u0440\u0435\u0431\u044b\u0432\u0430\u043d\u0438\u0438 \u0441\u0442\u0443\u0434\u0435\u043d\u0442\u043e\u0432 \u043d\u0430 \u043e\u0431\u0440\u0430\u0437\u043e\u0432\u0430\u0442\u0435\u043b\u044c\u043d\u043e\u043c \u043f\u043e\u0440\u0442\u0430\u043b\u0435. \u0412 \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u0435 \u0438\u0441\u043a\u0443\u0441\u0441\u0442\u0432\u0435\u043d\u043d\u043e\u0439 \u043d\u0435\u0439\u0440\u043e\u043d\u043d\u043e\u0439 \u0441\u0435\u0442\u0438 \u0431\u044b\u043b\u0430 \u0432\u044b\u0431\u0440\u0430\u043d\u0430 \u043f\u0440\u044f\u043c\u043e\u043d\u0430\u043f\u0440\u0430\u0432\u043b\u0435\u043d\u043d\u0430\u044f \u0438\u0441\u043a\u0443\u0441\u0441\u0442\u0432\u0435\u043d\u043d\u0430\u044f \u043d\u0435\u0439\u0440\u043e\u043d\u043d\u0430\u044f \u0441\u0435\u0442\u044c \u0441 \u0434\u0432\u0443\u043c\u044f \u0441\u043a\u0440\u044b\u0442\u044b\u043c\u0438 \u0441\u043b\u043e\u044f\u043c\u0438. \u041f\u0440\u0435\u0434\u043b\u043e\u0436\u0435\u043d\u043d\u044b\u0439 \u0432 \u0441\u0442\u0430\u0442\u044c\u0435 \u043f\u043e\u0434\u0445\u043e\u0434 \u0441\u043f\u043e\u0441\u043e\u0431\u0435\u043d \u043d\u0430\u0439\u0442\u0438 \u043f\u0440\u0438\u043c\u0435\u043d\u0435\u043d\u0438\u0435 \u043f\u0440\u0438 \u043e\u0440\u0433\u0430\u043d\u0438\u0437\u0430\u0446\u0438\u0438 \u043a\u0430\u043a \u0438\u043d\u0442\u0435\u0440\u0430\u043a\u0442\u0438\u0432\u043d\u043e\u0433\u043e \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f \u0441 \u043f\u0440\u0438\u043c\u0435\u043d\u0435\u043d\u0438\u0435\u043c \u0441\u0440\u0435\u0434\u0441\u0442\u0432 \u0438\u043d\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u043e\u043d\u043d\u044b\u0445 \u0442\u0435\u0445\u043d\u043e\u043b\u043e\u0433\u0438\u0439, \u0442\u0430\u043a \u0438 \u043f\u0440\u0438 \u0434\u0438\u0441\u0442\u0430\u043d\u0446\u0438\u043e\u043d\u043d\u043e\u043c \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0438.\n The article analyzes the methods of evaluating universities\u2019 educational portals effectiveness. Among the methods considered, the following were identified: assessment of the formal educational materials\u2019 compliance with regulatory documents; the method of expert assessments; a Web-analytical approach using SEO audit; a combined approach; the method of information and semantic systems ISS and the graphical method of Euler-Wien diagrams. The article offers an approach to the representation of the university educational portal structure in the form of an oriented graph. As a criterion for the effectiveness of the university educational portal organization, it is proposed to use the total time spent by a student on each page of the educational portal for one session of work. In this case, the total time is represented as a function of the page views sequence and the viewing time for each page. The article puts forward an approach to determining the quality of educational information presentation and the effectiveness of training by evaluating the time spent by students on each page of the educational portal. The article suggests the application of an artificial neural network in processing data regarding the time of students' stay on the educational portal. A direct-directed artificial neural network with two hidden layers was chosen as an artificial neural network. The approach proposed in the article can be utilized in the organization of both interactive learning using information technology tools and distance learning.","venue":"\u041c\u041e\u0414\u0415\u041b\u0418\u0420\u041e\u0412\u0410\u041d\u0418\u0415, \u041e\u041f\u0422\u0418\u041c\u0418\u0417\u0410\u0426\u0418\u042f \u0418 \u0418\u041d\u0424\u041e\u0420\u041c\u0410\u0426\u0418\u041e\u041d\u041d\u042b\u0415 \u0422\u0415\u0425\u041d\u041e\u041b\u041e\u0413\u0418\u0418","year":2021.0,"referenceCount":3,"citationCount":0,"fieldsOfStudy":null,"publicationDate":"2021-10-20","authors":[{"authorId":"2311552430","name":"\u0422.\u0418. \u041a\u0430\u0441\u0430\u0442\u043a\u0438\u043d\u0430"}]},{"paperId":"015799c496e6d1117f1ff65b90672ecf457a05ee","title":"On the structure of the Common Digital Space of Scientific knowledge ontology","abstract":"The work is a development of the research conducted by the authors in the field of creating a Common Digital Space of Scientific Knowledge (CDSSK). The CDSSK is a digital information structure aggregating heterogeneous polythematic information related to scientific knowledge and including a set of subspaces related to various thematic scientific areas. The sources of the CDSSK content are existing information systems, such as the Great Russian Encyclopedia, the Unified Catalog of Geographical Names, the National Electronic Library, etc. A distinctive features of the CDSSK are (a) data support in a structure that complies with the rules of the semantic WEB, and (b) the ability to process a wide range of polythematic queries and provide the ability to navigate through heterogeneous resources using semantic links between them. The real design of the CDSSK should begin with the formation of the ontology of space as a whole and its individual subspaces. In this paper, a hierarchical structuring of the CDSSK ontology is proposed. Such elements as \"subspace\", \"class of objects\", \"object\", \"attributes of an object\", three types of relations of objects and attributes (universal, quasi-universal and specific) are distinguished and defined. the concepts \"reference books\" and \"dictionaries\" of the CDSSK are introduced. Reference books contain information about attributes and their relationships and are used in the processes of content formation and implementation of search and navigation logic; dictionaries contain specific values of attributes and relationships. The formalization of these elements representations is proposed, which makes it quite simple to add, as necessary, new attributes and relationships between objects.","venue":"Proceedings of 24th Scientific Conference \u201cScientific Services &amp; Internet \u2013 2022\u201d","year":2022.0,"referenceCount":8,"citationCount":3,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"3479699","name":"N. Kalenov"},{"authorId":"153867154","name":"A. Sotnikov"}]},{"paperId":"0158656484323c22cb9a82ad07e658b5cd60cfb0","title":"\u0395\u03be\u03cc\u03c1\u03c5\u03be\u03b7 \u03b8\u03b5\u03bc\u03b1\u03c4\u03b9\u03ba\u03ce\u03bd \u03b1\u03bb\u03c5\u03c3\u03af\u03b4\u03c9\u03bd \u03b1\u03c0\u03cc \u03b9\u03c3\u03c4\u03bf\u03c3\u03b5\u03bb\u03af\u03b4\u03b5\u03c2 \u03b3\u03b9\u03b1 \u03c4\u03b7\u03bd \u03b4\u03b7\u03bc\u03b9\u03bf\u03c5\u03c1\u03b3\u03af\u03b1 \u03b5\u03bd\u03cc\u03c2 \u03b8\u03b5\u03bc\u03b1\u03c4\u03bf\u03bb\u03bf\u03b3\u03b9\u03ba\u03ac \u03c0\u03c1\u03bf\u03c3\u03b1\u03bd\u03b1\u03c4\u03bf\u03bb\u03b9\u03c3\u03bc\u03ad\u03bd\u03bf\u03c5 \u03c0\u03c1\u03bf\u03c3\u03ba\u03bf\u03bc\u03b9\u03c3\u03c4\u03ae","abstract":"Topical focused crawlers are applications that aim at collecting web pages of a specific topic from the Web. Building topical focused crawlers is an open research field. In this master thesis we develop a topical focused crawler using lexical chains. Lexical chains are an important lexical and computational tool which is used for representing the meaning of text. They have been used with success in automatic text summarization and text classification in thematic categories. We present the processes of hyperlink and web page scoring, as well as the computation of the semantic similarity between documents by using lexical chains. Combining the aforementioned methods we embody them in a topical focused crawler. Its results are very promising.","venue":"","year":2005.0,"referenceCount":0,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":"2005-10-11","authors":[{"authorId":"82013414","name":"\u03a0\u03b1\u03cd\u03bb\u03bf\u03c2 \u039a\u03bf\u03ba\u03cc\u03c3\u03b7\u03c2"}]},{"paperId":"0158a90a14fc9e2caa1192be587f066298da4508","title":"Legalo: Revealing the Semantics of Links","abstract":null,"venue":"International Conference Knowledge Engineering and Knowledge Management","year":2014.0,"referenceCount":3,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":"2014-11-24","authors":[{"authorId":"1748453","name":"S. Consoli"},{"authorId":"3198185","name":"Andrea Giovanni Nuzzolese"},{"authorId":"2280600","name":"V. Presutti"},{"authorId":"3349721","name":"D. Recupero"},{"authorId":"2420171","name":"Aldo Gangemi"}]},{"paperId":"0158ff4aba8f1d2323d6252fcdc3b006aa2ec2b5","title":"Award for the Best Poster Presentation Training across national frontiers: mid-term results of the NECOBELAC project","abstract":"The NECOBELAC project (NEtwork of COllaboration Between Europe and Latin American-Caribbean countries, LAC), funded by the EC within the 7th FP and coordinated by the Istituto Superiore di Sanita (Italy), has developed flexible, integrated, modular, and extensible teaching modules on scientific writing and open access publishing. The training methodology is based on a two-level approach (training for trainers and local training) and includes the use of topic maps as an innovative tool based on semantic web technology. The results of one-year training for trainers activity performed in Europe (Italy, Portugal and Spain) and LAC countries (Argentina, Brazil, Colombia Cuba, Mexico and Peru) show how international cooperation can help in developing a sound teaching programme taking into account international quality standards, best practices and cultural differences.","venue":"","year":2011.0,"referenceCount":9,"citationCount":1,"fieldsOfStudy":["Engineering"],"publicationDate":null,"authors":[{"authorId":"51992207","name":"It Istituto Superiore di Sanit"},{"authorId":"143803855","name":"P. Castro"},{"authorId":"49991153","name":"D. Marsili"},{"authorId":"49073455","name":"Federica Napolitani"},{"authorId":"3420272","name":"E. Poltronieri"},{"authorId":"70605298","name":"S. Salinetti"}]},{"paperId":"0159724aacb65df9223b192d79a8b4c14da068a9","title":"Semantic Integration Technonolgies Survey","abstract":"The \\underline{University of Southampton} and \\underline{Hewlett Packard Laboratories at Bristol} are collaborating in a joint project, CROSI, to investigate semantic integration. \\textbf{CROSI}, which stands for Capturing, Representing, and Operationalising Semantic Integration, aims to advance the state-of-the-art for semantic integration technologies. Semantic integration has become a much debated topic in today's research agenda, especially with the advent of the Semantic Web. Its roots, however, go long time back in history of computer science with early attempts to resolve the problem found in the database literature of the eighties. It is concerned with the use of explicit semantic descriptions to facilitate information and systems integration. Due to the widespread importance of integration, many disparate communities have tackled this problem. They have developed a wide variety of overlapping but complementary technologies and approaches. In this deliverable we present a comprehensive survey of the technological landscape in this area. As it is broadly defined and practiced by a number of diverse communities we aim to highlight this diversity. We complement and enhance previously published surveys in this area by focussing on convergence issues and techniques that can be carried over to similar problems. We also aim to identify concrete semantic integration cases which help us to inform a practical set of semantic integration criteria. These could be used to define desiderata for future semantic integration systems.","venue":"","year":2005.0,"referenceCount":0,"citationCount":7,"fieldsOfStudy":["Computer Science"],"publicationDate":"2005-04-01","authors":[{"authorId":"3104575","name":"Y. Kalfoglou"},{"authorId":"144020794","name":"Bo Hu"},{"authorId":"143863726","name":"D. Reynolds"},{"authorId":"1705314","name":"N. Shadbolt"}]},{"paperId":"0159c249de5593a1ffeec3db0ee48f7a3f793c93","title":"Collaborative Ocean Resource Interoperability: Multi-use of Ocean Data on the Semantic Web","abstract":null,"venue":"Extended Semantic Web Conference","year":2009.0,"referenceCount":25,"citationCount":5,"fieldsOfStudy":["Computer Science"],"publicationDate":"2009-05-31","authors":[{"authorId":"145292513","name":"Feng Tao"},{"authorId":"144003250","name":"Jon Campbell"},{"authorId":"88835205","name":"M. Pagnani"},{"authorId":"145583991","name":"G. Griffiths"}]},{"paperId":"015a04182e9c69b459536660eadedf435a4b87b0","title":"Design and Implement of Customer Information Retrieval System Based on Semantic Web","abstract":null,"venue":"International Conference on Intelligent Computing","year":2006.0,"referenceCount":1,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":"2006-08-16","authors":[{"authorId":"46522264","name":"Xinwen Liu"},{"authorId":"2286623863","name":"She-Xiang Ma"},{"authorId":"2286123419","name":"Zailani Abdullah"},{"authorId":"2286141985","name":"Siti Zulaikha Jaafar"},{"authorId":"2286109675","name":"Mustafa Mat"},{"authorId":"1403909112","name":"Amr Ei-Zawawi"},{"authorId":"2135144212","name":"Mohammed Y. Tarnini"}]},{"paperId":"015a7a022dccfc3b88b3548230e388196403b6b9","title":"DAML+OIL: A Reason-able Web Ontology Language","abstract":null,"venue":"International Conference on Extending Database Technology","year":2002.0,"referenceCount":47,"citationCount":184,"fieldsOfStudy":["Computer Science"],"publicationDate":"2002-05-27","authors":[{"authorId":"2257281543","name":"Ian Horrocks"}]},{"paperId":"015bfbd075c60ad9160d764b5b53bf5d14d2316a","title":"Intelligent document management for a paperless hospital pharmacy","abstract":"Background Hospital pharmacists often waste much time in sorting, labelling, storing and searching pharmacy's documentation. Purpose To describe a new software application that reduces the time spent sorting documents out, paper waste and physical space for storage, and also allows a fast and efficient document review and control while contributing to a more sustainable environment. Materials and methods Yerbabuena Software and our hospital pharmacy have been developing a software application based on intelligent document management called \u2018Paperless Hospital Pharmacy\u2019 (PHP) since March 2011. Intelligent document management is the application of semantic technology. This involves three improvements: automatic document classification, Intelligent Character Recognition instead of Optical Character Recognition, and automatic extraction of relevant information from any document. Results The following types of documents were managed through PHP: delivery notes, invoices, standard operating procedures, requests for inclusion of drugs, medical reports, prescriptions, health warnings and drug approvals. PHP allows multiple information inputs: scanner, email, or directly from the application. Therefore there is no need to print or copy the documents, and the authors save time, paper and space. Typed text, barcodes or any other common codes in healthcare are recognised properly. The system automatically assigns tags to the documents and stores them. They can be searched quickly and easily through a web interface. Searches can be performed by the preassigned tags or by any term in the document. Information is always available, and the authors avoid losing it. Duplicated documents can also be filtered and removed. The authors estimate saving 6 h monthly in archiving and also 38 h in searching for documents with a daily average of 80 patients. PHP can also organise the workflow: The authors can review, approve or sign documents collaboratively in a more efficient way. If a parameter is not satisfactory at any stage, the document returns to a previous one to be reviewed. Secure online access to documents throughout the process is guaranteed. Conclusions PHP, presented here, provides an efficient and eco-friendly software for document management to worldwide professional pharmacists.","venue":"","year":2012.0,"referenceCount":0,"citationCount":0,"fieldsOfStudy":["Medicine"],"publicationDate":"2012-03-12","authors":[{"authorId":"2038243652","name":"C. Gonz\u00e1lez-P\u00e9rez"},{"authorId":"46754365","name":"I. Carmona"},{"authorId":"66484705","name":"J. F. Ovi\u00e9s"},{"authorId":"49208346","name":"B. P\u00e9rez"},{"authorId":"2054098404","name":"A. D. P. Prieto"}]},{"paperId":"015c061367e7dd63a3cf14500747a021260b0736","title":"Ontology Based user Adaptive Web Personalization","abstract":"- The fundamental focus of client personalization is to offer revamp associations thought around clients inclination and side interests, likewise considering more important data access. The capacity to change clients distractions can incite colossal appeal things. Longings of customers from web once-over making like never be-fore to get and give inducing results to a given request and changed results.mystery is an unequivocal, formal determination of a demonstrated conceptualization of a space of wind,where formal embraces that the cosmology should be machine-clear and gave that it is seen by a get-together or social occasion. Objectivity changing, in the Semantic Web(sw) setting, is basically concerned with information securing from and for the Web content and to handle the goliath information heterogeneity of the Www.the probability of Cosmology showed in web records, customer can get most crucial and basic results concerning the customers issues. The updates in standard normal soundness tongues is Cosmology Web Vernacular. Owl Dialect makes it conceivable to portray a thought with a full degree and licenses the web records to give persuading results to the client. The proposed framework takes web mission device thought for some obliged space like News Grouping Framework. Appeal of System can be utilized as clear space rationale which is giving an alternate leveled structure to depict the unique examination zone fields in programming outlining, by procedure for this element affiliation cosmology can be made.","venue":"","year":2015.0,"referenceCount":15,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":"2015-06-02","authors":[{"authorId":"72920077","name":"Kiran B. Wagh"},{"authorId":"73764572","name":"Chanbas M. Varde"}]},{"paperId":"015caa7405269e6be1f87695cf37fd998d0311d6","title":"Ideal types of personality and leading communicative value strategies","abstract":"Currently, the world culture is characterized by clustering of the communicative practices and global cultural diffusion. Implementing the personal life strategies, a modern person usually does not associate oneself with ancestral traditions and often demonstrates outstanding results attaining recognition and leadership positions in extraneous and imported spheres. Studying the biographies of famous personalities shows that a significant component participating in the formation of leaders should be recognized as the existence of the value orientation system formed by the notion of \u201cideal personalities\u201d. According to Max Weber, the concept of the ideal type is ancestral; it provides the conditions forming various generic directions. The term \u201cideal type\u201d finds its use in the theoretical constructs of psychologists (types of characters, personality types), sociologists and cultural studies researchers (concepts of a bourgeois, proletarian, intellectual, or \u201craznochinets\u201d). In the realities of modern diffused culture, researchers observe the Western types of ideal personality spreading in the East, and vice versa, such heroes as bodhisattva, sannyasin, and junzi becoming more and more popular along with introducing certain foreign for Europeans rules, codes, regulations, and vows. Deeper analysis of the \u201cideal personality type\u201d allows, along with the notion of \u201csociocultural type\u201d, to introduce the notion of a \u201cbiographical type\u201d. In this paper, we find \u201csociocultural type\u201d in sociology and cultural studies while describing the language of social action (types of a nihilist, cultivated person, intellectual). Respectively, the concept of \u201cbiographical type\u201d is a representation of a certain life-behavior strategy of literary heroes or real idols of the era. The followers of Nietzsche, Voltaire, Werthers, Lenin, Sai Baba, Ole Nidahl represent the biographical types that reveal the mechanisms of typology within the culture in accordance with the ratio of individual and collective fundamentals and determine the nature of the influence of an image on the dialogue of generations. Identifying the important role of the \u201cideal type of personality\u201d in the formation of modern leaders, it is necessary to recognize this theoretical semantic structure as being applicable for solving both theoretical and applied problem. It contains significant potential for explaining, systematizing, understanding, predicting and evaluating communicative value strategies of leadership of the past and present.","venue":"Proceedings of the 3rd International Conference on\u00a0Social, Economic, and Academic Leadership (ICSEAL 2019)","year":2019.0,"referenceCount":17,"citationCount":0,"fieldsOfStudy":["Psychology"],"publicationDate":null,"authors":[{"authorId":"1483736731","name":"A. Alekseev-Apraksin"},{"authorId":"147279225","name":"Liudmila Artamoshkina"}]},{"paperId":"015d2ada17fac75523fe6eb8e66a4a789ee544f3","title":"Ontology Maintenance at Peer-to-Peer Environment Based on Voting and Similarity","abstract":"Internet has constribute great value for data exchange, on other hand, Internet introduced some new issues. Currently, information sources are more massive, distributed, dynamic and open. Diversity is one of focus to overcome in Internet era. Some approaches have been delivered, such as semantic web and Peer-to-Peer (P2P). P2P allows community which common interest to be in a group or cluster (SON - Semantic Overlay Network). The similar interest in SON will reduce the problem of diversity in concept between peers. One of approach in semantic web is by implementation common ontology as reference for information sharing. However, P2P is very dynamic and autonomous, some adjustment of ontology is important to handle this situation. The common ontology in a period will be not satisfy anymore for the community members as reference of interoperability. An approach is needed to handle ontology maintenance in the P2P environment. Our approach is based on social approach in voting to choose the representative members. In other word, common ontology will be adjusted based on peers which represent \u2019appropriate\u2019 information among the cluster members. The method to calculate appropriate peer and maintenance common ontology will based on semantic similarity calculation and weight of peer as sources.","venue":"","year":2006.0,"referenceCount":13,"citationCount":0,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"1959987","name":"L. Y. Banowosari"},{"authorId":"121726240","name":"W. S. Wicaksana"}]},{"paperId":"015db30757c968468d80e79eaee4a91dea13a222","title":"A Domain-Ontology Based Categorization Strategy for Web Pages","abstract":"Proposes a Domain-Ontology based categorization strategy for Web pages. An appropriate ontology warehouse is constructed with ontology description language and Web service technology in the Strategy. Users' requests of categorization precision are mapped to semantic distance and categorization concepts are determined. Associated with Web pages' subjects, Web pages in the domain are categorized. Experiments suggest that the strategy result in better Categorization effects.","venue":"","year":2007.0,"referenceCount":0,"citationCount":1,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"2105569671","name":"Zhang Yi"}]},{"paperId":"0160a05542a4abc17314a5a530e72c26f41ec7ac","title":"Making a Shift from Believing to Knowing by the Help of RDF CFL Formal Representation","abstract":null,"venue":"Lecture Notes in Electrical Engineering","year":2017.0,"referenceCount":2,"citationCount":1,"fieldsOfStudy":["Computer Science"],"publicationDate":"2017-09-27","authors":[{"authorId":"2610869","name":"M. \u017d\u00e1\u010dek"},{"authorId":"2233302","name":"A. Lukasov\u00e1"}]},{"paperId":"01649f27a3bcc33318677e25bf60519e1d113b5d","title":"An Ontology-Based Knowledge Framework for Software Testing","abstract":null,"venue":"","year":2017.0,"referenceCount":25,"citationCount":17,"fieldsOfStudy":["Computer Science"],"publicationDate":"2017-11-17","authors":[{"authorId":"1996978","name":"S. Vasanthapriyan"},{"authorId":"2136089094","name":"Jing Tian"},{"authorId":"2549361","name":"Jianwen Xiang"}]},{"paperId":"0164f2dc93b4edbb6f51a1913172886411786f8a","title":"Semantic Integration of Web-Based Learning Resources: A Topic MapsBased Approach","abstract":"To make an efficient and complete learning activity, many learning repositories have to be accessed by integrating and reusing learning resources. Unfortunately, learning resources are described by using several standards of metadata. In this paper, we propose a semantic representation and integration of Web-based learning resources to enable more efficient accessibility and reusing. We use topic maps to represent learning resources and associated semantics such as metadata. Topic maps is an ISO standard. Using topic maps, it is suitable to assign semantics to Web-based learning resources, given in a common ontology. So, learning resources are able to be effectively processed and reused in many e-learning applications. In this paper, we make a semantic integration of heterogeneous e-learning repositories","venue":"International Conference on Advanced Learning Technologies","year":2006.0,"referenceCount":18,"citationCount":16,"fieldsOfStudy":["Computer Science"],"publicationDate":"2006-07-05","authors":[{"authorId":"1803906","name":"Mourad Ouziri"}]},{"paperId":"0165185b58a0c4fdffaee6b359bc0496bef62285","title":"Improvement of complementary pedagogical resources indexing based on pedagogical warehouse for recommendation system CEHL","abstract":"In recent years, the fast growth of Web pages and the constant evolution of internet technologies have lead to a significant increase in the number of pedagogical resources. Thus, the indexing and search problems have become crucial. To overcome this problem, it was proposed to use information coming from the norms and standards of educational metadata. However, this solution does not solve completely the problem. Previously, traditional information retrieval systems rely on indexing by keywords for representing pedagogical resources and queries content. This process, based on lexical matching, allows selecting pedagogical resources based on keywords shared with the query, which can reduce the accuracy of search results if the meaning of common words in the query and in the pedagogical resources is different. To overcome this issue and provide a more sophisticated search, adding semantics becomes necessary. Semantic Indexing offers a representation by the meaning of words in order to find pedagogical resources semantically relevant to the user request. We present in this paper the choice of the indexing approach used for the complementary educational resources. The main objective is to integrate this approach in the warehouse model that aims on one hand to store the complementary pedagogical resources, and on the other hand to help the user fill in the description fields of these resources.","venue":"2016 Third International Conference on Systems of Collaboration (SysCo)","year":2016.0,"referenceCount":27,"citationCount":2,"fieldsOfStudy":["Computer Science"],"publicationDate":"2016-11-01","authors":[{"authorId":"31001512","name":"Rtili Mohammed Kamal"},{"authorId":"2303178","name":"Khaldi Mohamed"},{"authorId":"39576054","name":"Dahmani Ali"}]},{"paperId":"01653cc968bdafbb419c4fbefab0932c5fc9cc3f","title":"GIVA: a semantic framework for geospatial and temporal data integration, visualization, and analytics","abstract":"The availability of a wide variety of geospatial datasets demands new mechanisms to perform their integrated analysis and visualization. In this demo paper, we describe our semantic framework, GIVA, for Geospatial and temporal data Integration, Visualization, and Analytics. Given a geographic region and a time interval, GIVA addresses the problem of accessing simultaneously several datasets and of establishing mappings between the underlying concepts and instances, using automatic methods. These methods must consider several challenges, such as those that arise from heterogeneous formats, lack of metadata, and multiple spatial and temporal data resolutions. A web interface lets users interact with a map and select datasets to be integrated, displaying as a result reports where values pertaining to different datasets are compared, analyzed, and visualized.","venue":"SIGSPATIAL\/GIS","year":2013.0,"referenceCount":22,"citationCount":22,"fieldsOfStudy":["Computer Science"],"publicationDate":"2013-11-05","authors":[{"authorId":"143682244","name":"I. Cruz"},{"authorId":"145673506","name":"Venkat R. Ganesh"},{"authorId":"2058770","name":"Claudio Caletti"},{"authorId":"47497128","name":"P. Reddy"}]},{"paperId":"0166010aee8c09dc39867d5d295f6a2b340c1adf","title":"Ontology Knowledge Base Scheme for User Query Semantic Interpretation","abstract":"The method of recent information retrieval passes into an semantic search to provide more accurate results than keyword-based search. But in common user case, they are still accustomed to using existing keyword-based search. Hence they are hard to create a typed structured query language. In this paper, we propose to ontology knowledge-base scheme for query interpretation of these user. The proposed scheme was designed based on the OWL-DL for description logic reasoning, it can provide a richer representation of the relationship between the object by using SWRL(Semantic Web Rule Language). Finally, we are describe the experimental results of the similarity measurement for verification of a user query semantic interpretation.","venue":"","year":2013.0,"referenceCount":10,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"13227993","name":"H. Doh"},{"authorId":"2307397","name":"Moo-hun Lee"},{"authorId":"49146414","name":"Hoon Jeong"},{"authorId":"9230819","name":"E. Choi"}]},{"paperId":"01661e162816288b8b11c7302fec6e1571a98dc5","title":"Text, Speech and Dialogue: 11th International Conference TSD2008, Brno, Czech Republic, September 8-11th, 2008","abstract":"This book constitutes the refereed proceedings of the 17th\nInternational Conference on Text, Speech and Dialogue, TSD\n2014, held in Brno, Czech Republic, in September 2014. The 70\npapers presented together with 3 invited papers were carefully\nreviewed and selected from 143 submissions. They focus on\ntopics such as corpora and language resources; speech\nrecognition; tagging, classification and parsing of text and\nspeech; speech and spoken language generation; semantic\nprocessing of text and speech; integrating applications of text\nand speech processing; automatic dialogue systems; as well as\nmultimodal techniques and modelling. The papers present a\nwealth of state-of-the-art research and development results in\nthe field of natural language processing with emphasis on text,\nspeech, and spoken language, ranging from theoretical and\nmethodological issues to applications in various fields, such\nas web information retrieval, the semantic Web, algorithmic\nlearning, dialogue systems, etc.","venue":"","year":2014.0,"referenceCount":0,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":"2014-08-15","authors":[{"authorId":"1980208","name":"Petr Sojka"},{"authorId":"2333943","name":"Ales Horak"},{"authorId":"1830938","name":"I. Kopecek"},{"authorId":"1816601","name":"K. Pala"}]},{"paperId":"01670a145f8c2eecb1b3053d013d162465eb09d2","title":"Algorithmic building blocks for relationship analysis over large graphs","abstract":"Over the last decade, large-scale graph datasets with millions of vertices and edges have emerged in many diverse problem domains. Notable examples include online social networks, the Web graph, or knowledge graphs connecting semantically typed entities. An important problem in this setting lies in the analysis of the relationships between the contained vertices, in order to gain insights into the structure and dynamics of the modeled interactions. In this work, we develop efficient and scalable algorithms for three important problems in relationship analysis and make the following contributions: \u2022 We present the Ferrari index structure to quickly probe a graph for the existence of an (indirect) relationship between two designated query vertices, based on an adaptive compression of the transitive closure of the graph. \u2022 In order to quickly assess the relationship strength for a given pair of vertices as well as computing the corresponding paths, we present the PathSketch index structure for the fast approximation of shortest paths in large graphs. Our work extends a previously proposed prototype in several ways, including efficient index construction, compact index size, and faster query processing. \u2022 We present the Espresso algorithm for characterizing the relationship between two sets of entities in a knowledge graph. This algorithm is based on the identification of important events from the interaction history of the entities of interest. These events are subsequently expanded into coherent subgraphs, corresponding to characteristic topics describing the relationship. We provide extensive experimental evaluations for each of the methods, demonstrating the efficiency of the individual algorithms as well as their usefulness for facilitating effective analysis of relationships in large graphs.","venue":"","year":2015.0,"referenceCount":153,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"1792476","name":"Stephan Seufert"}]},{"paperId":"01673a7a7c182de81339a416bb4a205ef8a96d8f","title":"Towards Lifelong Object Learning by Integrating Situated Robot Perception and Semantic Web Mining","abstract":"Autonomous robots that are to assist humans in their daily lives are required, among other things, to recognize and understand the meaning of task-related objects. However, given an open-ended set of tasks, the set of everyday objects that robots will encounter during their lifetime is not foreseeable. That is, robots have to learn and extend their knowledge about previously unknown objects on-the-job. Our approach automatically acquires parts of this knowledge (e.g., the class of an object and its typical location) in form of ranked hypotheses from the Semantic Web using contextual information extracted from observations and experiences made by robots. Thus, by integrating situated robot perception and Semantic Web mining, robots can continuously extend their object knowledge beyond perceptual models which allows them to reason about task-related objects , e.g., when searching for them, robots can infer the most likely object locations. An evaluation of the integrated system on long-term data from real office observations, demonstrates that generated hypotheses can effectively constrain the meaning of objects. Hence, we believe that the proposed system can be an essential component in a lifelong learning framework which acquires knowledge about objects from real world observations.","venue":"European Conference on Artificial Intelligence","year":2016.0,"referenceCount":23,"citationCount":21,"fieldsOfStudy":["Computer Science"],"publicationDate":"2016-08-29","authors":[{"authorId":"143943688","name":"Jay Young"},{"authorId":"2256420234","name":"Valerio Basile"},{"authorId":"2256420301","name":"Lars Kunze"},{"authorId":"2258028581","name":"Elena Cabrio"},{"authorId":"2256420129","name":"Nick Hawes"}]},{"paperId":"0167fa54502ff948c7de8179d026e35a187d9c4c","title":"Learning query-dependent prefilters for scalable image retrieval","abstract":"We describe an algorithm for similar-image search which is designed to be efficient for extremely large collections of images. For each query, a small response set is selected by a fast prefilter, after which a more accurate ranker may be applied to each image in the response set. We consider a class of prefilters comprising disjunctions of conjunctions (\u201cORs of ANDs\u201d) of Boolean features. AND filters can be implemented efficiently using skipped inverted files, a key component of Web-scale text search engines. These structures permit search in time proportional to the response set size. The prefilters are learned from training examples, and refined at query time to produce an approximately bounded response set. We cast prefiltering as an optimization problem: for each test query, select the OR-of-AND filter which maximizes training-set recall for an adjustable bound on response set size. This may be efficiently implemented by selecting from a large pool of candidate conjunctions of Boolean features using a linear program relaxation. Tests on object class recognition show that this relatively simple filter is nevertheless powerful enough to capture some semantic information.","venue":"2009 IEEE Conference on Computer Vision and Pattern Recognition","year":2009.0,"referenceCount":22,"citationCount":39,"fieldsOfStudy":["Computer Science"],"publicationDate":"2009-06-20","authors":[{"authorId":"1732879","name":"L. Torresani"},{"authorId":"1778989","name":"M. Szummer"},{"authorId":"47139824","name":"A. Fitzgibbon"}]},{"paperId":"0169b779fc5a062865e07716be6cdf32a3ce67b7","title":"Understanding and Explanation: A Transcendental-Pragmatic Perspective","abstract":"The explanation versus understanding debate was important to the philosophy of the social sciences from the time of Dilthey and Weber through the work of Popper and Hempel. In recent years, with the development of interpretive approaches in hermeneutics, phenomenology, and language analysis, the problematic has become absolutely central. The broad literature to which it has given rise, while still split along \"analytic\" versus \"continental\" lines, shows increasing signs of a reunification in philosophy. G. H. von Wright's important book, Explanation and Understanding, originally published in 1971, is a good example of this trend.In Understanding and Explanation, Karl-Otto Apel takes von Wright's work as a point of departure for a rigorous, penetrating analysis of the issues involved. After reviewing the failure of earlier discussions to resolve these issues, Apel develops his own approach in light of the turn from logico-semantic to pragmatic analysis of language in post-Wittgensteinian philosophy. In doing so, he constructs bridges that reach back to themes and positions of the German tradition of the Geisteswissenschaften, but from strikingly new angles.Karl-Otto Apel holds the chair for social philosophy at the University of Frankfurt. His book is included in the series Studies in Contemporary German Social Thought, edited by Thomas McCarthy.","venue":"","year":1984.0,"referenceCount":0,"citationCount":88,"fieldsOfStudy":["Philosophy"],"publicationDate":null,"authors":[{"authorId":"46248066","name":"K. Apel"},{"authorId":"14221652","name":"G. Warnke"}]},{"paperId":"016b4232a1f2918caf3b84f26821ee93dd82acb8","title":"Supporting Ontology-Based Semantic Matching of Web Services in MoviLog","abstract":null,"venue":"IBERAMIA-SBIA","year":2006.0,"referenceCount":24,"citationCount":8,"fieldsOfStudy":["Computer Science"],"publicationDate":"2006-10-23","authors":[{"authorId":"2891834","name":"C. Mateos"},{"authorId":"2406410","name":"M. Crasso"},{"authorId":"1713755","name":"Alejandro Zunino"},{"authorId":"144221988","name":"M. Campo"}]},{"paperId":"016b8c0282720192cb12c00db6df2c1b2d8da024","title":"Using Term-Matching Algorithms for the Annotation of Geo-services","abstract":null,"venue":"Knowledge Discovery Enhanced with Semantic and Social Information","year":2009.0,"referenceCount":13,"citationCount":28,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"1714804","name":"Miha Grcar"},{"authorId":"47210205","name":"E. Klien"},{"authorId":"2372223","name":"B. Novak"}]},{"paperId":"016ced706be2c915a88ce6a59106b36cc380bb05","title":"ForBackBench: From Database to Semantic Web mappings and back","abstract":null,"venue":"International Workshop on the Semantic Web","year":2023.0,"referenceCount":0,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"2189596671","name":"Afnan G. Alhazmi"},{"authorId":"2283060283","name":"Jaime Salas Trejo"},{"authorId":"2282988991","name":"George Konstantinidis"}]},{"paperId":"016d6499c30279f4e4c0b3b108dd0b84214a3131","title":"Interlinking the Social Web with Semantics","abstract":"This paper deals with applying semantic Web technologies to the social Web can lead to a social semantic Web, creating a network of interlinked and semantically rich knowledge. One of the most visible trends on the Web is the emergence of social Web sites, which help people create and gather knowledge by simplifying user contributions via blogs, tagging and folksonomies, wikis, podcasts, and online social networks. The social Web has enabled community-based knowledge acquisition.","venue":"IEEE Intelligent Systems","year":2008.0,"referenceCount":13,"citationCount":125,"fieldsOfStudy":["Computer Science"],"publicationDate":"2008-05-01","authors":[{"authorId":"2395951","name":"Uldis Bojars"},{"authorId":"1707342","name":"J. Breslin"},{"authorId":"1695205","name":"Vassilios Peristeras"},{"authorId":"1700918","name":"G. Tummarello"},{"authorId":"1685642","name":"S. Decker"}]},{"paperId":"016e11526add8404f52aa8216e261e017cf9c756","title":"Semantic Web-Based Integration of Cancer Pathways and Allele Frequency Data","abstract":"We demonstrate the use of Semantic Web technology to integrate the ALFRED allele frequency database and the Starpath pathway resource. The linking of population-specific genotype data with cancer-related pathway data is potentially useful given the growing interest in personalized medicine and the exploitation of pathway knowledge for cancer drug discovery. We model our data using the Web Ontology Language (OWL), drawing upon ideas from existing standard formats BioPAX for pathway data and PML for allele frequency data. We store our data within an Oracle database, using Oracle Semantic Technologies. We then query the data using Oracle's rule-based inference engine and SPARQL-like RDF query language. The ability to perform queries across the domains of population genetics and pathways offers the potential to answer a number of cancer-related research questions. Among the possibilities is the ability to identify genetic variants which are associated with cancer pathways and whose frequency varies significantly between ethnic groups. This sort of information could be useful for designing clinical studies and for providing background data in personalized medicine. It could also assist with the interpretation of genetic analysis results such as those from genome-wide association studies.","venue":"Cancer Informatics","year":2009.0,"referenceCount":60,"citationCount":12,"fieldsOfStudy":["Medicine","Biology"],"publicationDate":"2009-01-01","authors":[{"authorId":"2505299","name":"Matthew Holford"},{"authorId":"1865090","name":"H. Rajeevan"},{"authorId":"145400502","name":"Hongyu Zhao"},{"authorId":"145864773","name":"K. Kidd"},{"authorId":"143896305","name":"K. Cheung"}]},{"paperId":"016e135c60db16000540ff6b34424541fcfde18a","title":"Biometric Acreditation Entities - An Approach for Web Acreditation Services","abstract":"Identity verification is nowadays a crucial task for security applications. In the near future organizations dedicated to store individual biometric information will emerge in order to determine individual identity. Biometric authentication is currently information intensive. The volume and diversity of new data sources challenge current database technologies. Biometric identity heterogeneity arises when different data sources interoperate. New promising application fields such as the Semantic Web and Semantic Web Services can leverage the potential of biometric identity, even though heterogeneity continues rising. Semantic Web Services provide a platform to integrate the lattice of biometric identity data widely distributed both across the Internet and within individual organizations. In this paper, we present a framework for solving biometric identity heterogeneity based on Semantic Web Services. We use a multimodal fusion recognition scenario as a test-bed for evaluation.","venue":"Signal Processing and Multimedia Applications","year":2018.0,"referenceCount":20,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":"2018-08-17","authors":[{"authorId":"1399094390","name":"B. Ru\u00edz-Mezcua"},{"authorId":"31164703","name":"Luis A. Puente"},{"authorId":"1806372","name":"Diego Carrero"},{"authorId":"144122522","name":"M. Poza"}]},{"paperId":"016f3d221fa5dbe4a2d0bfc1f40606c50a656d10","title":"E-Learning Systems Rendering Trustability","abstract":"The World Wide Web is perhaps the most transformative technology which is reshaping business, media, entertainment, and society in many ways. But for all its power, it is just now being tapped to transform education. The web is the enabler to e-Learning, wherein the learners are linked to virtual campuses extracting their knowledge based information from any corner of the World. Rather than fetching the ambiguous data from repository, it is required, that the data be trustable and semantically valid. The growing need for communication, visualization and organization technologies in the field of elearning environments has led to the demand of semantically structured and trustable information. In an efficient functioning of any e-Learning system, the data provenance aspect has to be very closely integrated during the development phase.","venue":"","year":2015.0,"referenceCount":13,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":"2015-11-17","authors":[{"authorId":"2072848008","name":"Amit Kumar Bajpai"},{"authorId":"39192279","name":"R. Pandey"}]},{"paperId":"016f56d93b48ccd163e9b96cc5916b741629af03","title":"Sistema colaborativo de revisi\u00f3n de m\u00e9tricas","abstract":"The notable evolution of Web-based distributed systems and the growing functionality and interoperability between Web applications have allowed users to move from an autonomous to a collaborative work, characterized by collaboration in common, shared tasks. This latter characteristic is the one that is supported by the tool discussed here. Therefore in this paper, design and implementation issues of a Web-based, collaborative metrics discussion system is presented. The system allows adding to an actual semantically structured repository of metrics and indicators, instances of metrics information that has been agreed among quality experts during the revision process. Particularly, aspects of the asynchronous collaborative discussion process and the tool which supports it are analysed thoroughly.","venue":"","year":2006.0,"referenceCount":9,"citationCount":1,"fieldsOfStudy":["Geography"],"publicationDate":"2006-10-01","authors":[{"authorId":"31611417","name":"Luis Antonio Olsina Santos"},{"authorId":"122391473","name":"Mar\u00eda Bel\u00e9n Rivera"},{"authorId":"104759499","name":"Malvina Soledad Baffini"}]},{"paperId":"017152f496bdd597ffc60e0ff74f533290ff8e2d","title":"Interoperability of bioinformatics resources","abstract":"Purpose \u2013 This paper aims to supply an introduction to the bioinformatics discipline for information professionals, outlining how current information management issues are hampering the effective integration and interoperability of resources.Design\/methodology\/approach \u2013 The approach taken is to outline some of the more challenging issues to illustrate their consequences, such as syntactic and semantic heterogeneity, data storage formats and media, and the existence of inconsistencies in information content in bioinformatics resources. A discussion of these topics indicates how semantic web concepts and technologies, together with e\u2010science initiatives, can be used to address these problems.Findings \u2013 The paper reveals that, if one considers the use of semantic web technologies such as XML and ontologies for the development of information standards that allows integration of different information systems, these systems could then be placed into applications such as web services and GRIDS tailored for biol...","venue":"","year":2005.0,"referenceCount":24,"citationCount":4,"fieldsOfStudy":["Computer Science"],"publicationDate":"2005-09-01","authors":[{"authorId":"40662482","name":"H. Vyas"},{"authorId":"46920063","name":"R. Summers"}]},{"paperId":"01729f5a8f24e201ab4c2248fe26b199f84ad7b6","title":"Screen Readers Cannot See: Ontology Based Semantic Annotation for Visually Impaired Web Travellers","abstract":null,"venue":"International Conference on Web Engineering","year":2004.0,"referenceCount":14,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":"2004-07-26","authors":[{"authorId":"1760899","name":"Y. Yesilada"},{"authorId":"2240384938","name":"Simon Harper"},{"authorId":"2288810478","name":"Carole A. Goble"},{"authorId":"143649898","name":"R. Stevens"}]},{"paperId":"0173cb5291928f3cec218e3e381b00b3450502eb","title":"Self-Extending Peer Data Management","abstract":"Peer data management systems (PDMS) are the natural extension of integrated information systems. Conventionally, a single integrating system manages an integrated schema, distributes queries to appropriate sources, and integrates incoming data to a common result. In contrast, a PDMS consists of a set of peers, each of which can play the role of an integrating component. A peer knows about its neighboring peers by mappings, which help to translate queries and transform data. Queries submitted to one peer are answered by data residing at that peer and by data that is reached along paths of mappings through the network of peers. The only restriction for PDMS to cover unbounded data is the need to formulate at least one mapping from some known peer to a new data source. We propose a Semantic Web based method that overcomes this restriction, albeit at a price. As sources are dynamically and automatically included in a PDMS, three factors diminish quality: The new source itself might store data of poor quality, the mapping to the PDMS might be incorrect, and the mapping to the PDMS might be incomplete. To compensate, we propose a quality model to measure this effect, a cost model to restrict query planning to the best paths through the PDMS, and techniques to answer queries in such Webscale PDMS efficiently. 1 An Ever-growing PDMS The step from centralized database systems (DBMS) to distributed and then to federated database systems (FDBMS) removed the assumption that data must be located at the same site as the query. A federated database provides a global schema that represents the data it can access locally and remotely. The global schema is related to the local schemata via schema mappings, which specify how the schema of a local database maps to the global schema. The federated database accepts a query against its global schema and distributes it according to the schema mappings to the different sites where the data resides. Those sites execute the partial queries and send results back to the requesting peer. Again, the schema mappings specify how data is to be translated to conform to the global schema. The results are further processed and combined to be finally fused into a single response to the user. A natural extension to this paradigm is to remove the assumption that queries are only asked against a single integrating site. Peer data management systems (PDMS) are built of multiple peers, each of which provides a schema and accepts queries against the schema. Again, the peers are connected by mappings among their schemata. However, instead of forming a tree with a single root, each peer can be connected to any number of other peers. Queries against a schema of one peer can be answered using the data of the entire PDMS, as long as appropriate mappings have been formed (see Fig. 1). In general, a query","venue":"Datenbanksysteme f\u00fcr Business, Technologie und Web","year":2005.0,"referenceCount":24,"citationCount":27,"fieldsOfStudy":["Computer Science"],"publicationDate":"2005-03-01","authors":[{"authorId":"2263172930","name":"Ralf Heese"},{"authorId":"2799760","name":"Sven Herschel"},{"authorId":"2262880542","name":"Felix Naumann"},{"authorId":"39566845","name":"A. Roth"}]},{"paperId":"0174c25bd07f5a00bd13a69de866b37918feecba","title":"A Structural Benchmark for Logical Argumentation Frameworks","abstract":null,"venue":"International Symposium on Intelligent Data Analysis","year":2017.0,"referenceCount":23,"citationCount":20,"fieldsOfStudy":["Computer Science"],"publicationDate":"2017-10-26","authors":[{"authorId":"37837698","name":"Bruno Yun"},{"authorId":"1754782","name":"Srdjan Vesic"},{"authorId":"1775412","name":"Madalina Croitoru"},{"authorId":"3169503","name":"Pierre Bisquert"},{"authorId":"2579618","name":"R. Thomopoulos"}]},{"paperId":"01795f1799d4af8eaea757a704194ff351bd26ca","title":"A Graph-Based Square Grids Generating Mechanism","abstract":"Graph grammar has been employed as a tool to express formal logic of graph structures. Among different mechanisms, pullback categorical grammars have been proved to be intrinsically context-free. We will show in this paper that this kind of graph grammar can be used for modeling a mechanism which generates square grids and only square grids. With semantics this mechanism will be a good candidate for studying semantic web, or semantic grid.","venue":"International Conference on E-Business and E-Government","year":2010.0,"referenceCount":11,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":"2010-05-07","authors":[{"authorId":"144313209","name":"R. Chen"},{"authorId":"49630348","name":"Nanjie Guo"}]},{"paperId":"017bccd1a5f8e5e1ea11d3314b1bdc926095a33f","title":"Workshop on semantic personalized information management (SPIM'13)","abstract":"The SPIM workshop focuses especially on people that are working on the social or semantic Web, machine learning, user modeling, recommender systems, information retrieval, semantic interaction, or their combination. The goal is to bring together researchers and practitioners to initiating discussions on the different requirements and challenges coming with the social and semantic Web for personalized information retrieval systems. The workshop aims at improving the exchange of ideas between the different research communities and practitioners involved in the research on semantic personalized information management.","venue":"Web Search and Data Mining","year":2013.0,"referenceCount":0,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":"2013-02-04","authors":[{"authorId":"1704885","name":"Till Plumbaum"},{"authorId":"1692708","name":"E. W. D. Luca"},{"authorId":"2420171","name":"Aldo Gangemi"},{"authorId":"1725855","name":"M. Hausenblas"}]},{"paperId":"017c5ac44c0d9322b7200003128e768df9cdab2f","title":"Towards automated web service composition with fluent calculus and domain ontologies","abstract":"Web service composition is mandatory when complex functional requirements cannot be satisfied by a single Web service. Due to the exponential growth of published Web services, the automatic Web service discovery and composition are highly desirable tasks. This paper presents a new approach for automatic Web service composition based on the the formalism of fluent calculus and using semantic service descriptions. In our approach, the Web service composition process is viewed as an AI planning problem in the fluent calculus formalism. To semantically describe the Web services, we have used a domain ontology which is then translated into a fluent calculus knowledge base, necessary for the composition planning phase. For verifying the composed services, the Label Transition System Analyzer (LTSA) formalism is used. We also present an experimental prototype for the fluent calculus based Web service composition and demonstrate its effectiveness with the help of an application scenario from the social event planning domain.","venue":"International Conference on Information Integration and Web-based Applications & Services","year":2008.0,"referenceCount":14,"citationCount":6,"fieldsOfStudy":["Computer Science"],"publicationDate":"2008-11-24","authors":[{"authorId":"1706937","name":"I. Salomie"},{"authorId":"2118172","name":"V. Chifu"},{"authorId":"2085697774","name":"Ioana Harsa"}]},{"paperId":"017cab891ca8f66b27a958d36576046a196e84d9","title":"What ontologies can do for eLearning","abstract":"In this paper, we discuss the role that ontologies, a key element in the Semantic Web vision, can have within eLearning and how they can help improve the learning process. We take the LT4eL project as test case, since in this project ontologies play a crucial role in enhancing the management, distribution and retrieval of the learning material within a Learning Management System (LMS). We also sketch a potential use of ontologies in facilitating social learning.","venue":"","year":2008.0,"referenceCount":41,"citationCount":27,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"1701740","name":"P. Monachesi"},{"authorId":"143964258","name":"K. Simov"},{"authorId":"32722259","name":"Eelco Mossel"},{"authorId":"1710801","name":"P. Osenova"},{"authorId":"2759273","name":"L. Lemnitzer"}]},{"paperId":"017db20b3e889e3da8b85165eb8706d072f9738f","title":"Decision Tree Learner in the Presence of Domain Knowledge","abstract":null,"venue":"China Semantic Web Symposium","year":2014.0,"referenceCount":30,"citationCount":6,"fieldsOfStudy":["Computer Science"],"publicationDate":"2014-08-08","authors":[{"authorId":"2065066843","name":"Jo\u00e3o Vieira"},{"authorId":"143775402","name":"C. Antunes"}]},{"paperId":"017eb2ee76d468a16c1c7aec025af791bb122aa6","title":"Multimedia content and the semantic web: Methods, standards and tools","abstract":null,"venue":"J. Assoc. Inf. Sci. Technol.","year":2007.0,"referenceCount":0,"citationCount":14,"fieldsOfStudy":["Computer Science"],"publicationDate":"2007-02-01","authors":[{"authorId":"9438683","name":"Ashraf M. A. Ahmad"}]},{"paperId":"017f6a17b8ea6a22f599764cdcd08cbe03183f35","title":"Building metadata-based navigation using semantic Web standards: the Dublin Core 2003 Conference Proceedings","abstract":"Summary form only given. One of the touted benefits of the semantic Web is that it will make searches more precise and efficient by leveraging metadata about Web-delivered content. Faceted metadata retrieval is an approach to providing users access to large collections of semistructured data and content that promises an improvement in usability over that available using more traditional search methods. We illustrate how the online proceedings for the 2003 Dublin Core Conference were implemented by combining traditional and innovative knowledge organization techniques. The 2003 Dublin Core Conference Proceedings served as a test-bed for generating a faceted metadata retrieval interface from instance metadata, ontologies, and controlled vocabularies expressed in RDF and RDF Schema. We share lessons learned in the design and implementation of the proceedings, and in particular focus on emerging best practices for representing and sharing metadata using Dublin Core Metadata recommendations, new interpretations of traditional Library and Information Science information retrieval techniques, and implementations of semantic Web standards.","venue":"Proceedings of the 2004 Joint ACM\/IEEE Conference on Digital Libraries, 2004.","year":2004.0,"referenceCount":4,"citationCount":2,"fieldsOfStudy":["Computer Science"],"publicationDate":"2004-06-07","authors":[{"authorId":"39460142","name":"Bradley Paul Allen"},{"authorId":"2958672","name":"Joseph T. Tennis"}]},{"paperId":"0180646eff35d545e37997d77e1f00bd369fdcb1","title":"Introduction to the Applications of Domain Ontology","abstract":"1. Preface Recently, the research on the ontology has been spread widely to be critical components in the knowledge management, Semantic Web, business-to-business applications, and several other application areas. In this article, I would like to introduce some applications of domain ontology presented by my research team in Taiwan, including\u201can ontology-based fuzzy image filter and its application to image processing,\u201d\u201ca fuzzy ontology and its application to news summarization,\u201d\u201ca genetic fuzzy agent using ontology model for meeting scheduling system,\u201d and \u201can ontology-based intelligent healthcare agent and its application to respiratory waveform recognition.\u201d","venue":"","year":2005.0,"referenceCount":12,"citationCount":3,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"2155591290","name":"Chang-Shing Lee"}]},{"paperId":"01818029764f6ebc7ce90ee193d0ef2f2cf7059f","title":"DIGITAL DOCUMENTATION\u2019S ONTOLOGY: CONTEMPORARY DIGITAL REPRESENTATIONS AS EXPRESS AND SHARED MODELS OF REGENERATION AND RESILIENCE IN THE PLATFORM BIM\/CONTAMINATED HYBRID REPRESENTATION","abstract":"Abstract. The study illustrates a university research project of \u201cDigital Documentation\u2019s Ontology\u201d, to be activated with other universities, of an Platform (P) \u2013 Building Information Modeling (BIM) articulated on a Contaminated Hybrid Representation (diversification of graphic models); the latter, able to foresee categories of Multi-Representations that interact with each other for to favour several representations, adapted to a different information density in the digital multi-scale production, is intended as platform (grid of data and information at different scales, semantic structure from web content, data and information storage database, archive, model and form of knowledge and ontological representation shared) of: inclusive digital ecosystem development; digital regenerative synergies of representation with adaptable and resilient content in hybrid or semi-hybrid Cloud environments; phenomenological reading of the changing complexity of environmental reality; hub solution of knowledge and simulcast description of information of Cultural Heritage (CH); multimedia itineraries to enhance participatory and attractive processes for the community; factor of cohesion and sociality, an engine of local development. The methodology of P-BIM\/CHR is articulated on the following ontologies: Interpretative and Codification, Morphology, Lexicon, Syntax, Metamorphosis, Metadata in the participatory system, Regeneration, Interaction and Sharing. From the point of view the results and conclusion the study allowed to highlight: a) Digital Regenerative synergies of representation; b) Smart CH Model for an interconnection of systems and services within a complex set of relationships.\n","venue":"The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences","year":2021.0,"referenceCount":0,"citationCount":0,"fieldsOfStudy":null,"publicationDate":"2021-08-28","authors":[{"authorId":"2059014111","name":"A. De Masi"}]},{"paperId":"01825e476a248dd0a7a27aeaa8a1bc520d01a528","title":"Developments in Polar Data Management 2006 \u2013 2019 and Beyond: standardization and community-building in support of enhanced interoperability","abstract":"\n <p>A consortium of polar data coordinating bodies has recently hosted a number of useful workshops and events to foster collaboration between individuals, institutions, projects and organizations. These events have built on polar data coordination efforts including progress made during the International Polar Year, focused workshops in 2016, 17, and 18, and three Polar Data Forum meetings (2013,15,19). &#160;<\/p><p>&#160;<\/p><p>These and other activities have identified a need for continued community development and detailed technical collaboration in order to advance Polar Data Management. Technical activity has centred on achieving federated search through the exchange of standardised, well formatted discovery metadata. This is an important first step towards an interconnected polar data system and important gaps and mitigation have been identified at the levels of standardisation, exchange protocols, and eventually semantic annotation of datasets.<\/p><p>&#160;<\/p><p>These activities have been and will continue to be organized by a group of coordination bodies including the IASC-SAON Arctic Data Committee, the Southern Ocean Observing System, Standing Committee on Antarctic Data Management, GEO Cold Regions Initiative, Polar View, Arctic Portal, ELOKA, Canadian Consortium on Arctic Data Interoperability, U.S. Inter-agency Arctic Research Policy Committee Arctic Data Sub-Team, and the WMO Global Cryosphere Watch.<\/p><p>&#160;<\/p><p>As a contribution to these international efforts, in January 2020, the European Union Horizon 2020 project CAPARDUS was established as a coordination and support action with the objective to establish a comprehensive framework for development, understanding and implementation of Arctic standards with focus on environmental topics and related data. The framework will integrate standards used by communities active in the Arctic and polar regions including research and services, Indigenous and local communities, commercial operators and governance bodies. Development of standards is important for many technologies and services (e.g. federated search) that can bring broad social and economic benefits within and beyond the Arctic region.<\/p><p>&#160;<\/p><p>In this presentation we first provide a synthesis of more than a decade and a half of activity and development in polar data management and interoperable data sharing.&#160; Results from this analysis reveal two primary areas of successful developments: i) social and organizational including data policy, building working relationships, and funding cyberinfrastructure ; ii) technical developments in federated search, semantic interoperability, and use of web services.&#160; Patterns, advancements and development gaps are identified and discussed.&#160; Secondly, we present an overview of the first quarter of activity under the CAPARDUS project, including a preliminary model aimed and enhancing appropriate levels of standardization in the polar data community.<\/p>\n","venue":"","year":2020.0,"referenceCount":0,"citationCount":0,"fieldsOfStudy":null,"publicationDate":"2020-03-23","authors":[{"authorId":"1831307","name":"P. Pulsifer"},{"authorId":"13215871","name":"Sandra G. McCubbin"},{"authorId":"2562423","name":"S. Sandven"},{"authorId":"46620052","name":"M. Parsons"}]},{"paperId":"01828f4160963788fea9e106348e1cac1ec6bda7","title":"A Knowledge-based Security Policy Framework for Business Process Management","abstract":"Business process management (BPM) is often a key component of the business change. Business rules, whether embedded within BPM or on their own, have begun playing an ever-increasing role of prominence in process-centric business and system strategies. Service-oriented architecture (SOA) is used to support the business processes and a novel approach to share service knowledge and application- specific information is needed. In this paper, we model web service policy with corporate knowledge, which is defined as the amount of knowledge provided by individual agents. The proposal builds upon the project AKT's work in defining a semantic Web constraint interchange format (CIF), which itself builds on the proposed semantic Web rule language (SWRL). The main contribution include also a new ontology for representing security constraints as policy and a knowledge management method to our proposed knowledge-based policy framework; we also show the possibility to integrate the business rules into policy specification by means of converting them into constraint satisfaction problem (CSP) using CIF.","venue":"International Conference on Computational Intelligence for Modelling, Control and Automation","year":2006.0,"referenceCount":29,"citationCount":6,"fieldsOfStudy":["Computer Science"],"publicationDate":"2006-11-28","authors":[{"authorId":"2110190381","name":"Dong Huang"},{"authorId":"2143685856","name":"Yi Yang"},{"authorId":"144416892","name":"J. Calmet"}]},{"paperId":"0182dd1b8aff47812289eb1ec53b4d1e4c6a3c10","title":"Applied logic and semantics on indoor and urban adaptive design through knowledge graphs, reasoning and explainable argumentation","abstract":"\n In the previous two decades, knowledge graphs (KGs) have evolved significantly, inspiring developers to build ever-more context-related KGs. Due to this development, artificial intelligence (AI) applications can now access open domain-specific information in a format that is both semantically rich and machine comprehensible. In this article, a framework that depicts functional design for indoor workspaces and urban adaptive design, in order to help architects, artists, and interior designers for the design and construction of an urban or indoor workspace, based on the emotions of human individuals, is introduced. For the creation of online adaptive environments, the framework may incorporate emotional, physiological, visual, and textual measures. Additionally, an information retrieval mechanism that extracts critical information from the framework in order to assist the architects, artists, and the interior designers is presented. The framework provides access to commonsense knowledge about the (re-)design of an urban area and an indoor workspace, by suggesting objects that need to be placed, and other modifications that can be applied to the location, in order to achieve positive emotions. The emotions referred reflect to the emotions experienced by an individual when being in the indoor or urban area, which are pointers for the functionality, the memorability, and the admiration of the location. The framework also performs semantic matching between entities from the web KG ConceptNet, using semantic knowledge from ConceptNet and WordNet, with the ones existing in the KG of the framework. The paper provides a set of predefined SPARQL templates that specifically handle the ontology upon which the knowledge retrieval system is based. The framework has an additional argumentation function that allows users to challenge the knowledge retrieval component findings. In the event that the user prevails in the reasoning, the framework will learn new knowledge.","venue":"Knowledge engineering review (Print)","year":2024.0,"referenceCount":22,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"98847197","name":"E. Stathopoulos"},{"authorId":"1471858890","name":"Alexandros Vassiliades"},{"authorId":"145962512","name":"S. Diplaris"},{"authorId":"3019137","name":"S. Vrochidis"},{"authorId":"1715604","name":"Y. Kompatsiaris"}]},{"paperId":"0182fb3c417f0c8685b0a755782bf9a03ea7f5d8","title":"Semantic Web: Who is who in the field \u2014 a bibliometric analysis","abstract":"The Semantic Web (SW) is one of the main efforts aiming to enhance human and machine interaction by representing data in an understandable way for machines to mediate data and services. It is a fast-moving and multidisciplinary field. This study conducts a thorough bibliometric analysis of the field by collecting data from Web of Science (WOS) and Scopus for the period of 1960\u20142009. It utilizes a total of 44,157 papers with 651,673 citations from Scopus, and 22,951 papers with 571,911 citations from WOS. Based on these papers and citations, it evaluates the research performance of the SW by identifying the most productive players, major scholarly communication media, highly cited authors, influential papers and emerging stars.","venue":"Journal of information science","year":2010.0,"referenceCount":58,"citationCount":24,"fieldsOfStudy":["Computer Science"],"publicationDate":"2010-06-01","authors":[{"authorId":"144481316","name":"Ying Ding"}]},{"paperId":"01832c070d9a185787464227c8cef1162a6f9440","title":"Semantic Recognition of Web Structure to Retrieve Relevant Documents from Google by Formulating Index Term","abstract":null,"venue":"Advances in Intelligent Systems and Computing","year":2019.0,"referenceCount":17,"citationCount":5,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"33073495","name":"Jinat Ara"},{"authorId":"2985748","name":"Hanif Bhuiyan"}]},{"paperId":"0183704e22d1c7e595d119013c994e5374c14a68","title":"Semantically enhanced sequential patterns for content adaptation on the web","abstract":"\u2014Content adaptation on the Web is aimed at reducing the total amount of information served by a site or application to the items matching the needs\/preferences\/tastes of a speci\ufb01c user. As a major trend thereof, recommender systems typically rely on the computation of a relevance score for content object to the anticipated user\u2019s needs. Using the navigation patterns for a user or a group of users as a support for the relevance guess is a classical approach to recommendation that breaks down to discovering, or mining, associations among content objects based on the way these are navigated through. As feeding domain knowledge into the mining process has proven to both increase the precision of these associations and ease their interpretation, we consider the \"extreme\" case, i.e., the availability of a full-scale domain ontology whose concepts and properties characterize the content objects and their relationships. We thus tackle the problem of frequent pattern extraction from sequences of content objects corresponding to user sessions, which are further described within a domain ontology. Here we de\ufb01ne a theoretical framework for the resolution of the mining task which comprises a pair of languages for data and pattern description, respectively, and a hierarchically-organized pattern space split into levels. The latter underlies an Apriori -like level-wise method for frequent pattern generation and evaluation.","venue":"","year":2006.0,"referenceCount":24,"citationCount":0,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"34651759","name":"Mehdi Adda"},{"authorId":"1736490","name":"Petko Valtchev"},{"authorId":"1735147","name":"R. Missaoui"},{"authorId":"1705776","name":"C. Djeraba"}]},{"paperId":"0183f3fba6acb86676d4fffd85410bac5e0d7b9d","title":"Main Content Detection in HTML Journal Articles","abstract":"Web content extraction algorithms have been shown to improve the performance of web content analysis tasks. This is because noisy web page content, such as advertisements and navigation links, can significantly degrade performance. This paper presents a novel and effective layout analysis algorithm for main content detection in HTML journal articles. The algorithm first segments a web page based on rendered line breaks, then based on its column structure, and finally identifies the column that contains the most paragraph text. On a test set of 359 manually labeled HTML journal articles, the proposed layout analysis algorithm was found to significantly outperform an alternative semantic markup algorithm based on HTML 5 semantic tags. The precision, recall, and F-score of the layout analysis algorithm were measured to be 0.96, 0.99, and 0.98 respectively.","venue":"ACM Symposium on Document Engineering","year":2018.0,"referenceCount":7,"citationCount":1,"fieldsOfStudy":["Computer Science"],"publicationDate":"2018-08-28","authors":[{"authorId":"153410529","name":"Alastair R. Rae"},{"authorId":"88581765","name":"Jongwoo Kim"},{"authorId":"1939973","name":"D. Le"},{"authorId":"145116486","name":"G. Thoma"}]},{"paperId":"0185a9c6405d0db96fde66c7c4752e280042a5ab","title":"Ontologies : Mappings and Translation The Theory of Top-Level Ontological Mappings and Its Application to Clinical Trial Protocols","abstract":"In this paper, we present a Notification Agent designed and implemented using Semantic Web Services. The Notification Agent manages alerts when critical financial situations arise discovering and selecting multichannel notification services. This agent applies open research results on the Semantic Web Services technologies including on-the-fly composition based on a finite state machine and automatic discovery of semantic services. Financial Domain ontologies, based on IFX financial standard, have been constructed and extended for building agent systems using OWL and OWL-S standard (as well as other approaches like DL or f-Logic). This agent is going to be offered through integrated Online Aggregation systems in commercial financial organizations.","venue":"","year":2006.0,"referenceCount":8,"citationCount":0,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"2322662649","name":"Enrico Motta Nigel Shadbolt"},{"authorId":"2322662607","name":"Arthur Stutt Nick Gibbins"}]},{"paperId":"0185b27163471c42f7df1a72fe029c13939beff9","title":"Towards a New Generation of Language Resources in the Semantic Web Vision","abstract":null,"venue":"","year":2007.0,"referenceCount":43,"citationCount":6,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"1707466","name":"N. Calzolari"}]},{"paperId":"0185d1034d5959e7fa485daebb815c80aba1871c","title":"Heron VE \u2013visualisation and dissemination of semantic cultural heritage data","abstract":"Over the past two decades, there has been a proliferation of software to create great 3D- models of archaeological sites and objects, and there has been plenty of thought and discussion on data models for finds. The results of those exertions have been made public through institutional websites and specific portals, but now, a further step is necessary: the cultural heritage data and (meta)data need to be taken into the semantic web. The \u201cHeritage Online Visualisation Engine\u201d (further: HeronVE) was born to do this. It provides tools for documenting, visualising and disseminating the semantic relations between sites, objects, documentation and narratives. Heron VE is scalable: it can be used to tell the story of a particular archaeological complex, but it can also illustrate relations between sites and objects which are widely separated in both time and space. With Heron VE, dissemination of (meta)data can take many different forms: Heron VE contains modules for presenting and reporting on data, but it can also be used to provide data only, for example in several XML-formats or in N-triples. The designer of Heron VE has 25 years of experience with cultural heritage data in the field of archaeology, in museums and in libraries. During those 25 years, he has also been working on the structured dissemination of cultural heritage data, first in the semantic web and now within the framework of linked data. The paper will illustrate the journey towards Heron VE, including considerations regarding the adoption, adaptation or rejection of existing data models and ontologies. It will also contain examples. These will mainly be based on data regarding (sites of former) castles and stately homes in the Netherlands, but it will become very clear that the Heron VE can be applied to many different culture heritage datasets, including those regarding ancient urban areas.","venue":"","year":2016.0,"referenceCount":0,"citationCount":0,"fieldsOfStudy":["Geography"],"publicationDate":"2016-11-26","authors":[{"authorId":"82394639","name":"M. V. D. Kaaij"}]},{"paperId":"0186a3afc40aeb811fd361a455ab49eb5fa44655","title":"Bridging the Paradigm Gap with Rules for OWL","abstract":"Accelerated by the vision of the semantic web, semantic technologies have recently made significant advances. The underlying methods and paradigms are already being transferred to adjacent areas of research in artificial intelligence, knowledge management, and elsewhere. Textbooks explaining the foundations have appeared. Large national and international projects on the topic are under way. The technology received a crucial impulse when the Web Ontology Language OWL became a W3C recommendation in 2004. It is already being perceived as a basic knowledge representation language with potential which goes far beyond the semantic web use case. At the same time, it is apparent that OWL needs to be extended with additional expressive features in order to become applicable and useful in many domains. Corresponding efforts are being pursued with frenzy by research institutions and industry. These efforts are being aided substantially by the fact that OWL is based on sound logical foundations as it can be understood as a well-understood decidable albeit very expressive fragment of first order logic. The need for an extension of OWL by rules has been known since the beginning. Indeed, the rule-based ontology representation language F-Logic [6, 1] is being used widely where a rule-based approach appears to be more feasible. As an example, we mention the HALO project1 by Vulcan Inc.2 whose ultimate goal is the creation of a \u201cdigital Aristotle\u201d, an expert tutor in a wide variety of subjects, with deep reasoning abilities. The initial","venue":"Rule Languages for Interoperability","year":2005.0,"referenceCount":9,"citationCount":13,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"1699771","name":"P. Hitzler"},{"authorId":"1680928","name":"J. Angele"},{"authorId":"1703160","name":"B. Motik"},{"authorId":"144446653","name":"R. Studer"}]},{"paperId":"0186f0410dd8e467276eeee5de964c91083a249a","title":"Knowledge Sharing by Information Retrieval in the Semantic Web","abstract":null,"venue":"Extended Semantic Web Conference","year":2005.0,"referenceCount":16,"citationCount":17,"fieldsOfStudy":["Computer Science"],"publicationDate":"2005-05-29","authors":[{"authorId":"1885547","name":"Neyir Sevilmis"},{"authorId":"144630278","name":"A. Stork"},{"authorId":"1716062","name":"T. Smithers"},{"authorId":"144690602","name":"Jorge Posada"},{"authorId":"1933592","name":"M. Pianciamore"},{"authorId":"2053182120","name":"Rui Castro"},{"authorId":"144781738","name":"I. Jimenez"},{"authorId":"40202921","name":"G. Marcos"},{"authorId":"2066554135","name":"M. Mauri"},{"authorId":"1892811","name":"Paolo Selvini"},{"authorId":"153574851","name":"B. Thelen"},{"authorId":"1888227","name":"Vincenzo Zecchino"}]},{"paperId":"01871654e0abb7276db78f600fede497cf35994f","title":"Web Page Classification Method Based on Semantics and Structure","abstract":"Network information has got explosive growth on because of the rapid development of Internet technology. Web page classification technology can solve the problem of information clutter to a large extent, which is widely used in search engines, digital libraries and information retrieval. Web page classification is different from text classification, because web page is a kind of semi-structured data that not only contains text semantic information, but also has rich structural information. This paper analyzes and utilizes the structural characteristics of web pages. Thus, we propose a web page classification method focused on semantics and structure joint features, and train on top of convolution neural networks model. The results show that using joint features of structure and semantics information plays an important role in classification accuracy, which has increased F1 value of web page classification by 4%-6%.","venue":"2019 2nd International Conference on Artificial Intelligence and Big Data (ICAIBD)","year":2019.0,"referenceCount":10,"citationCount":7,"fieldsOfStudy":["Computer Science"],"publicationDate":"2019-05-01","authors":[{"authorId":"2109030832","name":"Huaxin Li"},{"authorId":"1764064","name":"Zhaoxin Zhang"},{"authorId":"47103367","name":"Yongdong Xu"}]},{"paperId":"0187a09b39f593a67d3df43ba072c760b30641f4","title":"Knowledge Technologies for the Social Semantic Desktop","abstract":null,"venue":"Knowledge Science, Engineering and Management","year":2007.0,"referenceCount":9,"citationCount":14,"fieldsOfStudy":["Computer Science"],"publicationDate":"2007-11-28","authors":[{"authorId":"145279674","name":"A. Dengel"}]},{"paperId":"01885bb4a87e8e776b1604db82627265900b880a","title":"Multidimensional ontology-based visual ranking","abstract":"Evangelia Triperina obtained her PhD in Computer Sciences from the University of Limoges, France in 2020. Her thesis focuses on the interdisciplinary research in multidimensional decisions support in the ranking problematic aided by visual analytics and semantic web technologies. Interactive visual analytics exploit the increased visual perceptual abilities of the decision makers creating a more efficient decision support procedure, while semantic web technologies, and more specifically ontologies, structure data, make the system dynamic and add several needed capabilities to the decision support system. Furthermore, the multidimensional decision support method relies not only on evaluating an alternative based on multiple criteria, but also on important dimensions of the domain1.","venue":"SIGWEB Newsl.","year":2020.0,"referenceCount":7,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":"2020-07-27","authors":[{"authorId":"1847682","name":"Evangelia Triperina"}]},{"paperId":"01896ea75dc208672860d86268a62382ae061425","title":"Semiometrics: Applying Ontologies across Large-Scale Digital Libraries","abstract":"As large-scale digital libraries become more available and complete, not to mention more numerous, it is clear there is a need for services that can draw together and perform inference calculations on the metadata produced. However, the traditional Relational Database Management System (RDBMS) model, while efficiently constructed and optimised for many business structures, does not necessarily cope well with issues of concurrent data updates and retrieval at the scale of hundreds of thousands of papers. At the same time the growth of RDF and the increasing interest in Semantic Web technologies perhaps begins to present a viable alternative at a scalable, practical level. This paper considers a specific application of large-scale metadata analysis and conducts scalability tests using real-world data. It concludes that RDF technologies are both a scalable and performance-realistic alternative to traditional RDBMS approaches. It also shows that for relationship-based queries on large-scale metadata stores, RDF technologies can significantly out-perform traditional RDBMS approaches by allowing both retrieval and updating of data in a timely manner.","venue":"","year":2006.0,"referenceCount":8,"citationCount":1,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"1403819148","name":"D. McRae-Spencer"},{"authorId":"1705314","name":"N. Shadbolt"}]},{"paperId":"018bb88e299b09c2943d2939208dd6e1cca5ab5b","title":"Creating and Managing Ontology Data on the Web: A Semantic Wiki Approach","abstract":null,"venue":"WISE","year":2007.0,"referenceCount":22,"citationCount":5,"fieldsOfStudy":["Computer Science"],"publicationDate":"2007-12-03","authors":[{"authorId":"1722340","name":"Chao Wang"},{"authorId":"144864069","name":"Jie Lu"},{"authorId":"46266495","name":"Guangquan Zhang"},{"authorId":"35974492","name":"Xianyi Zeng"}]},{"paperId":"018c66f6f4d31599ef96d71a315784bc454b6ab1","title":"Comparison of reasoners for large ontologies in the OWL 2 EL profile","abstract":"This paper provides a survey to and a comparison of state-of-the-art Semantic Web reasoners that succeed in classifying large ontologies expressed in the tractable OWL 2 EL profile. Reasoners are characterized along several dimensions: The first dimension comprises underlying reasoning characteristics, such as the employed reasoning method and its correctness as well as the expressivity and worst-case computational complexity of its supported language and whether the reasoner supports incremental classification, rules, justifications for inconsistent concepts and ABox reasoning tasks. The second dimension is practical usability: whether the reasoner implements the OWL API and can be used via OWLlink, whether it is available as Protege plugin, on which platforms it runs, whether its source is open or closed and which license it comes with. The last dimension contains performance indicators that can be evaluated empirically, such as classification, concept satisfiability, subsumption checking and consistency checking performance as well as required heap space and practical correctness, which is determined by comparing the computed concept hierarchies with each other. For the very large ontology SNOMED CT, which is released both in stated and inferred form, we test whether the computed concept hierarchies are correct by comparing them to the inferred form of the official distribution. The reasoners are categorized along the defined characteristics and benchmarked against well-known biomedical ontologies. The main conclusion from this study is that reasoners vary significantly with regard to all included characteristics, and therefore a critical assessment and evaluation of requirements is needed before selecting a reasoner for a real-life application.","venue":"Semantic Web","year":2011.0,"referenceCount":62,"citationCount":232,"fieldsOfStudy":["Computer Science"],"publicationDate":"2011-04-01","authors":[{"authorId":"3295328","name":"Kathrin Dentler"},{"authorId":"3018242","name":"R. Cornet"},{"authorId":"145520593","name":"A. T. Teije"},{"authorId":"8086898","name":"N. D. Keizer"}]},{"paperId":"018dc133fcb95190aebc5b7b21888560f0b6143e","title":"Proceedings of the Second Workshop on Services and Applications over Linked APIs and Data co-located with the 10th Extended Semantic Web Conference (ESWC 2014), Crete, Greece, May 26, 2014","abstract":null,"venue":"SALAD@ESWC","year":2014.0,"referenceCount":0,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[]},{"paperId":"018ef9e3abaec6bfb8094d99b55d31fadcf74d24","title":"Interaction with Objects and Objects Annotation in the Semantic Web of Things","abstract":"This paper presents a model and an infrastructure for technology enhanced learning applications and discusses issues in using Semantic Web, Linked Data, and Internet of Things. In particular, we apply the novel paradigm of the Semantic Web of Things to enhance information management and users\u2019 experience in a setup borrowed from a previous work, which exploits contactless technologies in a museum exhibition to enable visitors to interact with the artworks exposed and receive relevant information. According to the Linked Data principles, the content delivery system has been empowered by introducing suited semantic annotations to the objects. This enables \u201cthings\u201d in the real world to be linked to their corresponding software images in the Web of Data and, in turn, it enables users to discover new facts about the objects and the available knowledge about them. Moreover, the enrichment of the real world objects with education-oriented annotations, which specify how to use the sensorized objects in educational activities, makes possible to match the objects features with learning tasks and users characteristics, thus providing personalized services and improving the learning experience. Keywords-technology enhanced learning; semantic web; linked open data; Internet of things.","venue":"Distributed Multimedia Systems","year":2014.0,"referenceCount":39,"citationCount":2,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"2304592","name":"M. Coccoli"},{"authorId":"144317088","name":"Ilaria Torre"}]},{"paperId":"01908a61153141bf803852c618b4c969d635462a","title":"URSW 2014 - proceedings of the 10th International Workshop on Uncertainty reasoning for the Semantic Web","abstract":null,"venue":"","year":2014.0,"referenceCount":0,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"1704173","name":"Fernando Bobillo"},{"authorId":"32535366","name":"Rommel N. Carvalho"},{"authorId":"2776924","name":"D. Ceolin"},{"authorId":"145919468","name":"P. Costa"},{"authorId":"8315951","name":"Claudia d\u2019Amato"},{"authorId":"1743194","name":"N. Fanizzi"},{"authorId":"145071427","name":"Kathryn B. Laskey"},{"authorId":"35306638","name":"K. Laskey"},{"authorId":"1690572","name":"Thomas Lukasiewicz"},{"authorId":"39801345","name":"T. Martin"},{"authorId":"1772443","name":"Matthias Nickles"},{"authorId":"145643278","name":"Michael Pool"},{"authorId":"1684481","name":"T. D. Nies"},{"authorId":"1699014","name":"O. Hartig"},{"authorId":"1727784","name":"Paul T. Groth"},{"authorId":"144513831","name":"S. Marsh"}]},{"paperId":"0190d5a707cece7aa18748ddc6f813b350420121","title":"Name Disambiguation Using Semantic Association Clustering","abstract":"Due to homonyms, abbreviations, etc., name ambiguity is widely available in web and e-document. For example, when integrating heterogeneous literature databases, because there are different name specifications, different authors may be thought of as the same author, and vice versa. Therefore, name ambiguity makes data robust even dirty and lowers the precision of information retrieval. In this paper, we present an approach, named as Semantic Association based Name Disambiguation method (SAND), to solve person name ambiguity. The basic idea of SAND is to explore the semantic association of name entities and cluster name entities according to their associations. Finally, the name entities in the same group are considered as the same entities. We test SAND using data from CitesSeer, DBLP and Libra. The test results show that SAND is an effective approach to solve the problem of name ambiguity.","venue":"IEEE International Conference on e-Business Engineering","year":2009.0,"referenceCount":19,"citationCount":12,"fieldsOfStudy":["Computer Science"],"publicationDate":"2009-10-21","authors":[{"authorId":"145914256","name":"Hai Jin"},{"authorId":"2143702034","name":"Li Huang"},{"authorId":"2881771","name":"Pingpeng Yuan"}]},{"paperId":"01920ad9b566ee163ce0b6916d1bffec74b2dbbc","title":"\u041c\u0438\u0440 \u044d\u043a\u043e\u043d\u043e\u043c\u0438\u0447\u0435\u0441\u043a\u043e\u0433\u043e: \u043a\u0440\u0430\u0442\u043a\u0438\u0439 \u043e\u0447\u0435\u0440\u043a \u0438\u0441\u0442\u043e\u0440\u0438\u0438 \u0444\u0438\u043b\u043e\u0441\u043e\u0444\u0441\u043a\u043e\u0439 \u043a\u043e\u043d\u0446\u0435\u043f\u0442\u0443\u0430\u043b\u0438\u0437\u0430\u0446\u0438\u0438","abstract":"My second article on philosophy of economics is a brief outline of historical and contemporary teachings in economic ontology, economic anthropology and axiology of economic activity. For my research purposes, I use ontological, axiological, social-philosophical, historical, semantic and comparative analysis in the framework of civilizational approach. In my article, I consider some of the most important pictures of the worlds of the economy that include its religious (Old and New Testaments) and regulatory (Xenophon) ones, world of pseudo-economy (Aristotle), extra-moral (Mandeville), ideal (Comte de Saint-Simon), social (Marx, Engels), spiritual (Weber, Sergey Bulgakov) and symbolic (Baudrillard) worlds. In turn, economic anthropology is closely related to the representations (images) of \u2018economic man\u2019 in economic theories. They are images of \u2018a natural man\u2019 (Quesnay), \u2018trading man\u2019 (mercantilism), \u2018moral egoist\u2019 (A. Smith), \u2018working man\u2019 (Marx), \u2018consuming man\u2019 (Veblen), \u2018choosing man\u2019 (Bentham and marginalists), \u2018man-entrepreneur\u2019 (J.M. Keynes), \u2018innovative man\u2019 (Schumpeter), \u2018market man\u2019 (von Mises, von Hayek, M. Friedman), \u2018rational man\u2019 (J.F. Muth, R.E. Lucas, Jr.). I use examples from Russian and world classical literature to consider two different axiological positions with respect to money: (i) money is evil; (ii) money is a possibility to bonify. The path of professionalization in the economic sphere at its every stage is fraught with the risk of a significant narrowing of the spiritual horizon and the transformation of the \u2018person of value\u2019 into a \u2018person of price.\u2019 I consider preventing the separation of \u2018pure economics\u2019 from the philosophical axiology is a way to overcome this risk. economic reality; world of economic; economic ontology; economic anthropology; economic axiology; philosophy of money Aristotle. \"Politics.\" Writings . Moscow: Mysl Publisher, 1983, volume 4, pp. 276\u2013644. (In Russian). Avtonomov V.S., ed. Austrian School in Political Economy: C. Menger, E. Bohm von Bawerk, F. von Wieser . Moscow: Ekonomika Publisher, 1992. (In Russian). Bakshtanovsky V.I., Sogomonov Yu.V. \"Sociology of Morality: Normative-Value Systems.\" Socis 5 (2003): 8\u201320. (In Russian). Baudrillard J. Symbolic Exchange and Death. Moscow: Dobrosvet Publisher, 2000. (In Russian). Bentham J. An Introduction to the Principles of Morals and Legislation . Moscow: ROSSPEN Publisher, 1972. (In Russian). Bulgakov S.N. \"Introduction to the \u201cEpitome of Political Economy\u201d.\" Moscow University Economics Bulletin 4 (2016): 72\u201385. (In Russian). Bulgakov S.N. History of Economical Teachings. Moscow, 1911. (In Russian). Dreiser T. Collected Writings. Volume 3: The Financier . Moscow: Khudozhestvennaya literatura Publisher, 1997. (In Russian). Friedman M. Money Mischief: Episodes in Monetary History . Moscow: Delo Publisher, 1998. New on \"OZONE\" . N.p., n.d. Web. . (In Russian). Fromm E. To Have Or To Be? . Moscow: AST Publisher, 2000. (In Russian). Garadzha V.I. Handbook on Sociology of Religion . Moscow: Nauka Publisher, 1995. (In Russian). Hamsun K. The Cultural Life of Modern America .. Moscow: Vladimir Dal Publisher, 2007. Gumer Library \u2013 Culturology . N.p., n.d. Web. . (In Russian). Heilbroner R.L. The Worldly Philosophers: The Lives, Times and Ideas of the Great Economic Thinkers . Moscow: KoLibri Publisher, 2008. (In Russian). Kanke V.A. Handbook on Philosophy of Economical Science . Moscow: INFRA-M Publisher, 2000. (In Russian). Keynes J.M. A Treatise on Money . London: Macmillan & Co, 1930, volume II. Klamer A. The New Classical Macroeconomics . Brighton: Harvester Press, 1984. Kruglov A. \"Value and Price.\" Common Sense 10 (1999): 35\u201344. (In Russian). Kruglov A. \"Value and Price.\" Common Sense 11 (1999): 7\u201320. (In Russian). Lagunov A.A. \"On Some Fallacies of Modern Economism.\" Electronic Scientific Edition Almanac Space and Time\u00a0 13.1 (2016). Web. . (In Russian). Mandeville B. The Fable of the Bees: Or Private Vices, Public Benefits. Oxford, 1966. Marx K. \"Economical and Philosophical Manuscripts of 1844.\" Writings\u00a0 by K. Marx and F. Engels. Moscow: Politizdat Publisher, 1974, volume 42, pp. 41\u2013174. (In Russian). Marx K., Engels F. \"Theses on Feuerbach.\" Writings\u00a0 by K. Marx and F. Engels. Moscow: Politizdat Publisher, 1970, volume 3, pp. 1\u20134. (In Russian). Muth J.F. \"Rational Expectations and the Theory of Price Movements.\" Econometrica 29 (1961): 315\u2013335. Orekhov A.M. Methods of Economic Research Moscow: INFRA-M Publisher, 2009. (In Russian). Pelevin V. Generation-\u03a0. Moscow: Vagrius Publisher, 2000. (In Russian). Petty W. A Treatise of Taxes and Contributions . Moscow: Os-89 Publisher, 1997. New on the \"OZONE\". p., n.d. Web. . (In Russian). Petty Quantulumcunque Concerning Money. Moscow: Os-89 Publisher, 1997. (In Russian). Quesnay F., Turgot A.R.J., du Pont de Nemours P.S. Physiocrats . Selected Economic Works. Moscow: EKSMO Publisher, 2008. (In Russian). Rudnev V. \"Russian Money.\" Logos 4 (2000): 78\u201384. (In Russian). Samuelson P.A., Barnett W.A., eds. \"An Interview with Robert Lucas Jr.\" Inside the Economist's Mind: Conversations with Eminent Economists . Moscow: United Press Publisher, 2009, pp. 98\u2013108. (In Russian). Schumpeter J.A. The Theory of Economic Development: An Inquiry into Profits, Capital, Credit, Interest, and the Business Cycle ; Capitalism, Socialism and Democracy. Moscow: EKSMO Publisher, 2007. (In Russian). Sen A. Development as Freedom . Moscow: Novoe izdatelstvo Publisher, 2004. (In Russian). Simmel G. \"The Philosophy of Money.\" The Theory of Society. \u00a0Ed. A.F. Filippov. Moscow: KANON-Press-Ts Publisher, 1999, pp. 309\u2013383. (In Russian). Smith A. An Inquiry into the Nature and Causes of the Wealth of Nations. Moscow: Sotsekgiz Publisher, 1962. (In Russian). Smith A. The Theory of Moral Sentiments . Moscow: Respublika Publisher, 1997. (In Russian). Soros G. Towards a Global Open Society: International Portfolio Investors . Moscow: Magistr Publisher, 1997. (In Russian). Veblen T. The Theory of the Leisure Class: An Economic Study of Institutions. Moscow: Progress Publisher, 1984. (In Russian). Weber M. Selected: Protestant Ethics and the Spirit of Capitalism. Moscow: ROSSPEN Publisher, 2006. (In Russian). \"Oeconomicus.\" Apology of Socrates and Other Works . Moscow: TERRA\u2013Knizhny klub Publisher, 2009, pp. 219\u2013288. (In Russian). Zasursky Ya.N. Theodor Dreiser . Moscow: Moscow State University Publisher, 1977. (In Russian). Kaftan, V. V. \"World of Economics: An Epitome of the History of Philosophical Conceptualization.\" Space and Time 1 (2017): 106\u2013119. (In Russian). Fixed network address 2226-7271provr_st1-27.2017.32.","venue":"","year":2017.0,"referenceCount":0,"citationCount":0,"fieldsOfStudy":["Sociology"],"publicationDate":"2017-05-08","authors":[{"authorId":"116513794","name":"\u0412\u0438\u0442\u0430\u043b\u0438\u0439 \u0412\u0438\u043a\u0442\u043e\u0440\u043e\u0432\u0438\u0447 \u041a\u0430\u0444\u0442\u0430\u043d"}]},{"paperId":"0192bce55f953571380e815513e6b48190f88782","title":"Individuals' Use Of E-mail Communication Genres In Open Source Software Community Building","abstract":"The advent of the participative Internet (Web 2.0) sheds a new light on traditional knowledge about communication practices. The role of information and communication technologies seems to be very central in managerial literature, while the human side of the issue is less considered. This paper argues that individuals establish communication genres as semantic templates for accomplishing their communicative projects. Communication genres are codes of default behavioral expectations resulting from recurrent communication actions over the time. By using semantic network analytical techniques, our argument is explored in a particular empirical setting, that is, a virtual community of open source software development.","venue":"","year":2011.0,"referenceCount":39,"citationCount":1,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"144515262","name":"V. Barberio"},{"authorId":"2322385680","name":"Antonio Mastrogiorgio"},{"authorId":"2359821","name":"A. Lomi"}]},{"paperId":"019318a348fe625c4ea70e03fb0314c74b520bbf","title":"Building ontologies from relational databases","abstract":"There are many relational databases (RDBs) on the web that store important and useful information. But, semantic search engines cannot use this kind of information for their search results. To overcome this problem, an approach is proposed to transform relational database schema and data into the corresponding ontology. In this paper, an approach to transform a relational database into its equivalent ontology is presented. The proposed method is implemented using Jena and MySQL and is applied on a sample RDB. The resulting ontology is shown as an OWL file. By validating the new ontology through reasoning, its correctness was verified.","venue":"2009 First International Conference on Networked Digital Technologies","year":2009.0,"referenceCount":4,"citationCount":10,"fieldsOfStudy":["Computer Science"],"publicationDate":"2009-07-28","authors":[{"authorId":"2578319","name":"Kobra Etminani"},{"authorId":"2841105","name":"M. Kahani"},{"authorId":"2311035","name":"Noorali Raeeji Yanehsari"}]},{"paperId":"019526693acfed609dd1fdf15af3b0768ab7c21d","title":"THE REINFORCED ENTERPRISE BUSINESS ARCHITECTURE (REBAR) ONTOLOGY","abstract":"Understanding organizations and their needs for new technology has never been more challenging than in today\u2019s high-tech business world. Enterprise managers are required to coordinate with other departmental managers, direct their personnel and solve problems along the way. Communicating new designs to IT for needed applications may not be in the manager\u2019s skillset. When the enterprise grows rapidly or tries to compete in new areas, a set of basic diagrams illustrating common workflows may no longer accurately reflect the complex environment. What is needed is a simple method for illustrating the enterprise as a whole, interoperable structure so managers and workers alike can describe their requirements in the unique vocabulary of their industry. REBAR offers a novel approach for using key strategic and operational business documents, written in natural language, as the basis for the formal enterprise ontology. Popular semantic web standards, including RDF, FOAF and DC, provide generic terms already designed to convey the subject\u2013predicate\u2013object structure of natural language in a social structure. The REBAR enterprise ontology extends these existing standards, thus evolving a socio-technical model of the functional organization distilled directly from existing enterprise documents. REBAR captures the essence of the unique enterprise in a graphical application that can be queried and dynamically recombined to illustrate details of complex workplace collaborations. An enterprise ontology should unite all defined departmental functions authorized by executive enterprise managers. Additionally, findings indicate the REBAR ontology has the potential to provide a reusable structure for linking core social business functions of the enterprise to other explicit enterprise knowledge, including policies, procedures, tech manuals, training documents and project metrics. The REBAR methodology offers evidence that the enterprise is more than the sum of its parts, it is the bridge unifying explicit and tacit knowledge during work","venue":"","year":2018.0,"referenceCount":21,"citationCount":1,"fieldsOfStudy":["Engineering"],"publicationDate":null,"authors":[{"authorId":"2445436","name":"Christine A. Hoyland"}]},{"paperId":"0195be9b2cf9cd7052ef359ff4167d63d0e80161","title":"DATABASE ON SALINITY PATTERNS IN FLORIDA BAY","abstract":"Salinity in Florida Bay is closely related to water management in South Florida. Water management activities over the last century have disrupted the quantity, quality, timing and distribution of freshwater flows into Florida Bay affecting salinity conditions. The main goal of the project presented in this paper is to accumulate all the data available on salinity in Florida Bay into one database and make this data available to the researchers and public via the Internet. This unified data source will give scientists one more tool to monitor the fragile ecosystem of the Everglades and to give better recommendations on water management in this area. The challenge of the project is in database design which will accumulate data collected by different groups of people who apply different methodology of data collection, different measuring equipment and techniques as well as different rules for data recording and formatting. Three major data sources on salinity conditions within Florida Bay are available. The three sources are historical data, temporal Everglades National Park (ENP) data, and spatial US Geological Survey (USGS) data. Historical data contains direct salinity observations from 1936 to present. ENP data include salinity and related parameters, such as rainfall, dissolved oxygen received from an increasing number of stations in the Bay continuously monitored by ENP since the early 1980's. The USGS dataset contains the spatially intensive bimonthly salinity survey records. Besides the aspects of the database design the paper covers implementation and maintenance issues. Also the web application is presented which provides access to the data via the Internet in a convenient and intuitive way without special knowledge of the database query tools. 1. SALINITY DATA AND REQUIREMENTS TO THE DATABASE The salinity record for Florida Bay extends from the beginning of 20th century. The early records are not systematic and are usually found across a diverse literature and many unpublished sources. Despite the fact that these data sources are usually sparse, poorly formatted and are not present in the digital form, they compile a historical dataset which should in some form or another be reflected in the database. The historical dataset is of value. It has information on water salinity prior to the present rapid human development of South Florida that changes salinity patterns in Florida Bay, which in turn affects environmental conditions in the area. In the past three decades with the extensive use of computers to store and process data, a number of salinity studies in Florida Bay resulted in a collection of the datasets which contain data in the digital form according to the well-documented formats. This data is ready to be stored in the database. However, the studies producing the data differ in methodology of collecting data and equipment used. Good example of the differences are NPS (National Park Service) hourly monitoring data, which represent time series from single locations, and USGS (United States Geological Survey) boat survey data which is spatial data with many locations represented by a single value at each location. This makes hard the work to unify the data in one database. * Presented at the Seventh International Conference on Remote Sensing for Marine and Coastal Environments, Miami, Florida, 20-22 May 2002. This research was supported in part by NASA (under grants NAG5-9478, NAGW-4080, NAG5-5095, NAS5-97222, and NAG5-6830), NSF (CDA-9711582, IRI-9409661, HRD-9707076, and ANI-9876409), ONR (N00014-99-1-0952), and the Florida Space Grant Consortium. Many salinity studies provide temperature data as well since the measurement equipment allowed to collect salinity and temperature data simultaneously. It was decided to store the acquired temperature data in the salinity database. It is expected that users of the salinity database will be mostly interested in averaged salinity data over a particular area of Florida Bay and during a certain period of time rather than some particular salinity record. Daily, weekly, monthly, seasonal and annual averages are to be used. Since variations in data density are common from one study to another, data integration may lead to inaccurate results. In order to minimize this effect the following rules have been applied when calculating monthly, seasonal and annual averages: (i) these calculations are based on daily average data; (ii) daily average data are calculated as the average salinity\/temperature for each station within each study on a given day, and (iii) in spatial data sets salinity\/temperature observations are averaged within each basin on a given day and assigned a station location of the geographic center of the respective basin. We refer to (Robblee et al, 2000) for more information. An extensive search has been performed by the researchers for literature references, published and unpublished, interpretable in terms of salinity conditions in Florida Bay. These references describe observations on salinity and other phenomena related to water quality like freshwater occurrences and fish kills. One of the requirements to the database was to facilitate storage and retrieval of these references. 2. CONCEPTUAL DATABASE SCHEMA We have employed a semantic modeling approach for the database design. It has certain advantages in comparison with other techniques: i. the output database schema design is intuitive and clear for understanding even by non-professionals in the field of databases ii. the semantic schema reflects only the semantics of data to be stored in the database and does not show any technicalities of implementation iii. semantic design can be automatically mapped to the relational schema on the implementation step, tools are available to produce instructions for physical database creation using any popular RDBMS (relational database management system). Every concept defined on the semantic schema is one of the following: a category a set of objects about which information is to be aggregated in the database. Categories are denoted on schema by boxes with their names in uppercase bold inside the box; an attribute a pattern of certain printable data about the objects of a category. Attributes are denoted on schema by text in italic inside corresponding categories; a relation a pattern of relationships between objects of two categories. Relations are denoted by arrows on the schema. Certain other notations appear on the semantic schema like cardinality of the relations and indication of some constraints. We refer to (Rishe, 1992) for further reference on semantic schema designs. We now turn to the description of the semantic schema of salinity database. For convenience purposes we are presenting the database schema comprising of three related subschemas, namely studies, locations and datasets subschemas. A key concept of studies subschema is salinity STUDY (see Figure 1). STUDY is performed by a group of INVESIGATORs. One of INVESTIGATORs is a primary investigator, denoted by the relation pi. INVESTIGATORs are associated with INSTITUTIONs. Relation works links these two categories. Category REFERENCE is a container for published and unpublished papers and other documents related to salinity studies and possibly but not necessarily authored by INVESTIGATORs. This subschema accommodates the situations when some information on the reference is missed. For example, it allows to store information in the database in case, nowadays common, when investigators conduct studies and publish reports on the studies; as well as in case when historical reference is taken from a private diary never being published and not related to any study. Category KEYWORD contains keywords related to references and studies and is used to facilitate efficient search of","venue":"","year":2002.0,"referenceCount":3,"citationCount":0,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"1719172","name":"N. Rishe"},{"authorId":"3118416","name":"M. Chekmasov"},{"authorId":"3250348","name":"M. Chekmasova"},{"authorId":"66346675","name":"D. Hernandez"},{"authorId":"2054776062","name":"A. Roque"},{"authorId":"16959125","name":"N. Terekhova"},{"authorId":"2079801171","name":"A. Zhyzhkevych"}]},{"paperId":"0195d6b7559728e45b993859ab042f27e22837ee","title":"Transforming Heterogeneous Messages Automatically in Web Service Composition","abstract":null,"venue":"Asia-Pacific Web Conference","year":2006.0,"referenceCount":7,"citationCount":4,"fieldsOfStudy":["Computer Science"],"publicationDate":"2006-01-16","authors":[{"authorId":"2120811652","name":"Wenjun Yang"},{"authorId":"8549842","name":"Juan-Zi Li"},{"authorId":"1679831","name":"Kehong Wang"}]},{"paperId":"0196200b244e0bccfb6ad7ad9a05a6ad7731744d","title":"An Efficient Way to Recommend Friends on Social Networks through Life-Style","abstract":":- : In this paper, we have exhibited a writing survey of the current Activity based companion suggestion administrations. Person to person communication locales suggest companion proposal Systems in commitment to giving better user experiences. Online companion proposal is a quick creating point in web mining. Current long range informal communication adjusting prescribe companions to clients in view of their social charts and shared companions , which may not be the most proper to mirror a client's taste on companion choice in genuine lifetime . In this paper propose a framework that suggests companions in view of the everyday exercises of clients. Here a semantic based companion proposal is done in light of the clients' ways of life. By utilizing content mining, we show a client's regular life as life chronicles, from which his\/her lifestyles are isolated by utilizing the Latent Dirichlet Allocation calculation. By then we find a similitude metric to measure the closeness of ways of life in the middle of clients, and as sure clients' impact similarly as lifestyles with a comparability coordinating outline. Finally, we consolidate an input part to further improve the proposition exactness.","venue":"","year":2015.0,"referenceCount":12,"citationCount":0,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"2082519100","name":"D. Vardhini"},{"authorId":"2287305701","name":"B.Ranjithkumar"}]},{"paperId":"0196591afdc0889c6e551117b30183fef0933f35","title":"An ontology-based architecture for Intelligent Tutoring System","abstract":"In Intelligent Tutoring Systems (ITS) and other related systems based on Semantic Web technologies recurring problems remain, being the most prominent one the fact that in their architecture some components encompass distinct responsibilities, reducing separation of concerns and increasing complexity of communication among these components. As a consequence, modeling, maintenance and reuse of components have been hard tasks. An architecture for ITS supported by several ontologies is proposed in this paper as a way of addressing the problems. This architecture extends the use of Semantic Web concepts, where the representation of each component is made by a specific ontology, making possible a clear separation of concerns of the components of ITS and explicit the communication among the components.","venue":"","year":2008.0,"referenceCount":37,"citationCount":14,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"35119580","name":"A. Jacinto"},{"authorId":"121637570","name":"Maria Parente de Oliveira"}]},{"paperId":"019762382183e4cb20daedc01a7962d494e61c83","title":"Behavioral Profile: Synonyms of \u2018Disagree","abstract":"There have been some developments in the area of lexical semantics through corpus linguistics in recent time. As a result, it is now possible to focus on semantic dimension of lexemes from a usage-based perspective. This paper presents a Behavioral Profile of synonymous words of the verb disagree. The data for this paper is taken from the Global Web-Based English (GloWbE) corpus.","venue":"East West Journal of Humanities","year":2017.0,"referenceCount":11,"citationCount":1,"fieldsOfStudy":null,"publicationDate":"2017-03-12","authors":[{"authorId":"2323630865","name":"Muhammad Zakaria"}]},{"paperId":"01979ed4a23d774bff32ba08577d8b73248b5138","title":"Simplicity in data models","abstract":"EDITOR'S SUMMARY \n \n \n \nEvolving from database models using punch cards, strict linear relational databases and predefined object-oriented data structures, the triple statements underlying Semantic Web technologies bypass many design constraints to offer endless flexibility. Overcoming structure is challenging, especially the relatively recent structure formalized in the Functional Requirements for Bibliographic Records (FRBR). Though geared to easier access and interoperability and recognizing a multilevel bibliographic model, FRBR remains tied to translating entity-relation diagrams to data structures. Resource Description Framework (RDF) provides a more flexible way to express concepts, in which bibliographic models may be thought of as graphs of properties and relationships. But even RDF-based models can undermine that flexibility by mixing concept classes and data structures. The advantage of RDF classes is to provide semantics that enable a user to focus on similarities, not bound by contextual constraints.and success metrics.","venue":"","year":2015.0,"referenceCount":0,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":"2015-04-01","authors":[{"authorId":"2452446","name":"Karen Coyle"}]},{"paperId":"0197f0a4a840eda71b58e8ee5bb758a7db8f90ef","title":"Closing Information Gaps with Need-driven Knowledge Sharing","abstract":"Closing Information Gaps with Need-driven Knowledge Sharing Knowledge management systems for asynchronous knowledge sharing \u2013 such as Intranets, Wikis, or file shares \u2013 often suffer from a lack of contributions. This is mainly because information providers are decoupled from information seekers, and thus have limited awareness about their actual information needs. Therefore, the questions which knowledge is worth sharing and how to motivate people to share knowledge, are core issues of knowledge management. To this end, we describe a novel approach called need-driven knowledge sharing (NKS), which consists of three elements. The first deals with indicators of information need \u2013 especially search queries \u2013 which are aggregated in order to derive continuous forecasts of organizational information needs (OIN). By comparing with private and shared information spaces, organizational information gaps (OIG) are derived to identify missing information. These gaps can be made transparent using so called mediation services and mediation spaces, which help to create awareness for organizational information needs and to guide knowledge sharing. The realization of NKS is illustrated by three tools, which are all based on established knowledge management systems. Inverse Search is a tool that identifies documents in the private information space of information providers, which may help closing organizational information gaps if moved to a shared information space. Woogle extends Wikis with features that identify and prioritize incomplete or missing information based on other users\u2019 information needs. Similarly, Semantic Need is an extension to Semantic MediaWiki that guides the creation of semantic data by analyzing information needs expressed through structured queries. The implementation and evaluation of all three tools shows, that need-driven knowledge sharing is technically feasible and can be a helpful extension to knowledge management practices. The concepts of mediation services and mediation spaces provide a framework to analyze and extend other tools with respect to NKS. Finally, our approach may also spark improvements of Internetscale services and infrastructures, such as the Wikipedia or the Semantic Web.","venue":"","year":2018.0,"referenceCount":517,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"1757127","name":"Hans-J\u00f6rg Happel"}]},{"paperId":"01994a08004360306aa8ec6877e1a0be0742bbef","title":"Automatic Web Service Composition - Models, Complexity and Applications","abstract":"The automatic composition of web services refers to how services can be used in a complex and aggregate manner, to serve a specific and known functionality. Given a list of services described by the input and output parameters, and a request of a similar structure: the initially known and required parameters; a solution can be designed to automatically search for the set of web services that satisfy the request, under certain constraints. We first propose two very efficient algorithms that solve the problem of the automatic composition of the web services as it was formulated in the competitions organized in 2005 and 2008. The algorithms obtain much better results than the rest of the participants with respect to execution time and even composition size. Evaluation consists of running the previous and the proposed solutions on given benchmarks and generated tests. Further, we design two new models to match service's parameters, extending the semantic expressiveness of the 2008 challenge. The initial goal is to resolve some simple and practical use-cases that cannot be expressed in the previous models. We also adhere to modern service description languages, like OpenAPI and especially this http URL. Algorithms for the new models can solve instances of significant size. Addressing a wider and more realistic perspective, we define the online version of the composition problem. In this regard, we consider that web services and compositions requests can be added and removed in real-time, and the system must handle such operations on the fly. It is necessary to maintain the workflows for users who actively run the compositions over time. As for the new semantic models, we propose new algorithms and provide comprehensive evaluation by generating test cases that simulate all corner cases.","venue":"arXiv.org","year":2020.0,"referenceCount":103,"citationCount":1,"fieldsOfStudy":["Computer Science"],"publicationDate":"2020-07-08","authors":[{"authorId":"17810233","name":"Paul Diac"}]},{"paperId":"0199b6dda77d7d76953b7fc0772324a08a5c2015","title":"The Web Semantic Analysis of Port Customer based on Hadoop","abstract":". With the changing of ports services market\u2019 relationship between supply and demand, companies are trying to assist their decision-making through traditional business intelligence technology. Ports through the internal data collection can play a limited role. Then it needs to be studied through external information. In this paper, we study the port customers Web semantic analysis method based on Hadoop, using distributed computing methods to study extraction port customer-related information.","venue":"","year":2016.0,"referenceCount":12,"citationCount":0,"fieldsOfStudy":["Business"],"publicationDate":"2016-10-15","authors":[{"authorId":"2118472323","name":"Song Zhang"},{"authorId":"2109137902","name":"Lei Huang"}]},{"paperId":"0199d87bb9fa9156c949ab416fc9a62a6e8466ab","title":"A Method of Ontology Mapping Based on Instance","abstract":"Ontology mapping is the key point to reach interoperability over ontologies. In semantic Web environment, ontologies are usually distributed and heterogeneous and thus it is necessary to find the mapping between them before processing across them. Many efforts have been conducted to automate the discovery of ontology mapping. However, some problems are still evident. This paper proposes an ontology similarity calculation method; this method constructs virtual instances for every concept node and takes the structure of ontology into consideration. We apply this method to PROMPT algorithm for ontology mapping and get a higher accuracy and recall through experiment.","venue":"Intelligent Information Hiding and Multimedia Signal Processing","year":2007.0,"referenceCount":14,"citationCount":5,"fieldsOfStudy":["Computer Science"],"publicationDate":"2007-11-26","authors":[{"authorId":"2052139033","name":"T. Jin"},{"authorId":"1821557","name":"Yuchen Fu"},{"authorId":"3326173","name":"Xinhong Lin"},{"authorId":"145014498","name":"QUAN LIU"},{"authorId":"47217082","name":"Zhiming Cui"}]},{"paperId":"0199ea13bbf5bacd0f3c24b388b0d9c689a3bcdb","title":"Reusing of Information Constructed in HTML Documents","abstract":"There have been efforts of making a knowledge based web, represented by Semantic Web. However, in this trend, HTML is not appropriate as a language for ontology and a structure of information. Due to numerous amounts of information in it, it seems rational to reuse those data in HTML. Previous studies are not enough to broadly convert HTML into OWL because they mainly focus on conversions of structured data (table tags), and they just give simple executions. In addition, GRDDL, a recommendation of W3C, needs an additional script for a conversion, and the output format of it is RDF which has some restrictions. This paper will offer three steps of conversions; (1) Extraction of information, (2) Acquiring triples, (3) Constructing ontology. There are two types of information; text-formed and non-text-formed information. In addition, there are two kinds of tags which include only text-formed information or which include both of text-formed and non-text-formed one. Depending on the type of tags, we classify tag categories and set rules for each of them. Using those rules, we can make triples, and finally we can construct ontology.","venue":"","year":2008.0,"referenceCount":2,"citationCount":1,"fieldsOfStudy":["Computer Science"],"publicationDate":"2008-10-01","authors":[{"authorId":"2136158478","name":"Hoon Hwangbo"},{"authorId":"2143767368","name":"Hongchul Lee"}]},{"paperId":"019a35a5de1d2156af5d7cda4d36e089c24254b7","title":"Semantic biomedical resource discovery: a Natural Language Processing framework","abstract":null,"venue":"BMC Medical Informatics and Decision Making","year":2015.0,"referenceCount":74,"citationCount":30,"fieldsOfStudy":["Computer Science","Medicine"],"publicationDate":"2015-09-30","authors":[{"authorId":"2849796","name":"Pepi Sfakianaki"},{"authorId":"49786676","name":"L. Koumakis"},{"authorId":"2466994","name":"S. Sfakianakis"},{"authorId":"3300775","name":"G. Iatraki"},{"authorId":"3002194","name":"G. Zacharioudakis"},{"authorId":"31710426","name":"N. Graf"},{"authorId":"2629216","name":"K. Marias"},{"authorId":"2992223","name":"M. Tsiknakis"}]},{"paperId":"019a682970f2d8a7a7b86a9d665dc6fe718fb098","title":"Integrating Semantic MediaWiki with Exhibit to Accelerate the Adoption of a Semantic Web","abstract":"This thesis promotes the integration of Semantic MediaWiki, a wiki engine for the collaborative management of structured data, and Exhibit, a rich visualization framework. The thesis argues that the integration of Semantic MediaWiki and Exhibit makes a contribution to the mitigation of two known problems causing the delayed adoption of a semantic web: the limited availability of semantic data on the web and the fact that data is rarely shared and reused block the emergence of a semantic web. The integration opposes these issues by attracting more casual users to face up with semantic technologies and enabling a convenient method of data exchange between two wikis. The integration is organized into three steps. The first step establishes Exhibit as new interface for viewing query results in Semantic MediaWiki. Exhibit\u2019s visualization widgets (e.g. maps and timelines) make wiki content more meaningful and clear users from analytic tasks. With features such as faceted browsing, sorting and aggregation of wiki content Exhibit helps subduing high information loads wikis tend to show. Next the design and implementation of a JSON exporter for Semantic MediaWiki is tackled to make data of a Semantic MediaWiki available throughout the web. By this means wiki data finds its way into other web applications such as blogs or content management systems. Finally, the previous outcomes are utilized to enable data exchange among Semantic MediaWikis.","venue":"","year":2009.0,"referenceCount":40,"citationCount":0,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"3184346","name":"F. Howahl"}]},{"paperId":"019aee49342c85c61a7bb1dfb5b5d9307868edca","title":"An Automatic Annotation Technique for Web Search Results","abstract":"The uses of web search engines are very frequent and common worldwide over the internet by end users for different purposes. A web search engine takes the query request from the end user and executes that query on relational database used to store the information on behalf of that web search engine. Based on input queries the dynamic response is generated by search engine, in the form of HTML based pages. Such pages are supported with the web databases. Every web page generated contains many results to display for particular query, called as Search Result Records (SRRs). Sometimes it becomes troublesome to extract relevant data from diverse sources. The SRRs generated may contain data units that are relevant to one common semantic. These SRRs are further required to be assigned with proper labels. The manual methods for record extraction and labeling have a worse scalability. Thus automatic annotation based method is needed to improve the accuracy as well as scalability of web search engines. This paper presents an automatic annotation technique for web search results. The proposed approach first aligns the data units on a result page into different groups such that the data in the same group have the same semantic. Then, each group is annotated from different aspects and aggregates the different annotations to predict a final annotation label for it. The annotation wrapper generated for the search site is automatically constructed and can be used to annotate new result pages from the same web database. Experiments indicate that","venue":"","year":2020.0,"referenceCount":0,"citationCount":0,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"40584023","name":"Wei Liu"},{"authorId":"143976873","name":"Xiaofeng Meng"},{"authorId":"38699354","name":"W. Meng"},{"authorId":"5351991","name":"D. Raghu"},{"authorId":"2069894784","name":"V. Reddy"},{"authorId":"18668487","name":"C. Jacob"},{"authorId":"1766422","name":"A. Arasu"},{"authorId":"1398574232","name":"H. Garcia-Molina"},{"authorId":"40343421","name":"Yanhong Zhai"},{"authorId":"2149123996","name":"Bing Liu"},{"authorId":"50094695","name":"P. Sundar"},{"authorId":"1775519","name":"Hongjun Lu"}]},{"paperId":"019b1bc64d06d12f23bcc79d56f0d1426702ae30","title":"Sentiment Analysis of Indian Tourist Place Reviews: A Machine Learning-Based Exploration","abstract":"the social media trend, where many followers are interested in visiting the areas based on the reviews offered by the influencers, has caused the tourism industry to start growing incredibly high in recent years. This study conducts sentiment analysis on user-generated reviews from online tourism review websites, employing advanced feature extraction techniques. The dataset which has been taken from different web sources contains textual reviews and numerical ratings, providing the framework for analysis. Data preprocessing includes text tokenization, stop word removal, lemmatization, and data cleaning, resulting in a refined dataset with a processed review column. For feature extraction, we used TF-IDF vectorization (limited to 5000 features) and GloVe-based word embedding for enhancing word importance and semantic relationships. We employ different machine learning models such as Naive Bayes, SVM, Logistic regression, and Random Forest Classifier (with 100 decision trees) for sentiment analysis, which is designed to handle complex data relationships. Random Forest has given the best accuracy of 89.54 percent compared to the other models, while future work will encompass precision, recall, and F1-score. Our novel approach integrates TF-IDF, word embedding, and Random Forest for improved sentiment analysis. This methodology results of subsequent discussion by a robust foundation for further exploration in this field.","venue":"2023 4th International Conference on Intelligent Technologies (CONIT)","year":2024.0,"referenceCount":14,"citationCount":0,"fieldsOfStudy":null,"publicationDate":"2024-06-21","authors":[{"authorId":"2316399055","name":"B. S. Kiran Kumar"},{"authorId":"2316398822","name":"M. L. Prajwal"},{"authorId":"2316402886","name":"Nivedita"}]},{"paperId":"019c15ea3c3a9298c306bfe69936a8759e45d4fb","title":"Semantic science and its communication - a personal view","abstract":null,"venue":"Journal of Cheminformatics","year":2011.0,"referenceCount":24,"citationCount":8,"fieldsOfStudy":["Medicine","Computer Science"],"publicationDate":"2011-10-14","authors":[{"authorId":"1400044832","name":"Peter Murray-Rust"}]},{"paperId":"019d1391fddb3599417c77cf7c264d31d2143e6e","title":"Understanding Billions of Triples with Usage Summaries","abstract":". Linked Data is a way to share and consume interlinked semantic web datasets. Usage summaries can help to understand the structure within and across interlinked datasets by partitioning entities based on how they are described, such as grouping entities that are instances of the same types and described with the same predicates. Because Linked Data is growing to billions of triples, scalable techniques for generating usage summaries are essential. In this work, we implement a novel Hadoop-based technique for generating usage summaries of billions of triples. We analyze and compare usage summaries generated for the entire BTC 2010 and 2011 datasets. We generate usage summaries involving classes and predicates, and of recommended patterns, such as for inferencing and interlinking.","venue":"","year":2011.0,"referenceCount":5,"citationCount":9,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"1984233","name":"S. Khatchadourian"},{"authorId":"1735847","name":"M. Consens"}]},{"paperId":"019ec700bd696cf3e929efc9b34a5e990b1e1e03","title":"Utilizing LOD Relationships and FOAF Vocabularies for Top-N Recommender System","abstract":"The World Wide Web is transitioning from a Web of hyper-linked documents to a Web of linked data. A large amount of Resource Description Framework (RDF) data was published in publicly available datasets and connected to create the so-called Linked Open Data cloud. The semantics embedded in the Linked Open Data (LOD) can be utilized to enhance the recommender systems (RSs). Limited content analysis, cold-start and data sparsity are well-known issues in traditional RSs, which occurs when few or no features describe the items or no ratings to achieve a recommendation task. Because the LOD cloud contains many features, the knowledge encoded can help resolve this issue. The proposed system's main idea is to design a knowledge-based recommendation system that uses semantic features extracted from multiple datasets in LOD. Our approach will generate recommendations depending on direct and indirect relationships between resources. The results will be ranked according to their similarity score with the input before presenting them to the user. The results of our approach were comparable to the results of the Internet Movie Database (IMDb) website. Furthermore, an experimental evaluation using the MovieLens dataset was conducted. The results were encouraging and stimulating further research in this particular field of study. The usage of different kinds of relations in LOD can enhance the accuracy of the recommendations.","venue":"2021 1st Babylon International Conference on Information Technology and Science (BICITS)","year":2021.0,"referenceCount":0,"citationCount":1,"fieldsOfStudy":null,"publicationDate":"2021-04-28","authors":[{"authorId":"144562972","name":"Ahmed M. Mahdi"},{"authorId":"2835407","name":"A. S. Hadi"}]},{"paperId":"019ef56f6b2147d0fa05a19e2972e6cecc73d956","title":"The paraphrase search assistant: terminological feedback for iterative information seeking","abstract":"We present a new linguistic approach to the construction of terminological feedback for use in interactive query refinement. The method exploits the tendency for key domain concepts within result sets to participate in families of semantically related lexical compounds. We outline an algorithm for computing a ranked list of result set \u201cthemes\u201d and describe a web application, the Paraphrase Search Assistant, designed to make use of the theme extraction algorithm to support a recognition-based, iterative information seeking dialog.","venue":"Annual International ACM SIGIR Conference on Research and Development in Information Retrieval","year":1999.0,"referenceCount":30,"citationCount":166,"fieldsOfStudy":["Computer Science"],"publicationDate":"1999-08-01","authors":[{"authorId":"1723684","name":"Peter G. Anick"},{"authorId":"2554782","name":"S. Tipirneni"}]},{"paperId":"019f5d8e275db29fd94bc70b21c2ccfd4807f549","title":"Emergent Community Structure in Social Tagging Systems","abstract":"A distributed classification paradigm known as collaborative tagging has been widely adopted in new Web applications designed to manage and share online resources. Users of these applications organize resources (Web pages, digital photographs, academic papers) by associating with them freely chosen text labels, or tags. Here we leverage the social aspects of collaborative tagging and introduce a notion of resource distance based on the collective tagging activity of users. We collect data from a popular system and perform experiments showing that our definition of distance can be used to build a weighted network of resources with a detectable community structure. We show that this community structure clearly exposes the semantic relations among resources. The communities of resources that we observe are a genuinely emergent feature, resulting from the uncoordinated activity of a large number of users, and their detection paves the way for mapping emergent semantics in social tagging systems.","venue":"Advances in Complex Systems","year":2008.0,"referenceCount":19,"citationCount":58,"fieldsOfStudy":["Computer Science"],"publicationDate":"2008-08-01","authors":[{"authorId":"144300761","name":"C. Cattuto"},{"authorId":"1730687","name":"A. Baldassarri"},{"authorId":"2776193","name":"V. Servedio"},{"authorId":"144347993","name":"V. Loreto"}]},{"paperId":"019fda77db71f2ab49da68ec8d70aaff9d190719","title":"Semantic Web for data harmonization in Chinese medicine","abstract":null,"venue":"Chinese Medicine","year":2010.0,"referenceCount":29,"citationCount":12,"fieldsOfStudy":["Medicine"],"publicationDate":"2010-01-12","authors":[{"authorId":"143896305","name":"K. Cheung"},{"authorId":"1729778","name":"Huajun Chen"}]},{"paperId":"01a06b48b0b4a12c0f1201b7bc4a13c808800a0f","title":"Application of Semantic Web Based on the Domain-Specific Ontology for Global KM","abstract":"This chapter introduces an application of the Semantic Web based on ontology to the tourism business. Tourism business is one promising area for Semantic Web applications. To realize the potential of the Semantic Web, we need to find a killer application of the Semantic Web in the knowledge management (KM) area. The ontology as a key enabler is deigned and implemented under a framework of the Se-mantic-Web-driven KM system in a tourism domain. Finally, we discussed the relationship between the Semantic Web and KM processes.","venue":"","year":2009.0,"referenceCount":22,"citationCount":4,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"4497236","name":"J. Joo"},{"authorId":"2152576841","name":"Sang M. Lee"},{"authorId":"2105577548","name":"Yongil Jeong"}]},{"paperId":"01a202c652aff2c2da3088c239dc33d64cee46c1","title":"Semantic Full-Text Search with ESTER: Scalable, Easy, Fast","abstract":"We present a demo of ESTER, a search engine that combines the ease of use, speed and scalability of full-text search with the powerful semantic capabilities of ontologies. ESTER supports full-text queries, ontological queries and combinations of these, yet its interface is as easy as can be: A standard search field with semantic information provided interactively as one types. ESTER works by reducing all queries to two basic operations: prefix search and join, which can be implemented very efficiently in terms of both processing time and index space.We demonstrate the capabilities of ESTER on a combination of the English Wikipedia with the Yago ontology, with response times below 100 milliseconds for most queries, and an index size of about 4 GB. The system can be run both stand-alone and as a Web application.","venue":"2008 IEEE International Conference on Data Mining Workshops","year":2008.0,"referenceCount":5,"citationCount":7,"fieldsOfStudy":["Computer Science"],"publicationDate":"2008-12-15","authors":[{"authorId":"1936883","name":"H. Bast"},{"authorId":"1679784","name":"Fabian M. Suchanek"},{"authorId":"1684687","name":"Ingmar Weber"}]},{"paperId":"01a233a2d7a7eeadc5639cea69e6446869a6c46b","title":"Visual Representation of Reifications in RDF Visualizer","abstract":"One family of visualization tools for the Semantic web are those that directly display the underlying RDF data. Most of them use the inherent graph structure of RDF data and present the user with some drawing of the graph. While it is usually sufficient to give the user with decent understanding of data, there are some features of RDF that could be used to improve the visualization, for instance the presence of reifications. While they can easily be displayed just like any other part of the RDF graph, their specific properties allow for more advanced processing.","venue":"2009 13th International Conference Information Visualisation","year":2009.0,"referenceCount":9,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":"2009-07-15","authors":[{"authorId":"1785889","name":"J. Dokulil"},{"authorId":"1769804","name":"J. Yaghob"},{"authorId":"1755582","name":"J. Katreniakov\u00e1"}]},{"paperId":"01a39ea3f157a867d4384cdc580a07fc17f66340","title":"Supporting Patient Empowerment by an Intelligent Self-Management Pathway for Diabetes Patients","abstract":"The EMPOWER project (2012-2015) develops a Patient Empowerment Framework facilitating the self-management of diabetes patients. This includes personalised services (web-based and mobile) for supporting changing behaviour and services for monitoring of vital, physical, mental parameters as well as physical and lifestyle activities. EMPOWER semantically integrates multiple information sources (EHR\/PHR, diabetes guidelines, patterns of daily living) for a shared knowledge model and focuses on a patient-centric perspective that involves both healthcare professionals and patients based on iterative cycles. The services in EMPOWER will embrace semantic interoperability based on health standards such as HL7 IHE profiles and ISO\/CEN13606 information models. EMPOWER will be validated in two pilot applications, one in Germany and one in Turkey. []","venue":"","year":2013.0,"referenceCount":0,"citationCount":0,"fieldsOfStudy":["Medicine"],"publicationDate":"2013-04-26","authors":[{"authorId":"2306432","name":"Robert A. Eckhoff"}]},{"paperId":"01a3ceb97ddf7f7ad62b651ccf93da25ae064c41","title":"A Semantic Web Approach to Enrich Information Retrieval Answers","abstract":"An automotive luggage rack has a pair of side rails extending parallel to one another and supported above the vehicle roof in stanchions at opposite ends of the side rails. One or more cross rails is provided between the side rails and cross rail end fittings have portions to encircle the side rails so that the cross rail can be moved longitudinally of the side rails. Clamping devices are provided in the end fittings for securing the cross rails in desired locations relative to the side rails. Each side rail is C-shaped with an elongated insert to close the open side of the C, and a flat underside to be engaged by the clamping device.","venue":"International Conference on Enterprise Information Systems","year":2007.0,"referenceCount":12,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"145725398","name":"R. C. M. Ram\u00edrez"},{"authorId":"2069115529","name":"V\u00edctor Manuel Ramos Ramos"}]},{"paperId":"01a52573ffa0cab766202a789c25eb0c2d31dfc6","title":"Exploring the Web and Semantic Knowledge-Driven Automatic Question Answering System","abstract":"The growth of information retrieval from the web sources are increased day by day, proving an effective and efficient way to the user for retrieving relevant documents from the web is an art. Asking the right question and retrieving a right answer to the posted query is a service which provide by the Natural Language Processing. Question Answering System is one of the best ways to identify the candidate answer with high accuracy. The web and Semantic Knowledge Driven Question Answering System (QAS) used to determine the candidate answer for the posted query in the NLP tools.\u00a0 This method includes Query expansion techniques and entity linking method to identify the information source snippets with ontology structure, also ranking the sentences by applying conditional probability between query and Answer to identify the optimal answer from the web corpus. The result provides an exact answer with high accuracy than the baseline method.\u00a0\u00a0","venue":"International journal of engineering and technology","year":2018.0,"referenceCount":10,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":"2018-07-04","authors":[{"authorId":"145551129","name":"S. Jayalakshmi"},{"authorId":"81264654","name":"Ananthi Sheshaayee"}]},{"paperId":"01a60fb32e0d65ecd059d2e955fe2b0330c87c8b","title":"The Advanced Data Service Architecture for Modern Enterprise Information System","abstract":"In recent years, the rapid growth of the Internet has greatly changed our way of sharing information. Internet brings both challenges and opportunities to modern enterprise information system. In this paper, we describe advanced data service architecture for modern enterprise information system. This architecture solves two main issues: semantic integration of data and adaptability of data server. The goal is to support a variety of enterprise information systems for obtaining data and sharing data by data service composition. For various heterogeneous data resource(Relational Data, XML, Web Service, OLAP),the internal model can realized heterogeneous data integration, describe the relationship between the business and data and present data by business term in semantic level by semantic mapping and data view.","venue":"International Conference on Information Science and Applications","year":2014.0,"referenceCount":16,"citationCount":7,"fieldsOfStudy":["Computer Science"],"publicationDate":"2014-05-06","authors":[{"authorId":"2120100611","name":"Xin Liu"},{"authorId":"3186278","name":"Chungjin Hu"},{"authorId":"2153494023","name":"Yang Li"},{"authorId":"2119413170","name":"Lina Jia"}]},{"paperId":"01a646723e9ca2afb35857bf5977c65e2f2b0718","title":"Evaluation of Website Usability Using Markov Chains and Latent Semantic Analysis","abstract":"SUMMARY The development of information\/communication technology has made it possible to access substantial amounts of data and retrieve information. However, it is often difficult to locate the desired information, and it becomes necessary to spend considerable time determining how to access specific available data. This paper describes a method to quantitatively evaluate the usability of large-scale information-oriented websites and the effects of improvements made to the site design. This is achieved by utilizing the Cognitive Walkthrough for the Web and website modeling using Markov chains. We further demonstrate that we can greatly improve usability through simple modification of the link structure by applying our approach to an actual informational database website with over","venue":"IEICE transactions on communications","year":2005.0,"referenceCount":20,"citationCount":18,"fieldsOfStudy":["Computer Science"],"publicationDate":"2005-04-01","authors":[{"authorId":"144692779","name":"M. Kitajima"},{"authorId":"2871664","name":"Noriyuki Kariya"},{"authorId":"2199577","name":"H. Takagi"},{"authorId":"2145044470","name":"Yongbing Zhang"}]},{"paperId":"01a730dbea3ea815ce479ff370e8fd74546eee6b","title":"Screen Readers Cannot See Ontology Based Semantic Annotation for Visually Impaired Web Travellers","abstract":"Travelling upon the Web is dif\ufb01cult for visually impaired users since the Web pages are designed for visual interaction [6]. Visually impaired users usually use screen readers 1 to access the Web in audio. However, unlike sighted users, screen readers cannot see the implicit structural and navigational knowledge encoded within the visual presentation of Web pages. Therefore, in a visually impaired user\u2019s environment, objects that support travel are missing or inaccessible. Our approach to remedy this is to annotate pages with an ontology, the Travel Ontology, that aims to encapsulate rich structural and navigational knowledge about these objects. We use Semantic Web technologies to make such knowledge explicit and computationally accessible. Our semi-automated tool, Dante identi\ufb01es travel objects on Web pages, annotates them appropriately with the Travel Ontology and uses this to transform the pages to enhance the travel support. Thus Dante uses the Travel Ontology to enhance the travel experience of visually impaired users. This paper introduces the Travel Ontology, the annotation pipeline used in the annotation part of Dante and some transformation scenarios to illustrate how the annotations are used to guide the transformation of Web pages.","venue":"","year":2004.0,"referenceCount":20,"citationCount":64,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"1760899","name":"Y. Yesilada"},{"authorId":"1749047","name":"S. Harper"},{"authorId":"46555127","name":"C. Goble"},{"authorId":"143649898","name":"R. Stevens"}]},{"paperId":"01a73be11a612ea9a9d99788313300ff0d038de6","title":"Tags Are Related: Measurement of Semantic Relatedness Based on Folksonomy Network","abstract":"Folksonomy and tagging systems, which allow users to interactively annotate a pool of shared resources using descriptive tags, have enjoyed phenomenal success in recent years. The concepts are organized as a map in human mind, however, the tags in folksonomy, which reflect users' collaborative cognition on information, are isolated with current approach. What we do in this paper is to estimate the semantic relatedness among tags in folksonomy: whether tags are related from semantic view, rather than isolated? We introduce different algorithms to form networks of folksonomy, connecting tags by users collaborative tagging, or by resource context. Then we perform multiple measures of semantic relatedness on folksonomy networks to investigate semantic information within them. The result shows that the connections between tags have relatively strong semantic relatedness, and the relatedness decreases dramatically as the distance between tags increases. What we find in this paper could provide useful visions in designing future folksonomy-based systems, constructing semantic web in current state of the Internet, and developing natural language processing applications.","venue":"Computing and informatics","year":2011.0,"referenceCount":78,"citationCount":5,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"2257759541","name":"Chao Wu"},{"authorId":"2257514128","name":"Bo Zhou"}]},{"paperId":"01a7a0cf31cef8975acb5f480fd28b2ef06d2abe","title":"A besorol\u00e1si adatcsere-form\u00e1tum b\u0151v\u00fcl\u00e9se. A legut\u00f3bbi k\u00e9t\u00e9vtized fejlem\u00e9nye","abstract":"The authority data exchange format, also called metadataformat looks back to a past of 50 years. Since its birth in 1968 the MARC format has beengradually improved, and a number of versions (such as Unimarc) have developed. As themost significant feature, its choice of data elements has been substantially extended.Extension pertained mainly to data on relationship and data on attributes. The choice of dataon relationship consisted initially merely in the \u201esee\u201d and \u201esee also\u201d relationship types asknown from manual cataloguing. Later, paradigmatic relationship types used in thesauri,having developed from the 1950\u2019s and defined in related standards, became to be applied. Ata certain time it has also become possible to provide the relationships in the 2XX and 3XXfields as text, within the format itself. It is expected that in the world of the semantic web thisopportunity will be highly appreciated in the future. The most significant extension was to beobserved in the field of data on attributes. As opposed to data relating to entity \u2013 which arerelated to bibliographic data, and as a result, constitute secondary or metadata \u2013, the data onattributes are related to the data on entities put into the leader, and represent, therefore,metadata of metadata, i.e. tertiary data. To such metadata belong the notes data in the 6XXfields and the information data in the 0XX fields respectively. The authority MARC format iscapable of managing even authority data used with the materials of archives, as is illustratedin the article.","venue":"","year":2011.0,"referenceCount":0,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":"2011-05-13","authors":[{"authorId":"52158327","name":"Ungv\u00e1ry Rudolf"}]},{"paperId":"01a7bfb7f136b1e912fc073d33a713c68d819d88","title":"A knowledge-rich distributed decision support framework: a case study for brain tumour diagnosis","abstract":"Abstract The HealthAgents project aims to provide a decision support system for brain tumour diagnosis using a collaborative network of distributed agents. The goal is that through the aggregation of the small data sets available at individual hospitals, much better decision support classifiers can be created and made available to the hospitals taking part. In this paper, we describe the technicalities of the HealthAgents framework, in particular how the interoperability of the various agents is managed using semantic web technologies. On the broad scale the architecture is based around distributed data-mart agents that provide ontological access to hospitals\u2019 underlying data that has been anonymized and processed from proprietary formats into a canonical format. Classifier producers have agents that gather the global data from participating hospitals such that classifiers can be created and deployed as agents. The design on a microscale has each agent built upon a generic-layered framework that provides the common agent program code, allowing rapid development of agents for the system. We believe that our framework provides a well-engineered, agent-based approach to data sharing in a medical context. It can provide a better basis on which to investigate the effectiveness of new classification techniques for brain tumour diagnosis.","venue":"Knowledge engineering review (Print)","year":2011.0,"referenceCount":28,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":"2011-07-28","authors":[{"authorId":"2689397","name":"D. Dupplaw"},{"authorId":"1775412","name":"Madalina Croitoru"},{"authorId":"2336372","name":"S. Dasmahapatra"},{"authorId":"39923921","name":"Alex Gibb"},{"authorId":"2257280678","name":"Horacio Gonz\u00e1lez-V\u00e9lez"},{"authorId":"2257278196","name":"Miguel Lurgi"},{"authorId":"144020794","name":"Bo Hu"},{"authorId":"2228085810","name":"Paul H. Lewis"},{"authorId":"2257277480","name":"A. Peet"}]},{"paperId":"01a89469890fd258eaf0bdf401e33348a7cff978","title":"A Bayesian Network Approach to Ontology Mapping","abstract":null,"venue":"International Workshop on the Semantic Web","year":2005.0,"referenceCount":35,"citationCount":167,"fieldsOfStudy":["Computer Science"],"publicationDate":"2005-11-06","authors":[{"authorId":"2066007300","name":"Rong Pan"},{"authorId":"2136611","name":"Zhongli Ding"},{"authorId":"2152845391","name":"Yang Yu"},{"authorId":"143894540","name":"Yun Peng"}]},{"paperId":"01aa00672d7ce6593ec5494402eb249982b0e881","title":"Using Fuzzy Semantic Log for Rough Set Web Page Recommendation","abstract":"Improving accuracy of web page recommendation through data mining technology is an important research topic. This paper presents a new rough set web page recommendation algorithm based on fuzzy semantic logs, which firstly changes the access logs in the web into fuzzy semantic logs, secondly matches the current session with the rules founded, finally gives a recommendation set of web pages to the users. To evaluate the effectiveness of the algorithm the backward path ratio method is used, and the result shows that the algorithm can effectively improve the accuracy of web page recommendation.","venue":"International Symposium on Information Engineering and Electronic Commerce","year":2009.0,"referenceCount":14,"citationCount":1,"fieldsOfStudy":["Computer Science"],"publicationDate":"2009-05-16","authors":[{"authorId":"9328615","name":"Haijun Xiong"},{"authorId":"47835189","name":"Qi Zhang"}]},{"paperId":"01aad2491f7b11e2260450e2b41de7765d6a0e0b","title":"On Identifying Knowledge Processing Requirements","abstract":null,"venue":"International Workshop on the Semantic Web","year":2005.0,"referenceCount":36,"citationCount":5,"fieldsOfStudy":["Computer Science"],"publicationDate":"2005-11-06","authors":[{"authorId":"71615704","name":"A. L\u00e9ger"},{"authorId":"49495876","name":"L. Nixon"},{"authorId":"2418440","name":"P. Shvaiko"}]},{"paperId":"01acead3620504301cebf156a3f1ca5841c56669","title":"Deeply supervised model for click-through rate prediction in sponsored search","abstract":null,"venue":"Data mining and knowledge discovery","year":2019.0,"referenceCount":44,"citationCount":19,"fieldsOfStudy":["Computer Science"],"publicationDate":"2019-04-03","authors":[{"authorId":"50371776","name":"J. Gligorijevic"},{"authorId":"2486589","name":"Djordje Gligorijevic"},{"authorId":"144140890","name":"Ivan Stojkovic"},{"authorId":"3042223","name":"Xiao Bai"},{"authorId":"46479604","name":"Amit Goyal"},{"authorId":"3844766","name":"Z. Obradovic"}]},{"paperId":"01af3e512ef0d7cec8722b2a2290346e7d690d39","title":"Medieval manuscripts and their migrations: Using SPARQL to investigate the research potential of an aggregated Knowledge Graph","abstract":"Although the RDF query language SPARQL has a reputation for being opaque and difficult for traditional humanists to learn, it holds great potential for opening up vast amounts of Linked Open Data to researchers willing to take on its challenges. This is especially true in the field of premodern manuscripts studies as more and more datasets relating to the study of manuscript culture are made available online. This paper explores the results of a two-year long process of collaborative learning and knowledge transfer between the computer scientists and humanities researchers from the Mapping Manuscript Migrations (MMM) project to learn and apply SPARQL to the MMM dataset. The process developed into a wider investigation of the use of SPARQL to analyse the data, refine research questions, and assess the research potential of the MMM aggregated dataset and its Knowledge Graph. Through an examination of a series of six SPARQL query case studies, this paper will demonstrate how the process of learning and applying SPARQL to query the MMM dataset returned three important and unexpected results: 1) a better understanding of a complex and imperfect dataset in a Linked Open Data environment, 2) a better understanding of how manuscript description and associated data involving the people and institutions involved in the production, reception, and trade of premodern manuscripts needs to be presented to better facilitate computational research, and 3) an awareness of need to further develop data literacy skills among researchers in order to take full advantage of the wealth of unexplored data now available to them in the Semantic Web.","venue":"Digital Medievalist","year":2021.0,"referenceCount":25,"citationCount":5,"fieldsOfStudy":null,"publicationDate":"2021-12-23","authors":[{"authorId":"2060463635","name":"H. Wijsman"},{"authorId":"145536615","name":"Toby Burrows"},{"authorId":"100841083","name":"L. Cleaver"},{"authorId":"49613615","name":"Doug Emery"},{"authorId":"2930307","name":"E. Hyv\u00f6nen"},{"authorId":"2106653","name":"M. Koho"},{"authorId":"145022714","name":"Lynn Ransom"},{"authorId":"47586165","name":"E. Thomson"}]},{"paperId":"01b2a3fc0a5ba24d25bd546c298a7306c5311a85","title":"Design, information organisation and the evaluation of the Virtual Museum of the Pacific digital ecosystem","abstract":null,"venue":"Journal of Ambient Intelligence and Humanized Computing","year":2012.0,"referenceCount":42,"citationCount":10,"fieldsOfStudy":["Computer Science"],"publicationDate":"2012-06-28","authors":[{"authorId":"145232960","name":"Peter W. Eklund"},{"authorId":"145034853","name":"T. Wray"},{"authorId":"29724248","name":"P. Goodall"},{"authorId":"119845594","name":"Amanda Lawson"}]},{"paperId":"01b46ebad6ca9440a987f909b542ade941ac9066","title":"Towards semantic interoperability in an open IoT ecosystem for connected vehicle services","abstract":"A present challenge in today's Internet of Things (IoT) ecosystem is to enable interoperability across heterogeneous systems and service providers. Restricted access to data sources and services limits the capabilities of a smart city to improve social, environmental and economic aspects. Interoperability in the IoT is concerned with both, messaging interfaces and semantic understanding of heterogeneous data. In this paper, the first building blocks of an emerging open IoT ecosystem developed at the EU level are presented. Semantic web technologies are applied to the existing messaging components to support and improve semantic interoperability. The approach is demonstrated with a proof-of-concept for connected vehicle services in a smart city setting.","venue":"Global Internet of Things Summit","year":2017.0,"referenceCount":17,"citationCount":15,"fieldsOfStudy":["Computer Science"],"publicationDate":"2017-06-06","authors":[{"authorId":"2066996409","name":"Niklas Kolbe"},{"authorId":"2391084","name":"Sylvain Kubler"},{"authorId":"145744000","name":"J. Robert"},{"authorId":"47681863","name":"Y. L. Traon"},{"authorId":"52425525","name":"A. Zaslavsky"}]},{"paperId":"01b58e4a71b2f39f40e0ccadb127a45b207cfe6a","title":"Data Preparation for Mining World Wide Web Browsing Patterns","abstract":null,"venue":"Knowledge and Information Systems","year":1999.0,"referenceCount":34,"citationCount":685,"fieldsOfStudy":["Computer Science"],"publicationDate":"1999-02-01","authors":[{"authorId":"122947525","name":"R. Cooley"},{"authorId":"1684679","name":"B. Mobasher"},{"authorId":"2237689610","name":"J. Srivastava"}]},{"paperId":"01b7195d52f134c407e7df97d4497e3fed649b05","title":"\u0397 \u03bd\u03ad\u03b1 \u03c5\u03c0\u03b7\u03c1\u03b5\u03c3\u03af\u03b1 Web- \u03bc\u03af\u03b1 \u03ba\u03b1\u03b9\u03bd\u03bf\u03c4\u03bf\u03bc\u03af\u03b1 \u03b3\u03b9\u03b1 \u03c4\u03b7\u03bd \u03b7\u03bb\u03b5\u03ba\u03c4\u03c1\u03bf\u03bd\u03b9\u03ba\u03ae \u03b1\u03bd\u03ac\u03c0\u03c4\u03c5\u03be\u03b7 \u03c4\u03c9\u03bd \u03b5\u03c0\u03b9\u03c7\u03b5\u03b9\u03c1\u03ae\u03c3\u03b5\u03c9\u03bd \u03ba\u03b1\u03b9 \u03c4\u03b7\u03c2 \u03a0\u03b5\u03c1\u03b9\u03c6\u03ad\u03c1\u03b5\u03b9\u03b1\u03c2","abstract":"The new Web will change the way of operation of Enterprises. During the next years it is forecasted that the Web services will have a progressive transformation. \nIn the present work are presented the constitution and the way of operation of new Web Service. Still are presented the technical factors (for example protocols etc.) that are involved with its operation. As basic point, it will be the exploitation of existing Data Bases. The growth of new applications will be by far more economic concerning the growth of corresponding applications today. The passage in the new Web is fore\u00accasted to be realized progressively. \nIt is expected that new Technology will be used more in Northern than in Southern Europe. \nThe next expected step will be the Semantic. The Semantic Web will be supported in the search of meaning and not the words, as it is today. Europe could contribute a lot to this subject because of its history and the way of approaching. In conclusion, the central idea of new Web exists and has been realized. The next time is the time for its Application. On the contrary, the Semantic Web is expected in far away time. The new Web, as technological change, is a given factor that will contribute in the electronic growth of enterprises, and indirectly in their decentralization.","venue":"","year":2004.0,"referenceCount":0,"citationCount":0,"fieldsOfStudy":["Engineering"],"publicationDate":null,"authors":[{"authorId":"69957415","name":"\u0395\u03bb\u03b5\u03c5\u03b8\u03ad\u03c1\u03b9\u03bf\u03c2 \u03a3\u03c4\u03b5\u03c1\u03b3\u03af\u03bf\u03c5"},{"authorId":"102101211","name":"\u0395\u03c5\u03c1\u03b9\u03c0\u03af\u03b4\u03b7\u03c2 \u0393\u03bb\u03b1\u03b2\u03ac\u03c2"}]},{"paperId":"01ba105b9f92e4f49142ba57b3e7a7bd5bc4d445","title":"How to Search and Contextualize Scenes Inside Videos for Enriched Watching Experience: Case Stories of the Second World War Veterans","abstract":null,"venue":"Extended Semantic Web Conference","year":2022.0,"referenceCount":7,"citationCount":5,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"2930307","name":"E. Hyv\u00f6nen"},{"authorId":"47605072","name":"Esko Ikkala"},{"authorId":"2106653","name":"M. Koho"},{"authorId":"2063770137","name":"Rafael Leal"},{"authorId":"2076478900","name":"Heikki Rantala"},{"authorId":"3403943","name":"Minna Tamper"}]},{"paperId":"01ba3e138b268e1b782e2bf981eb1e8782b5f893","title":"Semantic Description of the IMS Learning Design Specification","abstract":". In this paper we present a learning design ontology that is based on the IMS Learning Design (IMS LD) specification. The IMS LD is a metadata standard that describes the elements of the design of any teaching-learning process on the basis of a well-founded conceptual model. However, this specification has been modelled and represented using the XML-Schema language, which is not expressive enough to describe the semantics of all the elements of such conceptual model. To solve these limitations, we have developed an ontology using Prot\u00e9g\u00e9 at the knowledge level, and then translated into OWL, to represent it in the standard language of the Semantics Web, and first order logic, to formalize the axioms defined in the ontology.","venue":"","year":2005.0,"referenceCount":21,"citationCount":15,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"143837873","name":"M. Lama"},{"authorId":"144286229","name":"E. S\u00e1nchez"},{"authorId":"3095624","name":"R. Amorim"},{"authorId":"144372255","name":"Xos\u00e9 A. Vila"}]},{"paperId":"01bac6d975afbe0cb568b9bae9146604c488e478","title":"The Arabic Knowledge Graph: Opportunities and Challenges","abstract":"Semantic Web has brought forth the idea of computing with knowledge, hence, attributing the ability of thinking to machines. Knowledge Graphs represent a major advancement in the construction of the Web of Data where machines are context-aware when answering users' queries. The English Knowledge Graph was a milestone realized by Google in 2012. Even though it is a useful source of information for English users and applications, it does not offer much for the Arabic users and applications. In this paper, we investigated the different challenges and opportunities prone to the life-cycle of the construction of the Arabic Knowledge Graph (AKG) while following some best practices and techniques. Additionally, this work suggests some potential solutions to these challenges. The proprietary factor of data creates a major problem in the way of harvesting this latter. Moreover, when the Arabic data is openly available, it is generally in an unstructured form which requires further processing. The complexity of the Arabic language itself creates a further problem for any automatic or semi-automatic extraction processes. Therefore, the usage of NLP techniques is a feasible solution. Some preliminary results are presented later in this paper. The AKG has very promising outcomes for the Semantic Web in general and the Arabic community in particular. The goal of the Arabic Knowledge Graph is mainly the integration of the different isolated datasets available on the Web. Later, it can be used in both the academic (by providing a large dataset for many different research fields and enhance discovery) and commercial sectors (by improving search engines, providing metadata, interlinking businesses).","venue":"International Computer Science Conference","year":2017.0,"referenceCount":29,"citationCount":5,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"9942487","name":"Ahmed Ktob"},{"authorId":"1707275","name":"Zhoujun Li"}]},{"paperId":"01bd8485943f914fec7f4b8ec01f4dfc1b633cc3","title":"Making URIs Published on Data Web RDF Dereferencable","abstract":"Nowadays, more and more URIs reside on DataWeb, as published for linked open data, dereferencing URIs challenges the current Web to embrace Semantic Web. Although, quite a few practical recipes for publishing URIs have been provided to make URIs dereferencable, we believe a fundamental investigation of publishing and dereferencing URIs would contribute a forward compatibility with the RDF and OWL upper layers in the Semantic Web architecture. In this paper, we propose to make URIs published on Data Web RDF dereferencable, and we formalize such a requirement in an RDF-compatible semantics. Also, the dereferencing operation is defined in an abstract URI syntax, such that URIs, as interpreted as described resources, would be RDF dereferencable by default. Accompanied by a live demonstration, the poster demo explanation would elaborately discuss and seriously address issues on Data Web URIs, which were or have been taken for granted. Additionally, for case study, Metadata Web, a Data Web of enterprise-wide models, is explored. The URIs on Metadata Web is published as RDF dereferencable. Such an implementation of universal metadata management across the enterprise enables the metadata federation such that global query, search and analysis could be conducted on top of the Metadata Web.","venue":"International Workshop on the Semantic Web","year":2008.0,"referenceCount":11,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":"2008-10-28","authors":[{"authorId":"1789766","name":"Jing Mei"},{"authorId":"2052157756","name":"G. Xie"},{"authorId":"152245643","name":"Y. Ni"},{"authorId":"2035396","name":"Shengping Liu"},{"authorId":"2118384315","name":"Hanyu Li"},{"authorId":"144455843","name":"Yue Pan"}]},{"paperId":"01bd8942be1130039680af8abc2aef48e2c8c7eb","title":"Importance of HTML Structural Elements and Metadata in Automated Subject Classification","abstract":null,"venue":"European Conference on Research and Advanced Technology for Digital Libraries","year":2005.0,"referenceCount":23,"citationCount":51,"fieldsOfStudy":["Computer Science"],"publicationDate":"2005-09-18","authors":[{"authorId":"1921665","name":"Koraljka Golub"},{"authorId":"2779417","name":"A. Ard\u00f6"}]},{"paperId":"01be614e022ee02e5a92b91e06b72ceb4e00a468","title":"Enabling Semantic Web Programming by Integrating RDF and Common Lisp","abstract":"This paper introduces \"Wilbur\", an RDF and DAML toolkit implemented in Common Lisp. Wilbur exposes the RDF data model as a frame-based representation system; an object-oriented view of frames is adopted, and RDF data is integrated with the host language by addressing issues of input\/output, data structure compatibility, and error signaling. Through seamless integration we have achieved a programming system well suited for building \"Semantic Web\" applications.","venue":"International Conference on Semantic Web & Web Services","year":2001.0,"referenceCount":29,"citationCount":32,"fieldsOfStudy":["Computer Science"],"publicationDate":"2001-07-30","authors":[{"authorId":"35003282","name":"O. Lassila"}]},{"paperId":"01bf3bef80601926ed45d0df271a0f14acbd50f1","title":"Ontology-Based Information Retrieval: A Review","abstract":"\u2014Semantic Web has become a current challenge in World Wide Web (WWW), where it will lead to a new type of sharing data on the net openly. Main idea of this paper is to explore the current state of the semantic information retrieval with major focus on ontology based search. The paper includes introductory knowledge on the Semantic Web and its layer cake, classic Information Retrieval, semantic search and its approaches, ontology and why to use the ontology. Then a review of several papers on semantic and ontology based search are included covering different domains of applications. From the review, it hopes will encourage many researchers to revolutionize more in this field in the future.","venue":"","year":2013.0,"referenceCount":27,"citationCount":2,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"3088385","name":"A. Azizan"},{"authorId":"9218319","name":"Z. Bakar"},{"authorId":"66598121","name":"N. Khairuddin"},{"authorId":"9219708","name":"Nor Liza Saad"}]},{"paperId":"01c001d556b9e1404276f1fd0e6a7de3f681619d","title":"Lost and found, the importance of modelling map content semantically","abstract":null,"venue":"","year":2008.0,"referenceCount":25,"citationCount":7,"fieldsOfStudy":["Geography"],"publicationDate":null,"authors":[{"authorId":"2103957","name":"R. Lemmens"}]},{"paperId":"01c0f1036c5899880ac8364218b39a28917b5990","title":"Marcado sem\u00e1ntico autom\u00e1tico en gestores de contenidos: integraci\u00f3n y cuantificaci\u00f3n","abstract":"A general overview of the different semantic markup formats and the existing technologies to incorporate explicit semantic information (microformats, microdata and RDFa) is provided. Services are described that automate, to some extent, semantic annotation processes ( Sindice , Calais , AlchemyAPI and DBPedia Spotlight ), while characterizing the complete cycle of this process in a particular CMS ( Wordpress ) using a specialized plugin ( RDFaCE-Lite ). Finally, in order to quantify the creation and connectivity of semantically marked content on the Web, the space formed by all Spanish universities (and a selection of 25 international institutions) is analysed with Sindice . Semantic page count and visibility indicators (inlinks, outlinks, internal and third party) are calculated for the sample. The results indicate limited presence of semantically marked content in the universities and highly isolated web visibility of this content.","venue":"","year":2013.0,"referenceCount":15,"citationCount":3,"fieldsOfStudy":["Computer Science"],"publicationDate":"2013-09-20","authors":[{"authorId":"1403904994","name":"Juan-Antonio Pastor-S\u00e1nchez"},{"authorId":"2061584410","name":"Enrique Ordu\u00f1a-Malea"},{"authorId":"52092123","name":"Tom\u00e1s Saor\u00edn"}]},{"paperId":"01c106e4aedc02bf8c1d605f689c361d34596778","title":"Adaptive Spatio-temporal Query Planning For Linked Sensor Data","abstract":". Researchers in the Semantic Web community have proposed a substantial number of works that use Semantic Web technologies for effectively managing and querying heterogeneous IoT data. However, our survey of research work has shown that the goal of providing an intelligent processing and analysis engine for IoT has still not been fully achieved. Central to this problem is the requirement for a semantic spatio-temporal query processing engine that is able to not only analyze spatio-temporal correlations in a massive amount of IoT data but can also generate an effective query plan for a given query to execute in a timely manner. In this paper, we propose an alternative query optimization solution that uses query similarity identi\ufb01cation in conjunction with machine learning techniques to recommend a previously generated query plan to the optimizer for a given query. Our approach also aims to predict the query execution time for the purposes of workload management and capacity planning. Our extensive experiments indicate the ef\ufb01ciency of our learning approach with an impressive prediction accuracy on test queries.","venue":"","year":2021.0,"referenceCount":52,"citationCount":0,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"1391848087","name":"H. Mau"},{"authorId":"2243794215","name":"Hoan Nguyen"},{"authorId":"2102209757","name":"Mau Quoc"},{"authorId":"2110524946","name":"H. Nguyen"}]},{"paperId":"01c14993fb626adad1e97d54fc5a997f1f53a842","title":"Information Architecture Automatization for the Semantic Web","abstract":null,"venue":"IFIP TC13 International Conference on Human-Computer Interaction","year":2011.0,"referenceCount":14,"citationCount":5,"fieldsOfStudy":["Computer Science"],"publicationDate":"2011-09-05","authors":[{"authorId":"1995062","name":"Josep Maria Brunetti"},{"authorId":"143667487","name":"Roberto Garc\u00eda"}]},{"paperId":"01c2807ac3ce9708cf4e0a153ad3952ff93d1821","title":"Blockchain, black magic and event ontology Interview with Alexander Boldachev","abstract":"Alexander Boldachev is a Russian philosopher, futurologist (member of the Association of Futurologists of Russia), author of books and articles on universal evolutionism, biological evolution, philosophy of artificial intelligence, temporal ontology, epistemology, and logic. System architect and analyst of blockchain applications, author of articles on the problems of trust technologies, eGovernment, web 3.0, semantic modeling of complex systems, speaker of many specialized conferences.","venue":"Philosophical Problems of Information Technologies and Cyberspace","year":2020.0,"referenceCount":0,"citationCount":0,"fieldsOfStudy":["Art"],"publicationDate":"2020-12-25","authors":[{"authorId":"114707021","name":"Alexander Boldachev"},{"authorId":"115292512","name":"P. Baryshnikov"}]},{"paperId":"01c342f529b84639f7b6f99cede821063b09e3b0","title":"Linked Data and Service Orientation","abstract":null,"venue":"International Conference on Service Oriented Computing","year":2010.0,"referenceCount":42,"citationCount":7,"fieldsOfStudy":["Computer Science"],"publicationDate":"2010-12-07","authors":[{"authorId":"145714602","name":"Erik Wilde"}]},{"paperId":"01c3b9bc6299bf521787902a31d86b2a7c94f514","title":"Modeling and visualizing semantic and spatio-temporal evolution of topics in interpersonal communication on Twitter","abstract":"ABSTRACT Interpersonal communication on online social networks has a significant impact on the society by not only diffusing information, but also forming social ties, norms, and behaviors. Knowing how the conversational discourse semantically and geographically vary over time can help uncover the changing dynamics of interpersonal ties and the digital traces of social events. This article introduces a framework for modeling and visualizing the semantic and spatio-temporal evolution of topics in a spatially embedded and time-stamped interpersonal communication network. The framework consists of (1) a topic modeling workflow for modeling topics and extracting the evolution of conversational discourse; (2) a geo-social network modeling and smoothing approach to projecting connection characteristics and semantics of communication onto geographic space and time; (3) a web-based geovisual analytics environment for exploring semantic and spatio-temporal evolution of topics in a spatially embedded and time-stamped interpersonal communication network. To demonstrate, geo-located and reciprocal user mention and reply tweets over the course of the 2016 primary and presidential elections in the United States from 1 August 2015 to 15 November 2016 were analyzed. The large portion of the topics extracted from mention tweets were related to daily life routines, human activities, and interests such as school, work, sports, dating, wearing, birthday celebration, music, food, and live-tweeting. Specific focus on the analysis of political conversations revealed that the content of conversational discourse was split between civil rights and election-related discussions of the political campaigns and candidates. These political topics exhibited major shifts in terms of content and the popularity in reaction to primaries, debates, and events throughout the study period. While civil rights discussions were more dominant and in higher intensity across the nation and throughout the whole time period, election-specific conversations resulted in temporally varying local hotspots that correlated with locations of primaries and events.","venue":"International Journal of Geographical Information Science","year":2019.0,"referenceCount":115,"citationCount":22,"fieldsOfStudy":["Psychology","Computer Science"],"publicationDate":"2019-04-03","authors":[{"authorId":"2219064","name":"Caglar Koylu"}]},{"paperId":"01c52747c4d72d0cf5263b1073390ae183c84927","title":"5 Semantic Annotation and Retrieval: Web of Hypertext - RDFa and","abstract":null,"venue":"","year":2011.0,"referenceCount":2,"citationCount":1,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"152654090","name":"M. Adida"},{"authorId":"46407762","name":"M. Birbeck"},{"authorId":"1700939","name":"I. Herman"}]},{"paperId":"01c6e1c4196d2e80fb9f7b2eb018a5af15956509","title":"Linguistic Annotation for the Semantic Web","abstract":". Establishing the semantic web on a large scale implies the widespread annotation of web documents with ontology-based knowledge markup. For this purpose, tools have been developed that allow for semi-automatic annotation of web documents with ontology-based metadata. However, given that a large number of web documents consist either fully or at least partially of free text, language technology tools will be needed to support this authoring process by providing an automatic analysis of the semantic structure of textual documents. In this way, free text documents will become available as semi-structured documents, from which meaningful units can be extracted automatically ( information extraction ) and organized through clustering or classi\ufb01cation ( text mining ). Obviously, this is of importance for both knowledge markup and ontology development, i.e. the dynamic adaptation of ontologies to evolving applications and domains. In this paper we present the following linguistic analysis steps that underlie both of these: morphological analysis, part-of-speech tagging, chunking, dependency structure analysis, semantic tagging . Examples for each are given in the context of two projects that use linguistic and semantic annotation for the purpose of cross-lingual information retrieval and content-based multimedia access.","venue":"","year":2003.0,"referenceCount":57,"citationCount":35,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"3338131","name":"P. Buitelaar"},{"authorId":"1743895","name":"Thierry Declerck"}]},{"paperId":"01c714a94efbaca3ad54d8be3d66ff3c5fe04204","title":"Reasoning on the Semantic Web needs to reason both on ontology-based assertions and on ontologies themselves","abstract":"In this arti le, we present a method whi h aims at using ontologies to perform di(cid:27)erent types of reasoning. This method, alled operationalization, proposes to automati ally adapt the representation of the axioms to the type of reasoning the KBS in whi h the ontology is integrated is dedi ated to. This pro ess is based on the des ription of the operational goal of the KBS through a s enario of use. So, we argue for the distin tion between the problems of knowledge representation in ontologies, that are built at the on eptual level, and the problems related to reasoning with ontologies, that o ur at the operational level. Moreover, be ause reasoning on the Web requires to reason both on domain knowledge and on ontologies, for instan e for evaluation or alignment purposes, we propose an extension of the operationalization method that permits to reason on ontology by operationalizing a meta-representation of the language used to represent ontologies. The language we use, alled OCGL, is based on the Con eptual Graphs model and a tool, alled TooCoM, implements this language and the operationalization method.","venue":"","year":2006.0,"referenceCount":14,"citationCount":6,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"3187145","name":"F. F\u00fcrst"},{"authorId":"2784580","name":"F. Trichet"}]},{"paperId":"01c7c6320e544009691644e1e05145308f790aed","title":"Constructing Large-Scale Semantic Web Indices for the Six RDF Collation Orders","abstract":"The Semantic Web community collects masses of valuable and publicly available RDF data in order to drive the success story of the Semantic Web. Efficient processing of these datasets requires their indexing. Semantic Web indices make use of the simple data model of RDF: The basic concept of RDF is the triple, which hence has only 6 different collation orders. On the one hand having 6 collation orders indexed fast merge joins (consuming the sorted input of the indices) can be applied as much as possible during query processing. On the other hand constructing the indices for 6 different collation orders is very time-consuming for large-scale datasets. Hence the focus of this paper is the efficient Semantic Web index construction for large-scale datasets on today's multi-core computers. We complete our discussion with a comprehensive performance evaluation, where our approach efficiently constructs the indices of over 1 billion triples of real world data.","venue":"Open Journal of Big Data","year":2016.0,"referenceCount":46,"citationCount":2,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"145267753","name":"Sven Groppe"},{"authorId":"28012270","name":"Dennis Heinrich"},{"authorId":"3285006","name":"Christopher Blochwitz"},{"authorId":"2975719","name":"Thilo Pionteck"}]},{"paperId":"01c8c8ad31c6eecfb34cb04937964a0a39fe903d","title":"KIM - Semantic Annotation Platform","abstract":null,"venue":"International Workshop on the Semantic Web","year":2003.0,"referenceCount":22,"citationCount":314,"fieldsOfStudy":["Computer Science"],"publicationDate":"2003-10-20","authors":[{"authorId":"39502661","name":"Borislav Popov"},{"authorId":"3120224","name":"A. Kiryakov"},{"authorId":"153766394","name":"A. Kirilov"},{"authorId":"40163064","name":"D. Manov"},{"authorId":"2037799","name":"Damyan Ognyanoff"},{"authorId":"2077631368","name":"Miroslav Goranov"}]},{"paperId":"01c99bd1ea86db3b7b8405fcdbdf82159e2638d5","title":"A SYSTEMATIC STUDY ON SUGGESTION MINING FROM OPINION REVIEWS","abstract":"Online product reviews have become eminent in the purchase decision-making process. With progress in web 2.0 technologies, huge volumes of unstructured text data are generated as reviews on e-commerce platforms and third-party web portals. Opinion review mining has become a critical area of research in language processing and applied machine learning. Opinion reviews available across various portals are perceived primarily to understand the sentiment polarity expressed by the reviewer at multiple granularities. The opinion review may also contain suggestions or tips for manufacturers and peer customers. Suggestion Mining refers to the automatic extraction of suggestions from opinionated text. The applications include product quality improvement, peer customer suggestions, summarizing collected surveys and feedback, a recommender system, and enhancing sentiment polarity classification. Suggestion mining is considered a sentence classification task, such as classifying a given review as suggestive intent or not. Various linguistic, syntactic, and semantic features with core machine learning and neural network approaches are used for suggestion mining. This paper presents a comprehensive and systematic review of suggestion mining from opinion reviews and their facets in the literature.","venue":"","year":null,"referenceCount":32,"citationCount":0,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"2260856163","name":"Naveen Kumar"},{"authorId":"2260796500","name":"Suresh Kumar Laskari"},{"authorId":"2260797488","name":"Sanampudi"}]},{"paperId":"01c99d07a2f98690168d306084ce94ea54525d3d","title":"ISCF: A Semantic Web Service Composition Framework Based on OAA","abstract":"Through providing an execution environment for semantic web services, SWSF (Semantic Web Service Framework) can facilitate automatic web service delivery, discovery, selection, invoking, composition and interoperation. However, each of those ongoing approaches does not satisfy all basic requirements of SWSF, e.g. OWL-S (Ontology Language of Web Service) does not offer the mechanism for automatic web service tasks' execution and WSMO can not describe the composition of web services in a structural way yet. So, in order to provide a fully- fledged SWSF, we present the ISCF (Integrated Service Composition Framework) which is based on the OAA (Open Agent Architecture ). We describe the technical characters and design objectives of ISCF from global and detailed view. Comparing with other SWSFs, ISCF has more extensible and autonomous distributed architecture, and has more complete and effective web service automatization. In addition, ISCF provide some useful tools to help users design semantic web services and manage ISCF system.","venue":"2008 The 3rd International Conference on Grid and Pervasive Computing - Workshops","year":2008.0,"referenceCount":13,"citationCount":1,"fieldsOfStudy":["Computer Science"],"publicationDate":"2008-05-25","authors":[{"authorId":"2114190925","name":"Lei Deng"},{"authorId":"2115903617","name":"Jian Wu"},{"authorId":"1791157","name":"Zhengguo Hu"}]},{"paperId":"01cad1cbbcffc29c5ccc013b86ffccd76ea01a18","title":"Noun Compound Interpretation","abstract":"Noun compounds (or noun sequences) are a productive, continuous sequence of more than one nouns. Most of the noun compounds appear only once in a large corpus. These characteristics of noun compounds make them a special case, and demand special treatment. Here, the problem is to find noun compounds from text, parse them if required, and extract semantic relation between components of the noun compound. A task of extracting an abstract relation between components of the noun compound (e.g., apple pie: Made Of), or paraphrasing noun compound using verb and prepositions (apple pie : \u201ca pie made of apple\u201d or \u201ca pie with apple flavor\u201d), is known as interpretation of noun compound (or noun compound interpretation). For our work, we use a set of predefined abstract labels as semantic relations. Following are major bottlenecks in current system, and our approaches to solve the same: 1. There is no acceptable inventory of semantic relations. We have analzed a inventory of semantic relations[1], and we trying to refine the inventory. We are also planning to use a data driven approach which will help in refining the current inventories. 2. Inspite of millions of noun compounds in large corpora, there is no sufficiently large annotated dataset for supervised training. We are planning to use semisupervised approach to tackle this. 3. Context influences semantic relations. But, the present datasets have annotation for each noun compound without context. We are planning to study how context can be used for the task. We are planning to use web-extracted information to bring the context in play.","venue":"","year":2014.0,"referenceCount":6,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"2142462704","name":"Girishkumar Ponkiya"},{"authorId":"1747097","name":"Girish Keshav Palshikar"}]},{"paperId":"01cb85b1b1c79508cb0db0ff004a57a24e267dfe","title":"Software Failure Modes and Effect Analysis Method Combined with Ontology and Rule Reasoning","abstract":"Failures in safety-critical software will lead to catastrophic consequences. Software failure modes and effect analysis( SFMEA) is a safety analysis method which is commonly used in industry. However,the SFMEA method relies on manual analysis,thus it has poor reusability and low accuracy. To solve these problems,this paper proposes a creative SFMEA method combined with ontology and rule reasoning. Firstly,the SFMEA ontology is developed to accurately describe the software failure knowledge. Secondly,rules are built to describe the failure analysis processes using semantic web rule language( SWRL). According to the failure causes,the reasoning engine can analyze the failure effects automatically. At last,a case study of engine flameout-state module analysis confirms the feasibility and practicality of the research.","venue":"","year":2015.0,"referenceCount":0,"citationCount":1,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"1414927063","name":"Zhu Yi-qua"}]},{"paperId":"01cc7f21584b083793a2283cb83174daa9488aa8","title":"Semantic Features for Context Organization","abstract":"In recent years the technological world has grown by incorporating billions of small sensing devices, collecting and sharing real-world information. As the number of such devices grows, it becomes increasingly difficult to manage all these new information sources. There is no uniform way to share, process and understand context information. In previous publications we discussed efficient ways to organize context information that is independent of structure and representation. However, our previous solution suffers from semantic sensitivity. In this paper we review semantic methods that can be used to minimize this issue, and propose an unsupervised semantic similarity solution that combines distributional profiles with public web services. Our solution was evaluated against Miller-Charles dataset, achieving a correlation of 0.6.","venue":"International Conference on Future Internet of Things and Cloud","year":2015.0,"referenceCount":36,"citationCount":10,"fieldsOfStudy":["Computer Science"],"publicationDate":"2015-08-24","authors":[{"authorId":"144425777","name":"M\u00e1rio Antunes"},{"authorId":"143613980","name":"D. Gomes"},{"authorId":"1689246","name":"R. Aguiar"}]},{"paperId":"01cc8127d342307f3cd08c70533124700d0ad9a5","title":"Curating the Specificity of Ontological Descriptions under Ontology Evolution","abstract":null,"venue":"Journal on Data Semantics","year":2014.0,"referenceCount":36,"citationCount":15,"fieldsOfStudy":["Computer Science"],"publicationDate":"2014-06-01","authors":[{"authorId":"1801959","name":"Yannis Tzitzikas"},{"authorId":"3406576","name":"M. Kampouraki"},{"authorId":"2408941","name":"A. Analyti"}]},{"paperId":"01ccf0c42968ad089f516067f09d5beae184d572","title":"Semantic web service discovery based on business rule annotation","abstract":"An important vision of Service-Oriented Computing is to dynamically discover and bind services at run-time. Nowadays, how to identify relevant services which satisfy the desired goal by considering business policies is still a challenge. Although multiple efforts have tried to address this issue, these efforts usually provide solutions based on private specifications and protocols, not based on open standards. It causes obstacles to achieve interoperability among services from different organizations. In this paper, we present an approach integrating SAWSDL and OWL to enable annotating Quality of Business Services (QoBS) for describing business rules and constraints. Besides, we provide a method to classify the QoBS annotations and to reason out the matching degree from the viewpoint of business rules satisfaction.","venue":"International Conference on Machine Learning and Computing","year":2011.0,"referenceCount":12,"citationCount":3,"fieldsOfStudy":["Computer Science"],"publicationDate":"2011-07-10","authors":[{"authorId":"1736499","name":"Shang-Pin Ma"},{"authorId":"1875056","name":"Chia-Hsueh Li"},{"authorId":"2194011","name":"Chun-Ying Huang"},{"authorId":"2544295","name":"Yong-Yi Fanjiang"},{"authorId":"39270032","name":"J. Kuo"}]},{"paperId":"01cfa9d8a27d8f7227e6cd08e719c8e7bb205164","title":"Using Semantic Web Languages in Argumentation Models","abstract":". Recent research has created a multitude of argumentation models with varying degrees of formality. In this paper, we look at the feasibility of using semantic web languages like OWL and SWRL as an unbiased template for developing such models. We then present the Argumentation Ontology (ArgOn) as an example.","venue":"","year":2006.0,"referenceCount":9,"citationCount":0,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"1732545","name":"Florian Echtler"}]},{"paperId":"01d15033baa97eb1cbc51eaf26db2d627df6d9e8","title":"Desarrollo de un Servicio Middleware de Ontolog\u00edas Cooperativas Aplicado a Sistemas Embebidos de Transportes Inteligentes.","abstract":"Las primeras soluciones de comunicacion entre ordenadores se basaban en un modelo denominado centralizado en la que un unico equipo con una o multiples CPUs (Central Processing Unit) procesaba todas las solicitudes entre aplicaciones. No obstante, la necesidad de obtencion de datos complejos, de calculos entre aplicaciones de forma rapida, precisa y de coste accesible dio lugar a que este modelo fuera sustituido por un modelo distribuido que permitiese hacer viable el manejo de grandes estructuras de datos diseminados en multiples ordenadores que se comunican entre si a traves de una red comun. La independencia, distribucion y en algunos casos la naturaleza heterogenea de estos ordenadores demandan un sistema de software distribuido que sirva como estandar entre sistemas. La utilizacion de un software middleware entre la capa software y hardware actua como una capa de abstraccion de software distribuido y ofrece un conjunto de servicios que hace posible el funcionamiento de aplicaciones distribuidas sobre plataformas heterogeneas. La comunicacion entre aplicaciones es crucial ya que las tecnologias de la informacion estan evolucionando hacia una interaccion de aplicaciones a traves de Internet. Inicialmente, las aplicaciones en Internet surgieron para realizar la comunicacion entre humanos o entre humanos y aplicaciones. Una muestra de ello son: Email, Ftp, Web, Telnet, IRC, etc., Hoy en dia, la necesidad de interaccion entre aplicaciones a traves de Internet se esta demandando de forma creciente. La electronica, los sistemas informaticos y los sistemas embebidos estan cada vez mas integrados en entornos distribuidos. El descubrimiento de servicios es un reto bien reconocido en estos entornos. En la actualidad el desarrollo de aplicaciones SOA (Service Oriented Architecture) resulta un paradigma imperante para la integracion dinamica de servicios. Una de las arquitecturas pioneras orientadas a servicios es CORBA (Common Object Request Broker Architecture), que ofrece conectividad de un sistema a traves de los ORBs (Object Request Broker), parte medular de su estructura. Cuando se invoca a un servicio, se espera que este resuelva la peticion y produzca los mejores resultados con un rendimiento aceptable y ofreciendo algun tipo de QoS (Quality of Service). A pesar de todo, descubrir y localizar servicios no es tarea facil y las busquedas comunmente carecen de inteligencia. El agente que realiza la peticion podria obtener una infinidad de informacion no relacionada o sin sentido. La localizacion de la informacion o algun servicio especifico podrian realizarse, por ejemplo, a traves de algun servicio Trading de CORBA, donde la representacion estaria dada por pares de nombres\/valor y las propiedades de estos cubririan la referencia al servicio en si, de forma descriptiva. Pero el Trading Service de CORBA utiliza informacion almacenada en diferentes componentes de su estructura reduciendo la capacidad de trabajar con entornos dinamicos e intuitivos. Otro inconveniente que presenta este servicio de CORBA es que no es capaz de trabajar con homonimias, obligando al desarrollador a crear sistemas poco flexibles.\n\nEl trabajo desarrollado en esta tesis se aplica de forma especifica al campo de los ITS (Intelligent Transportation Systems), donde la exactitud y rapidez de la informacion enviada\/recibida es sumamente importante. La informacion confusa o la falta de interoperabilidad pueden resultar en ocasiones desastrosas, dando lugar a accidentes, retrasos y caos en el trafico dependiendo del area en que se implemente. El descubrimiento dinamico de la informacion, asi como la composicion y la invocacion de servicios a traves de agentes inteligentes serian una potencial solucion a estos problemas. La composicion de servicios podria permitir que los servicios cooperen mutuamente de forma dinamica. Para ello es necesario que el flujo de informacion sea gestionado de forma inteligente. La incorporacion de ontologias implementadas en un conjunto estandarizado de conceptos como RDF (Resource Description Framework) extendida por mecanismos de especificacion de clases y propiedades como RDFS (RDF-Schema) o escritas en un lenguaje OWL 2 (Web Ontology Language), asi como un servicio que gestione ontologias de forma cooperativa, jugarian un rol muy importante en un entorno orientado a los ITS. En esta tesis doctoral, el capitulo 1 realiza una introduccion general sobre los inicios, evolucion y actualidad de los ITS, exponiendo los principales escenarios de aplicacion, los sistemas de comunicaciones mas utilizados en este entorno y las principales carencias. En el capitulo 2 se introducen las tecnologias middleware existentes, haciendo hincapie en los principales tipos de middleware actuales. Se trata ademas de la importancia de las ontologias en las actuales infraestructuras de desarrollo software como parte crucial en el manejo inteligente de la informacion y mas especificamente en el campo de los ITS. Tambien se expone la importancia de los servicios colaborativos inteligentes y las ventajas de la incorporacion de un servicio semantico en el campo de los ITS. En el capitulo 3 se hace una propuesta para la creacion de entornos inteligentes cooperativos en el ambito de los ITS. Para ello se propone un metodo para medir y evaluar la carga computacional de CORBA ejecutada sobre plataformas embebidas. Tambien se propone un metodo especifico para la creacion de ontologias en el dominio de los ITS utilizando tecnicas de recuperacion de la informacion, extraccion del conocimiento, procesado del lenguaje natural y el analisis de datos estadisticos. Por ultimo se presenta la metodologia para la construccion de un servicio denominado SemancicService (Servicio de Comunicacion Semantico) desarrollado en TAO CORBA (The ACE ORB) en asociacion con un conjunto de librerias base (Redland RDF - librdf) que provee el soporte para interactuar con ontologias escritas en RDF y RDFS. Se introduce un analizador sintactico (Raptor RDF Syntax Library - libraptor2) para estudiar secuencias de simbolos a fin de determinar la estructura gramatical y un lenguaje de sintaxis tipo consulta (Rasqal RDF Query Library - librasqal) que se utilizara para construir y ejecutar consultas. El objetivo principal sera el de gestionar la informacion de la ontologia desarrollada e interoperar con servicios implementados en dispositivos embebidos en el campo de los ITS, (videocamaras, semaforos, paneles de trafico y dispositivos en-vehiculos, dispositivos moviles, PDAs, etc.). El SS (Semantic Service) puede ser implementado indistintamente tanto en entornos embebidos basados en entornos embebidos o bien en entornos PC. Las diferentes aplicaciones de trafico C\/S (cliente\/servidor), implementados en su mayoria en dispositivos con arquitecturas embebidas, interoperaran con el SS, que sera el encargado de proveer y gestionar toda la informacion y de intermediar entre ellos de manera dinamica e inteligente. SS actuara entonces como un agente inteligente entre proveedores y consumidores de servicios middleware enfocados a la gestion de los ITS. En el capitulo 4 se muestran los resultados obtenidos respecto al coste computacional de la capa middleware sobre dispositivos ARM (Advanced RISC Machines), el rendimiento y escalabilidad de los metodos propuestos para la creacion de la ontologias y los resultados, rendimientos y escalabilidad obtenidos en la implementacion del Servicio Semantico, comparandolo con el Servicio Trading de CORBA en un escenario real. Finalmente, en el capitulo 5 se dan a conocer las conclusiones de los diferentes capitulos, asi como las principales aportaciones realizadas. Se habla sobre la repercusion que podria tener esta tesis en futuros trabajos y se detallan las publicaciones realizadas durante el proceso de investigacion, tanto en revistas cientificas como en congresos internacionales.","venue":"","year":2013.0,"referenceCount":0,"citationCount":1,"fieldsOfStudy":["Philosophy"],"publicationDate":"2013-11-13","authors":[{"authorId":"134029315","name":"Gregor Recalde"},{"authorId":"133848877","name":"Derlis Orlando"}]},{"paperId":"01d168d1271ac771a1580f5d49e2121fd4bb7cff","title":"Domain ontology construction method based on knowledge graphs","abstract":"This paper proposed a domain ontology construction method based on knowledge graphs.This domain ontology was constructed based on the mature idea of software engineering by using the \"HowNet\" as the semantic knowledge resources,and knowledge graphs as a semantic representation.It has a clear structure with clear semantic meaning.It can provide effective supports for some applications such as semantic Web and information extraction.This paper introduced the concept of ontology,the standard of design,the process of modeling,and future prospects of ontology portability.This method was proved to be more effective than traditional ontology construction method in uncertain knowledge processing by experimental results.","venue":"","year":2011.0,"referenceCount":0,"citationCount":2,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"2113455734","name":"Zhang Lei"}]},{"paperId":"01d3d9501692a0689b90b8f92e45538a25dada59","title":"Design and implementation of database powered web systems - experiences from the DEMETER project","abstract":null,"venue":"Systems Implementation 2000","year":1998.0,"referenceCount":8,"citationCount":1,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"1689363","name":"K. M. G\u00f6schka"}]},{"paperId":"01d4c336c08520927ae143d661c799708cd8dfc6","title":"Mech Desk: An ontology based system to help drivers diagnosis vehicle problems","abstract":"Semantic Web is a vision about an extension of the existing World Wide Web, which provides tools and technologies to support the transparent exchange of information and knowledge among organizations. As one of the building blocks of Semantic Technology, ontologies are part of the W3C standards stack for the Semantic Web. Nowadays, multiple areas can be aborded by ontologies and the semantic web world, as the subject of this project, mechanics. Mechanics have been accentuated in a visible way, where the reality of living without means of transportation is not feasible in people's lives. The development of new methods to increase the knowledge of drivers and everyday people about automated vehicles is essential. Regarding cars, revisions, maintenance, inspections, change of parts, among others, are necessary and \"mandatory\" subjects and due to this, it is possible to prevent future damage by prolonging the life of the car. In certain cases, this doesn't happen, either due to wear of parts or unforeseen events, and despite being a busy market, drivers are not always informed about the best cares to take or the problems that may arise. As such, the theme of this project is to make a relationship between mechanical details, issues, and solutions, throughout an ontology, to help an everyday driver to a better perception of what he encounters at hand. For that purpose, the defined ontology was exposed via a mobile application, with it providing to the user, several details that he can or not relate, and trough them, provide a connection with a certain problem and solution. The semantic web ontology was developed in Prot\u00e9g\u00e9, exposed into Apache Jena Fuseki server, and was running in an Azure Virtual Machine, allowing it to be available into the OutSystems application.","venue":"International Conference on Frontiers of Educational Technologies","year":2022.0,"referenceCount":21,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":"2022-06-10","authors":[{"authorId":"2140114720","name":"D. Camelo"},{"authorId":"1492154520","name":"Jo\u00e3o Tiago Ascens\u00e3o"},{"authorId":"2113705500","name":"R. Alves"},{"authorId":"2069112909","name":"Paulo Matos"}]},{"paperId":"01d4f665a21a62e6bca317d68879c6669f89888d","title":"Combining Semantic Tools for Automatic Evaluation of Alternative Texts","abstract":"Automated accessibility evaluation will have an increasingly important role in the near future due to legal requirements to monitor the accessibility of the websites of public bodies in the European Union. However, automated evaluation tools are still limited in the scope of the conformance testing they are able to perform. Future solutions resorting to AI based techniques might help in addressing some of these limitations. In this paper we present an updated version of an algorithm that classifies the quality, from an accessibility perspective, of alternative texts for images in web pages. We evaluated the proposed algorithm on a set of 149 images and their corresponding alternative texts and found improved performance compared to the initial version of the algorithm.","venue":"International Cross-Disciplinary Conference on Web Accessibility","year":2019.0,"referenceCount":14,"citationCount":4,"fieldsOfStudy":["Computer Science"],"publicationDate":"2019-05-13","authors":[{"authorId":"143738437","name":"Carlos Duarte"},{"authorId":"143738437","name":"Carlos Duarte"},{"authorId":"145365688","name":"L. Carri\u00e7o"}]},{"paperId":"01d568ace8299a028901e7d4a30e873a780a04af","title":"Dynamic Selection of Best Service in Semantic Web Service Community","abstract":"How to precisely and meaningfully represent service capability and what is really detectable best service in available service space are two inescapable issues we must take into account when exploring dynamic selection of the best service. In this paper, Web Service Community (WSC) is proposed as a promising computational infrastructure in which web service is described in the way of concordant combination of explicit representation and implicit representation and attention on both commonness and peculiarity of service individual. In the context of WSC, we propose an efficient approach of best service selection based on foregone service experiences by manifesting directly the competition for same or similar function requests among Web service candidates.","venue":"International Conference on Computer Science and Software Engineering","year":2008.0,"referenceCount":10,"citationCount":3,"fieldsOfStudy":["Computer Science"],"publicationDate":"2008-12-12","authors":[{"authorId":"2827280","name":"Xuejuan Huang"},{"authorId":"8082805","name":"Xinmeng Chen"},{"authorId":"3153782","name":"Jinshuo Liu"},{"authorId":"2191705","name":"Jiazhen Xu"}]},{"paperId":"01d5a1f26fc5cc1306c86190ab6c7e3911a7e767","title":"Design and evaluation of an ontology-based tool for generating multiple-choice questions","abstract":"\nPurpose\nThe recent rise in online knowledge repositories and use of formalism for structuring knowledge, such as ontologies, has provided necessary conditions for the emergence of tools for generating knowledge assessment. These tools can be used in a context of interactive computer-assisted assessment (CAA) to provide a cost-effective solution for prompt feedback and increased learner\u2019s engagement. The purpose of this paper is to describe and evaluate a tool developed by the authors, which generates test questions from an arbitrary domain ontology, based on sound pedagogical principles encapsulated in Bloom\u2019s taxonomy.\n\n\nDesign\/methodology\/approach\nThis paper uses design science as a framework for presenting the research. A total of 5,230 questions were generated from 90 different ontologies and 81 randomly selected questions were evaluated by 8 CAA experts. Data were analysed using descriptive statistics and Kruskal\u2013Wallis test for non-parametric analysis of variance.\n\n\nFindings\nIn total, 69 per cent of generated questions were found to be useable for tests and 33 per cent to be of medium to high difficulty. Significant differences in quality of generated questions were found across different ontologies, strategies for generating distractors and Bloom\u2019s question levels: the questions testing application of knowledge and the questions using semantic strategies were perceived to be of the highest quality.\n\n\nOriginality\/value\nThe paper extends the current work in the area of automated test generation in three important directions: it introduces an open-source, web-based tool available to other researchers for experimentation purposes; it recommends practical guidelines for development of similar tools; and it proposes a set of criteria and standard format for future evaluation of similar systems.\n","venue":"Interactive Technology and Smart Education","year":2020.0,"referenceCount":39,"citationCount":3,"fieldsOfStudy":["Computer Science"],"publicationDate":"2020-02-12","authors":[{"authorId":"2296820","name":"M. Cubric"},{"authorId":"34726256","name":"M. Tosic"}]},{"paperId":"01d5e2f5e531cd97f3788185657a629caf48ea3f","title":"Adding Content-based 3D Model retrieval to semantic web","abstract":null,"venue":"International Conference on Intelligent Systems and Knowledge Engineering","year":2008.0,"referenceCount":0,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"9303289","name":"Shiguo Huang"},{"authorId":"40426830","name":"Mingquan Zhou"},{"authorId":"2004567","name":"Guohua Geng"},{"authorId":"2053976848","name":"Zheng Ning"},{"authorId":"3341384","name":"Kegang Wang"}]},{"paperId":"01d6ba85cd15a7120987fe4b82a0d9d5413dd5d9","title":"A Contract-Based Approach for Monitoring Collaborative Web Services Using Commitments in the Event Calculus","abstract":null,"venue":"WISE","year":2005.0,"referenceCount":10,"citationCount":19,"fieldsOfStudy":["Computer Science"],"publicationDate":"2005-11-20","authors":[{"authorId":"1804830","name":"M. Rouached"},{"authorId":"7261346","name":"Olivier Perrin"},{"authorId":"16558650","name":"C. Godart"}]},{"paperId":"01d7b662ed18826cedc33e6ca2e590a8a099c30e","title":"Using a Serious Game to Collect a Child Learner Speech Corpus","abstract":"We present an English-L2 child learner speech corpus, produced by 14 year old Swiss German-L1 students in their third year of learning English, which is currently in the process of being collected. The collection method uses a web-enabled multimodal language game implemented using the CALL-SLT platform, in which subjects hold prompted conversations with an animated agent. Prompts consist of a short animated Engligh-language video clip together with a German-language piece of text indicating the semantic content of the requested response. Grammar-based speech understanding is used to decide whether responses are accepted or rejected, and dialogue flow is controlled using a simple XML-based scripting language; the scripts are written to allow multiple dialogue paths, the choice being made randomly. The system is gamified using a score-and-badge framework with four levels of badges. We describe the application, the data collection and annotation procedures, and the initial tranche of data. The full corpus, when complete, should contain at least 5,000 annotated utterances.","venue":"International Conference on Language Resources and Evaluation","year":2014.0,"referenceCount":17,"citationCount":15,"fieldsOfStudy":["Computer Science"],"publicationDate":"2014-05-01","authors":[{"authorId":"11001577","name":"Claudia Baur"},{"authorId":"1761581","name":"Manny Rayner"},{"authorId":"3338503","name":"Nikos Tsourakis"}]},{"paperId":"01d955e5fec6ab3ef2290b91cf327c2d50587ead","title":"MUTUAL INFORMATION-AIDED SEMANTIC APPROACH FOR MEDICAL ONTOLOGY CONSTRUCTION","abstract":"The extraction of information from the web is dramatically important due to the immense growth of the World Wide Web. So, there is a need of techniques to extract the information from the web in a semantic way. Recent research works are concentrated on extracting the information directly from the web. But, this type of information extraction is not much as effective so there is a need of semantic extraction using ontology. In this paper, a model is developed for ontology construction which is then used for web information gathering. Here, web documents are extracted from the web and then, the concept from the web documents are identified. The concepts identified from the previous step are then used to build the taxonomy that is then utilized for the ontology construction. The model is implemented and the ontology is constructed using 100 documents relevant to medical field and the results are visualized.","venue":"","year":2014.0,"referenceCount":11,"citationCount":3,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"152708062","name":"Poonam Yadav"}]},{"paperId":"01d9fb472ad4346a8c06924e5b52230a9fa90e99","title":"Standard Part Library Resource Sharing Based on Cellular Ontology","abstract":"Aimed at the problems that the standard part library does not support heterogeneous CAD systems and the incompletion of the data information,a standard part library resource sharing framework based on cellular ontology was proposed.The cellular ontology model used Web Ontology Language (OWL) to develop the cellular ontology model.Using semantic mapping between legacy ontology and cellular ontology built the uniform representation of product model data,exchanged data information according to the cell,shielded the heterogeneity of information format,which implemented share of standard part library and real-time exchange of product model data among heterogeneous CAD systems.The applications in the synchronized collaborative design between Pro\/E,UG and CATIA were also introduced to prove the feasibility of the theories above.","venue":"","year":2010.0,"referenceCount":0,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"66695130","name":"Liu Xian-guo"}]},{"paperId":"01dc3b8513871eedf5cfc0b2d18d5d1b0c3335f4","title":"Enabling universal media experiences through semantic adaptation in the creative drama productionworkflow","abstract":"Viewers today have access to broadcasted audiovisual media via a multitude of platforms: from high definition movie theaters to smart cellular phones on the road, and online using the web. In order to provide these audiences with a proper universal media experience, each class of media consumption devices should receive a product not only adapted to its capabilities and usage environment, but also in a manner as to aid a better conveyance of the cinematic narrative, i.e., with proper subject framing, shots and sensible editing decisions. This paper presents a semantic adaptation system that incorporates the media adaptation process from the start of the production process. This allows producers, directors and other creative staff to operate in a multi-platform-aware workflow that compiles products with optimal adaptations for all intended distribution platforms. Production metadata obtained from various steps in the production process is used to guide the scaling, cropping and reframing operations applied to audiovisual material. In particular, this paper demonstrates how our system can be employed to adapt a single drama product into different versions, from high definition wide-shot cinematography to tightly shot cellular phone video.","venue":"Workshop on Image Analysis for Multimedia Interactive Services","year":2009.0,"referenceCount":7,"citationCount":3,"fieldsOfStudy":["Computer Science"],"publicationDate":"2009-05-06","authors":[{"authorId":"1934125","name":"D. V. Rijsselbergen"},{"authorId":"1831346","name":"Barbara Van De Keer"},{"authorId":"2186530","name":"M. Verwaest"},{"authorId":"1691320","name":"E. Mannens"},{"authorId":"144520698","name":"R. Walle"}]},{"paperId":"01dc98beaf13fb5d92458da021843776947a6af5","title":"The 8 th International Conference on Emerging Ubiquitous Systems and Pervasive Networks ( EUSPN 2017 ) A Lightweight Semantic Web-based Approach for Data Annotation on IoT Gateways","abstract":"Internet of Things (IoT) applications rely on networks composed of set of heterogeneous sensors and smart devices, which have the capability to constantly, observe the surroundings and gather data. This heterogeneity is reflected on raw data gathered by such type of systems. Consequently, the task of high-level IoT applications to interpret such data and detect events in the real world is more complex. Moreover, data heterogeneity leads to the lack of interoperability between IoT applications. Semantic Web (SW) technologies have been widely adopted to model and integrate data from different sources on the web; extending them to the IoT domain can be used to mitigate the aforementioned challenges. Semantically annotating IoT data is a fundamental step toward developing smarter and interoperable IoT applications. However, this type of process requires a large amount of computing resources, especially in scenarios where a large number of sensors is expected to be involved such as smart city. To address these challenges, we propose a lightweight semantic annotation approach that can be implemented on resource-constrained IoT gateways connected to a limited number of sensors. To evaluate the feasibility of the proposed approach, we have carried out a set of experimentations using a middleware prototype implementation. Several benchmarks are considered such as: Data size, response time, and resource utilization. c \u00a9 2017 The Authors. Published by Elsevier B.V. .","venue":"","year":2017.0,"referenceCount":6,"citationCount":26,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"1397315469","name":"Mahmud Al-Osta"},{"authorId":"25239380","name":"Bali Ahmed"},{"authorId":"89224314","name":"Gherbi Abdelouahed"}]},{"paperId":"01dcdd75088364caf83b193626050052c35e8145","title":"Allowing End Users to Query Graph-Based Knowledge Bases","abstract":null,"venue":"International Conference Knowledge Engineering and Knowledge Management","year":2012.0,"referenceCount":25,"citationCount":4,"fieldsOfStudy":["Computer Science"],"publicationDate":"2012-10-08","authors":[{"authorId":"2619539","name":"Camille Pradel"}]},{"paperId":"01dd19809cd812ef9109c1870dbb9eeda82f846a","title":"Stream Querying and Reasoning on Social Data","abstract":null,"venue":"Encyclopedia of Social Network Analysis and Mining","year":2014.0,"referenceCount":131,"citationCount":11,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"49549951","name":"J. Mondal"},{"authorId":"2064021125","name":"A. Deshpande"}]},{"paperId":"01dd92b8dd50ac5d5eb44f1b5c728b83e460cbec","title":"Trustworthiness-related Uncertainty of Semantic Web-style Metadata: A Possibilistic Approach","abstract":"We discuss the specific type of uncertainty deriving from the non-uniform trustworthiness of Semantic Web style metadata sources, arguing toward the feasibility of modal possibilistic reasoning based on trust assertions expressing such uncertainty.","venue":"Uncertainty Reasoning for the Semantic Web","year":2007.0,"referenceCount":6,"citationCount":8,"fieldsOfStudy":["Computer Science"],"publicationDate":"2007-11-12","authors":[{"authorId":"1734072","name":"P. Ceravolo"},{"authorId":"145522617","name":"E. Damiani"},{"authorId":"2826499","name":"C. Fugazza"}]},{"paperId":"01dd9ee0ab8bee9b9e022c105acf47318e6d3a3f","title":"Creating Multidimensional Views from RDF Sources","abstract":null,"venue":"","year":2017.0,"referenceCount":13,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":"2017-04-14","authors":[{"authorId":"40485747","name":"Yassine Laadidi"},{"authorId":"2747412","name":"M. Bahaj"}]},{"paperId":"01de0f35ac2d0f0a4f9dec23c638db3d659c49d8","title":"Monitoring the Web Sentiment, The Italian Prime Minister's Case","abstract":"The world has fundamentally changed as the Internet has become a universal means of communication. The Web is a huge virtual space where to express individual opinions and influence any aspect of life. Internet contains a wealth of data that can be mined to detect valuable opinions, with implications even in the political arena. Nowadays the Web sources are more accessible and valuable than ever before, but most of the times the true valuable information is hidden in thousands of textual pages. Their transformation into information is therefore strongly linked to their automatic lexical analysis and semantic synthesis. This poster describes a Knowledge Mining study performed on over 1000 news articles or posts in forum\/blogs, concerning the Italian Prime Minister Silvio Berlusconi, involved last year in the sexual scandal. All these textual contributions have been Morpho-Syntactically analysed, Semantically Role labelled and Clustered in order to find meaningful similarities, hilite possible hidden relationships and evaluate their sentiment polarity.","venue":"International Conference on Advances in Social Networks Analysis and Mining","year":2010.0,"referenceCount":13,"citationCount":15,"fieldsOfStudy":["Computer Science"],"publicationDate":"2010-08-09","authors":[{"authorId":"33413358","name":"F. Neri"},{"authorId":"49126319","name":"P. Geraci"},{"authorId":"2552022","name":"F. Camillo"}]},{"paperId":"01def99e199a030cb11e2ca304b829c47af2f841","title":"Reports of the AAAI 2014 Conference Workshops","abstract":"The AAAI-14 Workshop program was held Sunday and Monday, July 27\u201328, 2012, at the Qu\u00e9bec City Convention Centre in Qu\u00e9bec, Canada. Canada. The AAAI-14 workshop program included fifteen workshops covering a wide range of topics in artificial intelligence. The titles of the workshops were AI and Robotics; Artificial Intelligence Applied to Assistive Technologies and Smart Environments; Cognitive Computing for Augmented Human Intelligence; Computer Poker and Imperfect Information; Discovery Informatics; Incentives and Trust in Electronic Communities; Intelligent Cinematography and Editing; Machine Learning for Interactive Systems: Bridging the Gap between Perception, Action and Communication; Modern Artificial Intelligence for Health Analytics; Multiagent Interaction without Prior Coordination; Multidisciplinary Workshop on Advances in Preference Handling; Semantic Cities \u2014 Beyond Open Data to Models, Standards and Reasoning; Sequential Decision Making with Big Data; Statistical Relational AI; and The World Wide Web and Public Health Intelligence. This article presents short summaries of those events.","venue":"The AI Magazine","year":2015.0,"referenceCount":26,"citationCount":2,"fieldsOfStudy":["Computer Science","Engineering"],"publicationDate":"2015-03-25","authors":[{"authorId":"1961238","name":"Stefano V. Albrecht"},{"authorId":"1689289","name":"Andr\u00e9 Barreto"},{"authorId":"2239754","name":"Darius Braziunas"},{"authorId":"144795713","name":"D. Buckeridge"},{"authorId":"1806041","name":"H. Cuay\u00e1huitl"},{"authorId":"3198238","name":"Nina Dethlefs"},{"authorId":"36634859","name":"M. Endres"},{"authorId":"5689899","name":"Amir-massoud Farahmand"},{"authorId":"144797962","name":"M. Fox"},{"authorId":"2228238","name":"L. Frommberger"},{"authorId":"1704808","name":"Sam Ganzfried"},{"authorId":"145526918","name":"Y. Gil"},{"authorId":"3062708","name":"S\u00e9bastien Guillet"},{"authorId":"145720231","name":"L. Hunter"},{"authorId":"1763814","name":"A. Jhala"},{"authorId":"1746871","name":"K. Kersting"},{"authorId":"1765407","name":"G. Konidaris"},{"authorId":"1863173","name":"F. L\u00e9cu\u00e9"},{"authorId":"1683896","name":"Sheila A. McIlraith"},{"authorId":"145986014","name":"Sriraam Natarajan"},{"authorId":"2994264","name":"Z. Noorian"},{"authorId":"143715817","name":"D. Poole"},{"authorId":"2898850","name":"R\u00e9mi Ronfard"},{"authorId":"1815138","name":"A. Saffiotti"},{"authorId":"1398105314","name":"Arash Shaban-Nejad"},{"authorId":"50784532","name":"Biplav Srivastava"},{"authorId":"1699108","name":"G. Tesauro"},{"authorId":"1400349389","name":"Rosario A. Uceda-Sosa"},{"authorId":"1749506","name":"Guy Van den Broeck"},{"authorId":"2541098","name":"M. V. Otterlo"},{"authorId":"1912476","name":"Byron C. Wallace"},{"authorId":"144834415","name":"Paul Weng"},{"authorId":"38556322","name":"J. Wiens"},{"authorId":"40539618","name":"J. Zhang"}]},{"paperId":"01dfe982044ad357410fa731659e77c83279ae33","title":"ConBrowse - Contextual Content Browsing","abstract":"The World Wide Web today underlies a number of trends and visions that will change the manner of using and browsing it in a significant manner. The Semantic Web, the Mobile Web, or the Web of Things are three of these visions that already have produced manifold approaches and concepts, which, amongst others, focus on context-aware applications as a use case. These applications have the potential of usefully linking legacy web services and the personal area network of the user enabling novel services and tools. \n \nAs an approach that combines and harmonizes these different trends, we propose the concept of contextual content browsing in this paper, i.e., a context-aware approach for web browsing that utilizes personal information from the user to adapt web pages while he or she is browsing. In this manner, personalized and context-aware web content provisioning is enabled by connecting personal context sources and the web browser. Accordingly, we propose a framework, markup language, and software components to enable our approach.","venue":"2010 7th IEEE Consumer Communications and Networking Conference","year":2010.0,"referenceCount":16,"citationCount":4,"fieldsOfStudy":["Computer Science"],"publicationDate":"2010-01-09","authors":[{"authorId":"31901658","name":"C. Jacob"},{"authorId":"2795760","name":"S. Steglich"}]},{"paperId":"01e11da4edf15f590f764c7864cacd7dfa0a49cb","title":"SWSRS : Semantic Web service Retrieval Syst m based on Functional a d QOS Evaluation","abstract":"In this paper, Web service discovery involves the service selection based on parameter-based service extraction and semantic similarity-based matching. In this approach, SWSRS is considered as the Web service Retrieval System. This approach assumes that the web service interfaces are defined in WSDL files. In this approach the similarity evaluation between the two interfaces are evaluated, higher the similarity less are the difference among their interfaces. This work based on the structure of WSDL and Semantic Web documents. The proposed approach incorporates with QOS requirements. However, earlier the QOS based non-functional requirement search has not been addressed. The lack of textual information makes keyword-based search models unable to filter irrelevant search results, and therefore, become very primitive means for effectively discovering web services. Therefore, the proposed approach i.e., SWSRS not only discussed the pertinent web service, it provides the services based on functional and QOS aspects. Index Terms \u2013 Web service discovery, information search and retrieval, WSDL, OWL, QOS .","venue":"","year":2018.0,"referenceCount":14,"citationCount":0,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"144767881","name":"S. Ammal"}]},{"paperId":"01e1791342a76841a568024e0073225558a0f9f7","title":"MEDIALOEP: OPTIMIZING SEARCH IN A BROADCASTER ARCHIVE","abstract":"In this demonstration, we introduce \u2018MediaLoep\u2019, a media search platform developed to enable ef\ufb01cient media retrieval from a broadcaster archive. We illustrate how media search can be optimized by capturing valuable data generated during the media production process. The MediaLoep platform is based on Semantic Web technologies, allowing us to connect to the Linked Open Data cloud. This facilitates the introduction of search functionalities such as advanced faceted search and semantic query suggestion.","venue":"","year":2011.0,"referenceCount":2,"citationCount":1,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"1987117","name":"P. Debevere"},{"authorId":"2990414","name":"D. V. Deursen"},{"authorId":"1691320","name":"E. Mannens"},{"authorId":"144520698","name":"R. Walle"},{"authorId":"51201616","name":"K. Braeckman"},{"authorId":"39227688","name":"R. Sutter"}]},{"paperId":"01e341c0cff2e1e6b7c35242b7e25920a45c8592","title":"Doc-KG: Unstructured documents to knowledge graph construction, identification and validation with Wikidata","abstract":"The exponential growth of textual data in the digital era underlines the pivotal role of Knowledge Graphs (KGs) in effectively storing, managing, and utilizing this vast reservoir of information. Despite the copious amounts of text available on the web, a significant portion remains unstructured, presenting a substantial barrier to the automatic construction and enrichment of KGs. To address this issue, we introduce an enhanced Doc\u2010KG model, a sophisticated approach designed to transform unstructured documents into structured knowledge by generating local KGs and mapping these to a target KG, such as Wikidata. Our model innovatively leverages syntactic information to extract entities and predicates efficiently, integrating them into triples with improved accuracy. Furthermore, the Doc\u2010KG model's performance surpasses existing methodologies by utilizing advanced algorithms for both the extraction of triples and their subsequent identification within Wikidata, employing Wikidata's Unified Resource Identifiers for precise mapping. This dual capability not only facilitates the construction of KGs directly from unstructured texts but also enhances the process of identifying triple mentions within Wikidata, marking a significant advancement in the domain. Our comprehensive evaluation, conducted using the renowned WebNLG benchmark dataset, reveals the Doc\u2010KG model's superior performance in triple extraction tasks, achieving an unprecedented accuracy rate of 86.64%. In the domain of triple identification, the model demonstrated exceptional efficacy by mapping 61.35% of the local KG to Wikidata, thereby contributing 38.65% of novel information for KG enrichment. A qualitative analysis based on a manually annotated dataset further confirms the model's excellence, outshining baseline methods in extracting high\u2010fidelity triples. This research embodies a novel contribution to the field of knowledge extraction and management, offering a robust framework for the semantic structuring of unstructured data and paving the way for the next generation of KGs.","venue":"Expert Syst. J. Knowl. Eng.","year":2024.0,"referenceCount":24,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":"2024-05-08","authors":[{"authorId":"2163704945","name":"Muhammad Salman"},{"authorId":"2300717249","name":"Armin Haller"},{"authorId":"51313540","name":"S. M\u00e9ndez"},{"authorId":"1394609613","name":"Usman Naseem"}]},{"paperId":"01e3c6e1cac993a59ff537c4bfbc6dc3174bc369","title":"Web applications for the semantic categories","abstract":"This article deals with the web applications, which are helpful for constructing the semantic categories in various types of disciplines: mathematics, physics, statistics, computer science, linguistics. This software aims at forming the components within the semantic space of the category with unstable hierarchical structure. Such semantic structure with the core and peripheries is observed in the category of deviation. The core includes the most statistically frequent elements, which are connected with each other. The periphery consists of semantically related terms with the components of the core. This structure is considered in mathematics or computer science under the support of applications within cognitive and computational linguistics. Some of the applications are used online or can be designed by the scholar in accordance with the tasks of the research, using special tools for devices. The example of this work is the category of deviation in the framework of mathematical modeling in connection with computational linguistics, building the co-occurrence network of units, constructing frequency list, and doing hierarchical cluster analysis of the units in the system \u201ccore-periphery\u201d of the semantic concept, forming the domains. The quantitative content analysis, taking into account the statistical data of contextual analysis and mapping these measurements with web applications, is the key approach in this paper. The object of the quantitative content analysis here is the units of expressing the category of deviation in the work \u201cThe Shadow over Innsmouth\u201d by H. Lovecraft. The data received in this work can be essential for scholars in the spheres of computer science, mathematics, physics, computational linguistics as the method of understanding the connections between mathematical operations used in web applications and the meaning. Units within the semantic fields of the category of deviation were considered from the position of quantitative content analysis, mathematics, and cognitive science for the first time.","venue":"THE 7TH INTERNATIONAL CONFERENCE ON ENGINEERING, APPLIED SCIENCES AND TECHNOLOGY: (ICEAST2021)","year":2021.0,"referenceCount":14,"citationCount":0,"fieldsOfStudy":null,"publicationDate":"2021-09-15","authors":[{"authorId":"119114440","name":"A. Ptashkin"}]},{"paperId":"01e3c89c181e594c5a40b91de59ad3e630af0c8b","title":"Using reformulations to improve question answering","abstract":"This project has two major goals. In the first phase, we present a method for the automatic acquisition of reformulations from natural language questions. We hope to find useful and generic reformulation patterns, which can be used in our question answering system to find candidate answers. We use some examples of different types of questions and their right answers as training set and the system automatically extracts the patterns from retrieved documents. The system also calculates and assigns a weight to each of the extracted patterns. These patterns are added to the patterns set of the current Web-QA component. In the second part, we present a method to filter out noisy candidate answers and re-rank candidate answers in our Web-QA module by using semantic relations. We use the original Web-QA module of QUANTUM and developed the Web-QA2 module for this thesis. We use the 1400 questions of the TREC-8, TREC-9, and TREC-10 competitions for training to develop the reformulation patterns and the filtering algorithm and use the 500 questions of TREC-11 for testing.","venue":"","year":2005.0,"referenceCount":0,"citationCount":0,"fieldsOfStudy":["Mathematics"],"publicationDate":null,"authors":[{"authorId":"1966879","name":"Jamileh Yousefi"}]},{"paperId":"01e5edf6fe0c21225d14f77b05e0faac0e9176b2","title":"Service Oriented Architectures and Semantic Web Processes","abstract":"interface portType (abstract) operation (concrete) message (abstract) message concrete implementation binding (concrete) operation (concrete) message (concrete) message service concrete endpoint port types","venue":"","year":2004.0,"referenceCount":5,"citationCount":10,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"52108120","name":"Francisco Cubera"},{"authorId":"2065888927","name":"Kunal Verma"},{"authorId":"144463965","name":"A. Sheth"}]},{"paperId":"01e6c9b3042730b686aab96b1a1ccb4f79a9d2a6","title":"Wikidata as a semantic framework for the Gene Wiki initiative","abstract":"Open biological data is distributed over many resources making it challenging to integrate, to update and to disseminate quickly. Wikidata is a growing, open community database which can serve this purpose and also provides tight integration with Wikipedia. In order to improve the state of biological data, facilitate data management and dissemination, we imported all human and mouse genes, and all human and mouse proteins into Wikidata. In total, 59,530 human genes and 73,130 mouse genes have been imported from NCBI and 27,662 human proteins and 16,728 mouse proteins have been imported from the Swissprot subset of UniProt. As Wikidata is open and can be edited by anybody, our corpus of imported data serves as the starting point for integration of further data by scientists, the Wikidata community and citizen scientists alike. The first use case for this data is to populate Wikipedia Gene Wiki infoboxes directly from Wikidata with the data integrated above. This enables immediate updates of the Gene Wiki infoboxes as soon as the data in Wikidata is modified. Although Gene Wiki pages are currently only on the English language version of Wikipedia, the multilingual nature of Wikidata allows for a usage of the data we imported in all 280 different language Wikipedias. Apart from the Gene Wiki infobox use case, a powerful SPARQL endpoint and up to date exporting functionality (e.g. JSON, XML) enable very convenient further use of the data by scientists. In summary, we created a fully open and extensible data resource for human and mouse molecular biology and biochemistry data. This resource enriches all the Wikipedias with structured information and serves as a new linking hub for the biological semantic web.","venue":"bioRxiv","year":2015.0,"referenceCount":32,"citationCount":75,"fieldsOfStudy":["Biology","Computer Science","Medicine"],"publicationDate":"2015-11-19","authors":[{"authorId":"1399191961","name":"Sebastian Burgstaller-Muehlbacher"},{"authorId":"48709451","name":"A. Waagmeester"},{"authorId":"49049139","name":"Elvira Mitraka"},{"authorId":"49060916","name":"J. Turner"},{"authorId":"49074845","name":"Timothy Putman"},{"authorId":"2052406097","name":"Justin Leong"},{"authorId":"144551309","name":"P. Pavlidis"},{"authorId":"2126316","name":"L. Schriml"},{"authorId":"1751920","name":"Benjamin M. Good"},{"authorId":"1759053","name":"A. Su"}]},{"paperId":"01e7ad47ee069b39db3ce11f10d5d2b8b15b3c1e","title":"A Preliminary Research on the Dynamic Building of the Personalized Teaching Materials on Web","abstract":"This paper outlines an approach to dynamically build the teaching materials of a Web-based online course based on the concepts of learning objects. This technology introduces an approach to building the teaching materials to best match to individual study styles, where the teaching content is broken down into several manageable components that can be used, re-used, or referenced in different teaching units. In this paper the concepts of learning objects are described and then the methods of storing and managing the metadata which describes the semantic of learning objects on the network are presented. After that the issue of granularity of learning objects and the contextual meanings on a Web page are discussed. Finally, an experimental system developed by us, as an initial application of the technology, is reported.","venue":"","year":2003.0,"referenceCount":0,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"2094383023","name":"Pan Wei-dong"}]},{"paperId":"01e92d11cfcb00e1f1895d13dd5510dc6403d90a","title":"Information Retrieval Model in Self Directed E-Learning Using Dynamic Semantic Network","abstract":"Self-directed e-learning focuses on the independent learner one who engages in education at his own space free from curricular obligation. E-learning systems accessible through the Internet have great potential to improve education through extending educational opportunities for those who cannot use the time and place bound traditional courses and offering new services and functions that enhance the traditional classroom. Traditional information retrieval techniques have become inadequate, since significant differences exist between students, such as their learning rate, personal interest and domain knowledge. To alleviate this problem, personalization becomes a popular remedy to customize the web environment for the learners. Therefore the goal in e-learning is to be established as \"turning learners into better learners\". The learner's interest model is constructed based on the dynamic semantic network, which represents the learner's level of interest in the material currently being examined by the e-learner. Thus dynamic user profiles are maintained based on which, the information retrieval model is constructed. Considering the long term interest of the learner this retrieval model takes the initiative to push any newly entered information to the learner if the learning material is judged as being relevant to the learner.","venue":"","year":2015.0,"referenceCount":0,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":"2015-04-01","authors":[{"authorId":"71963357","name":"LathaKurian"}]},{"paperId":"01e94cf069626a10293594127fa16d2f2960c625","title":"Semantic Web Based Dynamic Workflow Interoperation","abstract":"Dynamic workflow interoperation is an important issue in the workflow interoperation area. The key problem of dynamic workflow interoperation is how to represent and understand the semantic of workflow. In addition, the emerging e-business makes workflow interoperation across Internet. Therefore, it becomes another problem to realize Internet-scale workflow interoperation. In this article, by analyzing the characteristics of workflow interoperation, a dynamic workflow interoperation model is proposed, which takes Web service as the interoperation interface and semantic Web technology as the service discovery mechanism and can support interoperation across Internet.","venue":"","year":2004.0,"referenceCount":0,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"2066476707","name":"Yuqin Shu"}]},{"paperId":"01e9eda6a16cc7806bf36068c81f3ee6cb9f1db4","title":"A cache-based method to improve query performance of linked Open Data cloud","abstract":null,"venue":"Computing","year":2020.0,"referenceCount":47,"citationCount":5,"fieldsOfStudy":["Computer Science"],"publicationDate":"2020-05-14","authors":[{"authorId":"3404535","name":"Usman Akhtar"},{"authorId":"1699627288","name":"Anita Sant\u2019Anna"},{"authorId":"70234558","name":"Chang-Ho Jihn"},{"authorId":"2161256","name":"Muhammad Asif Razzaq"},{"authorId":"37390258","name":"J. Bang"},{"authorId":"31273100","name":"Sungyoung Lee"}]},{"paperId":"01ea1eaacb059ddf7fe3c72c44ae027f08520b13","title":"Towards an authorisation model for distributed systems based on the Semantic Web","abstract":"Authorisation is a crucial process in current information systems. Nowadays, many of the current authorisation systems do not provide methods to describe the semantics of the underlying information model which they are protecting. This fact can lead to mismatch problems between the semantics of the authorisation model and the semantics of the underlying data and resources being protected. In order to solve this problem, this paper describes an authorisation model based on Semantic Web technologies. This authorisation model uses the common information model (CIM) to represent the underlying information model. For this reason, a new conversion process of CIM into the Semantic Web languages has been proposed converting properly the semantics available in the CIM model. This representation provides a suitable information model based on a well-known logic formalism for implementing the authorisation model and a formal language for describing concisely the semantic of the information models being protected. The formal authorisation model supports role-based access control (RBAC), hierarchical RBAC, conditional RBAC and object hierarchies, among other features. Moreover, this paper describes an authorisation architecture for distributed systems taking into account aspects such as privacy among parties and trust management. Finally, some implementation aspects of this system have also been described.","venue":"IET Information Security","year":2010.0,"referenceCount":21,"citationCount":11,"fieldsOfStudy":["Computer Science"],"publicationDate":"2010-12-20","authors":[{"authorId":"2694798","name":"J. A. Calero"},{"authorId":"1700329","name":"G. P\u00e9rez"},{"authorId":"1398022789","name":"A. G\u00f3mez-Skarmeta"}]},{"paperId":"01ea8d55468f02fb41f9a508edc8d006810c9649","title":"The NeoCrawler: identifying and retrieving neologisms from the internet and monitoring ongoing change","abstract":"Why do some new words manage to enter the lexicon and stay there while others drop out of use and are neither used nor heard anymore? Of interest to both lay people and linguists, this question has not been answered in an empirically convincing manner to date, mainly because systematic methods have not yet been found for spotting new words as soon as possible after their first occurrence and monitoring their early development and spread as exhaustively as possible. In this paper we present a new and improved tool which is designed to accomplish precisely these tasks when applied to material from the Internet. Following a brief review of existing tools for retrieving linguistic data from the Web (Section 2), we will introduce in some detail a tailor-made webcrawler, the so-called NeoCrawler, which identifies and retrieves neologisms from the Internet and stores data necessary for the systematic monitoring of their early development with regard to form and meaning as well as spread (Section 3). Following this description, we will present a case study discussing the results of an analysis of the neologism detweet with regard to its di\u00a4usion, institutionalization, lexicalization and lexical networkformation (Section 4). The study indicates that the NeoCrawler can indeed be applied fruitfully in the study of ongoing processes relating to how the meanings and forms of new words are negotiated in the speech community, how words spread in the early stages of their life cycles and how they begin to establish themselves in lexical and semantic networks.","venue":"","year":2011.0,"referenceCount":36,"citationCount":37,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"66396030","name":"D. Kerremans"},{"authorId":"66837804","name":"Susanne Stegmayr"},{"authorId":"49580528","name":"H. Schmid"}]},{"paperId":"01eb069109bef71187ca3d7635463b866d5472f8","title":"A categorical approach to ontology alignment","abstract":"Ontology matching and alignment is a key mechanism for linking the diverse datasets and ontologies arising in the Semantic Web. We show that category theory provides the powerful abstractions needed for a uniform treatment at various levels: semantics, language design, reasoning and tools. The Distributed Ontology Language DOL is extended in a natural way with constructs for networks of ontologies. We in particular show how the three semantics of Zimmermann and Euzenat can be uniformly and faithfully represented using these DOL language constructs. Finally, we summarise how the DOL alignment features are currently being implemented in the Ontohub\/ Hets ecosystem, including support for the OWL and Alignment APIs.","venue":"","year":2014.0,"referenceCount":32,"citationCount":20,"fieldsOfStudy":["Computer Science"],"publicationDate":"2014-10-20","authors":[{"authorId":"1737037","name":"M. Codescu"},{"authorId":"1764365","name":"Till Mossakowski"},{"authorId":"1781546","name":"O. Kutz"}]},{"paperId":"01ec416ace252e6b71b38d4cc8c785baedc9ba7a","title":"A Distributed, Collaborative, Structuring Model for a Clinical-Guideline Digital-Library","abstract":"The Digital Electronic Guideline Library (DeGeL) is a Web-based framework and a set of distributed tools that facilitate gradual conversion of clinical guidelines from free text, through semi-structured text, to a fully structured, executable representation. Thus, guidelines exist in a hybrid, multiple-format representation The three formats support increasingly sophisticated computational tasks. The tools perform semantic markup, classification, search, and browsing, and support computational modules that we are developing, for run-time application and retrospective quality assessment. We describe the DeGeL architecture and its collaborative-authoring authorization model, which is based on (1) multiple medical-specialty authoring groups, each including a group manager who controls group authorizations, and (2) a hierarchical authorization model based on the different functions involved in the hybrid guideline-specification process. We have implemented the core modules of the DeGeL architecture and demonstrated distributed markup and retrieval using the knowledge roles of two guidelines ontologies (Asbru and GEM). We are currently evaluating several of the DeGeL tools.","venue":"American Medical Informatics Association Annual Symposium","year":2003.0,"referenceCount":14,"citationCount":20,"fieldsOfStudy":["Computer Science","Medicine"],"publicationDate":null,"authors":[{"authorId":"48739778","name":"Yuval Shahar"},{"authorId":"1929475","name":"Erez Shalom"},{"authorId":"1402344193","name":"Alon Mayaffit"},{"authorId":"37657688","name":"O. Young"},{"authorId":"1398782737","name":"M. Galperin-Aizenberg"},{"authorId":"145682207","name":"S. Martins"},{"authorId":"2216258","name":"M. Goldstein"}]},{"paperId":"01ec6f4b5ec1fb2683ec58efdd8c1c522605765f","title":"XML Schema Matching \\& XML Data Migration \\& Integration: A Step Towards The Semantic Web Vision","abstract":"In the past ten years, computers and especially the Internet have managed to become an important part of our everyday life. For a big part, this can be credited to the creation of the World Wide Web, which has become a new means for retrieving information, providing education, recreation, and other services faster and more efficiently. While this is true, one can say that the Web is still in a primitive state. More and more people publish web pages every day and the quality in terms of practicality and aesthetics of the pages becomes better and better, but the fact is that the Web receives only a very limited amount of help from computers. In order to bring the machines more into action, two steps must be taken: put data on the Web in a form that machines can understand or convert it into that form and, second, provide the machines with the means to process this data. XML is the first step towards this end. XML is a markup language designed to structure and carry data in a sensible way, thus helping programmers and web developers manipulate the data easily and efficiently. But XML is not the solution by itself. XML is merely a convenient way to structure and carry data it does not do anything by itself. The second step is divided into two parts: logic inference tools using RDF and ontologies, and tools that automatically perform specific tasks which are up to now manual. The first part is a very hot research area at this time, fuelled by ideas stated as early as the 1960\u2019s for artificial intelligence. XML in coordination with RDF and ontologies are envisaged to enable computers provide high-level services by communicating with other web services and applications. The second part is concerned with providing tools to automatically perform tasks that are up to now expensive and time-consuming. Such tasks are importing\/exporting data from\/to XML files, automatic schema matching and migrating and integrating XML data. The realization of the Semantic Web vision depends on the implementation of the above two steps and is based on the already existing structure. \u201dThe Semantic Web is not a separate Web, but an extension of the current one, in which information is given well-defined meaning, better enabling computers and people to work in cooperation. [...] In the near future, these developments will usher in significant new functionality, as machines become much better able to process and \u2019understand\u2019 the data that they merely display at present\u201d [1].","venue":"","year":2003.0,"referenceCount":18,"citationCount":8,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"2368824","name":"Lucas Zamboulis"}]},{"paperId":"01ed1366eafd68baad1b41a404abe472a46c98f1","title":"Using Description Logic Semantics of the Web Service Behavior","abstract":"This paper focuses on the behavior of Web services and the use of description logic expression level of formal for additional information on the behavior. Interactive sequences using DL framework to describe sequential and parallel split, the content of research on Web service discovery and composition are to provide a certain reference value. Without changing the code,the expansion of the description of the characteristics of Web services; through combining with the ontology language OWLDL, based on current research results of Semantic Web services on the web service behavior description increase.","venue":"","year":2014.0,"referenceCount":0,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"2061582846","name":"Cui Don"}]},{"paperId":"01eefcab5f910445b12da00611d8eb1d0b1876e6","title":"Descri\u00e7\u00e3o de recursos em ambientes digitais: o modelo FRBROO","abstract":"It addresses the development of standards and metadata formats for the provision of information contents in digital media in an interoperable way, whose search requirements can be mediated by both humans and operated by software agents. Analyzes the semantic web impacts on organizational processes and access to information and perspectives brought by the FRBR conceptual model for the field of descriptive cataloging and shows the methodological developments in relation to the development of ontologies and vocabularies FRBR. Highlights the progress of the FRBR model toward the object-oriented approach through studies about the FRBRoo, new paradigm thought from the Principles of Cataloging, whose main concern has been to develop rules more intuitive that allow users to seek information independently. Brings, as result of reflections, that the representation and description of bibliographic data needs to be rethought from conceptual models of type ER (Entity-Relationship) in order to achieve good levels of interoperability both from the technical point of view, share and exchange of data, such as semantic, from the identification of relationships between data sets available in the system itself or outside. It shows that the representation of metadata built on a flexible structure and their descriptions in RDF language optimize the relationships between bibliographic entities and enhances the use and reuse of information between users. We emphasize that the use of metadata structure standards when associated the description using identifiers allow software agents identify\u00a0 the essential entities to recover the different resources available on the web from interconnecting logics and intuitive; declarations whose syntax and semantics are similar to the language and the user thought.","venue":"","year":2020.0,"referenceCount":0,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":"2020-01-17","authors":[{"authorId":"118025877","name":"Elisabete Gon\u00e7alves de Souza"},{"authorId":"134860325","name":"Wellington Freire Cunha Costa"}]},{"paperId":"01ef0a426580de2be9e56c28a5cdfc339bc82995","title":"An Improved Semantic Query Expansion Approach Using Incremental User Tag Profile for Efficient Information Retrieval","abstract":"The World Wide Web (WWW) comprises a wide range of information, and it is mainly operated on the principles of keyword matching which often reduces accurate information retrieval. The Keyword matching mechanism faces word mismatch problems while retrieving relevant information. Furthermore, the inherent ambiguity of short keyword queries demands enhanced methods for Web retrieval. Ontological-based query expansion is one of the primary methods for Web retrieval, and it handles the vocabulary mismatch problem by computing semantics from the ontology knowledgebase. However, the retrieval of information relevant to user interests is a major challenge. In this paper, we seek to improve retrieval performance by leveraging user preferences and ontology semantics in the process of query expansion. The expansion words are added to the user query using WordNet lexicon and domain ontology. Additionally, the search intent of the user is also added as expansion words by exploiting a tag-based user profile. When it comes to obtaining relevant documents, the proposed framework outperforms the keyword-based approach by achieving a 76% F1-score. This noticeable improvement accurately reflects the importance of including user intents in the process of semantic query expansion.","venue":"VFAST Transactions on Software Engineering","year":2022.0,"referenceCount":6,"citationCount":1,"fieldsOfStudy":null,"publicationDate":"2022-09-21","authors":[{"authorId":"2279469410","name":"Muhammad Ahsan Raza"},{"authorId":"2275816218","name":"M. Ali"},{"authorId":"144225210","name":"Maruf Pasha"},{"authorId":"2279857046","name":"Mubashir Ali"}]},{"paperId":"01f0b2b8d5185621aacbc7f85c330065920d1f16","title":"Semantic Web processes: semantics enabled annotation, discovery, composition and orchestration of Web scale processes","abstract":"This paper deals with the evolution of inter-enterprise and Web scale process to support e-commerce and e-services. It taps into the promises of two of the hottest R&D and technology areas: Web services and the semantic Web. It presents how applying semantics to each of the steps in the semantic Web process lifecycle can help address critical issues in reuse, integration and scalability.","venue":"Proceedings of the Fourth International Conference on Web Information Systems Engineering, 2003. WISE 2003.","year":2003.0,"referenceCount":8,"citationCount":8,"fieldsOfStudy":["Computer Science"],"publicationDate":"2003-12-10","authors":[{"authorId":"144374050","name":"J. Cardoso"},{"authorId":"144463965","name":"A. Sheth"}]},{"paperId":"01f0c2e6815a1275768b72b4b5a4ab9089e69b01","title":"A Sensor-Based Framework to Support Clinicians in Dementia Assessment: The Results of a Pilot Study","abstract":null,"venue":"International Symposium on Ambient Intelligence","year":2015.0,"referenceCount":13,"citationCount":13,"fieldsOfStudy":["Computer Science","Psychology"],"publicationDate":null,"authors":[{"authorId":"3278800","name":"A. Karakostas"},{"authorId":"1696389","name":"G. Meditskos"},{"authorId":"1727843","name":"Thanos G. Stavropoulos"},{"authorId":"1715604","name":"Y. Kompatsiaris"},{"authorId":"144515297","name":"M. Tsolaki"}]},{"paperId":"01f0dcbfa0e68584196bcf530aff47aca9598b88","title":"The Ontology-Based Approach Supporting Holistic Energy-Tunnel Design considering Cost, Heat Flux, and System Feasibility","abstract":"As an emerging geothermal structure, the energy tunnel has been an important part of geothermal engineering. However, the conventional methods for designing energy tunnels mostly rely on complex numerical models. Furthermore, a macrolevel multidomain collaborative design method to consider multiple areas and design indicators is unavailable. This study combined ontology and semantic Web rule language to establish the domain knowledge of energy tunnels which is an enrichment of the conventional ground source heat pump domain knowledge and develop a comprehensive decision-making tool named OntoETS for the design of energy-tunnel systems. The tool can promote the optimal design scheme with an optimal combination of multiple indexes through an analysis of the economy, heat flux, and system feasibility of the energy-tunnel system from a macroperspective by combining multiple domains. Furthermore, a case study was conducted to demonstrate the effectiveness and practicability of the developed holistic decision-making system.","venue":"Advances in Materials Science and Engineering","year":2021.0,"referenceCount":38,"citationCount":1,"fieldsOfStudy":null,"publicationDate":"2021-11-29","authors":[{"authorId":"2061864308","name":"K. Meng"},{"authorId":"2052274828","name":"Chunyi Cui"},{"authorId":"2200135690","name":"Cheng Zhang"},{"authorId":"2109527788","name":"Hailong Liu"}]},{"paperId":"01f12a6ffc11d7422edd48876887c02a032fbfb3","title":"Accelerated Sparse Learning on Tag Annotation for Web Service Discovery","abstract":"Learning latent features of Web services will greatly boost the ability of search engine to discover relevant services. Extracted information from Web Service Description Language (WSDL) documents of services is less efficient due to the limited usage of data source. Recently, a number of ongoing works have indicated incorporating service tag, a textual symbol provides additional contextual and semantic information, helps to enhance the process of service discovery. However, a large number of relevant tags for Web services are difficult to obtain in practice. In this paper, we propose a Web service Tag Learning system to address this issue. WT Learning system adopts sparse learning technique to fully understand the structure of high dimensional textual information extracted from WSDL documents and tags. Meanwhile, our proposed system implements Alternative Direction Method of Multiplier (ADMM) strategy, which accelerates solving process in Big Data environment. Extensive experiments are conducted based on real-world dataset, which consists of 24,569 Web services. The results demonstrate the effectiveness of WT Learning system. Specifically, our system outperforms other state-of-the-art frameworks in tag classification and recommendation tasks, with 29.6% and 27.1% performance gaining respectively.","venue":"IEEE International Conference on Web Services","year":2015.0,"referenceCount":19,"citationCount":4,"fieldsOfStudy":["Computer Science"],"publicationDate":"2015-06-27","authors":[{"authorId":"2069289799","name":"Wei Lo"},{"authorId":"1734105","name":"Jianwei Yin"},{"authorId":"144437322","name":"Zhaohui Wu"}]},{"paperId":"01f25eb16c6da9ce6559e8ac0f3dcc29ef566ed0","title":"Knowledge Analysis in Terms of Representation, Processing based Mobilisation and Distribution","abstract":"Understanding, defining and using knowledge can be based on a number of many approaches, such as the synthesis of Knowledge Management Systems, Knowledge Agents, Knowledge Discovery and Data Mining, Organizational Semantic Webs. Knowledge is based on the accumulation of facts, procedural rules or heuristics. Knowledge is supported by both formal and informal processes and structures in their acquisition, sharing and applications. Workers and employees communicate and assimilate values, procedures, rules and data from the beginning of their activity in an organization, and hypothetically should begin to be increasingly willing to share what they know as their length of service increases. This paper presents a deep analysis of knowledge, as the basic pillar of the intelligent enterprise and of many other Intelligent Economic Systems. In this respect I emphasize that it is essential to realize that Knowledge Management is both a cultural and a technological provocation. We might say that the cultural aspect is a priority. Any system designed to support these challenges must extend far beyond the technological boundaries and take into account the people who will use it and contribute to its success. Our work demonstrates the main aspects and strategic advantages of knowledge representation, processing based mobilisation and distribution in the long process from integrating information and applications to automate knowledge worker functions. Developing systems that incorporate knowledge within organizations differs significantly from other systems, because it is absolutely necessary to associate operational interpretations with the information, in order to transform them into knowledge useful in various acts of decision.","venue":"","year":2012.0,"referenceCount":53,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"52046358","name":"Vasile Mazilescu"}]},{"paperId":"01f28aa12ffcb0e55f2674f28ad9254c651d1199","title":"Ontology-Based Test Case Generation for Testing Web Services","abstract":"Web services (WS) enables agile application development by orchestrating the existing service components. However, the dynamically constructed service-based system has to be tested dynamically and automatically at runtime without human intervention. To address the challenges of automatic WS test case generation, this paper proposes a model driven ontology-based approach with the purpose of improving test formalism and test intelligence. The semantic WS specification OWL-S is used to describe the application logic of composite service process. A Petri-Net model is created to provide a formal representation of the OWL-S (Web Ontology Language for Web service) process model. The Petri-net ontology is defined to incorporate the operation and IOPE (inputs, outputs, preconditions, and effects) semantics for test generation. Test cases are generated from two aspects. Test steps are generated by traversing various execution paths of the Petri-net graph. Test data are generated by reasoning over the IOPE ontology","venue":"International Symposium on Autonomous Decentralized Systems","year":2007.0,"referenceCount":31,"citationCount":95,"fieldsOfStudy":["Computer Science"],"publicationDate":"2007-03-21","authors":[{"authorId":"2109302697","name":"Yongbo Wang"},{"authorId":"2157440","name":"Xiaoying Bai"},{"authorId":"8549842","name":"Juan-Zi Li"},{"authorId":"2070950","name":"Ruobo Huang"}]},{"paperId":"01f28c544d35bd8a94a132e2a4e67e3034b8afd6","title":"Understanding and Supporting Volunteer Contributors: The Case of Metadata and Document Servers","abstract":"The semantic interpretation of text remains a hard AI problem, and it becomes particularly relevant when large archives have to be built and searched. To aid in this process, advanced Web-based publication services (that is, document servers with surrounding infrastructure) adapt methods from traditional archiving, employing bibliographic metadata to improve data quality. However, most services cannot afford to pay for ex-post annotation, so the document authors themselves must provide metadata content and markup\u2014additional work that may deter them. Services therefore have to acknowledge that while there may be many authors who are potential contributors , the steps to actually publishing with the service and to delivering high-quality metadata are voluntary; i.e. authors who decide to do so are volunteer contributors . In order to win contributors, a service must therefore understand its potential contributors\u2019 concerns, and it must evaluate its capabilities of addressing them. We present a case study of a large university document and publication server. Surveys and Web usage mining identified which kinds of knowledge can or cannot easily be gathered from volunteer contributors. We also describe a tool that aims at improving the HCI incentives by employing text mining methods and presenting an easy-to-use interface to ensure correct markup. We expect that the recommendations and technology and interface concepts can be generalised to the needs of a range of other volunteer services with similar incentive structures.","venue":"AAAI Spring Symposium: Knowledge Collection from Volunteer Contributors","year":2005.0,"referenceCount":8,"citationCount":2,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"2990203","name":"Bettina Berendt"}]},{"paperId":"01f36b62d3838d6d6c19659fec48bec20666f646","title":"Term Dependence on the Semantic Web","abstract":null,"venue":"International Workshop on the Semantic Web","year":2008.0,"referenceCount":21,"citationCount":22,"fieldsOfStudy":["Computer Science"],"publicationDate":"2008-10-26","authors":[{"authorId":"144592996","name":"Gong Cheng"},{"authorId":"1887019","name":"Yuzhong Qu"}]},{"paperId":"01f47a786eecb3af0b204de03b87b755c665570b","title":"Linked Data Workshop","abstract":"Are you wondering what this \"linked data\" is all about? Come to a half-day, hands-on class where you will learn how to link data using pencil, paper, and post-its(tm). At the end of this course you will know: the basic concepts behind the Semantic Web and linked data the key terminology of linked data how linking can create new knowledge through navigation\u00a0 The course requires no prior technical knowledge, and is of interest to catalogers, tech services, reference staff, and management. There will be time for your questions, and follow-up reading suggestions will be provided. The course instructor is Karen Coyle, a librarian with over thirty years of experience with library technology. Find out more at kcoyle.net. Getting there: The Perry-Castaneda Library is located at the southwest corner of 21 st Street and Speedway on the UT Austin campus, less than 3 blocks away from the AT&T Conference Center. Room 1.224 is located on the first floor of the library, one floor below ground level. For more information about the location of the PCL, visit http:\/\/lib.utexas.edu\/pcl\/ . Registration for Linked Data Workshop: The Linked Data Workshop is available to attendees of the conference at no additional cost, but space is limited and advance sign-up is required. You may register for these special events at: http:\/\/LinkedData-TCDL2014.eventbrite.com . Sponsors: The Linked Data Workshop is made possible through generous sponsorships from the following institutions: Baylor University Libraries Texas Tech University Libraries University of Houston Libraries UT Austin Libraries University of North Texas Libraries","venue":"","year":2014.0,"referenceCount":0,"citationCount":0,"fieldsOfStudy":["Engineering"],"publicationDate":"2014-03-25","authors":[{"authorId":"2452446","name":"Karen Coyle"}]},{"paperId":"01f5312185d3f83f5132c6fcd6bde385e7120875","title":"GeneWeaver: a web-based system for integrative functional genomics","abstract":"High-throughput genome technologies have produced a wealth of data on the association of genes and gene products to biological functions. Investigators have discovered value in combining their experimental results with published genome-wide association studies, quantitative trait locus, microarray, RNA-sequencing and mutant phenotyping studies to identify gene-function associations across diverse experiments, species, conditions, behaviors or biological processes. These experimental results are typically derived from disparate data repositories, publication supplements or reconstructions from primary data stores. This leaves bench biologists with the complex and unscalable task of integrating data by identifying and gathering relevant studies, reanalyzing primary data, unifying gene identifiers and applying ad hoc computational analysis to the integrated set. The freely available GeneWeaver (http:\/\/www.GeneWeaver.org) powered by the Ontological Discovery Environment is a curated repository of genomic experimental results with an accompanying tool set for dynamic integration of these data sets, enabling users to interactively address questions about sets of biological functions and their relations to sets of genes. Thus, large numbers of independently published genomic results can be organized into new conceptual frameworks driven by the underlying, inferred biological relationships rather than a pre-existing semantic framework. An empirical \u2018ontology\u2019 is discovered from the aggregate of experimental knowledge around user-defined areas of biological inquiry.","venue":"Nucleic Acids Res.","year":2011.0,"referenceCount":38,"citationCount":135,"fieldsOfStudy":["Computer Science","Medicine","Biology"],"publicationDate":"2011-11-12","authors":[{"authorId":"3010456","name":"E. Baker"},{"authorId":"39887794","name":"Jeremy J. Jay"},{"authorId":"35598918","name":"J. Bubier"},{"authorId":"1739601","name":"M. Langston"},{"authorId":"1957571","name":"E. Chesler"}]},{"paperId":"01f5a19ba14bc152cd40e4e469f92402fc2c14c0","title":"Automated structural semantic annotation for RESTful services","abstract":"Adding semantics to Web Services can automate the processes of discovery, selection and composition of services. Although many annotating models are proposed to support this automation, the adoption of these models is significantly hampered by the tedious manual annotation process. The unstructured nature of the descriptions of RESTful services is making the goal even harder to achieve than the traditional Web Services. To address this problem, we propose ASSARS, namely Automated Structural Semantic Annotation for RESTful Services, to automatically transform the unstructured RESTful service pages into structured RESTful service descriptions. In our method, there are two key steps: a The semantic block division of RESTful service pages, and b the identification of the semantics of blocks which significantly describe the RESTful services from different aspects. The evaluation result shows that our approach is practical and effective.","venue":"International Journal of Web and Grid Services","year":2016.0,"referenceCount":19,"citationCount":9,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"1958235","name":"C. Luo"},{"authorId":"2115205467","name":"Zibin Zheng"},{"authorId":"2108766670","name":"Xiaorui Wu"},{"authorId":"2115413256","name":"Fei Yang"},{"authorId":"2109880924","name":"Yao Zhao"}]},{"paperId":"01f5a3ae14abb810432161f395eadb7bb004e98b","title":"Introduction to the Semantic Web Technologies","abstract":null,"venue":"Handbook of Semantic Web Technologies","year":2011.0,"referenceCount":40,"citationCount":38,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"145543299","name":"J. Domingue"},{"authorId":"1766239","name":"D. Fensel"},{"authorId":"1701341","name":"J. Hendler"}]},{"paperId":"01f5e7f5e54cd025af93ac1a197fd1b81ea0b80a","title":"Search types and context of use in the semantic Web","abstract":"Current search engines do not process queries semantics. However, most of the times contexts of use embed ontologies that do provide meanings. The paper suggests that the capability to satisfy users' queries is at variance with the level of ontology complexity. When extracting information from simple ontologies, the search engines are able to satisfy easily queries because the ambiguity of interpretation of terms and relations is very little or non-existent. The paper identifies and describes four different categories of information search (so-called \"ideal types of information search\"), that show a growing level of complexity. At the highest level of complexity they present an higher level of ambiguity. This means that meanings might be embedded in more ontologies and\/or use contexts. Finally, the paper suggests that scenario analysis can enable to characterize the ontologies of use contexts by means of Web services and personalization tools.","venue":"Proceedings of the Fourth International Conference on Web Information Systems Engineering, 2003. WISE 2003.","year":2003.0,"referenceCount":9,"citationCount":3,"fieldsOfStudy":["Computer Science"],"publicationDate":"2003-12-10","authors":[{"authorId":"2185303","name":"M. Visciola"}]},{"paperId":"01f7fd5d20f23c680b4a19e1dbe2cc2d763f7dc1","title":"A hybrid statistical and semantic model for identification of mental health and behavioral disorders using social network analysis","abstract":"The advent of social networking and open health web forums such as PatientsLikeMe, WebMD, ehealth forum etc. have provided avenues for social user data that can prove instrumental in suggesting futuristic trends in healthcare. Homophily in social networks is a vital contributor for analyzing patterns for medical conditions, diagnosis and treatment options. Since, members with similar medical issues contribute to a common discussion pool; this offers a rich source of information that can be utilized. This paper intends to explore growing trends in Mental Health and Behavioral Studies (MHB) which lays emphasis on co-existing conditions resulting in comorbidity. We present a novel approach where personality traits inferred from unstructured text of patients and general social users are compared via statistical analysis. This is achieved by our Psychiatric Disorder Determination (PDD) algorithm. Further, Social media data of users showing personality traits of patients is subjected to semantic based text classification using Natural Language Processing (NLP) and Ontology Based Information Extraction (OBIE) in our Addiction Category Determination (ACD) algorithm. This provides categorization of user journals to common topics of discussion by referring to ontologies DBpedia, Freebase and YAGO2s. The final category hence obtained can be predicted to be a trending subject of concern for users with Psychiatric disorders developing Addictive behavioral personalities.","venue":"International Conference on Advances in Social Networks Analysis and Mining","year":2016.0,"referenceCount":30,"citationCount":15,"fieldsOfStudy":["Computer Science"],"publicationDate":"2016-08-18","authors":[{"authorId":"3359531","name":"Madan Krishnamurthy"},{"authorId":"145460043","name":"Khalid Mahmood"},{"authorId":"7889795","name":"Pawel Marcinek"}]},{"paperId":"01f8a4f76eaff96aba0b301bf38b3ac2027d2c60","title":"Towards Semantic Web-based competence management: Going beyond the limits of traditional competence management","abstract":"In knowledge society organizations as well as individuals publish relevant data about themselves in the Web. However, still most Web content is only suitable for human consumption. It is not machine-understandable. In this paper, we have restricted ourselves on publishing machine-understandable competence-oriented data in the Web. Such data allows the development of new and more strengthen solutions for collaborative competence management. We present relevant data infrastructures and technologies for such collaboration. In particular, we introduced the notion of Competence Collaboration Domain for data sharing, and the notion of Semantic Profile for representing competences in machine-understandable way.","venue":"","year":2016.0,"referenceCount":11,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":"2016-09-01","authors":[{"authorId":"2721814","name":"J. Puustj\u00e4rvi"},{"authorId":"101583134","name":"Leena Puustj\u00e4rvi"}]},{"paperId":"01f90c2a3abc8812d552da2a3fa0e36735d5fec2","title":"Smart Business Objects for Web Applications: A New Approach to Model Business Objects","abstract":null,"venue":"International Conference on Software and Data Technologies","year":2006.0,"referenceCount":17,"citationCount":13,"fieldsOfStudy":["Computer Science"],"publicationDate":"2006-09-11","authors":[{"authorId":"2320355","name":"Xufeng Liang"},{"authorId":"2876510","name":"A. Ginige"}]},{"paperId":"01f9c69f34a5621168f3a6e94ca00fe574757314","title":"Query Processing in a Mediator Based Framework for Linked Data Integration","abstract":"In this paper, the authors present a three-level mediator based framework for linked data integration. In the approach, the mediated schema is represented by a domain ontology, which provides a conceptual representation of the application. Each relevant data source is described by a source ontology, published on the Web according to the Linked Data principles. Each source ontology is rewritten as an application ontology, whose vocabulary is restricted to be a subset of the vocabulary of the domain ontology. The main contribution of the paper is an algorithm for reformulating a user query into sub-queries over the data sources. The reformulation algorithm exploits inter-ontology links to return more complete query results. The approach is illustrated by an example of a virtual store mediating access to online booksellers. aspects of the Semantic Web that make it appropriate for the integration of data from distributed and heterogeneous data sources (Wache et al., 2001). Briefly, these are: RDF, the Resource Description Framework, a simple, but powerful and extensible data model; URIs (or IRIs) used for global naming; and the possibility of reasoning based on Description Logic (Calvanese et al., 2008). In this paper, we consider the problem of designing data integration systems (Lenzerini, DOI: 10.4018\/jbdcn.2011040103 30 International Journal of Business Data Communications and Networking, 7(2), 29-47, April-June 2011 Copyright \u00a9 2011, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited. 2002) when the data sources are published on the Web according to the Linked Data principles (Bizer, Heath, & Berners-Lee, 2009), which require the identification of entities with URI references that can be resolved over the HTTP protocol into RDF data that describes the identified entity. These descriptions may include RDF links pointing to other data sources. RDF links take the form of RDF triples, where the subject of the triple is an URI reference in the namespace of one data source, while the object is a URI reference in the namespace of the other. The notion of identity is an important issue in the Semantic Web. URIs guarantee that resources are uniquely identifiable resources on the Web, but they do not guarantee the uniqueness of the entities the resources refer to (Halpin, 2006). Thus, there is a need for a service that is able to find different URIs that refer to the same real-world entity. In this paper, we propose a mediator-based framework for implementing data integration over linked data. We provide a sound and complete algorithm for reformulating a SPARQL query into a query over the (linked) data sources. The reformulation algorithm exploits inter-ontology links to return more complete query results. This paper is organized as follows. Section 2 describes the framework proposed for linked data integration. Section 3 summarizes some basic concepts required in the paper. Section 4 presents an example that will be used throughout the paper. Section 5 discusses the query answering method adopted. Section 6 introduces a strategy for query reformulation, which is the central contribution of the paper. Section 7 lists related work. Finally, Section 8 presents the conclusions and directions for future research. 2. A FRAMEWORK FOR LINKED DATA INTEGRATION In this section, we discuss the three-level architecture for linked data integration, which is depicted in Figure 1. The mediated schema is represented by a domain ontology (DO), which provides a conceptual representation of the domain (a globally shared vocabulary and a set of constraints). Each relevant data source is described by a source ontology, published on the Web according to the Linked Data principles, thereby becoming part of the Web of linked data. These source ontologies are depicted in the Web of Linked Data layer in Figure 1. The local source schemas are accessed via wrappers, like those introduced in Berners-Lee et al. (2006) which export the local data into OWL. Each source ontology is rewritten as an application ontology (AO), whose vocabulary is restricted to be a subset of the vocabulary of the domain ontology. In Sacramento et al. (2010) we present a strategy to automatically generate such application ontologies, considering a set of local ontologies, a domain ontology and the result of the matching between each local ontology and the domain ontology. We adopt OWL Lite (Bechhofer et al., 2004) as the ontology language to represent the domain Figure 1. Three-level architecture for linked data integration 17 more pages are available in the full version of this document, which may be purchased using the \"Add to Cart\" button on the product's webpage: www.igi-global.com\/article\/query-processing-mediator-basedframework\/55301?camid=4v1 This title is available in InfoSci-Journals, InfoSci-Journal Disciplines Communications and Social Science. Recommend this product to your librarian: www.igi-global.com\/e-resources\/libraryrecommendation\/?id=2","venue":"","year":2015.0,"referenceCount":7,"citationCount":2,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"2285230797","name":"V\u00e2nia M. P. Vidal"}]},{"paperId":"01fb61be8378f18fd2498a6fe003837dc5264d97","title":"A Frame Work for XML Ontology to STEP-PDM from Express Entities: A String Matching Approach","abstract":null,"venue":"Annals of Data Science","year":2016.0,"referenceCount":47,"citationCount":1,"fieldsOfStudy":["Computer Science"],"publicationDate":"2016-10-17","authors":[{"authorId":"9414938","name":"Chinta Someswara Rao"},{"authorId":"21263779","name":"A. Balakrishna"},{"authorId":"9226177","name":"M. B. Bhadri Raju"},{"authorId":"2719153","name":"S. Viswanadha Raju"}]},{"paperId":"01fde87a880872ac116e336b691e2a9e4d31ba16","title":"A Step towards the Arabic DBpedia","abstract":"is considered as one of the recently emerging hot topics in the field of Semantic Web due to its importance in adding structure to Wikipedia, the largest online encyclopedia worldwide covering 285 Wikipedia languages. Thought to be a step towards the internationalization of DBpedia, this paper describes the best practices and the efforts performed as part of the work in the deployment of the Arabic DBpedia as a new chapter will be added to the available multilingual DBpedia chapters which can support the maintenance, extraction and enriching of DBpedia especially for those users who their native language is Arabic.","venue":"","year":2013.0,"referenceCount":24,"citationCount":15,"fieldsOfStudy":["Computer Science"],"publicationDate":"2013-10-18","authors":[{"authorId":"1398651200","name":"Haytham Al-Feel"}]},{"paperId":"01fdfeaef9f0534e95679dab57b4b4c47229668e","title":"FUTURE INFORMATICS TEACHERS\u2019 READINESS TO USE EDUCATIONAL","abstract":"Summary . Introduction. The article analyzes the component composition of the preparation of future IT teachers to use educational WEB-resources in professional activities. Purpose. The article is to identify the components of the preparation of future IT teachers to use educational WEB-resources in professional activities. Methods. Analysis of scientific sources on the research problem. Results. We defined the functions of components: motivation and value \u2013 activation of manifestation of other components, cognitive-semantic \u2013 providing measures of the use of resource possibilities concerning other components for achievement - definition of relations between components in the course of realization of resource potential in space and time. We found out that the indicator of the motivational and value component is the awareness of the importance of informatization in education; cognitive interest in web technologies, ways of forming information culture of students; stability of beliefs and the need to use web-resources; interest and need to use information tools, management of the process of using WEB-resources in school; the presence of motives, interests, needs and value orientations (values-guidelines, values-goals, val-ues-relationships, values-quality, values-means) for the use of WEB-resources in professional activities; necessary qualities and personality traits; cognitive-semantic: the presence of the necessary volume and completeness of general cultural, general professional, professional, special knowledge of WEB-resources, methods of their use, the level of theoretical knowledge on the informatization in","venue":"","year":2020.0,"referenceCount":4,"citationCount":0,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"2285640445","name":"Shuliak Andrii"},{"authorId":"2285669496","name":"\u041a\u0430\u0446\u0456\u043c\u043e\u043d \u041e\u043a\u0441\u0430\u043d\u0430"},{"authorId":"2285655398","name":"\u0412\u0430\u0441\u0438\u043b\u0456\u0432\u043d\u0430"},{"authorId":"2285662277","name":"\u0425\u043e\u0434\u0430\u043a\u043e\u0432\u0441\u044c\u043a\u0430 \u041e\u043b\u0435\u043d\u0430"},{"authorId":"2285662270","name":"\u041e\u043b\u0435\u043a\u0441\u0430\u043d\u0434\u0440\u0456\u0432\u043d\u0430"},{"authorId":"2285655400","name":"\u0424\u0430\u0439 \u0412\u0456\u043a\u0442\u043e\u0440\u0456\u044f"},{"authorId":"2285640441","name":"\u0421\u0442\u0435\u043f\u0430\u043d\u0456\u0432\u043d\u0430"}]},{"paperId":"01fe184039fa1ba462a83a595d9c31df1dced431","title":"Sparql Rules! Sparql Rules!","abstract":". As the data and ontology layers of the Semantic Web stack have achieved a certain level of maturity in standard recommendations such as RDF and OWL, the current focus lies on two related aspects. On the one hand, the de\ufb01nition of a suitable query language for RDF, SPARQL, seems to be close to candidate recommendation status within the W3C. The establishment of the rules layer on top of the existing stack on the other hand marks the next step to be taken, where especially languages with their roots in Logic Programming and Deductive Databases are receiving considerable attention. The purpose of this paper is threefold. First, we discuss the formal semantics of SPARQL extending recent results in several ways. Second, we provide translations from SPARQL to Datalog with strati\ufb01ed negation as failure. Third, we propose some useful and easy to implement extensions of SPARQL, based on this translation. As it turns out, the combination serves for direct implementations of SPARQL on top of existing rules engines as well as a basis for more general rules and query languages on top of RDF. A prototype implementation is available for evaluation of our approach.","venue":"","year":2006.0,"referenceCount":25,"citationCount":0,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"1708607","name":"A. Polleres"}]},{"paperId":"01fe4556a11fcd234f1b6865b15c6ade9ca806c2","title":"Linked file system: Towards exploiting linked data technology in file systems","abstract":"Most of the file systems today are based on desktop metaphor utilizing hierarchies of folders and sub-folders for information storage and retrieval. A folder is usually assumed to store the semantically related information in the form of files and sub-folders. However, there always exist related files somewhere else in the local file system hierarchy. Users often fail to find these disconnected files or discover the relationship among these. File systems maintain a plain set of metadata items about each file which could be utilized to discover some of the hidden relationships. However, this meta-information is very sparse as most of this metadata is rarely entered by the user. Moreover, files in a file system are mostly private and cannot get the benefit of collaborative tagging. Web of Data, on the other hand also contains information related to the file system objects which could be utilized for linking with information in file systems. The purpose of introducing Linked Data technology was to solve similar issues on the web. This article investigates the exploitation of Linked Data technology in file systems and provides a comprehensive review on the possible use of Linked Data Technology in file systems.","venue":"2016 International Conference on Open Source Systems & Technologies (ICOSST)","year":2016.0,"referenceCount":26,"citationCount":2,"fieldsOfStudy":["Computer Science"],"publicationDate":"2016-12-01","authors":[{"authorId":"9100773","name":"Syed Rahman Mashwani"},{"authorId":"17099473","name":"Azhar Rauf"},{"authorId":"3351931","name":"Shah Khusro"},{"authorId":"2304334","name":"Saeed Mahfooz"}]},{"paperId":"0200afdff69ac2f5768f3e01cb089f37127b7a8e","title":"Recognizing Textual Entailment by Generality Using Informative Asymmetric Measures and Multiword Unit Identification to Summarize Ephemeral Clusters","abstract":"In the context of Ephemeral Clustering of web Pages, it can be interesting to label each cluster with a small summary instead of just a label. Within this scope, we introduce the paradigm of Textual Entailment by Generality, which can be defined as the entailment from a specific web snippet towards a more general web snippet. The subjacent idea is to find the best web snippet, which summarizes and subsumes all the other web snippets within an ephemeral cluster. To reach this objective, we first propose a new informative asymmetric similarity measure called the Simplified Asymmetric InfoSimba(AISs), which can be combined with different asymmetric association measures. In particular, the AISs proposes an unsupervised language-independent solution to infer Textual Entailment by Generality and as such can help to encounter the web snippet with maximum semantic coverage. This new methodology is tested against the first Recognizing Textual Entailment data set (RTE-1)1 for an exhaustive number of asymmetric association measures with and without the identification of Multiword Units. The comparative experiments with existing state-of-the-art methodologies show promising results.","venue":"2011 IEEE\/WIC\/ACM International Conferences on Web Intelligence and Intelligent Agent Technology","year":2011.0,"referenceCount":10,"citationCount":4,"fieldsOfStudy":["Computer Science"],"publicationDate":"2011-08-22","authors":[{"authorId":"143673279","name":"G. Dias"},{"authorId":"34443965","name":"Sebasti\u00e3o Pais"},{"authorId":"1398535955","name":"K. Wegrzyn-Wolska"},{"authorId":"1978646","name":"R. Mahl"}]},{"paperId":"020139981033b326f3be844c221bf94f95a81b03","title":"Exploiting Existed Medical Ontologies to Build Domain Ontology for Hepatobiliary System Diseases","abstract":null,"venue":"International Conference on Advanced Intelligent System and Informatics","year":2016.0,"referenceCount":11,"citationCount":1,"fieldsOfStudy":["Computer Science"],"publicationDate":"2016-10-24","authors":[{"authorId":"1403815550","name":"Galal Al-Marzoqi"},{"authorId":"3375693","name":"M. Alfonse"},{"authorId":"1741003","name":"Ibrahim F. Moawad"},{"authorId":"2288960","name":"M. Roushdy"}]},{"paperId":"0204004b1ec64f163ef568b8660b8a63974ae489","title":"Incorporating Heterogeneous Information for Mashup Discovery with Consistent Regularization","abstract":null,"venue":"Pacific-Asia Conference on Knowledge Discovery and Data Mining","year":2016.0,"referenceCount":18,"citationCount":12,"fieldsOfStudy":["Computer Science"],"publicationDate":"2016-04-19","authors":[{"authorId":"2389866","name":"Yao Wan"},{"authorId":"40451135","name":"Liang Chen"},{"authorId":"144790496","name":"Qi Yu"},{"authorId":"34905515","name":"Tingting Liang"},{"authorId":"2115902405","name":"Jian Wu"}]},{"paperId":"020460e33b84a47501c74c1cf6a94da14ab12253","title":"Semantic web, ubiquitous computing, or internet of things? A macro-analysis of scholarly publications","abstract":"Purpose \u2013 The purpose of this paper is to investigate concepts that are used in depicting future visions of society, as afforded by technology, to map the extent of their use, examine the level of their dominance in different research areas and geographic boundaries, identify potential overlaps, analyse their longitudinal growth, and examine whether any of the identified concepts has assumed an overarching position. Design\/methodology\/approach \u2013 In total, 14 concepts, each of which is used to depict visions of future information infrastructures, were identified. More than 20,000 scholarly documents related to 11 of these concepts (those with 20 or more documents) are analysed by various qualitative\/quantitative methods. Findings \u2013 The concepts most referred to are semantic web and ubiquitous computing (all years), and internet of things (Year 2013). Publications on some newer concepts (e.g. digital living, real world internet) are minimal. There are variations in the extent of use and preferred concepts b...","venue":"J. Documentation","year":2015.0,"referenceCount":71,"citationCount":35,"fieldsOfStudy":["Computer Science"],"publicationDate":"2015-09-02","authors":[{"authorId":"32345344","name":"Nasrine Olson"},{"authorId":"2148835","name":"Jan Nolin"},{"authorId":"2941544","name":"Gustaf Nelhans"}]},{"paperId":"0206b841738bd35ae79057acd345c453c7ed8e38","title":"Ontologies and semantic web for an evolutive development of logistic applications. (Ontologies et web s\u00e9mantique pour une construction \u00e9volutive d'applications d\u00e9di\u00e9es \u00e0 la logistique)","abstract":"Le domaine de la logistique implique souvent la resolution de problemes combinatoires complexes. Ces derniers font egalement implicitement reference a des processus, acteurs, activites et methodes concernant divers aspects qu'il faut considerer. Ainsi, un meme probleme peut faire intervenir des processus de vente\/achat, transport\/livraison et gestion de stock. Ces processus sont tellement divers et interconnectes qu'il est difficile pour un logisticien de tous les maitriser. Dans cette these, nous proposons l'explicitation, par le biais d'ontologies, de connaissances conceptuelles et semantiques concernant les processus logistiques. Ces connaissances explicites sont alors mises a contribution pour construire un systeme a base de connaissances permettant de guider les logisticiens dans la construction, de facon incrementale et semi-automatique, de solutions informatiques a un probleme qui leur est pose a un moment donne. Nous mettons en oeuvre une ontologie concernant le domaine de la logistique connectee a une ontologie associee a la problematique de l'optimisation. Nous etablissons ainsi un lien semantique explicite entre le domaine de la logistique et celui de l'optimisation. Cela permet aux logisticiens d'identifier de facon precise et sans ambiguite le probleme logistique auquel il est confronte et les problemes d'optimisation associes. L'identification des problemes conduit alors a un processus de choix des solutions allant du choix du processus logistique precis a mettre en oeuvre a celui de la methode de resolution du probleme combinatoire et cela jusqu'a la decouverte du composant informatique a invoquer et qui est materialise par un service web. L'approche que nous avons adoptee et mise en oeuvre a ete experimentee avec les problemes de routage de vehicules, le probleme de transport ferroviaire de passagers et le probleme de terminaux de conteneurs.","venue":"","year":2017.0,"referenceCount":74,"citationCount":0,"fieldsOfStudy":["Computer Science","Philosophy"],"publicationDate":"2017-12-04","authors":[{"authorId":"9406756","name":"Hayder Hendi"}]},{"paperId":"0206fbc0ad13eb38af40a8cdd4325841f4d09f27","title":"Personal navigating agents","abstract":"The World Wide Web provides a huge distributed web database. However, information in the web database is free formatted and unorganized. Traditional keyword-based retrieval approaches are no longer appropriate. In this paper, we consider a framework for constructing agents that can simulate the behavior of human browsing on the Internet. Given a specific target, such an agent will make use of existing search engines to navigate through the web to locate the sites containing the target information and extract them into a database. We refer to these types of agents as Personal Navigating Agents (PNA). Since the information service is domain specific, we shall first focus on those PNA that can retrieve people\u2019s information on the web in this paper. In this particular experiment, given the name of a university, we shall extract the following information about its faculty: name, telephone number, fax number, email address and URL. We explore web page knowledge in two ways: First, we develop a tagging system for each web page to facilitate information extraction. Our tagging system employs an HTML parser together with a natural language semantic tagger. These semantic tags are more general than part-of-speech tags used in linguistics. Second, we equip our PNA with a navigation map. A navigation map will guide our PNA to traverse through related pages and to arrive at pages containing the target information. In our experiments, our prototype agents have successfully explored a university web site and extracted target information with a very high accuracy.","venue":"International Conference on Autonomous Agents","year":1999.0,"referenceCount":8,"citationCount":3,"fieldsOfStudy":["Computer Science"],"publicationDate":"1999-04-01","authors":[{"authorId":"35746925","name":"H. L. Wang"},{"authorId":"1685972","name":"W. Shih"},{"authorId":"34607455","name":"Chun-Nan Hsu"},{"authorId":"2153248979","name":"Y. S. Chen"},{"authorId":"37622879","name":"Y. L. Wang"},{"authorId":"2072747478","name":"W. Hsu"}]},{"paperId":"0207adfbb519ab550a919a6f89071888cd777365","title":"Trust-QoS Based Semantic Web Service Discovery Technology","abstract":"The discovery of suitable Web services for a given user requirement is one of the key technology in application of web services. A mechanism is proposed to support QoS-based semantic Web service discovery. Firstly to reduce the overhead and enhance the discovery efficiency, genetic algorithm is adopted as a method of service clustering. Furthermore, the evaluation and calculation of QoS was realized to satisfy the user's QoS requirements. In the end, simulation results demonstrated the effectiveness of the proposed method.","venue":"Pacific-Asia Conference on Circuits, Communications and Systems","year":2011.0,"referenceCount":5,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":"2011-07-17","authors":[{"authorId":"2116339753","name":"XiaoJiang Li"},{"authorId":"2285411074","name":"Shuyu Li"},{"authorId":"2285625301","name":"Xiaojuan Chen"}]},{"paperId":"0207b44a2d179480a9de5fd20caea717924ae635","title":"Enriching ebXML registries with OWL ontologies for efficient service discovery","abstract":"Web services, like their real life counterparts have several properties and thus truly useful semantic information can only be defined through standard ontology languages. Semantic Web is an important initiative in this respect. However, although service registries are the major mechanisms to discover services, the semantic support provided by service registries is completely detached from the semantic Web effort. In this paper, we address how ebXML registries can be enriched through OWL ontologies to describe Web service semantics. We describe how the various constructs of OWL can be mapped to ebXML classification hierarchies and show how the stored semantics can be queried through standardized queries by using the ebXML query facility. We also provide our observations on how ebXML registries can be extended to provide more efficient semantic support.","venue":"14th International Workshop Research Issues on Data Engineering: Web Services for e-Commerce and e-Government Applications, 2004. Proceedings.","year":2004.0,"referenceCount":15,"citationCount":77,"fieldsOfStudy":["Computer Science"],"publicationDate":"2004-03-28","authors":[{"authorId":"1695901","name":"A. Dogac"},{"authorId":"1873184","name":"Y. Kabak"},{"authorId":"1728213","name":"Gokce Laleci"}]},{"paperId":"020802378533de7222b899d96bc9a93d6c590438","title":"A Framework for Automating the Invocation of Web APIs","abstract":"Web APIs, characterized by their relative simplicity and their natural suitability for the Web, have become increasingly dominant in the world of services on the Web. Despite their popularity, Web APIs are so heterogeneous in terms of the underlying principles adopted and the means used for publishing them that discovering, understanding and notably invoking Web APIs is nowadays more an art than a science. In this paper, we present our work towards supporting the automated invocation of Web APIs. In particular, we describe a framework that provides a unique entry point for the invocation of most Web APIs that can be found on the Web, by exploiting non-intrusive semantic annotations of HTML pages describing Web APIs in order to capture both their semantics as well as information necessary to carry out their invocation.","venue":"","year":2011.0,"referenceCount":19,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"2289231536","name":"Ning Li"},{"authorId":"2248188079","name":"Carlos Pedrinaci"},{"authorId":"2298633","name":"M. Maleshkova"},{"authorId":"31840124","name":"J. Kopeck\u00fd"},{"authorId":"2266260366","name":"J. Domingue"}]},{"paperId":"0209e7a60fe2c34b77b5a8de7a78a1fb1dd7dcfe","title":"PEANO: pictorial enriched annotation of video","abstract":"In this DEMO, we present a tool set for video digital library management that allows i) structural annotation of edited videos in MPEG-7 by automatically extracting shots and clips; ii) automatic semantic annotation based on perceptual similarity against a taxonomy enriched with pictorial concepts iii) video clip access and hierarchical summarization with stand-alone and web interface iv) access to clips from mobile platform in GPRS-UMTS video-streaming. The tools can be applied in different domain-specific Video Digital Libraries. The main novelty is the possibility to enrich the annotation with pictorial concepts that are added to a textual taxonomy in order to make the automatic annotation process more fast and often effective. The resulting multimedia ontology is described in the MPEG-7 framework. The PEANO (Perceptual Annotation of Video) tool has been tested over video art , sport (Soccer, Olimpic Games 2006, Formula 1) and news clips.","venue":"ACM Multimedia","year":2006.0,"referenceCount":8,"citationCount":3,"fieldsOfStudy":["Computer Science"],"publicationDate":"2006-10-23","authors":[{"authorId":"1705203","name":"C. Grana"},{"authorId":"1723285","name":"R. Vezzani"},{"authorId":"38350683","name":"Daniele Bulgarelli"},{"authorId":"1766510","name":"Giovanni Gualdi"},{"authorId":"1741922","name":"R. Cucchiara"},{"authorId":"1801509","name":"Marco Bertini"},{"authorId":"2277925","name":"C. Torniai"},{"authorId":"8196487","name":"A. Bimbo"}]},{"paperId":"020a71d6443104ca0443069c3470167d251df0ba","title":"The Interoperability of Learning Object Design, Search and Adaptation Processes in the Repositories","abstract":"Learning environments ensure successful implementation of the learning process but not always the effective design of the e-learning objects (ELOs) and moreover, search and adaptation. A technological solution for the design of the learning objects, repositories, and the semantic web is needed. There are many open educational resources, but not many platforms assure the possibility to adapt learning objects. The existing developed multifunctional platforms do not ensure the effective ELOs adaptation as well as the process of design and adaptation in the multifunctional environment. They do not have an automatic search of ELOs in the semantic web, which is directly targeted to the specific objects in repositories of open educational resources and do not allow for adaptation of the already developed ELO by automatically assigning reusable objects. The structure of the papers consists of the literature review and overview of existing practices, research methodology, research results description and conclusions provided by authors. The objective of the research is to suggest, to teachers, a model for effective e-learning objects design, automatic search and adaptation processes in the multifunctional environment by developing a platform based on semantic technologies for e-learning objects design and adaptation.","venue":"Applied Sciences","year":2022.0,"referenceCount":32,"citationCount":1,"fieldsOfStudy":null,"publicationDate":"2022-04-03","authors":[{"authorId":"2012314","name":"D. Gudoniene"},{"authorId":"2200575","name":"E. Staneviciene"},{"authorId":"48686191","name":"L. Motiej\u016bnas"}]},{"paperId":"020b796f80765ad720eef50ad1b304170c757211","title":"Text-to-image Retrieval Based on Zero-shot Transfer Learning with CLIP Model and Vector Database","abstract":"With the continuous increase in the number of internet users, the explosion of multimodal data on the web has led to a growing demand for image retrieval. Current text-to-image retrieval systems often rely on keyword matching, which frequently fails to accurately capture users' retrieval needs. This work proposes a text-to-image retrieval method based on zero-shot transfer learning with the CLIP model and vector database, designed to be applied in text-to-image retrieval systems. By leveraging the semantic alignment capability of the CLIP model for text and images, this study effectively addresses the semantic gap problem in text-to-image retrieval. Additionally, the method utilizes the Milvus database for efficient storage and retrieval of image feature vectors, thereby enhancing system stability. Experimental results on the Flickr30k dataset demonstrate that this method improves the accuracy of text-to-image retrieval, verifying its effectiveness. Furthermore, this work extends the proposed method by incorporating the iFLYTEK Spark Cognitive Model to support image retrieval using Chinese text descriptions, further broadening the system's applicability and reliability.","venue":"International Conference on Behavioral, Economic, and Socio-Cultural Computing","year":2024.0,"referenceCount":9,"citationCount":0,"fieldsOfStudy":null,"publicationDate":"2024-08-16","authors":[{"authorId":"2335153970","name":"Junfeng Xie"},{"authorId":"2291205015","name":"Junying Chen"}]},{"paperId":"020cbcf7129af8c4f1566afecab2c863bbc6174a","title":"Developing complex services in an IoT ecosystem","abstract":"Recent advancements in single board computers, communications technologies and protocols, as well as the concepts of service-oriented architectures (SoA) and everything as a service (EaaS), constitute a prelude to the Internet of Things (IoT) revolution. Billions of devices are interconnected and integrated as modular web services, which can be used and re-used by developers making the building and realization of complex applications easier. In this work, we take advantage of the SYNAISTHISI platform, which is able to interface and integrate devices, services and humans, and expose their capabilities as virtualized semantically annotated services that can be mashed into applications. We analyze the development process from a developer's perspective, present an ontology for smart meeting rooms and focus on a real-world case, that is delivering a complex application for counting the persons in the interior of a smart meeting room, using technologies that support IoT.","venue":"World Forum on Internet of Things","year":2015.0,"referenceCount":16,"citationCount":22,"fieldsOfStudy":["Computer Science"],"publicationDate":"2015-12-14","authors":[{"authorId":"2815429","name":"C. Akasiadis"},{"authorId":"2477518","name":"Grigorios Tzortzis"},{"authorId":"144116678","name":"E. Spyrou"},{"authorId":"2124138","name":"C. Spyropoulos"}]},{"paperId":"020dd10586675d2254156e3ddebe5e7cd6bc3607","title":"Sketch theory as a framework for knowledge management","abstract":null,"venue":"Innovations in Systems and Software Engineering","year":2016.0,"referenceCount":15,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":"2016-03-01","authors":[{"authorId":"3178875","name":"R. Wojtowicz"}]},{"paperId":"020f488af54e46a29ca27fbb8f71fbcca355ddda","title":"Annotation s\u00e9mantique des services web \u00e0 base des donn\u00e9es ouvertes li\u00e9es","abstract":"With the growth in the number of services published on the Internet, it is difficult for service\u2019s providers to discover the Web services corresponding to their needs. The main reason for this phenomenon is that the conventional services do not have semantic information to discover them or to select the most appropriate web services. However, in order to perform automatic tasks such as the discovery and the composition of Web services, it is essential to provide these services with a semantic information. This project presents a new approach to semantic annotation of existing Web services. The approach is supported by a software tool that allows the annotation of an existing web service, and this is according to the annotation principle proposed by the SAWSDL standard, from an ontology of domain and a description file for WSDL services. Thus, the domain ontology used for the annotation was created basing on the instances available in Linked Open Data.","venue":"","year":2017.0,"referenceCount":93,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"150336308","name":"Wahiba Boudjou"},{"authorId":"150299749","name":"Sofiane Khima"},{"authorId":"2084922892","name":"H. E. Bouhissi"},{"authorId":"52375892","name":"Promoteur"}]},{"paperId":"0210fb1b6be4fb8cfa84d8c56c8a4bf14412dd04","title":"Spectral Analysis for Data Mining","abstract":null,"venue":"Workshop on Algorithm Engineering and Experimentation","year":2001.0,"referenceCount":0,"citationCount":6,"fieldsOfStudy":["Computer Science"],"publicationDate":"2001-01-05","authors":[{"authorId":"1693265","name":"Anna R. Karlin"}]},{"paperId":"0210fcc48d7bf1d72dc31c5a4f3587ef4bccd989","title":"Tagging image by merging multiple features in a integrated manner","abstract":null,"venue":"Journal of Intelligence and Information Systems","year":2011.0,"referenceCount":38,"citationCount":8,"fieldsOfStudy":["Computer Science"],"publicationDate":"2011-10-26","authors":[{"authorId":"2115306399","name":"Xiaoming Zhang"},{"authorId":"1707275","name":"Zhoujun Li"},{"authorId":"7277241","name":"Wen-Han Chao"}]},{"paperId":"02147ad7afcba5ed9ed40c01f9e09ee488f45025","title":"Trends in Legal Knowledge. The Semantic Web and the Regulation of Electronic Social Systems","abstract":"Papers from the B4 Workshop on Artificial Intelligence and Law. XXII World Congress of Philosophy of Law and Social Philosophy. IVR'05. Granada. May 25-27 2005 Source URL: https:\/\/www.iiia.csic.es\/en\/node\/55004 Links [1] https:\/\/www.iiia.csic.es\/en\/staff\/pompeu-casanovas [2] https:\/\/www.iiia.csic.es\/en\/staff\/pablo-noriega [3] https:\/\/www.iiia.csic.es\/en\/staff\/dani%C3%A8le-bourcier","venue":"","year":2007.0,"referenceCount":0,"citationCount":23,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"2084859","name":"Pompeu Casanovas"},{"authorId":"144399852","name":"Pablo Noriega"},{"authorId":"1927978","name":"D. Bourcier"}]},{"paperId":"021494822595596fdfedfad3a71e25b3167d5534","title":"Design and Development of an Intelligent Semantic Recommendation System for Websites","abstract":null,"venue":"Lecture Notes of the Institute for Computer Sciences, Social Informatics and Telecommunications Engineering","year":2019.0,"referenceCount":18,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":"2019-12-04","authors":[{"authorId":"2118678390","name":"Zhiqiang Zhang"},{"authorId":"2109771146","name":"Heping Yang"},{"authorId":"1817577798","name":"Dinglong Yang"},{"authorId":"2144811902","name":"Xiaowei Jiang"},{"authorId":"2118768744","name":"Nan Chen"},{"authorId":"2025880094","name":"Feng Mingnong"},{"authorId":"1726024310","name":"Mingyi Yang"}]},{"paperId":"0215f1c8be52174da56e41491413c1598456da55","title":"STEX+: a system for flexible formalization of linked data","abstract":"We present the S<sup>T<\/sup>E<sup>X<\/sup>+ system, a user-driven advancement of S<sup>T<\/sup>E<sup>X<\/sup> --- a semantic extension of LAT<sub>E<\/sub>X that allows for producing high-quality PDF documents for (proof)reading and printing, as well as semantic XML\/OMDoc documents for the Web or further processing. Originally S<sup>T<\/sup>E<sup>X<\/sup> had been created as an invasive, semantic frontend for authoring XML documents. Here, we used S<sup>T<\/sup>E<sup>X<\/sup> in a Software Engineering case study as a formalization tool. In order to deal with modular pre-semantic vocabularies and relations, we upgraded it to S<sup>T<\/sup>E<sup>X<\/sup>+ in a participatory design process. We present a tool chain that starts with an S<sup>T<\/sup>E<sup>X<\/sup>+ editor and ultimately serves the generated documents as XHTML+RDFa Linked Data via an OMDoc-enabled, versioned XML database. In the final output, all structural annotations are preserved in order to enable semantic information retrieval services.","venue":"International Conference on Semantic Systems","year":2010.0,"referenceCount":44,"citationCount":21,"fieldsOfStudy":["Computer Science"],"publicationDate":"2010-06-23","authors":[{"authorId":"2732414","name":"A. Kohlhase"},{"authorId":"1713140","name":"M. Kohlhase"},{"authorId":"40466850","name":"C. Lange"}]},{"paperId":"021644c44ab6b48bc3de253eded060e3d1f6d786","title":"Semantic web meets egoverment : papers from the AAAI Spring Symposium","abstract":null,"venue":"","year":2006.0,"referenceCount":0,"citationCount":6,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"1689856","name":"A. Abecker"},{"authorId":"144463965","name":"A. Sheth"},{"authorId":"1711109","name":"G. Mentzas"},{"authorId":"144395406","name":"Ljiljana Stojanovi\u0107"}]},{"paperId":"021694553bff244ae9d55e4ed974a803ff8b940b","title":"Semantic Service Bus: Architecture and Implementation of a Next Generation Middleware","abstract":"In this paper we present a middleware for the service oriented architecture, called the Semantic Service Bus. It is an advanced middleware possessing enhanced features, as compared to the conventional service buses. It is distinguished by the fact that it uses semantic description of service capabilities, and requirements towards services to enable more elaborate service discovery, selection, routing, composition and data mediation. The contributions of the paper are the conceptual architecture of the Semantic Service Bus and a prototypical implementation supporting different semantic Web service technologies (OWL-S and WSMO) and conventional Web services. Since mission critical application scenarios (for SOA) involve complex orchestrations of services, we have chosen to utilize semantically annotated service orchestrations as the applications to employ this middleware.","venue":"2007 IEEE 23rd International Conference on Data Engineering Workshop","year":2007.0,"referenceCount":28,"citationCount":50,"fieldsOfStudy":["Computer Science"],"publicationDate":"2007-04-17","authors":[{"authorId":"143727987","name":"Dimka Karastoyanova"},{"authorId":"2614615","name":"Branimir Wetzstein"},{"authorId":"1684733","name":"Tammo van Lessen"},{"authorId":"1794984","name":"Daniel Wutke"},{"authorId":"1695266","name":"J\u00f6rg Nitzsche"},{"authorId":"1688415","name":"F. Leymann"}]},{"paperId":"02173c9e054fc503da2267e7d4f0628034c25fa8","title":"INTELLIGENT INFORMATION PROCESSIG IN A DIGITAL LIBRARY USING SEMANTIC WEB","abstract":"With the explosive growth of information, it is becoming increasingly difficult to retrieve the relevant documents with current search engine only. The information is treated as an ordinary database that manages the contents and positions. To the individual user, there is a great deal of useless information in addition to the substantial amount of useful information. This begets new challenges to docent community and motivates researchers to look for intelligent information retrieval approach and ontologies that search and\/or filter information automatically based on some higher level of understanding are required. We study improving the efficiency of search methods and classify the search patrons into several models based on the profiles of agent based on ontology. We have proposed a method to efficiently search for the target information on a Digital Library network with multiple independent information sources. This paper outlines the development of an expert prototype system based in an ontology for retrieval information of the Digital Library University of Seville. The results of this study demonstrate that by improving representation by incorporating more metadata from within the information and the ontology into the retrieval process, the effectiveness of the information retrieval is enhanced. We used Jcolibri and Pr\u00f3t\u00e9ge for developing the ontology and creation the expert system respectively.","venue":"","year":2009.0,"referenceCount":3,"citationCount":0,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"47619513","name":"Antonio Mart\u00edn"},{"authorId":"2285432474","name":"Carlos Le\u00f3n"}]},{"paperId":"02174b9ab8289110f652af761a5b92b4ccf2e3cf","title":"Discovering cultural conceptual structures from texts for ontology generation","abstract":"Today, the development of the semantic web is heavily impacted by the knowledge acquisition bottleneck. To address this problem, the discovery of conceptual structures have to become automatic. In addition, it has to guarantee that these structures are socially-constructed and consensually-shared in accordance with the requirements for designing ontologies. In this research, we present a process to automatically discover ready-made cultural knowledge structures from texts fitting the needs of ontology engineering. Relying on a framework coming from cognitive anthropology, we designed the latter to identify hypernym\/hyponym relations. During our experiment we obtained a promising 92.46% precision.","venue":"International Conference on Control, Decision and Information Technologies","year":2017.0,"referenceCount":58,"citationCount":5,"fieldsOfStudy":["Computer Science"],"publicationDate":"2017-04-01","authors":[{"authorId":"2070417858","name":"Jean Petit"},{"authorId":"31624541","name":"J. Boisson"},{"authorId":"2125313","name":"F. Rousseaux"}]},{"paperId":"021768a71a6e9a79b9250193ba2090951d18f394","title":"Hybrid semantic tagging for information extraction","abstract":"The semantic web is expected to have an impact at least as big as that of the existing HTML based web, if not greater. However, the challenge lays in creating this semantic web and in converting existing web information into the semantic paradigm. One of the core technologies that can help in migration process is automatic markup, the semantic markup of content, providing the semantic tags to describe the raw content. This paper describes a hybrid statistical and knowledge-based information extraction model, able to extract entities and relations at the sentence level. The model attempts to retain and improve the high accuracy levels of knowledge-based systems while drastically reducing the amount of manual labor by relying on statistics drawn from a training corpus. The implementation of the model, called TEG (Trainable Extraction Grammar), can be adapted to any IE domain by writing a suitable set of rules in a SCFG (Stochastic Context Free Grammar) based extraction language, and training them using an annotated corpus. The experiments show that our hybrid approach outperforms both purely statistical and purely knowledge-based systems, while requiring orders of magnitude less manual rule writing and smaller amount of training data. We also demonstrate the robustness of our system under conditions of poor training data quality. This makes the system very suitable for converting legacy web pages to semantic web pages.","venue":"The Web Conference","year":2005.0,"referenceCount":3,"citationCount":3,"fieldsOfStudy":["Computer Science"],"publicationDate":"2005-05-10","authors":[{"authorId":"145864794","name":"Ronen Feldman"},{"authorId":"47861681","name":"Binyamin Rosenfeld"},{"authorId":"1716503","name":"Moshe Fresko"},{"authorId":"1800527","name":"Brian D. Davison"}]},{"paperId":"0217e2c195c6a7921f95ba23702ad93d89382d99","title":"A Semantic Search Engine to Discover and Select Sensor Web Services for Wireless Sensor Network","abstract":null,"venue":"","year":2013.0,"referenceCount":7,"citationCount":2,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"145701493","name":"Chinmohan Nayak"},{"authorId":"1965082","name":"Manoranjan Parhi"}]},{"paperId":"02195c3b5f85477a7cb3846468f44ba07605a4d7","title":"Fairtrace - A Semantic-web Oriented Traceability Solution Applied to the Textile Traceability","abstract":"This paper presents solutions that leverage Semantic Web Technologies (SWT) to allow pragmatic traceability in supply-chains, especially for the textile industry. Objectives are the identification of the supply-chain, order management, tracking and problem reporting (such as dangerous substance detection). It is intended to be a generic platform supporting potentially any kind of industrial supply-chain, to be usable in harsh environments (mobile appliances) without any kind of communications possibility and to be fully usable to non-IT people, including for the modeling of the production processes. The developed solutions also allow the consumer to benefit from the traceability through information pages available by scanning the QR codes available on the finished products (clothes, clocks, etc.). This paper presents: i) the methodology applied to achieve those functionalities, ii) the design and implementation choices, and iii) the test results. The main value of this paper is the usage of the Semantic Web in real-world industrial traceability solutions, which were tested in real supply-chains in Switzerland and India. The commercialization of the developed solutions is in preparation.","venue":"International Conference on Enterprise Information Systems","year":2013.0,"referenceCount":29,"citationCount":3,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"145483549","name":"Bruno Alves"},{"authorId":"46779638","name":"M. Schumacher"},{"authorId":"3305648","name":"Fabian Cretton"},{"authorId":"3278915","name":"A. Calv\u00e9"},{"authorId":"2774198","name":"G. Cherix"},{"authorId":"2115978","name":"David Werlen"},{"authorId":"37130476","name":"Christian Gapany"},{"authorId":"1993559","name":"Bertrand Baeryswil"},{"authorId":"2057880287","name":"Doris Gerber"},{"authorId":"2245424","name":"Philippe Cloux"}]},{"paperId":"02198fd089b37eb8a7688b74bdbc48f130a6091c","title":"Building Knowledge Flow of Textual Topics for the e-Science Knowledge Grid","abstract":"In order to build knowledge flow of textual topics, the enormous topics of scientific texts are needed to be managed and organized. Island is proposed to manage the topic of scientific text belonging to the same domain. Interest table is presented to store the textual topics that researcher is interested recently. KM-Chord is introduced to organize KM, which not only reflects the concepts (keywords) of textual topic, but also takes the relationships between concepts into account. So KM-Chord has more strong semantic information than traditional Chord. Knowledge map (KM) representing textual topic can be located quickly with the help of KM-Chord, and the semantic information between KMs can be found (eg. similar and subtype relationship) for building the knowledge flow of the textual topics. The knowledge flow of textual topics can support knowledge innovation, cooperative teamwork, problem-solving and decision-making in e-Science Knowledge Grid. Experiments show KM-Chord not only can locate and route the textual topic, but also build the knowledge flow of textual topic effectively. So the proposed KM-Chord is a good method to build the Knowledge Flow of textual topics for the e-science Knowledge Grid, Semantic Grid and current Web.","venue":"International Conference on Grid and Cooperative Computing","year":2007.0,"referenceCount":26,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":"2007-08-16","authors":[{"authorId":"2167614","name":"Xiangfeng Luo"},{"authorId":"2469752","name":"Zhian Yu"}]},{"paperId":"021a63c04fe173c34209d9ae647832b6505fb61b","title":"Automated Semantic Interpretations in Web Applications via Cloud Computing Aspects","abstract":"The creation and execution of applications in several disciplines have been greatly aided by the integration of cloud computing and semantic web technologies. Although they are independent entities, they may also be combined in many ways to provide answers\u2014a subject that has been thoroughly researched lately. The number of \u201cnew cloud providers, applications, facilities, management systems, and data\u201d has significantly increased in recent years. The complexity that has resulted from this expansion emphasises the need for new technology in order to efficiently manage and support these varied and many services and resources. As a result, difficulties with \u201ccloud services and resources\u201d transferability, compatibility, security, choice, negotiation, identity, and specification might arise. Semantic Technologies are a vital tool for reassessing these issues because of their enormous \u201ccloud computing\u201d capacity. This study uses a variety of sources to examine and evaluate the impact of \u201cSemantic-Web Technology\u201d in the cloud. Moreover, a cloud-based engagement strategy shows how we may leverage the features and advantages of cloud computing to build the semantic web and provide automatic semantic annotations to online applications on a large scale.","venue":"2024 International Conference on Communication, Computer Sciences and Engineering (IC3SE)","year":2024.0,"referenceCount":41,"citationCount":0,"fieldsOfStudy":null,"publicationDate":"2024-05-09","authors":[{"authorId":"2281352791","name":"Preethi D"},{"authorId":"2312752375","name":"Poornima Mehta"},{"authorId":"2312765325","name":"Devendra Sood"}]},{"paperId":"021aac664fc1a2f5d3c4d833dec96289d77e2b5f","title":"On the Modeling of Entities for Ad-Hoc Entity Search in the Web of Data","abstract":null,"venue":"European Conference on Information Retrieval","year":2012.0,"referenceCount":30,"citationCount":47,"fieldsOfStudy":["Computer Science"],"publicationDate":"2012-04-01","authors":[{"authorId":"3147916","name":"R. Neumayer"},{"authorId":"1680484","name":"K. Balog"},{"authorId":"1394074062","name":"K. N\u00f8rv\u00e5g"}]},{"paperId":"021c4d56a9253f3ac4b87ff065d1939dbc79a256","title":"Dual cross-media relevance model for image annotation","abstract":"Image annotation has been an active research topic in recent years due to its potential impact on both image understanding and web image retrieval. Existing relevance-model-based methods perform image annotation by maximizing the joint probability of images and words, which is calculated by the expectation over training images. However, the semantic gap and the dependence on training data restrict their performance and scalability. In this paper, a dual cross-media relevance model (DCMRM) is proposed for automatic image annotation, which estimates the joint probability by the expectation over words in a pre-defined lexicon. DCMRM involves two kinds of critical relations in image annotation. One is the word-to-image relation and the other is the word-to-word relation. Both relations can be estimated by using search techniques on the web data as well as available training data. Experiments conducted on the Corel dataset and a web image dataset demonstrate the effectiveness of the proposed model.","venue":"ACM Multimedia","year":2007.0,"referenceCount":40,"citationCount":142,"fieldsOfStudy":["Computer Science"],"publicationDate":"2007-09-29","authors":[{"authorId":"46701354","name":"J. Liu"},{"authorId":null,"name":"Bin Wang"},{"authorId":"8392859","name":"Mingjing Li"},{"authorId":"2109689495","name":"Zhiwei Li"},{"authorId":"1712167","name":"Wei-Ying Ma"},{"authorId":"1694235","name":"Hanqing Lu"},{"authorId":"38450168","name":"Songde Ma"}]},{"paperId":"021e4aa7b28b25dee02a8b8a9852c7b5f6e16c47","title":"Natural Language Interface to Database using Semantic Matching","abstract":"Information is playing an important role in our lives. One of the major sources of information is databases. Databases and database technology are having major impact on the growing use of computers. In order to retrieve information from a database, one needs to formulate a query in such way that the computer will understand and produce the desired output. The Structured Query Language (SQL) norms are been pursued in almost all languages for relational database systems. However, not everybody is able to write SQL queries as they may not be aware of the structure of the database. So there is a need for non-expert users to query relational databases in their natural language instead of working with the values of the attributes. The idea of using natural language instead of SQL, has promoted the development of Natural Language Interface to Database systems (NLIDB). The need of NLIDB is increasing day by day as more and more people access information through web browsers, PDA\u2019s and cell phones. In this paper we introduce an intelligent interface for database. We prove that our NLIDB is guaranteed to map a natural language query to the corresponding SQL query. We have tested our system on Northwind database and show that our NLIDB compares favourably with MS English Query product.","venue":"","year":2011.0,"referenceCount":19,"citationCount":23,"fieldsOfStudy":["Computer Science"],"publicationDate":"2011-10-31","authors":[{"authorId":"1397632730","name":"Nihalan Neelu"},{"authorId":"70205847","name":"Mahesh Motwani"},{"authorId":"1397632726","name":"Sanjay Silaka"}]},{"paperId":"021e50a8acf2d86dd3171fce90619d02a2d4c3f6","title":"Semantic web service ontology standards","abstract":null,"venue":"","year":2005.0,"referenceCount":0,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":"2005-10-25","authors":[{"authorId":"2158900","name":"N. Rouquette"}]},{"paperId":"021ea45d6cd2a3109d31e099c91f03267ac796f0","title":"A multi-stage modeling framework for web service composition","abstract":"This paper considers Web service as a process net and defines it as an extended Petri net, in order to inherit the closure property of Petri nets. Some operators in the web service calculus are illustrated and mapped to the Petri nets operation. Then a multi-stage modeling framework for Web service composition is proposed based on formal modeling language. The framework is semi-automatic. It leverages the advantages of process algebra and semantic web modeling approaches, and integrates various practical tools proposed by literatures in each stage to improve productivity and reduce the expert skill requirements.","venue":"IEEE International Conference on Industrial Engineering and Engineering Management","year":2007.0,"referenceCount":15,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":"2007-12-01","authors":[{"authorId":"144834236","name":"Jian Xiao"},{"authorId":"143988902","name":"Li Zheng"}]},{"paperId":"021eaf2ea758d8d48e13fa79e43f2964fdb862e5","title":"Semantic Interoperability in Multi-Disciplinary Domain. Applications in Petroleum Industry","abstract":"The petroleum industry is a technically challenging business with high investments, complex projects and operational structures. There are numerous companies and public offices involved in the exploitation of a new oil field, and there is a high degree of specialization among them. Even though standardization has been considered important in this industry for many years, there is still very little integration across phases and across disciplines. An industrially driven consortium launched the Integrated Information Platform project in 2004, in which semantic standards based on OWL and Semantic Web technologies were to be developed for the subsea petroleum industry. In this paper, we present the IIP project in more detail and discuss applications for semantic information interoperability and retrieval.","venue":"C&O@ECAI","year":2006.0,"referenceCount":17,"citationCount":6,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"1755274","name":"J. Gulla"},{"authorId":"1741339","name":"Darijus Strasunskas"},{"authorId":"1714956","name":"Stein L. Tomassen"}]},{"paperId":"021fa24c0bf7cd737913099fb6ef5611c0b8b575","title":"Exposing SAMOS Data and Vocabularies within the Semantic Web","abstract":null,"venue":"","year":2014.0,"referenceCount":0,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":"2014-05-01","authors":[{"authorId":"49827718","name":"N. Dockery"},{"authorId":"116563474","name":"J. Elya"},{"authorId":"2110486167","name":"Shawn R. Smith"}]},{"paperId":"02213279c2d67c4e69421fe642f83fc20e60ae1e","title":"A Novel Semantic Web Service Discovery Algorithm based on Decentralized Systems","abstract":"In this paper, we described the efficient semantic web service discovery algorithm in DHT network based on decentralized systems. The algorithm focuses on the analysis of the input and output of web service and designs a procedure to construct WSDS to publish web services in DHT network that can let discovering the service more efficiently and accurately.","venue":"","year":2010.0,"referenceCount":0,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"2152750292","name":"Liu Feng"},{"authorId":"9234168","name":"Gao Guo-hong"},{"authorId":"9144713","name":"Fu Junhui"}]},{"paperId":"02225794e6ece0d5cc86e325fba2161706c27126","title":"On the semantics of the Semantic Web","abstract":null,"venue":"","year":2005.0,"referenceCount":0,"citationCount":2,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"1810016","name":"M. Colombetti"}]},{"paperId":"0223d1dc682b42daac2c6eb40aa1f4986d3d9ba6","title":"The taxonomic name resolution service: an online tool for automated standardization of plant names","abstract":null,"venue":"BMC Bioinformatics","year":2013.0,"referenceCount":67,"citationCount":449,"fieldsOfStudy":["Computer Science","Medicine"],"publicationDate":"2013-01-16","authors":[{"authorId":"49094158","name":"B. Boyle"},{"authorId":"2070690341","name":"Nicole Hopkins"},{"authorId":"1892594","name":"Zhenyuan Lu"},{"authorId":"40257580","name":"J. R. Garay"},{"authorId":"49666312","name":"D. Mozzherin"},{"authorId":"48125744","name":"Anthony J. J. (Tony) Rees"},{"authorId":"3140911","name":"Naim Matasci"},{"authorId":"1965308","name":"M. Narro"},{"authorId":"1991686","name":"W. H. Piel"},{"authorId":"35887337","name":"S. McKay"},{"authorId":"2059668870","name":"Sonya J. Lowry"},{"authorId":"50254248","name":"Chris Freeland"},{"authorId":"3303641","name":"R. Peet"},{"authorId":"3224953","name":"B. Enquist"}]},{"paperId":"02251ce46ba3c48be47fc0795496da2621b5289c","title":"The Semantic Web MIDI Tape: An Interface for Interlinking MIDI and Context Metadata","abstract":"The Linked Data paradigm has been used to publish a large number of musical datasets and ontologies on the Semantic Web, such as MusicBrainz, AcousticBrainz, and the Music Ontology. Recently, the MIDI Linked Data Cloud has been added to these datasets, representing more than 300,000 pieces in MIDI format as Linked Data, opening up the possibility for linking fine-grained symbolic music representations to existing music metadata databases. Despite the dataset making MIDI resources available in Web data standard formats such as RDF and SPARQL, the important issue of finding meaningful links between these MIDI resources and relevant contextual metadata in other datasets remains. A fundamental barrier for the provision and generation of such links is the difficulty that users have at adding new MIDI performance data and metadata to the platform. In this paper, we propose the Semantic Web MIDI Tape, a set of tools and associated interface for interacting with the MIDI Linked Data Cloud by enabling users to record, enrich, and retrieve MIDI performance data and related metadata in native Web data standards. The goal of such interactions is to find meaningful links between published MIDI resources and their relevant contextual metadata. We evaluate the Semantic Web MIDI Tape in various use cases involving user-contributed content, MIDI similarity querying, and entity recognition methods, and discuss their potential for finding links between MIDI resources and metadata.","venue":"SAAM@ISWC","year":2018.0,"referenceCount":33,"citationCount":4,"fieldsOfStudy":["Computer Science"],"publicationDate":"2018-10-09","authors":[{"authorId":"1401909927","name":"Albert Mero\u00f1o-Pe\u00f1uela"},{"authorId":"2260071","name":"R. Valk"},{"authorId":"3256660","name":"E. Daga"},{"authorId":"1811300","name":"Marilena Daquino"},{"authorId":"1410691351","name":"Anna Kent-Muller"}]},{"paperId":"0225780e1a273f23aa32690328db4e17e0a3a2eb","title":"Defining trustworthiness in Semantic Web by ontological assertions","abstract":"The paper introduces the model of knowledge management system that handles some aspects of trustworthiness. A method of defining trustworthiness in semantic Web and reasoning over knowledge enriched with trust information is presented. The method provides a way of building trustworthiness information into the assertional part of an ontology. Defining trustworthiness is meant as assigning a set of features to unary and binary assertions. The model defines a ldquotrust ontologyrdquo - an ontology that allows for assigning some features to specified assertions. There is also explained how Semantic Web agents could express their requirements for trust while querying a knowledge management system. The paper concludes with some implementation aspects of a prototype system that incorporates the presented model.","venue":"International Conference on Information Technology","year":2008.0,"referenceCount":13,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":"2008-05-18","authors":[{"authorId":"1719099","name":"K. Goczy\u0142a"},{"authorId":"2155747757","name":"Teresa Zawadzka"},{"authorId":"2091905683","name":"Michal Zawadzki"}]},{"paperId":"02282957659ab916311507c2b718c96f90b1ff11","title":"Extracting semantic knowledge from Wikipedia category names","abstract":"Wikipedia being a large, freely available, frequently updated and community maintained knowledge base, has been central to much recent research. However, quite often we find that the information extracted from it has extraneous content. This paper proposes a method to extract useful information from Wikipedia, using Semantic Features derived from Wikipedia categories. The proposed method provides good performance as a Wikipedia category based method. Experimental results on benchmark datasets show that the proposed method achieves a correlation coefficient of 0.66 with human judgments. The Semantic Features derived by this method gave good correlation with human rankings in a web search query completion application.","venue":"Conference on Automated Knowledge Base Construction","year":2013.0,"referenceCount":33,"citationCount":9,"fieldsOfStudy":["Computer Science"],"publicationDate":"2013-10-27","authors":[{"authorId":"1876013","name":"P. Radhakrishnan"},{"authorId":"1704709","name":"Vasudeva Varma"}]},{"paperId":"0229149990a84c3a9cdfbd60717bed97e79d89dc","title":"Mobile Pediatric Consultation and Monitoring System through Semantic Web Technology","abstract":"Health is a popular aspect of eHealth applications that is starting to explode exponentially. The use of technology offering solutions with a potential of making patients' lives easier in the health sector has gradually increased with mHealth. Technology has great bearing in the health sector in order to increase the efficiency to serve patients by helping to diagnose ailments reliably. Mobile systems help observation of child patients in their treatment process and the collection of health data on the course. Therefore, people will be more aware of their children's health problems and preventive measures in accordance with those health problems. This article is on Mobile Pediatric Consultation and Monitoring System (mPCMS). Details of design and operation are given in this article. Mpcms not only will assist doctors but also help patients in decision making process of the medical treatment due to the information's ease use. Accordingly, with mPCMS, there will be a contribution to distant consultation by the doctor and the family by collecting the health data before and after the treatment of child patients.","venue":"2014 IEEE 38th International Computer Software and Applications Conference Workshops","year":2014.0,"referenceCount":12,"citationCount":1,"fieldsOfStudy":["Computer Science"],"publicationDate":"2014-07-21","authors":[{"authorId":"21543653","name":"D. \u00c7elik"},{"authorId":"1723633","name":"Atilla El\u00e7i"},{"authorId":"2089663","name":"Ridvan Akcicek"},{"authorId":"13219829","name":"Bora Gokce"},{"authorId":"2893735","name":"Pelin Hurcan"}]},{"paperId":"022a9e3ad68974255728ae1452f3497c5ecfd24d","title":"Precise Matching of Semantic Web Services","abstract":null,"venue":"International Conference on Conceptual Structures","year":2006.0,"referenceCount":6,"citationCount":1,"fieldsOfStudy":["Computer Science"],"publicationDate":"2006-05-28","authors":[{"authorId":"2074925","name":"Yonglei Yao"},{"authorId":"3185257","name":"Sen Su"},{"authorId":"1716407","name":"Fangchun Yang"}]},{"paperId":"022b4e3221056597932377efa7a8c641f458ec64","title":"Web Feeds and Content Syndication:The Extension, Generation, Publication, Discovery and Sharing of RSS\/Atom","abstract":"RSS\/Atom feeds are XML-based contents in semantic Web and can be used as data sources by client-side parser.Microformats are semantic micorcontents embedded in HTML.Web feeds include RSS\/Atom feeds and microformat feeds.RSS\/Atom standardization leads to widely adoption by various applications and Web sites.Extensions for RSS\/Atom are used in specific domains.The S\/C mode and HTTP protocol are implemented between syndication providers and syndication consumers.RSS\/Atom feeds as a list enable updating and deleting client-side cache.Aotudiscovery is the best choice for Web sites informing their visitors about their RSS\/Atom feeds.The Microsoft SSE specification is used for two sites mutually subscribing to the RSS\/Atom feeds of their counterparts,enabling the bi-directional,asynchronous synchronization of new and changed items.","venue":"","year":2009.0,"referenceCount":0,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"101900311","name":"Jing Ji-peng"}]},{"paperId":"022bca2600b96998a0200955ed8fa5206b0d94c5","title":"Topic Maps, RDF Graphs, and Ontologies Visualization","abstract":null,"venue":"Visualizing the Semantic Web, 2nd Edition","year":2006.0,"referenceCount":15,"citationCount":32,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"1746981","name":"B. L. Grand"},{"authorId":"144996036","name":"M. Soto"}]},{"paperId":"022c06e60ff1129feba0ba8ccec95d8c9610a498","title":"Towards a behavioral description of cyber-physical systems using the thing description","abstract":"The World Wide Web Consortium (W3C) introduced the Thing Description (TD), a standardized and unified human- and machine-readable semantic description of Internet of Things (IoT) devices that focuses on describing how to interact with the described device using its network-interfaces. However, the TDs lack a way to describe the physical effect of said interactions on the device itself, as well as on the environment around the device, limiting its viability for cyber-physical scenarios. In this paper, we propose an extension for describing the effects of an interaction on the property affordances of a Thing in the TD as a first step towards a TD that is able to fully describe a Cyber-Physical System (CPS). We show this extension permits the generation of accurate Digital Twins, facilitates machine-aided system design and device mashup generation and allows for formal verification of the functionality of CPSs during their deployment and maintenance.","venue":"DAI-SNAC@CoNEXT","year":2021.0,"referenceCount":8,"citationCount":1,"fieldsOfStudy":["Computer Science"],"publicationDate":"2021-12-07","authors":[{"authorId":"146746817","name":"Farid Salama"},{"authorId":"118116662","name":"Ege Korkan"},{"authorId":"2423006","name":"Sebastian K\u00e4bisch"},{"authorId":"2120525","name":"S. Steinhorst"}]},{"paperId":"022c9074e0c3714f28ed03eddb8ea48356cf595f","title":"Ontologies in RDF ( S )","abstract":"RDF(S) constitutes a newly emerging standard for metadata that is about to turn the World Wide Web into a machineunderstandable knowledge base. It is an XML application that allows for the denotation of facts and schemata in a web-compatible format, building on an elaborate object-model for describing concepts and relations. Thus, it might turn up as a natural choice for a widely-useable ontology description language. However, its lack of capabilities for describing the semantics of concepts and relations beyond those provided by inheritance mechanisms makes it a rather weak language for even the most austere knowledge-based system. This paper presents an approach for modeling ontologies in RDF(S) that also considers axioms as objects that are describable in RDF(S). Thus, we provide exible, extensible, and adequate means for accessing and exchanging axioms in RDF(S). Our approach follows the spirit of the World Wide Web, as we do not assume a global axiom speci cation language that is too intractable for one purpose and too weak for the next, but rather a methodology that allows (communities of) users to specify what axioms are interesting in their domain. This paper is a revised version of a paper presented at the ECDL-2000Workshop on Semantic Web, Lisbon, Portugal, September 2000. We use \\RDF(S)\" to refer to the combined technologies of RDF and RDFS.","venue":"","year":2001.0,"referenceCount":18,"citationCount":0,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"2259136384","name":"Steffen Staab"},{"authorId":"2285307128","name":"Michael Erdmann"},{"authorId":"1806905","name":"A. Maedche"}]},{"paperId":"022d2b9ac276ee38c8f338993145963a2dc50d82","title":"Temporal Data Modeling and Reasoning for Information Systems","abstract":"Temporal knowledge representation and reasoning is a major research field in Artificial \nIntelligence, in Database Systems, and in Web and Semantic Web research. The ability to \nmodel and process time and calendar data is essential for many applications like appointment \nscheduling, planning, Web services, temporal and active database systems, adaptive \nWeb applications, and mobile computing applications. This article aims at three complementary \ngoals. First, to provide with a general background in temporal data modeling \nand reasoning approaches. Second, to serve as an orientation guide for further specific \nreading. Third, to point to new application fields and research perspectives on temporal \nknowledge representation and reasoning in the Web and Semantic Web.","venue":"","year":2006.0,"referenceCount":126,"citationCount":2,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"2073460802","name":"Stephanie Spranger"},{"authorId":"1767012","name":"Fran\u00e7ois Bry"}]},{"paperId":"022dc03a1dc9b607c3d56e51834f4d7352397948","title":"Improving e-Services Adoption With Semantic e-Services Platform and Question-Based Approach","abstract":"E-services have significantly changed the way of doing business in recent years. However, the implementation of these services remains poor. There is a significant gap between supply and actual e-service usage. This is why we started a project to provide an environment that will encourage the use of e-services. We believe that merely providing e-services does not automatically translate into consumers using them. This paper shows the origins of our project and its current position. We discuss the decision of using semantic web technologies and their potential to improve e-services usage. In this paper, we will present an e-services platform. Ontologies and semantic web technologies are used heavily in the platform. They enable the platform to be used as a basis for intelligent components, such as an e-service proposing component.","venue":"","year":2012.0,"referenceCount":10,"citationCount":0,"fieldsOfStudy":["Engineering"],"publicationDate":"2012-06-27","authors":[{"authorId":"1687986","name":"Luka Pavli\u010d"},{"authorId":"1713163","name":"M. Heri\u010dko"},{"authorId":"2228381","name":"Maja Pusnik"}]},{"paperId":"022e393213d6455f8bf38be1d758e5d4c2b62c3b","title":"A Semantic Model to Query Spatial-Temporal Data","abstract":null,"venue":"Information Fusion and Geographical Information Systems","year":2013.0,"referenceCount":18,"citationCount":10,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"2502598","name":"Benjamin Harbelot"},{"authorId":"2106585","name":"Helbert Arenas"},{"authorId":"145378327","name":"C. Cruz"}]},{"paperId":"022e6258f5d570577e6f87b9a75c9400ee96d494","title":"Extracting Spatial Semantics to Support the Development of Geospatial Ontologies on the Semantic Web","abstract":"Geo-ontologies have a key role to play in the development of the geospatial-semantic web, with regard to facilitating the search for geographical information and resources. They normally hold large amounts of geographic information and undergo a continuous process of revision and update. Hence, means of ensuring their integrity are crucial and needed to allow them to serve their purpose. This paper proposes a novel qualitative representation scheme to structure geoontology A-Boxes. The scheme captures two types of spatial relationships between geo-objects, namely, adjacency and orientation. It facilitates qualitative manipulation of the data and the efficient derivation of implicit information using spatial reasoning techniques.","venue":"","year":2008.0,"referenceCount":20,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"1398993196","name":"B. El-Geresy"},{"authorId":"1698708","name":"A. Abdelmoty"}]},{"paperId":"023298b047a793a633451d9a3212f29f753b0162","title":"Brainlets: \"instant\" Semantic Web applications","abstract":"In this paper we present the \"Brainlet\" paradigm, a way to create rich Semantic Web user interfaces and interaction environments. Brainlets are half way between configuration files and light scripts and are \"executed\" by the DBin rich Semantic Web Platform. The main motivation behind Brainlets is enabling domain experts, rather than programmers, to create rich Semantic Web environments and communities. Brainlets can in fact be created simply by XML configuration files and XML based scripts along with the proper ontologies. Advanced Brainlets can be created based on the internal DBin API and\/or the Eclipse Rich Client platform API. Brainlets are distributed as plug-ins and enable user communities, providing a common 'vision' of the domain and tools, to collectively create and exploit rich Semantic Web datasets.","venue":"","year":2006.0,"referenceCount":13,"citationCount":9,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"1700918","name":"G. Tummarello"},{"authorId":"1698989","name":"C. Morbidoni"},{"authorId":"38436958","name":"Michele Nucci"},{"authorId":"15362482","name":"O. Panzarino"}]},{"paperId":"02329e7369826b1f6d7869a14ae115ce97bc02f1","title":"A gyroidal pyramid searching model in digital ecosystems","abstract":"When ambiguous search terms are submitted to search engines, search results are usually literally but not always semantically relevant to the search terms. Users need to manually pick up relevant results from among thousands of the hit-list items. A gyroidal pyramid information retrieval model is proposed which intends to refine the results by grouping them into a predefined Web ontology, lets users choose which category is of interest, and thus presents the users with refined results. Users are allowed to choose subcategory to further refine the results, or choose another interesting category. Preliminary experimental results are positive and encouraging.","venue":"IEEE International Conference on Digital Ecosystems and Technologies","year":2009.0,"referenceCount":18,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":"2009-06-01","authors":[{"authorId":"2635255","name":"Dengya Zhu"},{"authorId":"2813696","name":"H. Dreher"}]},{"paperId":"0235c12abd7d6f83b9a53b4b805f95b57b248b3f","title":"Ontologies and metadata for E-Learning environments in Ecological and Environmental science","abstract":": - Ecological and environmental science has remained a discipline in which e-Learning has not been widely utilized, possibly due to the complexity and heterogeneity of the e-Learning content available. Traditionally the Learning Objects for ecological and environmental science consist of Web pages, unstructured documents, numerical data files and numerical data in databases. Using metadata attached to Learning Objects and different kinds of data enhances the use of heterogeneous materials. Metadata may be characterized as information about the data required to understand not only the data itself but also its context, quality and structure, as well as to make the data accessible and retrievable. This paper reviews research on metadata, ontologies and markup languages for e-Learning and describes the e-Learning content for ecological and environmental science. The paper describes two common metadata specifications, i.e. the Learning Object Metadata and the Dublin Core as well as two potential markup languages for ecological and environmental e-Learning, i.e. the Ecological Metadata Language and the Geography Markup Language. Metadata provides means to organize the major topics of e-Learning courses and for visualize the semantic connections between concepts. It is possible to extend and reuse metadata specifications by utilizing ontologies and ontology languages (e.g. Web Ontology Language). A semantic e-Learning environment for ecological and environmental science gives a student a possibility to build mental structures and learn in a constructive, self directed and activity oriented way.","venue":"","year":2008.0,"referenceCount":44,"citationCount":6,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"49319570","name":"P. Kuitunen"},{"authorId":"1771062","name":"Anne Honkaranta"},{"authorId":"1925949219","name":"Salonen"},{"authorId":"122239010","name":"Kalevi"},{"authorId":"49319570","name":"P. Kuitunen"}]},{"paperId":"0235f99ab8abf62c699e144efb3d28b64a98f5b9","title":"Enabling RETE Algorithm for RDFS Reasoning on Apache Spark","abstract":"Semantic web technology has been used to help various software, including Intelligence Personal Assistant, by acquiring new data or understanding the knowledge through relations between data. However, it is hard to apply the current semantic web schemes such as RDFS reasoning to the real world data because of huge volume of data need to be processed. In this study, we design and enable RDFS reasoning with RETE algorithm on Apache Spark in parallel fashion. In addition, we apply rule sequence optimization ordering from existing studies to enhance the processing performance. From the empirical experiment results, we verified that the implementation of our design shows a strong scalability. However, the current na\u00efve approach of using Spark provided distinct function to deduplicate data should be improved to yield a better processing performance. In future studies, we will study further to find new deduplication method.","venue":"International Symposium on Cloud and Service Computing","year":2018.0,"referenceCount":11,"citationCount":3,"fieldsOfStudy":["Computer Science"],"publicationDate":"2018-11-01","authors":[{"authorId":"46368927","name":"H. Ju"},{"authorId":"1678752","name":"Sangyoon Oh"}]},{"paperId":"023692b32b2d27d37f93f81081152d4302ff7793","title":"Computational Processing of the Portuguese Language : 7th International Workshop, PROPOR 2006, Itatiaia, Brazil, May 13-17, 2006, Proceedings","abstract":"Summarization.- Modeling and Evaluating Summaries Using Complex Networks.- SABio: An Automatic Portuguese Text Summarizer Through Artificial Neural Networks in a More Biologically Plausible Model.- Resources.- Building a Dictionary of Anthroponyms.- REPENTINO - A Wide-Scope Gazetteer for Entity Recognition in Portuguese.- Translation.- Using Natural Alignment to Extract Translation Equivalents.- Open-Source Portuguese-Spanish Machine Translation.- Weighted Finite-State Transducer Inference for Limited-Domain Speech-to-Speech Translation.- Named Entity Recognition.- A Golden Resource for Named Entity Recognition in Portuguese.- Functional Aspects in Portuguese NER.- SIEMES - A Named-Entity Recognizer for Portuguese Relying on Similarity Rules.- Tools and Frameworks.- Tools for Nominalization: An Alternative for Lexical Normalization.- A Framework for Integrating Natural Language Tools.- Methods and Tools for Encoding the WordNet.Br Sentences, Concept Glosses, and Conceptual-Semantic Relations.- A Multi-agent Approach to Question Answering.- Systems and Models.- Adaptation of Data and Models for Probabilistic Parsing of Portuguese.- A Set of NP-Extraction Rules for Portuguese: Defining, Learning and Pruning.- Resolving Portuguese Nominal Anaphora.- Design of a Multimodal Input Interface for a Dialogue System.- Review and Evaluation of DiZer - An Automatic Discourse Analyzer for Brazilian Portuguese.- Classroom Lecture Recognition.- Information Extraction.- Semi-supervised Learning for Portuguese Noun Phrase Extraction.- Automatic Extraction of Keywords for the Portuguese Language.- Semi-automatically Building Ontological Structures from Portuguese Written Texts.- Speech Processing.- On the Use of Machine Learning and Syllable Information in European Portuguese Grapheme-Phone Conversion.- A Model to Computational Speech Understanding.- Phonetic Sequence to Graphemes Conversion Based on DTW and One-Stage Algorithms.- Lexicon.- Very Strict Selectional Restrictions: A Comparison Between Portuguese and French.- Towards a Formalization of Tense and Aspect for the Generation of Portuguese Sentences.- The Need for Application-Dependent WSD Strategies: A Case Study in MT.- A Lexical Database of Portuguese Multiword Expressions.- Morpho-syntactic Studies.- Dedicated Nominal Featurization of Portuguese.- Part-of-Speech Tagging of Portuguese Based on Variable Length Markov Chains.- From Syntactical Analysis to Textual Segmentation.- Syntactical Annotation of COMPARA: Workflow and First Results.- Web, Corpus and Evaluation.- A Complex Evaluation Architecture for HAREM.- What Kinds of Geographical Information Are There in the Portuguese Web?.- Corpus-Based Compositionality.","venue":"","year":2006.0,"referenceCount":0,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"2294889492","name":"Maria das Gra\u00e7as Volpe Nunes"},{"authorId":"2294889492","name":"Maria das Gra\u00e7as Volpe Nunes"},{"authorId":"2295474721","name":"Claudia F de Oliveira"},{"authorId":"2294918912","name":"Paulo Quaresma"},{"authorId":"2294912381","name":"Renata Vieira"},{"authorId":"1790325","name":"N. Mamede"},{"authorId":"2295287522","name":"Maria Carmelita Dias"}]},{"paperId":"0238249699bb656e20580d18185d334c882ed8a6","title":"Moby and Moby 2: Creatures of the Deep (Web)","abstract":"Facile and meaningful integration of data from disparate resources is the 'holy grail' of bioinformatics. Some resources have begun to address this problem by providing their data using Semantic Web standards, specifically the Resource Description Framework (RDF) and the Web Ontology Language (OWL). Unfortunately, adoption of Semantic Web standards has been slow overall, and even in cases where the standards are being utilized, interconnectivity between resources is rare. In response, we have seen the emergence of centralized 'semantic warehouses' that collect public data from third parties, integrate it, translate it into OWL\/RDF and provide it to the community as a unified and queryable resource. One limitation of the warehouse approach is that queries are confined to the resources that have been selected for inclusion. A related problem, perhaps of greater concern, is that the majority of bioinformatics data exists in the 'Deep Web'-that is, the data does not exist until an application or analytical tool is invoked, and therefore does not have a predictable Web address. The inability to utilize Uniform Resource Identifiers (URIs) to address this data is a barrier to its accessibility via URI-centric Semantic Web technologies. Here we examine 'The State of the Union' for the adoption of Semantic Web standards in the health care and life sciences domain by key bioinformatics resources, explore the nature and connectivity of several community-driven semantic warehousing projects, and report on our own progress with the CardioSHARE\/Moby-2 project, which aims to make the resources of the Deep Web transparently accessible through SPARQL queries.","venue":"Briefings Bioinform.","year":2009.0,"referenceCount":74,"citationCount":27,"fieldsOfStudy":["Computer Science","Medicine"],"publicationDate":"2009-03-01","authors":[{"authorId":"8682058","name":"Benjamin P. Vandervalk"},{"authorId":"145050671","name":"E. McCarthy"},{"authorId":"31764087","name":"Mark D. Wilkinson"}]},{"paperId":"023827695ccba439ba35f453bf39db54df75b62b","title":"Semantic Web Practices: Infrastructural Politics and the Future of the Web","abstract":"In the past thirty years, the Web has developed from its inception as a layer of protocols on top of the Internet to use by more than 5 billion people and organizations. This has driven the creation of vast quantities of data and led to deep concerns about the politics of digital data and computational methods. To date, critical investigation of these concerns has focused on large commercial platforms built on top of the Web, and their use of machine learning methods. Meanwhile, less attention has been paid to the underlying design and protocols of Web itself, and how these might be implicated in the very same process and concerns. We explore ongoing endeavors to transform the Web from a library of documents intended for humans to a \u201csemantic Web\u201d using symbolic artificial intelligence to enable machine reasoning across multiple heterogenous data sources. In principle, this would transform the production and circulation of knowledge at Web scale. We present the findings from an experimental, interdisciplinary study exploring the epistemological politics and sociomaterial practices involved in situated accomplishment of the semantic Web. Our findings have consequences for the future of the Web and the future of Web-based platforms.","venue":"Science, Technology, &amp; Human Values","year":2024.0,"referenceCount":21,"citationCount":0,"fieldsOfStudy":null,"publicationDate":"2024-05-06","authors":[{"authorId":"2020931","name":"S. Halford"},{"authorId":"2806972","name":"M. Weal"},{"authorId":"2300671868","name":"Faranak Hardcastle"},{"authorId":"2300667471","name":"Nicholas Gibbins"},{"authorId":"2300667764","name":"Samantha Pearman-Kanza"},{"authorId":"2300508526","name":"Catherine Pope"}]},{"paperId":"023898a9ce3335de8ff5e3843b58c203ea41f878","title":"HISMA: A Human-Machine Iterative Schema Matching Algorithm","abstract":"The rapid development of the Semantic Web has led to the emergence of knowledge models in the form of ontology. The schema matching algorithm maps relational databases (RDB) to ontology models, which is an important method to solve the lack of ontology model instance data. However, existing schema matching algorithm is not compatible with the localization features of the data source and does not take full advantage of the results of manual validation. In this paper, we analyzed the localization features of the data source and modeled the manual validation process. We proposed a human-machine iterative schema matching method. This method utilizes the matched result in the schema matching process to optimize the matching algorithm, therefore to reduce the workload of manual validation. We used a real-world data set to evaluate the effectiveness of the algorithm.","venue":"2019 IEEE SmartWorld, Ubiquitous Intelligence & Computing, Advanced & Trusted Computing, Scalable Computing & Communications, Cloud & Big Data Computing, Internet of People and Smart City Innovation (SmartWorld\/SCALCOM\/UIC\/ATC\/CBDCom\/IOP\/SCI)","year":2019.0,"referenceCount":19,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":"2019-08-01","authors":[{"authorId":"1591220669","name":"Shuang Tang"},{"authorId":"49530603","name":"Junfeng Zhao"},{"authorId":"2108738446","name":"Yasha Wang"},{"authorId":"2058885164","name":"Da Cui"}]},{"paperId":"02396a9e2a229f53d6a0e553f306bb6233b86058","title":"Manipal Academy of Higher Education \u2013 Technology Transfer Flyer Licensing and Technology Transfer Opportunity Title of Technology: A System and Method for Linked Data Process to Explore Interdisciplinary Research","abstract":"The present invention provides a method and system for linking data processes in interdisciplinary research collaborations. The non-semantic data is transformed into semantic data using a data transformation module. The data is cleaned up by removing inconsistencies and represented in standard representation format. Resources are identified in the cleaned up data. The cleaned up data is mapped with a resource representation using semantic ontologies and the mapped data is converted into triple format. The triplicated data is enriched with semantic vocabularies and is linked with other data sources on the web using a link reconciliation module. The interlinked data available in machine-readable RDF format is deployed into a database. The visualization module allows visualization of machine readable RDF format data in human interpretable format using SPARQL protocol. The clients access the human interpretable format data through SPARQL protocol, custom applications or linked data applications.","venue":"","year":2020.0,"referenceCount":0,"citationCount":0,"fieldsOfStudy":null,"publicationDate":null,"authors":[]},{"paperId":"023a7e83a763efa82ff9875ef150faa76d301958","title":"Discovering Model of Semantic Web Service Based on Ontology","abstract":"Web services have already become one of the most important computing resources and software assets in the Internet. With the increasing number of Web services,how to find the required services efficiently or how to gain the best service from the vast service sets become important. The semantic description of Web service and the efficiency of OWL-S retrieval model of semantic Web service are the key to the discovery of the Web service. This article proposes the OWL-S framework of semantic Web service,and adopts OWL-S to describe the Web service,and raises pointed matching algorithm. Through experiments,in this model,together with the semantic Web service technology,the dynamical searching and composition of Web service are implemented,so that the precision ratio and the recall ratio of Web service can be improved.","venue":"","year":2010.0,"referenceCount":0,"citationCount":2,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"2110618177","name":"Cao Yu"}]},{"paperId":"023b44423602ef1286986470c0211384fbfdf46e","title":"The Online World of Information: Metadata Harvesting and Database Storage for Optimized Searching","abstract":"Modern life is hard to imagine without Internet and the myriad of information it o\ufb00ers. That\u2019s why it is becoming increasingly important to sort out this information and develop methods for quick and \u201dintel-ligent\u201d searching. These are problems for the Semantic Web [1, 2]. It provides a common framework that allows data to be shared and reused across application, enterprise, and community boundaries. Currently there are lots of tools and standards available for metadata handling. In the following paper I am describing a design for managing XML content exclusively on the database side. As a case study, I explore the capabilities of MySQL 5.1 in a user friendly Service Provider environment which collects metadata from di\ufb00erent online repositories. It stores the information in a centralized database thus making it available for local applications and at the same time providing basis for optimized searching through one of the latest database technologies. In addition, I o\ufb00er a solution for conversion between metadata formats, e","venue":"","year":2007.0,"referenceCount":18,"citationCount":0,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"116624918","name":"P. Kalpakliev"}]},{"paperId":"023bd19d480ed61e9a8ba9e7ee3aa9796d746c2d","title":"Query optimization for graph analytics on linked data using SPARQL","abstract":"Triplestores that support query languages such as SPARQL are emerging as the preferred and scalable solution to represent data and meta-data as massive heterogeneous graphs using Semantic Web standards. With increasing adoption, the desire to conduct graph-theoretic mining and exploratory analysis has also increased. Addressing that desire, this paper presents a solution that is the marriage of Graph Theory and the Semantic Web. We present software that can analyze Linked Data using graph operations such as counting triangles, finding eccentricity, testing connectedness, and computing PageRank directly on triple stores via the SPARQL interface. We describe the process of optimizing performance of the SPARQL-based implementation of such popular graph algorithms by reducing the space-overhead, simplifying iterative complexity and removing redundant computations by understanding query plans. Our optimized approach shows significant performance gains on triplestores hosted on stand-alone workstations as well as hardware-optimized scalable supercomputers such as the Cray XMT.","venue":"","year":2015.0,"referenceCount":23,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":"2015-07-01","authors":[{"authorId":"3056282","name":"Seokyong Hong"},{"authorId":"2108049553","name":"S. Lee"},{"authorId":"8600116","name":"Seung-Hwan Lim"},{"authorId":"1750800","name":"S. Sukumar"},{"authorId":"3001600","name":"Ranga Raju Vatsavai"}]},{"paperId":"023bdb4a405a8b61825caec902974860c591e8ac","title":"Information management in civil engineering infrastructural development: With focus on geological and geotechnical information","abstract":"In civil engineering infrastructural projects, information exchange and (re-) use in and between involved parties is difficult. This is mainly caused by a lack of information harmonization. Various specialists are working together on the development of an infrastructural project and are all using their own specific software and definitions for the various information types. The variety of information types adds to the differences regarding the use and definition of thematic semantic information. Also the source of the information may vary from surveyed and interpreted to designed objects. This makes harmonization of geo-information extremely difficult. Realistic 3D models describing and integrating part of the earth already exist, but are generally neglecting the subsurface, and especially the aspects of geological and geotechnical information. This paper summarizes the first steps undertaken towards the extension of an existing integrated semantic information model to include (above and on) surface as well as subsurface objects and in particular, subsurface geological and geotechnical objects. Standards, exchange formats and existing models used as a basis for the development of a core geological model as part of an integrated 3D information model are described in this paper. Examples of definitions of subsurface geological objects and required attribute information (to be) included in the integrated 3D information model are given. Web-based visualisation tools are, too, investigated to be able to access and visualise the model also in an application-independent environment.","venue":"","year":2009.0,"referenceCount":38,"citationCount":28,"fieldsOfStudy":["Engineering"],"publicationDate":"2009-07-27","authors":[{"authorId":"47693941","name":"W. Tegtmeier"},{"authorId":"1689750","name":"S. Zlatanova"},{"authorId":"1717628","name":"P. V. Oosterom"},{"authorId":"102946946","name":"H. Hack"}]},{"paperId":"023bf4b448e24e7415fb19e568fe26a222d9f26d","title":"The Journal of Systems and Software","abstract":"Recently, there has been growing interest in web services composition. Web services composition gives us a possibility to ful\ufb01l the user request when no single web service can satisfy the functionality required by the user. In this paper, we propose a new system called PSR for the scalable and ef\ufb01cient web services composition search using a relational database. In contrast to previous work, the PSR system pre-computes web services composition using joins and indices and also supports semantic matching of web services composition. We demonstrate that our pre-computing web services composition approach in RDBMS yields lower execution time for processing user queries despite of and shows good scalability when handling a large number of web services and user queries.","venue":"","year":null,"referenceCount":39,"citationCount":57,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"1756616","name":"Daewook Lee"},{"authorId":"1756023","name":"Joonho Kwon"},{"authorId":"1693603","name":"Sangjun Lee"},{"authorId":"1720830","name":"Seog Park"},{"authorId":"2333893786","name":"Hong c"}]},{"paperId":"023cbea8c470fd116a2eeaf3167d48573572d9d6","title":"On Knowledge Representation Issues","abstract":"Abstract : Knowledge Representations issues take on special significance in the light of development of the novel Web's reality that involves the Semantic Web, GRID, P2P and other today's ITs. In contrast to the previous IT evolution's stages, the recent one utilizes ontology as separated resource. An elaborate knowledge representation approach implies an efficiency of knowledge-based systems and their interoperability. This paper deals with Ontology Engineering approach that allows both build and generate the consistent dynamic autonomous knowledge-based systems.","venue":"","year":2004.0,"referenceCount":10,"citationCount":1,"fieldsOfStudy":["Computer Science"],"publicationDate":"2004-08-01","authors":[{"authorId":"3305160","name":"A. Abramovich"}]},{"paperId":"023f6164480d101f402c1cf9cd2c9cdc499b39a8","title":"Creating automated plans for Semantic Web applications through planning as model checking","abstract":null,"venue":"Expert systems with applications","year":2009.0,"referenceCount":28,"citationCount":4,"fieldsOfStudy":["Computer Science"],"publicationDate":"2009-09-01","authors":[{"authorId":"27502836","name":"B. Anderson"},{"authorId":"1766955","name":"J. Hansen"},{"authorId":"1786893","name":"P. Lowry"}]},{"paperId":"02417f4c024ed37ef68cf1abe0d7dbac0d6d70c6","title":"Resources and Semantic-based knowledge models for personalized and self-regulated learning in the Web: survey and trends","abstract":"Learning is a complex and multifaceted process. Research findings in recent years show that student's control over the learning process is important for achieving higher results. As every student or lifelong learner have his specific interests and needs, in many cases no one learning course can meet all these needs. It is important to ensure possibilities for learners to find additional knowledge sources or tools during his learning process. Cloud Learning consider the entire Web (including Social Web tools, Open Educational Resources and many other sources for learning) as a space for learning content. Finding exactly the needed resource for every learning need in this enormous space is a challenge. There is a need to explore all the resources useful for learning, classify them in a way that will support searching, and to express relations between them using semantic annotations. In this paper we analyze the current state of the resources, appropriate for learning in the internet from technological point of view. We classify resources according to several dimensions, important for searching and using by learners. We take special attention to the ways of semantic description of resources and users (used metadata and models) as metadata are the most important for finding the most appropriate resources for specific learning task. Tasks as searching and retrieval for learning are not new and our main aim in this work is to outline resent changes in web-based learning, resulting from technological changes and discuss how they will affect resource searching. We will discuss how cloud-based technologies and embedded semantic descriptions will simplify searching and finding appropriate learning sources.","venue":"International Conference on Computer Systems and Technologies","year":2019.0,"referenceCount":40,"citationCount":5,"fieldsOfStudy":["Computer Science"],"publicationDate":"2019-06-21","authors":[{"authorId":"144911896","name":"T. Ivanova"}]},{"paperId":"0243ab7dcaffd43c87b556129a90d5ff77cd680f","title":"Ontology-based Autonomic Computing for Resource Sharing between Data Warehouses in Decision Support Systems","abstract":"Complexity is the biggest challenge in managing information systems today, because of the continuous growth in data and information. As decision experts, we are faced with the problems generated by managing Decision Support Systems, one of which is the efficient allocation of shared resources. In this paper, we propose a solution for improving the allocation of shared resources between groups of data warehouses within a decision support system, with the Service Levels Agreements and Quality of Service as performance objectives. We base our proposal on the notions of autonomic computing, by challenging the traditional way of autonomic systems and by taking into consideration decision support systems\u2019 special characteristics such as usage discontinuity or service level specifications. To this end, we propose the usage of specific heuristics for the autonomic self-improvement and integrate aspects of semantic web and ontology engineering as information source for knowledge base representation, while providing a critical view over the advantages and disadvantages of such a solution.","venue":"International Conference on Enterprise Information Systems","year":2010.0,"referenceCount":21,"citationCount":1,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"1403819584","name":"Vlad Nicolicin-Georgescu"},{"authorId":"2842917","name":"Vincent Benatier"},{"authorId":"2950573","name":"R\u00e9mi Lehn"},{"authorId":"34566158","name":"H. Briand"}]},{"paperId":"024590d656f4047331bfb01c6880760481fa6363","title":"Usability Reasoning Using OWL 2 RL","abstract":"How users experience a web-site's usability is mostly subjective. There is an ISO standard adressing usability requirements (EN ISO 9241-11). However, its propositions are kept rather general and focus strongly on individual usage situations. Nevertheless, there are usability critera for websites that can be considered negative, e.g. bad contrast, a high readability index, or discrepancies between an expected user behavior and the users' actual behavior. Our system \u2014 AbRUPt \u2014 is able to capture a large number of such criteria automatically. By converting, modeling and developing a rule base in the semantic ontology language OWL 2 RL, a system is created that allows automated reasoning for potential web usability problems. This rule base will be presented in this paper.","venue":"Quality of Information and Communications Technology","year":2016.0,"referenceCount":14,"citationCount":1,"fieldsOfStudy":["Computer Science"],"publicationDate":"2016-09-01","authors":[{"authorId":"32938447","name":"Ludger Martin"},{"authorId":"2093953573","name":"Manuel Dudda"}]},{"paperId":"0247f8077a31d4db6d0d40e16253cac745a4d928","title":"Using Ontology for Personalized E-Learning in K-12 Education","abstract":"E-learning environments incorporate the notion of semantic Web into their future directions. Semantic Web uses ontologies to show the interconnectedness in a Web environment. Ontologies are being developed in order to decrease the annotated amount of markup and increase the reliability of using computational (intelligent) agents; consequently, a number of ontologies in a variety of domains are being constructed. Within the concept of semantic mapping, domain ontology is at the core of intelligent e-learning AbsTRACT","venue":"","year":2010.0,"referenceCount":13,"citationCount":3,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"1808911","name":"P. A\u015fkar"},{"authorId":"2287075808","name":"Arif Altun"},{"authorId":"72241379","name":"Kagan Kalinyazgan"},{"authorId":"71558988","name":"S. S. Pekince"}]},{"paperId":"0248e438b508178ef4bf89c385c2811e1be6dd3d","title":"Large-Scale SVD and Subspace-Based Methods for Information Retrieval","abstract":null,"venue":"Workshop on Parallel Algorithms for Irregularly Structured Problems","year":1998.0,"referenceCount":14,"citationCount":27,"fieldsOfStudy":["Computer Science"],"publicationDate":"1998-08-09","authors":[{"authorId":"145203884","name":"H. Zha"},{"authorId":"32195587","name":"O. Marques"},{"authorId":"35124559","name":"H. Simon"}]},{"paperId":"02497b101ba10b2752e161468372e593f6617306","title":"A Semantic Web Service Architecture for Supply Chain Management","abstract":null,"venue":"ANT\/SEIT","year":2017.0,"referenceCount":9,"citationCount":12,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"2538382","name":"Kamalendu Pal"}]},{"paperId":"024be1acbf36e0d378d946ce499277cafd978c71","title":"Virtual organization for open innovation: Semantic web based inter-organizational team formation","abstract":null,"venue":"Expert systems with applications","year":2011.0,"referenceCount":41,"citationCount":34,"fieldsOfStudy":["Business","Computer Science"],"publicationDate":"2011-07-01","authors":[{"authorId":"34946615","name":"Hyeongon Wi"},{"authorId":"2505098","name":"Seungjin Oh"},{"authorId":"46927279","name":"M. Jung"}]},{"paperId":"024d8ed5f7ff66e89ebeda700219d6bd65c1b766","title":"K-Tools: Towards Semantic Knowledge Management","abstract":null,"venue":"Extended Semantic Web Conference","year":2009.0,"referenceCount":6,"citationCount":1,"fieldsOfStudy":["Computer Science"],"publicationDate":"2009-05-31","authors":[{"authorId":"37970742","name":"Sam Chapman"},{"authorId":"145866489","name":"V. Lanfranchi"},{"authorId":"2988600","name":"Ravish Bhagdev"}]},{"paperId":"024db004f761b692a4fefe85accba8381ebee008","title":"Data Compression and Clustering: A Blind Approach to Classification","abstract":": Data Compression is today essential for a wide range of applications: for example Internet and the World Wide Web infrastructures benefits from compression. New general compression methods are always being developed, in particular those that allow indexing over compressed data or error resilience. Compression also inspires information theoretic tools for pattern discovery and classification, in particular it is possible to use data compression as a metric for clustering. This leads to a powerful clustering strategy that does not use any \u201csemantic\u201d information on the data to be classified but does a \u201cblind\u201d and effective classification that is based only on the compressibility of digital data and not on its \u201cmeaning\u201d. Here we experiment with this strategy and show its effectiveness.","venue":"","year":2012.0,"referenceCount":4,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"2200559","name":"B. Carpentieri"}]},{"paperId":"024ea80abdf7a4a04f6b9ffad4499790d37905b7","title":"Reasoning with expressive description logics: logical foundations for the semantic web","abstract":"Description Logics (DLs) are a family of logic based Knowledge Representation formalisms descended from semantic networks and KL-ONE. They are distinguished by having formal (model theoretic) semantics, and by the provision of (sound and complete) inference services, with several highly optimised implementations now being available. DLs have a wide range of applications, but are perhaps best know as ontology languages (they provide the basis for recent \"Semantic Web\" ontology languages such as OIL, DAML+OIL and OWL). In this talk I will give a brief history of DLs and of DL applications, in particular their application in the context of the Semantic Web. If time permits, I will then give an overview of the reasoning techniques that are employed by state of the art DL implementations, and which enable them to be effective in realistic applications, in spite of the high worst case complexity of their basic inference problems. Finally, I will point out some interesting areas for future research, in particular those related to the Semantic Web application area.","venue":"","year":2004.0,"referenceCount":8,"citationCount":5,"fieldsOfStudy":["Computer Science"],"publicationDate":"2004-10-01","authors":[{"authorId":"145655431","name":"Ian Horrocks"}]},{"paperId":"024f69e7a3985ef6f451c3990c5ac4e8cac8975e","title":"Automatic Mapping of Relational Databases to OWL Antology","abstract":"Nowadays relational models are most frequently used to store, treat and extract data. Yet, the increase of semantic web technologies and the fast development of its applications based on ontology have made the problem of migrating RDB to OWL an active research domain. The difficulties with this problem lay especially in the treatment of semantic constraints of the data stored in RDB which let the transition from RDB to OWL require a thorough study of all characteristics of the data structures to be converted. In this context, we give a state of the art comparison of existing mapping methods from RDB to RDF\/OWL and propose a novel migration solution that generalizes these methods, optimizes constraints extraction and retains the RDB source schema characteristics. A tool based on our approach has also been developed and tested to demonstrate the effectiveness and power of our strategy. Keywords\u2014 web ontology; semantic web; relational database RDB; OWL","venue":"","year":2014.0,"referenceCount":14,"citationCount":7,"fieldsOfStudy":["Computer Science"],"publicationDate":"2014-04-29","authors":[{"authorId":"145080995","name":"L. Alaoui"},{"authorId":"51125546","name":"Oussama El Hajjamy"},{"authorId":"2747412","name":"M. Bahaj"}]},{"paperId":"024faf692a492c71871e3c8fceb14aee61ca86cb","title":"Ontology Evolution Detection: Method and Results","abstract":null,"venue":"China Semantic Web Symposium","year":2014.0,"referenceCount":17,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":"2014-08-08","authors":[{"authorId":"113475856","name":"Gaofan Li"},{"authorId":"2155300106","name":"Peng Wang"},{"authorId":"2116416129","name":"Bin Yu"}]},{"paperId":"02510a7762613221405a330fe013121cb178c26c","title":"Type Linking for Query Understanding and Semantic Search","abstract":"Huawei is currently undertaking an effort to build map and web search services using query understanding and semantic search techniques. We present our efforts to built a low-latency type mention detection and linking service for map search. In addition to latency challenges, we only had access to low quality and biased training data plus we had to support 13 languages. Consequently, our service is based mostly on unsupervised term- and vector-based methods. Nevertheless, we trained a Transformer-based query tagger which we integrated with the rest of the pipeline using a reward and penalisation approach. We present techniques that we designed in order to address challenges with the type dictionary, incompatibilities in scoring between the term-based and vector-based methods as well as over-segmentation issues in Thai, Chinese, and Japanese. We have evaluated our approach on the Huawei map search use case as well as on community Question Answering benchmarks.","venue":"Knowledge Discovery and Data Mining","year":2022.0,"referenceCount":40,"citationCount":3,"fieldsOfStudy":["Computer Science"],"publicationDate":"2022-08-14","authors":[{"authorId":"2174835","name":"G. Stoilos"},{"authorId":"3451396","name":"Nikos Papasarantopoulos"},{"authorId":"7631872","name":"P. Vougiouklis"},{"authorId":"1492145963","name":"Patrik Bansky"}]},{"paperId":"0252b7f1ed67ef07940ba10c7e72eba738be0bc7","title":"WebSifter II: A Personalizable Meta-Search Agent Based on Weighted Semantic Taxonomy Tree","abstract":"This paper addresses the problem of specifying, retrieving, filtering and rating Web searches so as to improve the relevance and quality of hits, based on the user\u2019s search intent and preferences. We present a methodology and architecture for an agent-based system, called WebSifter II, that captures the semantics of a user\u2019s decision-oriented search intent, transforms the semantic query into target queries for existing search engines, and then ranks the resulting page hits according to a user-specified weighted-rating scheme. Users create personalized search taxonomies via our Weighted Semantic-Taxonomy Tree. The terms in the tree can be refined by consulting a web taxonomy agent such as Wordnet. The concepts represented in the tree are then transformed into a collection of queries processed by existing search engines. Each returned page is rated according to user-specified preferences such as semantic relevance, syntactic relevance, categorical match, page popularity and authority\/hub rating.","venue":"International Conference on Internet Computing","year":2001.0,"referenceCount":27,"citationCount":23,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"1701723","name":"L. Kerschberg"},{"authorId":"145883782","name":"Wooju Kim"},{"authorId":"1756755","name":"Anthony Scime"}]},{"paperId":"0252c600672a52ebe18549ccca548446cb09c6c6","title":"TIGHTLY INTEGRATED PROBABILISTIC DESCRIPTIONLOGIC PROGRAMS","abstract":"We present a novel approach to probabilistic description lo gic programs for the Semantic Web, which constitutes a tight combination of disjuncti ve logic programs under the answer set semantics with both description logics and Bayesian probab ilities. The approach has a number of nice features. In particular, it allows for a natural probab ilistic data integration, where probabilities over possible worlds may be used as trust, error, or mapping p robabilities. Furthermore, it also provides a natural integration of a situation-calculus based l anguage for reasoning about actions with both description logics and Bayesian probabilities. We sho w that consistency checking and query processing are decidable resp. computable, and that they ca n be reduced to consistency checking resp. cautious\/brave reasoning in tightly integrated disj unctive description logic programs. We also analyze the complexity of consistency checking and query pr ocessing in probabilistic description logic programs in special cases. In particular, we present a special case of these problems with polynomial data complexity. 1Facolt\u0300a di Scienze e Tecnologie Informatiche, Libera Universit \u00e0 di Bolzano, Piazza Domenicani 3, I-39100 Bolzano, Italy; e-mail: cali@inf.unibz.it. 2Dipartimento di Informatica e Sistemistica, Universit \u00e0 di Roma \u201cLa Sapienza\u201d, Via Salaria 113, I-00198 Roma, Italy; e-mail: lukasiewicz@dis.uniroma1.it. Institut f \u00fcr Informationssysteme, Technische Universit \u00e4t Wien, Favoritenstra\u00dfe 9-11, A-1040 Wien, Austria; e-mail: lukasiewicz@kr .tuwien.ac.at. Acknowledgements: This work has been partially supported by the STREP FET proj ect TONES (FP6-7603) of the European Union and by a Heisenberg Professorship of th e German Research Foundation (DFG). Copyright c \u00a9 2007 by the authors INFSYS RR 1843-07-05 I","venue":"","year":2007.0,"referenceCount":0,"citationCount":2,"fieldsOfStudy":null,"publicationDate":null,"authors":[]},{"paperId":"0252cd6ecb77b82107c3b747790828c8a7592580","title":"On Ontologology","abstract":"The study of models, and related concepts such as metamodels, is largely situated within the software engineering community under the banner of model-driven development. Yet these concepts have some obvious parallels with concepts developed within the arti\ufb01cial intelligence community under the banners of ontologies and the semantic web. Although a considerable amount of work has been done that aims to relate the development of ontologies to the model-driven development of software, the place of bidirectional transformations within these connected worlds is (almost) unstudied. Yet, experts in the study of ontologies have experienced the need to check and restore consistency, and have developed techniques, terminology and tools that relate to these tasks. In this paper we provide a high-level introduction to the work that has been done, aiming to promote further study and perhaps collaboration between these communities.","venue":"BX@ETAPS","year":2017.0,"referenceCount":21,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"145098640","name":"P. Stevens"},{"authorId":"1737044","name":"J. Gibbons"}]},{"paperId":"0253b8640541ca8a977c8eb092fbc081d69f3b72","title":"Towards Maximum Spanning Tree Model in Web 3.0 Design and Development for Students using Discriminant Analysis","abstract":"Web 3.0 is an evolving extension of the web 2.0 scenario. The perceptions regarding web 3.0 is different from person to person . Web 3.0 Architecture supports ubiquitous connectivity, network computing, open identity, intelligent web, distributed databases and intelligent applications. Some of the technologies which lead to the design and development of web 3.0 applications are Artificial intelligence, Automated reasoning, Cognitive architecture, Semantic web . An attempt is made to capture the requirements of Students inline with web 3.0 so as to bridge the gap between the design and development of web 3.0 applications and requirements among Students. Maximum Spanning Tree modeling of the requirements facilitate the identification of key areas and key attributes in the design and development of software products for Students in Web 3.0 using Discriminant analysis. Keywords : Web 3.0, Discriminant analysis, Design and Development, Model, Maximum Spanning Tree 1.","venue":"arXiv.org","year":2012.0,"referenceCount":18,"citationCount":2,"fieldsOfStudy":["Computer Science"],"publicationDate":"2012-02-15","authors":[{"authorId":"153718679","name":"S. Padma"},{"authorId":"2608202","name":"Ananthi Seshasaayee"}]},{"paperId":"02551902e8aeb8e9fee48c5d83b02b5136b29c10","title":"dlvhex : A Tool for Semantic-Web Reasoning under the Answer-Set Semantics !","abstract":". We brie\ufb02y report about the development status of dlvhex , a reasoning engine for HEX -programs, which are nonmonotonic logic programs featuring both higher-order atoms as well as external ones. Higher-order features are widely acknowledged as useful for various tasks and are essential in the context of meta-reasoning. Furthermore, the possibility to exchange knowledge with ex-ternal sources in a fully declarative framework such as answer-set programming (ASP) is particularly important in view of applications in the Semantic-Web area. Through external atoms, HEX -programs can deal with external knowledge and reasoners of various nature, such as RDF datasets or description-logic bases.","venue":"","year":2006.0,"referenceCount":11,"citationCount":12,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"72431510","name":"Thomas Eiter"},{"authorId":"1693628","name":"Giovambattista Ianni"},{"authorId":"2746504","name":"Roman Schindlauer"},{"authorId":"2756122","name":"H. Tompits"}]},{"paperId":"025550bf7dbf008cd574066119c3a6d51a80928b","title":"Linked Data in Business","abstract":null,"venue":"Business & Information Systems Engineering","year":2016.0,"referenceCount":5,"citationCount":12,"fieldsOfStudy":["Computer Science"],"publicationDate":"2016-08-15","authors":[{"authorId":"2846021","name":"W. Abramowicz"},{"authorId":"145044578","name":"S. Auer"},{"authorId":"144131553","name":"T. Heath"}]},{"paperId":"02556c2045bbc117cdde7a756b73b2d0f0995431","title":"Social semantic cloud of tags: semantic model for folksonomies","abstract":null,"venue":"","year":2010.0,"referenceCount":32,"citationCount":10,"fieldsOfStudy":["Computer Science"],"publicationDate":"2010-09-01","authors":[{"authorId":"1804394","name":"H. Kim"},{"authorId":"1707342","name":"J. Breslin"},{"authorId":"29098509","name":"H. Kim"},{"authorId":"2149220491","name":"Jaehwa Choi"}]},{"paperId":"02561d0a644e996ff3708b900d1f89723e0a6904","title":"Building Ecommerce Framework for Online Shopping using Semantic Web and Web 3.0","abstract":": E-commerce is one of the popular areas. In Online Shopping we can perform add, remove, edit, and update the product as per dealers and end users requirement. With the use of semantic web and web 3.0 the system performance will increase. The system should have proper user interface. The customers who visit online shopping system, they will have easy implementation of search item. This will increase the participation of various dealers for their product to get them online. For each Dealer have separate login and they also insert product, tracking products delivery for their products. The proposed system will use semantic web and web 3.0 Therefore, for Customer and also for Dealer it is useful. For both Customer and Dealers it shows own interface .","venue":"","year":2016.0,"referenceCount":16,"citationCount":0,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"2103268108","name":"Pranita Barpute"},{"authorId":"2082296796","name":"Dhananjay Solankar"},{"authorId":"2102626579","name":"Ravi Hanwate"},{"authorId":"2099409226","name":"Puja Kurwade"},{"authorId":"145796644","name":"Kiran Avhad"}]},{"paperId":"0256471e49386665e5f59be3b21c4cdaee56d96f","title":"Transatlantic health IT policies: opportunities for small businesses and health systems.","abstract":"I t is unfortunate that headlines on global health reforms have largely focused attention on the public\u2013private payment system shifts. Although this may be unsurprising given the political battles on which many elections hinge, beyond the politics, reforms create new markets for services, particularly via changes in management for data and transactions handled electronically. These new markets have the potential for creating jobs for skilled laborers in information technology (IT) as well as reducing costs for strained health systems without adding to the political divide on health service regulations. Although opportunities are certain, barriers with connecting needs to providers have been hindered by lack of progress on various transatlantic policies that could develop such advances. These issues include semantic interoperability\u2014the alignment of diverse systems across parallel groups\u2014and the ability to reference past successes of comparable work. This letter aims to address these issues through highlighting possibilities for health IT (HIT) experts in a global market, beginning in Europe. In December 2010, the U.S. Department of Health and Human Services (DHHS) and the European Commission\u2019s Directorate General for Communications Networks, Content and Technology (DG CONNECT) signed a memorandum of understanding (MoU) outlining the need to improve interoperability between U.S. and European electronic health (e-health) records (EHRs). This established a clear path toward overlapping health service markets between the two largest health economies. The MoU has been reinforced by the Trans-Atlantic Economic Council and provides a framework on which e-health solutions can be built. Preliminary discussions between the DHSS and the European DirectorateGeneral of InformationSociety andMedia aim toestablisha global conceptual framework for the integration of e-healthcare. Although steps toward interoperability have clearly begun, a summit of HIT stakeholders between the two sides was held in Copenhagen, Denmark, inMay2012 toaddress opportunities and remaining issues in this field. Pressing areas of need and opportunity were outlined, including the expanding role ofHIT companies inEurope.However, there is little evidence that considerable progress has been made in the time since this meeting toward improving interoperability. At the Copenhagen meeting, the DHHS outlined the key policy incentives to reward implementations based on adoption and \u2018\u2018meaningful use\u2019\u2019 of e-health applications. These solutions should be based on patient-centeredness and meaningful certification procedures for future products. The first results of this policy indicate a dramatic increase in the area of EHR certification\u2014recently, the number of certified products increased from the low hundreds into the thousands. Since the Copenhagen meeting, there has been a debatable amount of progress on the MoU, although a roadmap was recently produced via agreements between the European Commission\u2019s DG CONNECT and DHHS. This roadmap focuses on standardization and workforce development for users and providers of HIT services in the United States and is a key component (much of the information on this comes from gray literature, technical documents, and Web information; for an overview, see http:\/\/ec.europa.eu\/digital-agenda\/en\/ news\/eu-and-us-step-cooperation-ehealth-it) of the Digital Agenda for Europe (see http:\/\/ec.europa.eu\/digital-agenda\/), a seven \u2018\u2018pillar\u2019\u2019 strategy aimed to enhance digital technologies focus on sustainable economic growth. Given this approach, as well as concurrent aims to enhance small-to-medium enterprises (SMEs) in Europe, it is entirely appropriate that further efforts should be made to learn from established, similar markets. The associated industry (in the United States) is led by SMEs, with 60% of the innovation coming from small players in the market according to the DHHS. This is a remarkable share given the size and costs associated with healthcare\u2014both public and private\u2014in the United States. Furthermore, this indicates the level of expertise available from small businesses in HIT. However, given the resources available to SMEs, the ability to expand services into new markets largely relates to the availability of information on comparable issues manifested in dissimilar systems. The key drivers for SME success in this field are based on trends in healthcare, policy, and technology. Although, and because, EHRs are a transatlantic priority, semantic interoperability (ensuring that the data have universal meaning and utility, or are capable of conversion for parallel use) is a core requirement to satisfy elements of modern healthcare. It is required for complex care scenarios, multiple location treatment, evidence-based treatment (and payment), decision support in medicine in a wide variety of locations, and biomedical research through statistical data access, as a key catalyst in improving safety and cost of healthcare, as a means to enrich population health management and prevention of illness, and as a motivator to empower and involve citizens and patients in healthcare scenarios. The MoU is important in health economics beyond the political debate on public\/private health coverage: it is an international step toward improving care, saving costs, and creating jobs through","venue":"Telemedicine journal and e-health","year":2014.0,"referenceCount":7,"citationCount":1,"fieldsOfStudy":["Medicine","Business"],"publicationDate":"2014-06-03","authors":[{"authorId":"5850927","name":"K. Ruggeri"},{"authorId":"3265394","name":"Patrick K. A. Wollner"}]},{"paperId":"02582215e50c88736795eda1273f47d531dcdd7a","title":"New Areas of Contributions and New Addition of Security","abstract":"Open Journal of Big Data (OJBD) (www.ronpub.com\/ojbd) is an open access journal, which addresses the aspects of Big Data, including new methodologies, processes, case studies, poofs-of-concept, scientific demonstrations, industrial applications and adoption. This editorial presents two articles published in the first issue of the second volume of OJBD. The first article is about the investigation of social media for the public engagement. The second article looks into large-scale semantic web indices for six RDF collation orders. OJBD has an increasingly improved reputation thanks to the support of research communities. We will set up the Second International Conference on Internet of Things, Big Data and Security (IoTBDS 2017), in Porto, Portugal, between 24 and 26 April 2017. OJBD is published by RonPub (www.ronpub.com), which is an academic publisher of online, open access, peer-reviewed journals.","venue":"Open Journal of Big Data","year":2016.0,"referenceCount":10,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"41196331","name":"V. Chang"}]},{"paperId":"02585c3d4d5c54044adf4859f34ebe5a937f2306","title":"Web Services based Collaborative B2B e-commerce in the Oil Industry","abstract":"Collaborative B2B e-commerce provides enterprises with the necessary level of flexibility and efficiency to retain competitiveness under the increasingly turbulent business environment. XML-based frameworks may be utilized by enterprises to integrate enterprise level applications to provide B2B e-commerce without, though seamlessly integrating inter-enterprise processes with intra-enterprise processes to provide collaborative B2B e-commerce. This paper presents an innovative approach towards collaborative B2B e-commerce by utilizing the RosettaNet emerging standard in combination with Service Oriented Architecture and semantically enriched information in order to seamlessly integrate the inter-enterprise (public) and intra-enterprise (private) processes. An implementation of a collaborative B2B e-commerce business model in the oil industry is given as a use case example.","venue":"Parallel and Distributed Computing and Communications Systems","year":2008.0,"referenceCount":5,"citationCount":0,"fieldsOfStudy":["Computer Science","Business"],"publicationDate":null,"authors":[{"authorId":"1752391","name":"J. Gialelis"},{"authorId":"2498324","name":"Dimitrios Karadimas"},{"authorId":"39518232","name":"P. Chondros"},{"authorId":"2281565","name":"A. Kalogeras"},{"authorId":"1776686","name":"S. Koubias"},{"authorId":"1757088","name":"D. Serpanos"}]},{"paperId":"02597f2285e932ec6fbce8e9748931ffe252aa26","title":"Semantic query execution in a video database system","abstract":"SEMANTIC QUERY EXECUTION IN A VIDEO DATABASE SYSTEM Cemil ALPER M.S. in Computer Engineering Supervisors: Prof. Dr. \u00d6zg\u00fcr Ulusoy and Assist. Prof. Dr. U\u011fur G\u00fcd\u00fckbay August, 2004 In this thesis, we have extended a video database management system, called BilVideo, with semantic querying capability. Our work is based on a video data model for the extraction and storage of the semantic contents of videos, and a query language to support semantic queries on video data. The Web based query interface of BilVideo has also been modified to handle semantic queries both visually and textually.","venue":"","year":2004.0,"referenceCount":30,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"20703273","name":"C. Alper"}]},{"paperId":"0259b4ff28683b50a0baacd8b1eb1cef7c3c949c","title":"Semantic-Based Resource Retrieval using Non-Standard Inference Services in Description Logics","abstract":"Retrieval of resources semantically annotated is a problem that is gaining interest as more and more documents and services expose descriptions based on languages developed in the framework of Semantic Web. In a semanticenabled resource retrieval process, given a request, a ranking of compatible resources should be provided. Obviously having semantically annotated resources, the ranking sholud be based on some semantic-based parameters. Furthermore, the availability of such descriptions makes explanation of rank possible and can provide useful information in order to modify or refine the original request in a principled way. In this work we briefly present results obtained and ongoing activity on these challenging topics.","venue":"Sistemi Evoluti per Basi di Dati","year":2005.0,"referenceCount":33,"citationCount":10,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"144000468","name":"Simona Colucci"},{"authorId":"153844094","name":"Stefano Coppi"},{"authorId":"1737962","name":"T. D. Noia"},{"authorId":"1738818","name":"E. Sciascio"},{"authorId":"2921342","name":"F. Donini"},{"authorId":"2491987","name":"A. Pinto"},{"authorId":"1738932","name":"Azzurra Ragone"}]},{"paperId":"0259b9600368541d217e38359044f353eb47d125","title":"Design and Development of Density-Based Effective Document Clustering Method Using Ontology","abstract":null,"venue":"Multimedia tools and applications","year":2022.0,"referenceCount":24,"citationCount":5,"fieldsOfStudy":["Computer Science"],"publicationDate":"2022-04-16","authors":[{"authorId":"72899751","name":"Giridhar Urkude"},{"authorId":"1483732860","name":"Manju Pandey"}]},{"paperId":"025a8aef2913f5c69df8efaf31cdd10d2bc49944","title":"A IMPORT\u00c2NCIA DO PROFISSIONAL FARMAC\u00caUTICO NA ADES\u00c3O AO TRATAMENTO DO HIV\/AIDS: UMA REVIS\u00c3O DE LITERATURA INTEGRATIVA","abstract":"O V\u00edrus da Imunodefici\u00eancia Humana (HIV) \u00e9 uma quest\u00e3o de destaque para a sa\u00fade p\u00fablica desde a d\u00e9cada de 1980. Trata-se de uma infec\u00e7\u00e3o que compromete o sistema imunol\u00f3gico, por meio da deple\u00e7\u00e3o dos linf\u00f3citos T, especialmente\u00a0\u00a0 da\u00a0\u00a0 linhagem\u00a0\u00a0 CD4, que em est\u00e1gio mais avan\u00e7ado da infec\u00e7\u00e3o pelo HIV, pode progredir a S\u00edndrome da Imunodefici\u00eancia Adquirida (AIDS). O estudo objetiva analisar a import\u00e2ncia da atua\u00e7\u00e3o do profissional farmac\u00eautico no tratamento de pacientes com HIV\/AIDS. Estudo exploratorio do tipo revis\u00e3o de literatura integrativa, nas bases de dados eletr\u00f4nicas: Semantic Scholar, Web of Science e Harzing\u2019s Publisher or Perish, com as seguintes palavras chaves: \u201cAdes\u00e3o\u201d, \u201cAssist\u00eancia Farmac\u00eautica\u201d, \u201cTerapia Antirretroviral\u201d, \u201cS\u00edndrome da Imunodefici\u00eancia Adquirida\u201d, em portugu\u00eas e ingl\u00eas \u201cAdherence\u201d, \u201cPharmaceutical Assistance\u201d, \u201cAntiretroviral Therapy\u201d, \u201cAcquired Immunodeficiency Syndrome\u201d, entre os anos de 2019 a 2024. Ap\u00f3s os crit\u00e9rios de sele\u00e7\u00e3o e exlus\u00e3o foram selecionados 20 exemplares t\u00e9cnico-cient\u00edficos que abordam a import\u00e2ncia da atua\u00e7\u00e3o do profissional farmac\u00eautico no tratamento de pacientes com HIV\/AIDS. Verificou-se que os cuidados com o HIV\/AIDS precisam ser estruturados no fortalecimento entre farmac\u00eauticos e pacientes, pois o monitoramento farmacoter\u00e1pico auxilia na adapta\u00e7\u00e3o do tratamento e \u00e0s necessidades individuais de cada paciente, sendo crucial para precau\u00e7\u00e3o de intera\u00e7\u00f5es indesejadas e efeitos colaterais que possam prejudicar a efetividade da terapia. Conclui-se que a participa\u00e7\u00e3o do farmaceutico no tratamento do HIV\/AIDS ajuda a melhorar a compreens\u00e3o do paciente sobre seu tratamento, resultando em uma maior satisfa\u00e7\u00e3o dos cuidados recebidos e em uma diminui\u00e7\u00e3o das taxas de abandono do tratamento.","venue":"Revista Foco","year":2024.0,"referenceCount":13,"citationCount":0,"fieldsOfStudy":null,"publicationDate":"2024-11-18","authors":[{"authorId":"2332155466","name":"Ana Paula de Oliveira Felicio"},{"authorId":"2320002211","name":"Thiago Serr\u00e3o Pinto"}]},{"paperId":"025c6bfc2554132e9f013512669215e761158739","title":"Trill: A Reusable Front-End for QA Systems","abstract":null,"venue":"Extended Semantic Web Conference","year":2017.0,"referenceCount":20,"citationCount":15,"fieldsOfStudy":["Computer Science"],"publicationDate":"2017-05-28","authors":[{"authorId":"3370065","name":"Dennis Diefenbach"},{"authorId":"35054383","name":"Shanzay Amjad"},{"authorId":"1697447","name":"A. Both"},{"authorId":"2109143854","name":"K. Singh"},{"authorId":"3124654","name":"P. Maret"}]},{"paperId":"025ccbcc77601e2981da1e03ee33abfcb05df21d","title":"Y!Q: contextual search at the point of inspiration","abstract":"Contextual search tries to better capture a user's information need by augmenting the user's query with contextual information extracted from the search context (for example, terms from the web page the user is currently reading or a file the user is currently editing).This paper presents Y!Q---a first of its kind large-scale contextual search system---and provides an overview of its system design and architecture. Y!Q solves two major problems. First, how to capture high quality search context. Second, how to use that context in a way to improve the relevancy of search queries. To address the first problem, Y!Q introduces an information widget that captures precise search context and provides convenient access to its functionality at the point of inspiration. For example, Y!Q can be easily embedded into web pages using a web API, or it can be integrated into a web browser toolbar. This paper provides an overview of Y!Q's user interaction design, highlighting its novel aspects for capturing high quality search context.To address the second problem, Y!Q uses a semantic network for analyzing search context, possibly resolving ambiguous terms, and generating a contextual digest comprising its key concepts. This digest is passed through a query planner and rewriting framework for augmenting a user's search query with relevant context terms to improve the overall search relevancy and experience. We show experimental results comparing contextual Y!Q search results side-by-side with regular Yahoo! web search results. This evaluation suggests that Y!Q results are considered significantly more relevant.The paper also identifies interesting research problems and argues that contextual search may represent the next major step in the evolution of web search engines.","venue":"International Conference on Information and Knowledge Management","year":2005.0,"referenceCount":23,"citationCount":86,"fieldsOfStudy":["Computer Science"],"publicationDate":"2005-10-31","authors":[{"authorId":"46467526","name":"Reiner Kraft"},{"authorId":"2171488","name":"F. Maghoul"},{"authorId":"2143611133","name":"Chi-Chao Chang"}]},{"paperId":"025d926092b086aa3493292eab37a6e1e76a01fb","title":"Ranking Entities in the Age of Two Webs, an Application to Semantic Snippets","abstract":null,"venue":"Extended Semantic Web Conference","year":2015.0,"referenceCount":32,"citationCount":4,"fieldsOfStudy":["Computer Science"],"publicationDate":"2015-05-31","authors":[{"authorId":"2958008","name":"Mazen Alsarem"},{"authorId":"2769723","name":"P. Portier"},{"authorId":"1682119","name":"S. Calabretto"},{"authorId":"1800054","name":"H. Kosch"}]},{"paperId":"025dd06e75fda6996285814e59c28bdaf5c2b229","title":"A Study of Travel Agent System in Mobile Devices using Multi-Agent and Semantic Web Technologies","abstract":"The thesis work intends to provide the cost implementation method for the travel products from the travel agency to the mobile devices. Mobile devices are now capable of accessing the internet services as their considerable advancements are achieved in the wireless devices. The mobile devices are capable of searching through the web content for extracting the required data. But as the search engines face the problems due to their searching strategies such as keyword based search, semantic web has come into picture. This thesis work explains how semantic web technologies are integrated in the mobile devices for getting the desired products for optimal price. Semantic web is the suitable for the travel agent system as there is exchange of information. The data from the mobile devices is carried through the agents between the travel agency and the devices. This work intends to provide how the semantic web and the multi-agent systems are helpful for searching the desired products of the user (using mobile devices). The agents in the multi-agent system communicate with each other in the travel agent system through the ontologies which are written in the OWL ontology language.","venue":"","year":2015.0,"referenceCount":36,"citationCount":0,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"70071320","name":"Pradeep Japala"}]},{"paperId":"025f117eb5a3091abc54af7e59bbf1f5d9003810","title":"Semantic Web Based Reasoning Model for Controlled Natural Language System","abstract":"Proposed a semantic Web based reasoning model for controlled natural language system which can be used by experts to describe business logic in controlled natural language.The framework of the reasoning model includes two parts,one is language processing part and the other is reasoning part.Firstly,the controlled language sentences were partially made into discourse representation structure through ontology lexicon model based on the WordNet and the controlled natural language interpreter based on ontology lexicon model.Then discourse representation structure was transformed into semantic Web OWL and SWRL through the reasoning part.Finally,semantic Web OWL and SWRL was mapped into Jess facts and rules through template tools,and then reasoning was conducted on controlled natural language according to a predefined axiom of semantic Web.Experiment proves that this mode has greatly enhanced the efficiency of knowledge representation modeling,can basically meet the simple reasoning tasks,and has practical value.","venue":"","year":2011.0,"referenceCount":0,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"2055479812","name":"S. Yong"}]},{"paperId":"025fa5a1f25e00f2b1933fb6932a70ff41dca604","title":"Open Archive Toulouse Archive Ouverte (OATAO)","abstract":"Globally, the need to check regulation compliance for sustainability has become central in the delivery of construction projects. This is partly due to policies by various governments requiring existing and new buildings to comply with certain standards or regulations. How ever, the verification of whether a building complies with any particular standard or regulation has proven challenging in practice. The purpose of formal verification is to prove that under a certain set of assumptions, a building will adhere to a certain set of requirements, for example the minimum performance standards of key environmental issues. Compliance checking requires different criteria often dif ficult to straightforwardly define and combine in an integrated fashion for providing holistic interpretation to facilitate easy decision making. Such criteria, their various flows and combinations can easily be dealt with using conceptual graph theories and Semantic Web concepts which allow rules to be imbued to facilitate reasoning. The aim ofthis study is to tap on conceptual graphs and Semantic Web concepts to develop a system for checking Building Research Establishment Environmental Assessment Methodology (BREEAM) sustainability standard compliance in the French construction industry. A conceptual graph based framework that formally descnbes BREEAM requirements and visually analyse compliance checking processes has been proposed. When implemented in a software that integrates conceptual graphs and Semantic Web knowledge, automatic reasoning allows both the logical specification and the visual interpretation to be displayed and further provides a semantic support for compliance checking information.","venue":"","year":2019.0,"referenceCount":58,"citationCount":0,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"2219625008","name":"B."},{"authorId":"2085024794","name":"H. F"},{"authorId":"2281534753","name":"F. J."}]},{"paperId":"0263cd6b45c5e5e7164ff790dd32f218b9d63bae","title":"A Generic and Flexible Framework for Selecting Correspondences in Matching and Alignment Problems","abstract":"The Web 2.0 and the inexpensive cost of storage have pushed towards an exponential growth in the volume of collected and produced data. However, the integration of distributed and heterogeneous data sources has become the bottleneck for many applications, and it therefore still largely relies on manual tasks. One of this task, named matching or alignment, is the discovery of correspondences, i.e., semantically-equivalent elements in different data sources. Most approaches which attempt to solve this challenge face the issue of deciding whether a pair of elements is a correspondence or not, given the similarity value(s) computed for this pair. In this paper, we propose a generic and flexible framework for selecting the correspondences by relying on the discriminative similarity values for a pair. Running experiments on a public dataset has demonstrated the im-provment in terms of quality and the robustness for adding new similarity measures without user intervention for tuning.","venue":"International Conference on Data Technologies and Applications","year":2013.0,"referenceCount":31,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":"2013-07-29","authors":[{"authorId":"1757970","name":"F. Duchateau"}]},{"paperId":"02643b3ac70161896c1fbfeee0e4ed933666b5db","title":"Fuzzy rule interchange between f-R2ML and f-RIF","abstract":"f-R2ML is a very important fuzzy rule markup language in the Semantic Web, which should be included in the f-RIF interchange framework. However, there are heterogeneous syntaxes between f-RIF and f-R2ML. Therefore, it is necessary to construct transformations between these two languages. In the paper, a syntax mapping between f- R2ML and f-RIF is constructed. Two kinds of transformations are proposed. What's more, the information loss in the process of transformations is also analyzed. And the remedial measures are also proposed to reduce possible information loss.","venue":"International Conference on Fuzzy Systems and Knowledge Discovery","year":2013.0,"referenceCount":24,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":"2013-07-23","authors":[{"authorId":"2144801270","name":"Xing Wang"},{"authorId":"2108116540","name":"Ji Chen"},{"authorId":"2851404","name":"Xiangfu Meng"},{"authorId":"46270356","name":"Bing Wang"}]},{"paperId":"026488c60d76b3b794bcc091483415ba14c45522","title":"WIRIS OM tools : a semantic formula","abstract":"With the increasing reliance on computers for the automatic processing of information a new method is needed for editing mathematical formulae. We are used to WYSIWYG editors that produce beautiful presentations of formulae and store the typesetting primitives rather than the meaning of the formulas. However, new services such as database searching or calculation web-services work best if they have access to the semantic information behind a formula. This can only be done with a new generation of formula editors. In this paper we present WIRIS OM Tools [17], a semantic oriented formula editor which addresses these concerns. It is based on the OpenMath language and a suitable transformation process between OpenMath and MathML expressions. Additionally, this approach adds new features for the users such as error, type and syntax checking. The editor is currently being used in the LeActiveMath and WebALT projects.","venue":"","year":2019.0,"referenceCount":4,"citationCount":0,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"48416390","name":"D. Marques"},{"authorId":"69013353","name":"R. Eixarch"},{"authorId":"1573825771","name":"G. Casanellas"},{"authorId":"47029822","name":"B. Martinez"}]},{"paperId":"0266749ac3836a16e06877ee3ea4ab8432f3f665","title":"Ontology Matching: Current Status, Dilemmas and Future Challenges","abstract":"Ontology matching is still one of the hottest topics of Semantic Web research. The aim of this position statement is three-fold. Firstly, to briefly update the research community about the ldquowhere are we nowrdquo in ontology matching. Secondly, to trigger discussion on dilemmas and critical questions as these were recently identified in the latest ontology-matching-related research events. Thirdly, to comment on visible challenges that may influence the future of this hot topic and consequently the Semantic Web research in general, pointing on the ldquowhere shall we gordquo in the near future.","venue":"Computational Intelligence in Security for Information Systems","year":2008.0,"referenceCount":10,"citationCount":23,"fieldsOfStudy":["Computer Science"],"publicationDate":"2008-03-04","authors":[{"authorId":"2800291","name":"Konstantinos I. Kotis"},{"authorId":"3166259","name":"M. Lanzenberger"}]},{"paperId":"0266a2b93271156f991d625040afb0f98c3aa15b","title":"Language support for processing distributed ad hoc data","abstract":"This paper presents the design, theory and implementation of Gloves, a domain-specific language that allows users to specify the provenance (the derivation history starting from the origins), syntax and semantic properties of collections of distributed data sources. In particular, Gloves specifications indicate where to locate desired data, how to obtain it, when to get it or to give up trying, and what format it will be in on arrival. The Gloves system compiles such specification into a suite of data-processing tools including an archiver, a provenance tracking system, a database loading tool, an alert system, an RSS feed generator and a debugging tool. In addition, the system generates description-specific libraries so that developers can create their own applications. Gloves also provides a generic infrastructure so that advanced users can build new tools applicable to any data source with a Gloves description. We show how Gloves may be used to specify data sources from two domains: CoMon, a monitoring system for PlanetLab's 800+ nodes, and Arrakis, a monitoring system for an AT&T web hosting service. We show experimentally that our system can scale to distributed systems the size of CoMon. Finally, we provide a denotational semantics for Gloves and use this semantics to prove two important theorems. The first shows that our denotational semantics respects the typing rules for the language, while the second demonstrates that our system correctly maintains the provenance.","venue":"ACM-SIGPLAN International Conference on Principles and Practice of Declarative Programming","year":2009.0,"referenceCount":38,"citationCount":1,"fieldsOfStudy":["Computer Science"],"publicationDate":"2009-09-07","authors":[{"authorId":"1796651","name":"Kenny Q. Zhu"},{"authorId":"2852252","name":"Daniel S. Dantas"},{"authorId":"145271194","name":"Kathleen Fisher"},{"authorId":"144191105","name":"Limin Jia"},{"authorId":"3321583","name":"Y. Mandelbaum"},{"authorId":"1751163","name":"Vivek S. Pai"},{"authorId":"145242702","name":"D. Walker"}]},{"paperId":"0267d4edbc29234e95df4f55f29061de09b77f2d","title":"Web Semantics for Personalized Information Retrieval","abstract":"This chapter explores the synergy between Semantic Web (SW) technologies and Web Personalization (WP) for demonstrating an intelligent interface for Personalized Information Retrieval (PIR) on web. Benefits of adding semantics to WP through ontologies and Software Agents (SA) has already been realized. These approaches are expected to prove useful in handling the information overload problem encountered in web search. A brief introduction to PIR process is given, followed by description of SW, ontologies and SA. A comprehensive review of existing web technologies for PIR has been presented. Although, a huge contribution by various researchers has been seen and analyzed but still there exist some gap areas where the benefits of these technologies are still to be realized in future personalized web search.","venue":"","year":2017.0,"referenceCount":53,"citationCount":4,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"2140151309","name":"Aarti Singh"},{"authorId":"145382278","name":"Anu Sharma"}]},{"paperId":"026899ffb99575dbc3e214c171334a4e21ec0b6c","title":"A Model Theoretic Semantics for Ontology Versioning","abstract":null,"venue":"International Workshop on the Semantic Web","year":2004.0,"referenceCount":15,"citationCount":64,"fieldsOfStudy":["Computer Science"],"publicationDate":"2004-11-07","authors":[{"authorId":"2148199","name":"J. Heflin"},{"authorId":"38876930","name":"Zhengxiang Pan"}]},{"paperId":"0268a05daa3c08a744004f75d2f902e4acce6791","title":"Artificial Intelligence in Medicine, 11th Conference on Artificial Intelligence in Medicine, AIME 2007, Amsterdam, The Netherlands, July 7-11, 2007, Proceedings","abstract":"Agent-Based Systems.- A Human-Machine Cooperative Approach for Time Series Data Interpretation.- MRF Agent Based Segmentation: Application to MRI Brain Scans.- R-CAST-MED: Applying Intelligent Agents to Support Emergency Medical Decision-Making Teams.- Knowledge-Based Modeling and Simulation of Diseases with Highly Differentiated Clinical Manifestations.- Co-operative Agents in Analysis and Interpretation of Intracerebral EEG Activity: Application to Epilepsy.- An Ontology-Driven Agent-Based Clinical Guideline Execution Engine.- Temporal Data Mining.- An Intelligent Aide for Interpreting a Patient's Dialysis Data Set.- Temporal Data Mining with Temporal Constraints.- A Nearest Neighbor Approach to Predicting Survival Time with an Application in Chronic Respiratory Disease.- Using Temporal Context-Specific Independence Information in the Exploratory Analysis of Disease Processes.- Discovery and Integration of Organ-Failure Episodes in Mortality Prediction.- Machine Learning and Knowledge Discovery.- Contrast Set Mining for Distinguishing Between Similar Diseases.- Multi-resolution Image Parametrization in Stepwise Diagnostics of Coronary Artery Disease.- Classifying Alarms in Intensive Care - Analogy to Hypothesis Testing.- Hierarchical Latent Class Models and Statistical Foundation for Traditional Chinese Medicine.- Interpreting Gene Expression Data by Searching for Enriched Gene Sets.- Variable Selection for Optimal Decision Making.- Supporting Factors in Descriptive Analysis of Brain Ischaemia.- Knowledge Acquisition from a Medical Corpus: Use and Return on Experiences.- Machine Learning Techniques for Decision Support in Anesthesia.- Learning Decision Tree for Selecting QRS Detectors for Cardiac Monitoring.- Monitoring Human Resources of a Public Health-Care System Through Intelligent Data Analysis and Visualization.- An Integrated IT System for Phenotypic and Genotypic Data Mining and Management.- Automatic Retrieval of Web Pages with Standards of Ethics and Trustworthiness Within a Medical Portal: What a Page Name Tells Us.- A Mixed Data Clustering Algorithm to Identify Population Patterns of Cancer Mortality in Hijuelas-Chile.- Novel Features for Automated Lung Function Diagnosis in Spontaneously Breathing Infants.- Multi-level Clustering in Sarcoidosis: A Preliminary Study.- Text Mining, Natural Language Processing and Generation.- An Experiment in Automatic Classification of Pathological Reports.- Literature Mining: Towards Better Understanding of Autism.- Automatic Generation of Textual Summaries from Neonatal Intensive Care Data.- Anonymisation of Swedish Clinical Data.- MetaCoDe: A Lightweight UMLS Mapping Tool.- Unsupervised Documents Categorization Using New Threshold-Sensitive Weighting Technique.- Application of Cross-Language Criteria for the Automatic Distinction of Expert and Non Expert Online Health Documents.- Extracting Specific Medical Data Using Semantic Structures.- Ontologies.- Using Semantic Web Technologies for Knowledge-Driven Querying of Biomedical Data.- Categorical Representation of Evolving Structure of an Ontology for Clinical Fungus.- Replacing SEP-Triplets in SNOMED CT Using Tractable Description Logic Operators.- Building an Ontology of Hypertension Management.- Analyzing Differences in Operational Disease Definitions Using Ontological Modeling.- Decision Support Systems.- Adaptive Optimization of Hospital Resource Calendars.- On the Behaviour of Information Measures for Test Selection.- Nasopharyngeal Carcinoma Data Analysis with a Novel Bayesian Network Skeleton Learning Algorithm.- Enhancing Automated Test Selection in Probabilistic Networks.- ProCarSur: A System for Dynamic Prognostic Reasoning in Cardiac Surgery.- Content Collection for the Labelling of Health-Related Web Content.- Bayesian Network Decomposition for Modeling Breast Cancer Detection.- A Methodology for Automated Extraction of the Optimal Pathways from Influence Diagrams.- Computer-Aided Assessment of Drug-Induced Lung Disease Plausibility.- Applications of AI-Based Image Processing Techninques.- Segmentation Techniques for Automatic Region Extraction: An Application to Aphasia Rehabilitation.- A Pattern Recognition Approach to Diagnose Foot Plant Pathologies: From Segmentation to Classification.- A Novel Way of Incorporating Large-Scale Knowledge into MRF Prior Model.- Predictive Modeling of fMRI Brain States Using Functional Canonical Correlation Analysis.- Protocols and Guidelines.- Formalizing 'Living Guidelines' Using LASSIE: A Multi-step Information Extraction Method.- The Role of Model Checking in Critiquing Based on Clinical Guidelines.- Integrating Document-Based and Knowledge-Based Models for Clinical Guidelines Analysis.- Document-Oriented Views of Guideline Knowledge Bases.- Maintaining Formal Models of Living Guidelines Efficiently.- A Causal Modeling Framework for Generating Clinical Practice Guidelines from Data.- Semantic Web Framework for Knowledge-Centric Clinical Decision Support Systems.- Inference in the Promedas Medical Expert System.- Computerised Guidelines Implementation: Obtaining Feedback for Revision of Guidelines, Clinical Data Model and Data Flow.- Workflow Systems.- Querying Clinical Workflows by Temporal Similarity.- Testing Careflow Process Execution Conformance by Translating a Graphical Language to Computational Logic.- Induction of Partial Orders to Predict Patient Evolutions in Medicine.- Interacting Agents for the Risk Assessment of Allergies in Newborn Babies.","venue":"","year":2007.0,"referenceCount":0,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"2270652685","name":"Riccardo Bellazzi"},{"authorId":"2243674079","name":"Ameen Abu-Hanna"},{"authorId":"2269918645","name":"Jim Hunter"}]},{"paperId":"0268a32ee6381a3ce2aecdee9ea92a3d20174d14","title":"WHU Question Answering System at NTCIR-8 ACLIA Task","abstract":"paper, we describe our system implemented for the NTCIR-8 CCLQA task. The system consists of a question translation model and a general question answering system for both factoid and complex questions. The translation model combines a translation engine and an online dictionary, which can provide more accurate translations of named entities in the questions. With regard to the question answering system, a PLSA based approach is introduced for answer sentence acquisition. For answer ranking, our system expands the question set by summarizing relevant sentences from a web knowledge base and leverages both semantic and statistical information of questions. In the official evaluation results, our system achieves 18.41% F- score in English to Chinese subtask and 25.66% in monolingual Chinese subtask.","venue":"NTCIR Conference on Evaluation of Information Access Technologies","year":2010.0,"referenceCount":11,"citationCount":6,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"2114291977","name":"Han Ren"},{"authorId":"1719916","name":"D. Ji"},{"authorId":"143638128","name":"Jing Wan"}]},{"paperId":"0268c71b069edf04b0dbb544ea06c6dc6fed3255","title":"Explass: Exploring Associations between Entities via Top-K Ontological Patterns and Facets","abstract":null,"venue":"International Workshop on the Semantic Web","year":2014.0,"referenceCount":22,"citationCount":54,"fieldsOfStudy":["Computer Science"],"publicationDate":"2014-10-19","authors":[{"authorId":"144592996","name":"Gong Cheng"},{"authorId":"2108132758","name":"Yanan Zhang"},{"authorId":"1887019","name":"Yuzhong Qu"}]},{"paperId":"0269e3bc3b5a315b7f455ec427316636d4121942","title":"OpenCitations Meta","abstract":"Abstract OpenCitations Meta is a new database for open bibliographic metadata of scholarly publications involved in the citations indexed by the OpenCitations infrastructure, adhering to Open Science principles and published under a CC0 license to promote maximum reuse. It presently incorporates bibliographic metadata for publications recorded in Crossref, DataCite, and PubMed, making it the largest bibliographic metadata source using Semantic Web technologies. It assigns new globally persistent identifiers (PIDs), known as OpenCitations Meta Identifiers (OMIDs) to all bibliographic resources, enabling it both to disambiguate publications described using different external PIDS (e.g., a DOI in Crossref and a PMID in PubMed) and to handle citations involving publications lacking external PIDs. By hosting bibliographic metadata internally, OpenCitations Meta eliminates its former reliance on API calls to external resources and thus enhances performance in response to user queries. Its automated data curation, following the OpenCitations Data Model, includes deduplication, error correction, metadata enrichment, and full provenance tracking, ensuring transparency and traceability of data and bolstering confidence in data integrity, a feature unparalleled in other bibliographic databases. Its commitment to Semantic Web standards ensures superior interoperability compared to other machine-readable formats, with availability via a SPARQL endpoint, REST APIs, and data dumps.","venue":"Quantitative Science Studies","year":2023.0,"referenceCount":65,"citationCount":4,"fieldsOfStudy":["Computer Science"],"publicationDate":"2023-06-28","authors":[{"authorId":"2100710072","name":"Arcangelo Massari"},{"authorId":"2220735262","name":"Fabio Mariani"},{"authorId":"51898010","name":"Ivan Heibi"},{"authorId":"2382525","name":"S. Peroni"},{"authorId":"1727412","name":"D. Shotton"}]},{"paperId":"026aad0a0545487d5930bac938349eb83af4415f","title":"Sentiment Analysis using Improved Novel Convolutional Neural Network (SNCNN)","abstract":"Sentiment Analysis is an important method in which many researchers are working on the automated approach for extraction and analysis of huge volumes of user achieved data, which are accessible on social networking websites. This approach helps in analyzing the direct falls under the domain of SA. SA comprises the vast field of effective classification of user-initiated text under defined polarities. The proposed work includes four major steps for solving these issues: the first step is preprocessing which holds tokenization, stop word removal, stemming, cleaning up of unwanted text information like removing of Ads from Web pages, Text normalization for converting binary format. Secondly, the Feature extraction is based on the Bag words, Word2Vec and TF-ID which is a Term Frequency-Inverse Document Frequency. Thirdly, this feature selection includes the procedure for examining semantic gaps along with source features using teaching models and this involves target task characteristic application for Improved Novel Convolutional Neural Network (INCNN). The Feature Selection accompanies the procedure of Information Gain (IG) and PCC which is a Pearson Correlation Coefficient. Finally, the classification step INCNN gives out sentiment posts and responses for the user-based post aspects which helps in enhancing the system performance. The experimental outcome proposes the INCNN algorithm and provides higher performance rather than the existing approach. The proposed INCNN classifier results in highest accuracy.","venue":"International Journal of Computers Communications & Control","year":2022.0,"referenceCount":28,"citationCount":2,"fieldsOfStudy":["Computer Science"],"publicationDate":"2022-03-18","authors":[{"authorId":"97951667","name":"M. Kalaiarasu"},{"authorId":"2265891598","name":"C. Ranjeeth"},{"authorId":"2265892751","name":"Kumar M. Kalaiarasu"},{"authorId":"2061595621","name":"C. Kumar"},{"authorId":"2265891601","name":"Sr. Gr"}]},{"paperId":"026c0fc40270626227ef703e7e0fb7628e57398c","title":"Co-operative and Distributed Configuration","abstract":null,"venue":"Net.ObjectDays","year":2004.0,"referenceCount":23,"citationCount":18,"fieldsOfStudy":["Computer Science"],"publicationDate":"2004-09-27","authors":[{"authorId":"3350934","name":"A. Altuna"},{"authorId":"2784046","name":"Alvaro Cabrerizo"},{"authorId":"2160741","name":"I. Laresgoiti"},{"authorId":"144450029","name":"N. Pe\u00f1a"},{"authorId":"2082225473","name":"Daniel Sastre"}]},{"paperId":"026ddc3295ab753ffb0a576d4773789f653c86d3","title":"A Grounded Ontology for Identity and Reference of Web Resources","abstract":"The identity and reference of web resources used to be a critical subject, and recently it has become a key item in the research agenda of web science. After an introduction to the research related to web identity and reference, we present a new version of IRE, an OWL ontology of web resources and their referencing kinds. Finally, as a case study, we describe an implementation of IRE. Specifically, we show how IRE theory has been used to implement a semantic web application which supports the ontology-driven development and evolution of semantic web portals.","venue":"I3+","year":2007.0,"referenceCount":58,"citationCount":11,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"2420171","name":"Aldo Gangemi"},{"authorId":"2280600","name":"V. Presutti"}]},{"paperId":"026eddb8fff7e66b3b2a5e030fdb0e599e0cf0bd","title":"Using Semantic Web Technologies in Visualizing Medicinal Vocabularies","abstract":"The number of new medications and medicinal knowledge increases all the time. Further, as each drug has its unique indications, cross-reactivity, complications and costs also the management and dissemination of medication information becomes still more complex giving rise for potential medication errors. However, by utilizing the Semantic Web technologies in visualizing medication information this complexity can be alleviated in many ways. In this paper we report our work on developing an electronic medicinal vocabulary. It deviates from other medicinal vocabularies in that the terms and their relationships are graphically illustrated and additional queries can be made on the graphical presentation. The supported visualization format is a variation of the concept mapping.","venue":"2008 IEEE 8th International Conference on Computer and Information Technology Workshops","year":2008.0,"referenceCount":8,"citationCount":6,"fieldsOfStudy":["Computer Science"],"publicationDate":"2008-07-08","authors":[{"authorId":"2721814","name":"J. Puustj\u00e4rvi"},{"authorId":"101583134","name":"Leena Puustj\u00e4rvi"}]},{"paperId":"026ee44893eb9e77e5f652c83c280e7bd815117b","title":"Semantic caching via query matching for web sources","abstract":"A semantic caching scheme suitable for wrappers wrapping web sources is presented. Since the web sources have typically weaker querying capabilities than conventional databases, existing semantic caching schemes cannot be applied directly. A seamlessly integrated query translation and capability mapping between the wrappers and web sources in semantic caching is described. In addition, an analysis on the match types between the user's input query and cached queries is presented. Semantic knowledge acquired from the data can be used to avoid unnecessary access to the web sources by transforming the cache miss to the cache hit. A polynomial time algorithm based on the proposed query matching technique is presented to find the best matched query in the cache. Experimental results reveal the effectiveness of the proposed semantic caching scheme.","venue":"International Conference on Information and Knowledge Management","year":1999.0,"referenceCount":30,"citationCount":65,"fieldsOfStudy":["Computer Science"],"publicationDate":"1999-11-01","authors":[{"authorId":"145948198","name":"Dongwon Lee"},{"authorId":"1724907","name":"W. Chu"}]},{"paperId":"0270058ee5f91192a4ac5ee037dbd8ddf0aa25de","title":"\uc758\ubbf8\ub9dd \uc81c\uc57d\uc2dd\uc5b8\uc5b4\ub97c \uae30\ubc18\uc73c\ub85c \ud55c \uc778\ud130\ub137 \uc1fc\ud551 \uc758\uc0ac\uacb0\uc815 \ud2c0","abstract":"Semantic Web society initially focused only on data but has gradually moved toward knowledge. Recently rule beyond ontology has emerged as a key element of the Semantic Web. All of these activities are obviously aiming at making data and knowledge on the Web sharable and reusable between various entities around the world. If one of ultimate visions of the Semantic Web is to increase human's decision making quality assisted by machines, there is a missing but important part to be shared and reused. It is knowledge about constraints on data and concepts represented by ontology which should be emphasized more. In this paper, we propose Semantic Web Constraint Language (SWCL) based on OWL and show how effective SWCL can be in representing and solving an internet shopper's decision making problem by an implementation of a shopping agent in the Semantic Web environment.","venue":"","year":2008.0,"referenceCount":0,"citationCount":2,"fieldsOfStudy":["Computer Science"],"publicationDate":"2008-09-01","authors":[{"authorId":"52364895","name":"\uc774\uba85\uc9c4"},{"authorId":"152282782","name":"\uae40\ud559\uc9c4"},{"authorId":"52057086","name":"\uae40\uc6b0\uc8fc"}]},{"paperId":"02717202fa9353d7c9f06a3a2fe9e168a3caff78","title":"M\u00e9todo para la Indexaci\u00f3n de Grafos RDF desde un SPARQL Endpoint (A Method for Indexing RDF Graphs from a SPARQL Endpoint)","abstract":". Linked Data refers to a set of principles and best practices for publishing and linking structured data on the web. The linked data research community has been publishing library data using the standard RDF, a graph-based data model. These RDF graphs are stored in a spe-ci\ufb01c type of database called triplestore and provides a SPARQL endpoint for querying them. However, these triplestores are not optimized for executing real-time queries submitted by the users, a\ufb00ecting the response time and usability in real environments. In this paper, we propose an index-based method for optimizing the query response time and solve the issues related to search and retrieval in large RDF graphs stored in triplestores. To prove the feasibility of the method proposed, it was applied to a semantic digital library, improving the query response time.","venue":"International Workshop on Semantic Web Technologies","year":2018.0,"referenceCount":22,"citationCount":1,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"1409959548","name":"Alejandro Jes\u00fas Mari\u00f1o-Molerio"},{"authorId":"145279520","name":"Juan Carlos Moreira de Lara"},{"authorId":"1414097228","name":"Leduan Flores-Riera"},{"authorId":"1404996532","name":"Yusniel Hidalgo-Delgado"}]},{"paperId":"02717dbae24abb077a9393af65f984bfb355023a","title":"A Combinatorial Optimized Knapsack Linear Space for Information Retrieval","abstract":"Key information extraction can reduce the dimensional effects while evaluating the correct preferences of users during semantic data analysis. Currently, the classifiers are used to maximize the performance of web-page recommendation in terms of precision and satisfaction. The recent method disambiguates contextual sentiment using conceptual prediction with robustness, however the conceptual prediction method is not able to yield the optimal solution. Context-dependent terms are primarily evaluated by constructing linear space of context features, presuming that if the terms come together in certain consumerrelated reviews, they are semantically reliant. Moreover, the more frequently they coexist, the greater the semantic dependency is. However, the influence of the terms that coexist with each other can be part of the frequency of the terms of their semantic dependence, as they are non-integrative and their individual meaning cannot be derived. In this work, we consider the strength of a term and the influence of a term as a combinatorial optimization, called Combinatorial Optimized Linear Space Knapsack for Information Retrieval (COLSK-IR). The COLSK-IR is considered as a knapsack problem with the total weight being the \u201cterm influence\u201d or \u201cinfluence of term\u201d and the total value being the \u201cterm frequency\u201d or \u201cfrequency of term\u201d for semantic data analysis. The method, by which the term influence and the term frequency are considered to identify the optimal solutions, is called combinatorial optimizations. Thus, we choose the knapsack for performing an integer programming problem and perform multiple experiments using the linear space through combinatorial optimization to identify the possible optimum solutions. It is evident from our experimental results that the COLSK-IR provides better results than previous methods to detect strongly dependent snippets with minimum ambiguity that are related to inter-sentential context during semantic data analysis.","venue":"Computers Materials & Continua","year":2021.0,"referenceCount":26,"citationCount":1,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"2262776612","name":"Varghese S Chooralil"},{"authorId":"2124819057","name":"Vinodh P Vijayan"},{"authorId":"46706953","name":"Biju Paul"},{"authorId":"2262776061","name":"Anishin Raj M.M"},{"authorId":"2262768856","name":"Karthikeyan B"},{"authorId":"2262770304","name":"G.Manikandan"}]},{"paperId":"0271a649c5f320931ef617710541c7c0df4597d2","title":"Too many tags spoil the metadata: investigating the knowledge management of scientific research with semantic web technologies","abstract":null,"venue":"Journal of Cheminformatics","year":2019.0,"referenceCount":56,"citationCount":11,"fieldsOfStudy":["Medicine","Computer Science"],"publicationDate":"2019-03-21","authors":[{"authorId":"26554027","name":"Samantha Kanza"},{"authorId":"151494985","name":"Nicholas Gibbins"},{"authorId":"32113616","name":"J. Frey"}]},{"paperId":"027513141522938f8f17d176e997a98ce841884c","title":"A QoS-Based Semantic Web Service Discovery Framework","abstract":"Different users wish to select service according to their demand in the service discovery,so providing services that satisfy the quality of service(QoS) requirements of users is crucial for semantic Web services applications.In this paper,an OWL-based QoS meta-model named OWL-QoS is presented at first.Furthermore,a QoS-based service discovery framework is proposed,which adopts a service matching algorithm from three levels:basic description,IOPE and QoS.Compared with traditional methods,experiment results show that our approach can effectively improve the quality and efficiency of service matching.","venue":"","year":2011.0,"referenceCount":0,"citationCount":1,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"46787152","name":"Li Shu-yu"}]},{"paperId":"0275501a93521a4b1acb6f7dab0967ac5c95925f","title":"A Three-Level Approach to Ontology Merging","abstract":null,"venue":"Mexican International Conference on Artificial Intelligence","year":2005.0,"referenceCount":14,"citationCount":8,"fieldsOfStudy":["Computer Science"],"publicationDate":"2005-11-14","authors":[{"authorId":"1770434","name":"Agustina Buccella"},{"authorId":"1807649","name":"A. Cechich"},{"authorId":"1713004","name":"N. Brisaboa"}]},{"paperId":"02778660c1206cf3f9ad166d334b0bbef8a29ba9","title":"Big data analysis of economic news","abstract":"We propose a novel method to improve the forecast of macroeconomic indicators based on social network and semantic analysis techniques. In particular, we explore variables extracted from the Global Database of Events, Language, and Tone, which monitors the world\u2019s broadcast, print and web news. We investigate the locations and the countries involved in economic events (such as business or economic agreements), as well as the tone and the Goldstein scale of the news where the events are reported. We connect these elements to build three different social networks and to extract new network metrics, which prove their value in extending the predictive power of models only based on the inclusion of other economic or demographic indices. We find that the number of news, their tone, the network constraint of nations and their betweenness centrality oscillations are important predictors of the Gross Domestic Product per Capita and of the Business and Consumer Confidence indices.","venue":"","year":2017.0,"referenceCount":71,"citationCount":20,"fieldsOfStudy":["Economics"],"publicationDate":"2017-07-11","authors":[{"authorId":"46191093","name":"Mohammed Elshendy"},{"authorId":"49913766","name":"Andrea Fronzetti Colladon"}]},{"paperId":"02778fd639ec774759ee1bc50bbf31506f266d89","title":"Interpreting Heterogeneous Geospatial Data Using Semantic Web Technologies","abstract":null,"venue":"Communication Systems and Applications","year":2016.0,"referenceCount":35,"citationCount":17,"fieldsOfStudy":["Computer Science"],"publicationDate":"2016-07-04","authors":[{"authorId":"3424209","name":"Timo Homburg"},{"authorId":"37272923","name":"C. Prudhomme"},{"authorId":"2382329","name":"F. W\u00fcrriehausen"},{"authorId":"1854995","name":"A. Karmacharya"},{"authorId":"2234423","name":"F. Boochs"},{"authorId":"1713819","name":"Ana Roxin"},{"authorId":"145378327","name":"C. Cruz"}]},{"paperId":"027874ec8262e2cba20b955072e28b1c18b82634","title":"A Novel Method for Unsupervised and Supervised Conversational Message Thread Detection","abstract":"Efficiently detecting conversation threads from a pool of messages, such as social network chats, emails, \n \ncomments to posts, news etc., is relevant for various applications, including Web Marketing, Information \n \nRetrieval and Digital Forensics. Existing approaches focus on text similarity using keywords as features that \n \nare strongly dependent on the dataset. Therefore, dealing with new corpora requires further costly analyses \n \nconducted by experts to find out new relevant features. This paper introduces a novel method to detect threads \n \nfrom any type of conversational texts overcoming the issue of previously determining specific features for \n \neach dataset. To automatically determine the relevant features of messages we map each message into a three \n \ndimensional representation based on its semantic content, the social interactions in terms of sender\/recipients \n \nand its timestamp; then clustering is used to detect conversation threads. In addition, we propose a supervised \n \napproach to detect conversation threads that builds a classification model which combines the above extracted \n \nfeatures for predicting whether a pair of messages belongs to the same thread or not. Our model harnesses the \n \ndistance measure of a message to a cluster representing a thread to capture the probability that a message is \n \npart of that same thread. We present our experimental results on seven datasets, pertaining to different types \n \nof messages, and demonstrate the effectiveness of our method in the detection of conversation threads, clearly \n \noutperforming the state of the art and yielding an improvement of up to a 19%.","venue":"International Conference on Data Technologies and Applications","year":2016.0,"referenceCount":30,"citationCount":22,"fieldsOfStudy":["Computer Science"],"publicationDate":"2016-07-24","authors":[{"authorId":"2972684","name":"Giacomo Domeniconi"},{"authorId":"2973714","name":"Konstantinos Semertzidis"},{"authorId":"144217232","name":"V. L\u00f3pez"},{"authorId":"35136112","name":"E. Daly"},{"authorId":"1680354","name":"S. Kotoulas"},{"authorId":"143853729","name":"G. Moro"}]},{"paperId":"0278d1e5746cc5cd378ca4623ce8d011397c866f","title":"Combining Logic Programming with Description Logics and Machine Learning for the Semantic Web","abstract":"In this paper we consider an extension of Logic Programming that tackles the Semantic Web challenge of acquiring rules combined with ontologies. To face this bottleneck problem we propose a framework that resorts to the expressive and deductive power of DL+log and adopts the methodological apparatus of Inductive Logic Programming.","venue":"","year":2008.0,"referenceCount":26,"citationCount":0,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"145091756","name":"F. Lisi"},{"authorId":"1700821","name":"F. Esposito"}]},{"paperId":"02797d62f723ca555e0e98a90a778aba9546d78c","title":"Web service composition: a semantic web and automated planning technique application","abstract":"This article proposes applying semantic web and artificial intelligence planning techniques to a web services composition model dealing with problems of ambiguity in web service description and handling incomplete web information. The model uses an\u00a0OWL-S services and implements a planning technique which handles open world semantics in its reasoning process to resolve\u00a0these problems. This resulted in a web services composition system incorporating a module for interpreting OWL-S services and\u00a0converting them into a planning problem in PDDL (a planning module handling incomplete information) and an execution service\u00a0module concurrently interacting with the planner for executing each composition plan service.","venue":"INGENIER\u00cdA INVESTIGA","year":2008.0,"referenceCount":1,"citationCount":2,"fieldsOfStudy":null,"publicationDate":"2008-09-01","authors":[{"authorId":"9142712","name":"Jaime Alberto Guzm\u00e1n Luna"},{"authorId":"30951344","name":"D. A. Ovalle Carranza"}]},{"paperId":"027a45b1839ad8454392224f87d472ce6fdf3a16","title":"TERA: the Toxicological Effect and Risk Assessment Knowledge Graph.","abstract":"Ecological risk assessment requires large amounts of chemical effect data from laboratory experiments. Due to experimental effort and animal welfare concerns it is desired to extrapolate data from existing sources. To cover the required chemical effect data several data sources need to be integrated to enable their interoperability. In this paper we introduce the Toxicological Effect and Risk Assessment (TERA) knowledge graph, which aims at providing such integrated view, and the data preparation and steps followed to construct this knowledge graph. \nWe also present the applications of TERA for chemical effect prediction and the potential applications within the Semantic Web community.","venue":"","year":2019.0,"referenceCount":34,"citationCount":1,"fieldsOfStudy":["Computer Science"],"publicationDate":"2019-08-27","authors":[{"authorId":"101224103","name":"E. B. Myklebust"},{"authorId":"1402158435","name":"Ernesto Jim\u00e9nez-Ruiz"},{"authorId":"1731892","name":"Jiaoyan Chen"},{"authorId":"36588949","name":"Raoul Wolf"},{"authorId":"7167745","name":"K. Tollefsen"}]},{"paperId":"027aa2feec6d0e907db4f0ab92464b5b41048628","title":"NINE PSYCHOLOGISTS: MAPPING THE COLLECTIVE MIND WITH GOOGLE","abstract":"All pairs of names generated by the individual names of nine historically important psychologists were submitted as queries to the Google search engine. The resulting page counts were used to generate similarity\/dissimilarity indices that were submitted to both cluster analysis and multidimensional scaling. Both of the analyses separated the names into three distinct clusters that were easily associated with three historically important schools of psychology. The purpose of the study was to examine the idea that the world-wide-web contains latent structures of the sort made familiar awhile ago by Charles Osgood. Earlier related data, gathered by the author in the last three or four years, is summarized and presented as further evidence that Osgood meaning may be latent in the world-wide-web. Questions regarding appropriate indices of similarity\/dissimilarity and problems of the reliability and validity of these procedures and their results are discussed. Evidence is presented for all of these qualities in the results of this study. Finally, it is demonstrated that at least one of Osgood\u2019s connotative Semantic Differential factors is hidden in the structure of the world-wide-web. Current Research in Social Psychology (Vol. 11, No. 12) (Arnold)","venue":"","year":2006.0,"referenceCount":26,"citationCount":1,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"133551810","name":"A. Adler"},{"authorId":"145762127","name":"J. Watson"},{"authorId":"113469609","name":"B. Skinner"},{"authorId":"48600062","name":"E. Thorndike"}]},{"paperId":"027ad39a12316695bdee3458f2e50d71bbd80079","title":"Analysis of schema structures in the Linked Open Data graph based on unique subject URIs, pay-level domains, and vocabulary usage","abstract":null,"venue":"Distributed and parallel databases","year":2015.0,"referenceCount":33,"citationCount":11,"fieldsOfStudy":["Computer Science"],"publicationDate":"2015-12-01","authors":[{"authorId":"1752017","name":"Thomas Gottron"},{"authorId":"47510577","name":"Malte Knauf"},{"authorId":"1753135","name":"A. Scherp"}]},{"paperId":"027b85e19ab2962bf1ed2fa31857e64e816c5341","title":"Cross-Media Service Delivery","abstract":null,"venue":"","year":2003.0,"referenceCount":0,"citationCount":11,"fieldsOfStudy":["Engineering"],"publicationDate":null,"authors":[{"authorId":"1740799","name":"D. Spinellis"}]},{"paperId":"027cc133577e931c07ad3b7db22cc0edb93798d6","title":"Ontology-based Web Knowledge Management 3C3.8","abstract":"The knowledge management is becoming more and more important in organizations, either over the intranet or Internet. In this paper we present an ontology-based web knowledge management (KM) framework based on web ontology language DAML+OIL. This framework supports content-oriented rather than traditionally document-oriented approach to knowledge management. Three fundamental building blocks, i.e., annotations based on ontologies, knowledge-bases based on assertions in ontologies and web resources crawling, and rule-based reasoninghference system for semantic knowledge manipulation. Our approach to knowledge management is the result of our semantic web research efforts. We adopt the web-standard based tools in our development of knowledge management. We believe that this approach of annotation-crawlinginference (A-C-I) to knowledge management is flexible and effective in supporting knowledge sharing on the web. An ongoing prototype is briefly described.","venue":"","year":2003.0,"referenceCount":6,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"2130356222","name":"Yanmei Wang"},{"authorId":"2155684178","name":"Zhonghua Yang"},{"authorId":"2093699901","name":"Pe Hin"},{"authorId":"2364110","name":"Hinny P. H. Kong"},{"authorId":"113734407","name":"Robert Kheng"}]},{"paperId":"027f09f576d5935f9e6f95fc21af756aea90d7cb","title":"Analysis of Online Social Networks Posts to Investigate Suspects Using SEMCON","abstract":null,"venue":"Interacci\u00f3n","year":2015.0,"referenceCount":9,"citationCount":15,"fieldsOfStudy":["Computer Science"],"publicationDate":"2015-08-02","authors":[{"authorId":"2429723","name":"Zenun Kastrati"},{"authorId":null,"name":"Ali Shariq Imran"},{"authorId":"2939019","name":"Sule YAYILGAN YILDIRIM"},{"authorId":"2035596","name":"F. Dalipi"}]},{"paperId":"02807c8d1105e45aa64fad5badddb95c1b1c746c","title":"Collaborative Enrichment of Interactive Arabic Dictionary","abstract":"In this paper we present a web-based Interactive Arabic Dictionary developed in HIAST (Higher Institute for Applied Sciences and Technology). Users can search online any Arabic word. The system provides different meanings with example sentences and multimedia illustrations, in addition to other related information like associated words, semantic domains, expressions, linguistic avails, common mistakes, and morphologic, syntactic and semantic information. The dictionary can be enriched collaboratively by expert users with new words, new meanings for available entries, or other morphological, syntactic, and semantic related information.","venue":"","year":2013.0,"referenceCount":2,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"3165960","name":"Nada Ghneim"},{"authorId":"9194066","name":"Ghaida Rebdawi"}]},{"paperId":"0280cfb7463b1d337c130033cdec98bce883270e","title":"A Semantics-Preserving Approach for Extracting OWL Ontologies from UML Class Diagrams","abstract":null,"venue":"FGIT-DTA","year":2009.0,"referenceCount":18,"citationCount":8,"fieldsOfStudy":["Computer Science"],"publicationDate":"2009-12-10","authors":[{"authorId":"2308113","name":"Zhuoming Xu"},{"authorId":null,"name":"Yuyan Ni"},{"authorId":"2111069189","name":"Lili Lin"},{"authorId":"2064784076","name":"Huajian Gu"}]},{"paperId":"02813511c1711a0d7fd52a2ac838090777348a1f","title":"Integrating institutional repositories into the Semantic Web","abstract":"The Web has changed the face of scientific communication; and the Semantic Web promises new ways of adding value to research material by making it more accessible to automatic discovery, linking, and analysis. Institutional repositories contain a wealth of information which could benefit from the application of this technology. In this thesis I describe the problems inherent in the informality of traditional repository metadata, and propose a data model based on the Semantic Web which will support more efficient use of this data, with the aim of streamlining scientific communication and promoting efficient use of institutional research output.","venue":"","year":2008.0,"referenceCount":0,"citationCount":2,"fieldsOfStudy":["Computer Science"],"publicationDate":"2008-06-01","authors":[{"authorId":"2061333132","name":"H. Mason"}]},{"paperId":"02826463a1f025f5d2b63bdd2a00db09cc25ea4d","title":"Web Semantics: Science, Services and Agents on the World Wide Web","abstract":"Semantic and linked-data technologies are currently used by several cultural heritage institutions to make their content available through the Web. Although these technologies are heavily oriented towards data reuse and integration, one clear benefit highlighted by recent literature is the enhancement of human cultural consumption and user experience through the development of novel cultural end-user applications like Online Public Access Catalogues (OPACs). However, to the best of our knowledge, studies into the impact of these technologies on end-user applications are scarce. In order to address this lack, we report the results of two within-group user-centred studies of two online bibliographic systems in a realistic setting \u2014 using a widely deployed OPAC and its counterpart linked-data based system, datos.bne.es. The results of our first within-group study show that users of the system based on linked data required significantly less time and visited fewer pages to complete a typical search and retrieval activity. Additionally, the results of our user satisfaction tests also provided significantly better results for this new system. These results are consistent with the hypothesis that semantic technologies applied to library catalogues provide an enhancement that helps satisfy users\u2019 information needs. \u00a9 2019ElsevierB.V.Allrightsreserved.","venue":"","year":2019.0,"referenceCount":30,"citationCount":0,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"145000677","name":"M. Rico"},{"authorId":"1403849795","name":"Daniel Vila-Suero"},{"authorId":"9055520","name":"Iuliana Botezan"},{"authorId":"1398348796","name":"Asunci\u00f3n G\u00f3mez-P\u00e9rez"}]},{"paperId":"0282705a18a88179cbfc2c042e17844027ff5d40","title":"CHIME : service-oriented framework for adaptive web-based systems","abstract":"In this paper we present our view on how the current development of knowledge engineering in the context of Semantic Web can contribute to the better applicability, reusability and sharability of adaptive web-based systems. We propose a service-oriented framework for adaptive web-based systems, where the main goal is to help the semantic enrichment of the information search and usage process and to allow for adaptive support of user activites. In other words, our aim is to provide flexible information access, presentation and update to a broad range of users (individual and groups) in a personalized way within the context of pursuing a user's goals and performing tasks. We take an ontological approach to enable a shared understanding of concepts throughout the system and to provide semantic relationships between the information resources and the user's knowledge of (or interest in) them. We argue that the future of adaptive web-based systems lies in the modularity of the architecture and the openess to interoperate with other applications or compontens. To achieve this we adopt the concept of the UPML framework for semantic web service integration. Our ideas are illustrated in the context of the Token2000 project for Cultural Heritage in Interactive Multimedia Environments (CHIME) and show how combining elaborate AI strategies with the simplicity of hypermedia interaction can result in more easily applicable knowledge-based systems, or in more reasoning enhanced adaptive hypermedia systems.","venue":"","year":2003.0,"referenceCount":27,"citationCount":15,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"2955936","name":"V. Chepegin"},{"authorId":"1745337","name":"Lora Aroyo"},{"authorId":"1831425","name":"P. D. Bra"},{"authorId":"143779489","name":"G. Houben"}]},{"paperId":"0282f0d1a21c047ff62a24d11d8beb0c3d309364","title":"Translating Naive User Queries on the Semantic Web","abstract":"Query is an important way of information retrieval. One type of queries is those to search engines, which are lists of keywords without structures. Another type of queries is those to databases or knowledge bases, which must conform to the structure and terminology of the data source (e.g., SQL query to a database). In this paper, we deal with another type of queries: naive user queries\u2013queries in users\u2019 own terms and structures. We envision that this type of queries would be a common phenomenon on the future Semantic Web. We propose an approach that, given a naive user query, translates it into a list of queries conforming to different data source schemas. The approach is based on partial alignment between some data sources. An early prototype showed that the result is promising.","venue":"","year":2003.0,"referenceCount":19,"citationCount":5,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"1743388","name":"B. Yan"},{"authorId":"35038586","name":"R. MacGregor"}]},{"paperId":"028500e61ab93f7c79eedeb6193ded51a97c69f7","title":"Multi-Agent Technique and Semantic Web Services for Extended","abstract":"Nowadays the industrial world must face strong mutations such as the globalisation or customers' rapidly changing needs. Information and logistics are two main problems in supply chain management. Management information systems and simulations tools have been commonly used to control information on logistics in recent years. Some focus on applying artificial intelligence to solving the problem. In this paper, we have proposed a framework based on Multi-Agent Systems (MAS) and Semantic Web Services (SWS) for assistance in collaborative decision-making in the context of the extended enterprise.","venue":"","year":2013.0,"referenceCount":27,"citationCount":1,"fieldsOfStudy":["Computer Science"],"publicationDate":"2013-03-31","authors":[{"authorId":"119006374","name":"B. Ezzeddine"},{"authorId":"7602961","name":"Benaissa Mounir"},{"authorId":"32489123","name":"Benabdelhafid Abdellatif"}]},{"paperId":"0285688c1a07e49a663d0f49ef39370fbd00d3aa","title":"ActionBert: Leveraging User Actions for Semantic Understanding of User Interfaces","abstract":"As mobile devices are becoming ubiquitous, regularly interacting with a variety of user interfaces (UIs) is a common aspect of daily life for many people. To improve the accessibility of these devices and to enable their usage in a variety of settings, building models that can assist users and accomplish tasks through the UI is vitally important. However, there are several challenges to achieve this. First, UI components of similar appearance can have different functionalities, making understanding their function more important than just analyzing their appearance. Second, domain-specific features like Document Object Model (DOM) in web pages and View Hierarchy (VH) in mobile applications provide important signals about the semantics of UI elements, but these features are not in a natural language format. Third, owing to a large diversity in UIs and absence of standard DOM or VH representations, building a UI understanding model with high coverage requires large amounts of training data. \n\nInspired by the success of pre-training based approaches in NLP for tackling a variety of problems in a data-efficient way, we introduce a new pre-trained UI representation model called ActionBert. Our methodology is designed to leverage visual, linguistic and domain-specific features in user interaction traces to pre-train generic feature representations of UIs and their components. Our key intuition is that user actions, e.g., a sequence of clicks on different UI components, reveals important information about their functionality. We evaluate the proposed model on a wide variety of downstream tasks, ranging from icon classification to UI component retrieval based on its natural language description. Experiments show that the proposed ActionBert model outperforms multi-modal baselines across all downstream tasks by up to 15.5%.","venue":"AAAI Conference on Artificial Intelligence","year":2020.0,"referenceCount":27,"citationCount":73,"fieldsOfStudy":["Computer Science"],"publicationDate":"2020-12-22","authors":[{"authorId":"21145493","name":"Zecheng He"},{"authorId":"31801337","name":"Srinivas Sunkara"},{"authorId":"2055666765","name":"Xiaoxue Zang"},{"authorId":"2145205516","name":"Ying Xu"},{"authorId":"2116184149","name":"Lijuan Liu"},{"authorId":"50981270","name":"Nevan Wichers"},{"authorId":"3230461","name":"Gabriel Schubiner"},{"authorId":"2115986516","name":"Ruby B. Lee"},{"authorId":"47740493","name":"Jindong Chen"}]},{"paperId":"0288f510e7d513d35ec071e63794b39330160eef","title":"Social Network Analysis on Educational Data Set in RDF Format","abstract":"The increased usage of information technologies in educational tasks resulted in high volume of data, exploited to build analytical systems that can provide practical insight in the learning process. In this paper, we propose a method of running social network analysis on multiple data sources (academic years, communication tools). To achieve this, the collected data that describe social interactions were converted into a common format by employing a prior developed semantic web educational ontology. Using a mapping language the relational data set was linked to the appropriate concepts defined in the ontology and then it was exported in RDF format. The means for SPARQL access was also provided. Subsequently, query patterns were defined for different social interactions in the educational platform. To prove the feasibility of this approach, Gephi tool set was used to run SNA (Social Network Analysis) on data obtained with the SPARQL queries. The added value of this research lies in the potential of this method to simplify running social network analysis on multiple data sets, on a specific course or the entire academic year, by simply modifying the query pattern.","venue":"Journal of computer & information technology","year":2015.0,"referenceCount":36,"citationCount":3,"fieldsOfStudy":["Computer Science"],"publicationDate":"2015-08-14","authors":[{"authorId":"1912520","name":"Bogdan Dr\u0103gulescu"},{"authorId":"48680897","name":"Marian Bucos"},{"authorId":"3337767","name":"R. Vasiu"}]},{"paperId":"0289302d55741bf9f8c7f464b72e7d029819cf44","title":"Semantics Based Information Trust Computation and Propagation Algorithm for Semantic Web","abstract":"Trustable information delivering and propagation is important for the peers in semantic web. In this paper, we present a semantics based semantic trust score computation method. Trustable semantics of information is represented through trust ontology. Entire trust is measured by a combined trust score from both subjective and objective sides of information. The objective side of trust is semantic trust of information, and the subjective side is trust relationship between peers. Semantic trust of information is computed from three aspects: frequency of known feature words, context location of known feature words and the ontology location of known feature words. And trust relationship is based on the historical interactions between peers. Then we proposed an information propagation mechanism in semantic web. Stimulations and analyses show that the semantic trust of information can be computed and propagated effectively.","venue":"International Conference on Wireless Communications, Networking and Mobile Computing","year":2009.0,"referenceCount":12,"citationCount":5,"fieldsOfStudy":["Computer Science"],"publicationDate":"2009-09-24","authors":[{"authorId":"2182423417","name":"Bo Zhang"},{"authorId":"2068337065","name":"Yang Xiang"},{"authorId":"2149105823","name":"Qiang Xu"}]},{"paperId":"028959e7c52f5ca17ac533701e1aef2c60722d22","title":"Measuring Semantic Similarity between Named Entities by Searching the Web Directory","abstract":"The importance of named entities in information retrieval and knowledge management has recently brought interest in characterizing semantic relationships between entities. In this paper, we propose a method for measuring semantic similarity, an important type of semantic relationship, between entities. The method is based on Google Directory, a search interface to the Open Directory Project. Via the search engine, we can locate the web pages relevant to an entity and automatically create a profile of the entity according to the directory assignments of its web pages, which capture various features of the entity. Using their profiles, the semantic similarity between entities can be measured in different dimensions. We apply the semantic similarity measurement to two knowledge acquisition tasks: thesaurus construction of entities and fine grained categorization of entities. Our experiments demonstrate that the proposed method works effectively in these two tasks.","venue":"International Conference on Wirtschaftsinformatik","year":2007.0,"referenceCount":16,"citationCount":41,"fieldsOfStudy":["Computer Science"],"publicationDate":"2007-11-02","authors":[{"authorId":"2108421261","name":"Jiahui Liu"},{"authorId":"144218567","name":"L. Birnbaum"}]},{"paperId":"0289d758a7680ce145d8c3883a372d59ca53e891","title":"Towards Reusability in the Semantic Web: Decoupling Naming, Validation, and Reasoning","abstract":". RDFS and OWL ontologies simultaneously de\ufb01ne naming, hierarchy, syntactical data structure, and axioms. This strong coupling complicates the reusability of both ontological concepts and annotated data, due to logical pitfalls in RDFS and OWL semantics. The di\ufb00erences between OWL axioms and integrity constraints used for validation are often not clear to users and lead to confusing and unintended semantics in practice. To avoid these pitfalls, we revisit Tom Gruber\u2019s basic ontology de\ufb01nition and reimagine a more decoupled ontology design pattern, consisting of independent layers for naming , validation , and reasoning . We argue that such decoupling improves reusability because it clari\ufb01es the usage of the three layers during ontology creation and reuse. A naming layer built on synonym sets enables reusing named concepts in di\ufb00erent contexts, detached from constraints or OWL axioms de\ufb01ned elsewhere. On top of that, we suggest a two-step approach of constraint checking and reasoning: Validate a term\u2019s integrity via constraints \ufb01rst, and only include it for reasoning if that validation succeeds. Our proposal is one step towards a clearer in-practice usage of naming, validation, and reasoning - and additionally supports this with a revised semantic layer model.","venue":"","year":2020.0,"referenceCount":9,"citationCount":9,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"40917722","name":"Johannes Lipp"},{"authorId":"31648495","name":"L. Gleim"},{"authorId":"152589583","name":"S. Decker"}]},{"paperId":"028a0df183424443b5029f784a20e93d58196ae3","title":"Context-Aware Semantic Web Service Discovery","abstract":"Context-aware semantic Web service discovery mechanism brought forth in the paper supplements the service expression meaning of UDDI through the combination with OWLS, which not only enhances the service discovery capability with the adoption of semantic reasoning in the process of service matching, but also introduces the context information to make users find out the suitable one among a variety of services with similar functions.","venue":"International Conference on Semantics, Knowledge and Grid","year":2007.0,"referenceCount":8,"citationCount":9,"fieldsOfStudy":["Computer Science"],"publicationDate":"2007-10-29","authors":[{"authorId":"2057436036","name":"Qi Yong"},{"authorId":"30873437","name":"Qi Saiyu"},{"authorId":"2055941223","name":"Zhu Pu"},{"authorId":"3192059","name":"Lin-feng Shen"}]},{"paperId":"028a64360d72c1bf33d03c1cf8f837215c26887c","title":"Supporting Mobile Service Interaction through Semantic Service Description Annotation and Automatic Interface Generation","abstract":"One of the current challenges in Mobile Computing is bringing services directly to mobile users, which is handicapped by two major hurdles: Phones and services do not interoperate as smoothly as they should and the delivered services have to be adapted to a wide range of different mobile client platforms. In order to address these problems we present a service framework that extends Semantic Web Service descriptions with abstract interface annotations and uses them for the automatic generation of adapted user interfaces. These interfaces support and facilitate the mobile interaction with physical objects and thus the interaction with associated Semantic Web Services. The focus of this paper lies on the service description annotations based on OWL-S. Furthermore we show how these extensions can be used for the generation of a compact and abstract interface description as the basis for the rendering of Java ME and XHTML - based interfaces. In order to motivate our approach and confirm its concept, we developed two prototypes for mobile ticketing that are based on the presented system.","venue":"SemDesk","year":2006.0,"referenceCount":13,"citationCount":5,"fieldsOfStudy":["Computer Science"],"publicationDate":"2006-11-06","authors":[{"authorId":"2521525","name":"G. Broll"},{"authorId":"2640002","name":"Sven Siorpaes"},{"authorId":"2021950","name":"E. Rukzio"},{"authorId":"2103681682","name":"M. Paolucci"},{"authorId":"2656128","name":"J. Hamard"},{"authorId":"143672332","name":"M. Wagner"},{"authorId":"145823914","name":"A. Schmidt"}]},{"paperId":"028a8749c4021f443600d6dfead2dae337f218d9","title":"Temporal adaptation of multimedia scripts","abstract":"Hypermedia systems structure large quantities of multimedia information into webs of associated concepts. Users can selectively explore these concepts, limiting the quantity of information viewed to suit their personal goals for using the system. But the flexibility of navigational freedom creates a problem for hypermedia designers--that of incorporating mandatorily viewable information into the web. One frequently used solution is to script information illustrating multiple levels of detail into a single non- interruptable presentation to be associated with a single node of the web. This technique affords the designer control over what the user sees, yet does so at the expense of the user's control over time spent with the system. This paper addresses the need for adaptivity at the presentation-level in hypermedia systems. A two-component system is described for the authoring and temporal adaptation of multimedia scripts used in hypermedia applications. With the authoring component, a user (taking on the role of hypermedia designer) can design multimedia presentations using text, still images, sound, animation and video objects. Using graphic interfaces, the user can format these objects in space and time, modify their media-specific attributes, and semantically delineate these objects as pertaining to specific levels of detail. This delineation creates hierarchical structures which can then be selectively parsed by the system to create variations on the original presentation. The user can save all formatting and chunking decisions in a script, creating a persistent record of the presentation. These scripts can then be associated with the nodes of a hypermedia system, so that when a hypermedia user invokes a node, some version of the scripted presentation is played back. The hypermedia component is responsible for determining version content of a presentation. Based on user-imposed constraints (hypermedia users can dynamically input how much time they wish to spend with the system, as well as interest levels associated with represented concepts), the system can adjust the amount of detail shown in a given presentation, thus contracting or expanding the presentation over time.","venue":"Electronic imaging","year":1991.0,"referenceCount":0,"citationCount":2,"fieldsOfStudy":["Engineering","Computer Science"],"publicationDate":"1991-08-01","authors":[{"authorId":"71125256","name":"L. Robin"}]},{"paperId":"028af025ebf9f1d17a0115096946608b38dbb1cd","title":"Implementation of a knowledge discovery and enhancement module from structured information gained from unstructured sources of information","abstract":"Knowledge is the largest differentiator between companies and essential to create a competitive advantage over competitors. Nowadays access to knowledge is not hindered by physical limitations; all information is a click away, still modern systems provide poor information distribution, especially if there are no proper tools to locate and process. As part of a global challenge to conceptualize, design and implement a proof of concept Knowledge Management System, with the support of Natural Language Processing and semantic information, following a philosophy of \"Open Innovation\". This dissertation focuses on all the research and the system it originates. The system is a proof of concept of a method for generating a semantic representation of a document; enhance the volume of current information and their quality, using external data and metadata to improve the existing knowledge base. With the raise of the semantic web, a web of data with defined meaning, transverse to multiple domains, enable computers and users to work in cooperation to generate new possibilities to represent and integrate knowledge. The syntactical and semantic analyses of the documents lead to a knowledge representation, a taxonomical structure. When combined with metadata annotation tools, which can expose new semantic information, hidden in any content and connect to related data, the data volume and quality is greatly increased. By exploring the taxonomy structure, inference and query engines, the network information is vastly superior to the original document knowledge; new relations are revealed.","venue":"","year":2010.0,"referenceCount":51,"citationCount":0,"fieldsOfStudy":["Engineering"],"publicationDate":null,"authors":[{"authorId":"95305584","name":"C. Costa"}]},{"paperId":"028cb06afd60a456803df9e4bc262d12cc46c412","title":"A Framework of Web Services Discovery and Composition Based on Semantic","abstract":"A framework of web services discovery and composition based on semantic is proposed to find appropriate web services according to the requests of user. Some service discovery and composition algorithms are used in this framework. The component of service description can transfer the services requirements of the user to semantic description. When a formal service request is defined, the service discovery component queries the service repository for a service that matches the service request. In case no match is found, the composition component creates a composite service that matches the request with optimal QoS. Index Terms - Web services; service composition; quality of service; knapsack problem","venue":"","year":2013.0,"referenceCount":9,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":"2013-07-02","authors":[{"authorId":"2158556420","name":"Zhi-qiu Huang"},{"authorId":"2058030643","name":"Weihua Ai"}]},{"paperId":"028e7e0824b3d5423c567689a8e4102cdf0905cc","title":"Contract Based, Non-invasive, Black-Box Testing of Web Services","abstract":null,"venue":"International Conference on Service Oriented Computing","year":2010.0,"referenceCount":14,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":"2010-12-07","authors":[{"authorId":"2052882","name":"Michael Averstegge"}]},{"paperId":"028f79b44ea5565e64e84a36726b075dee28f06e","title":"Representing Security Policies in Web Information Systems","abstract":"which usually govern the behaviour of networking services (e.g., security, QoS, mobility, etc.), are becoming an increasingly popular approach for the dynamic regulation of web information systems. The adoption of a policy-based approach for controlling a system requires an appropriate policy representation regarding both syntax and semantics, and the design and development of a policy management framework. In the context of the Web, the use of languages enriched with semantics (i.e. semantic languages) has been limited primarily to represent Web content and services. However the capabilities of these languages, coupled with the availability of tools to manipulate them, make them well suited for many other kinds of application, as policy representation and management. This paper provides the current trends of policy-based management enriched by semantics applied to the protection of web information systems. It also presents an approach for using DMTF Common Information Model (CIM) ontology with semantic languages.","venue":"","year":2005.0,"referenceCount":15,"citationCount":25,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"39703898","name":"F\u00e9lix Garc\u00eda"},{"authorId":"49669222","name":"Gregorio Martinez"},{"authorId":"1737426","name":"J. Bot\u00eda"},{"authorId":"46630675","name":"A. F. G\u00f3mez"}]},{"paperId":"0290632c2c41e9e81a3b038f359f7e97d716c79b","title":"Disparate Ontology Understanding, Brokering, Linking, and Elaboration (DOUBLE)","abstract":"Abstract : The primary work under the \"Disparate Ontology Understanding, Brokering, Linking, and Elaboration (DOUBLE)\" effort is OpenCyc, the publication of an open-content version of Cycorp's upper ontology together with a freely distributable knowledge base store and deductive inference engine. OpenCyc is one of the largest and most comprehensive reference ontology for the Semantic Web. The other part of the effort consisted of developing an automatic web page annotator, that takes unstructured web page text as input; and outputs OWL statements corresponding to relationships between entities parsed from the text. This tool is intended to facilitate OWL adoption by automating the initial stages of the process and flattening the otherwise steep learning curve.","venue":"","year":2004.0,"referenceCount":0,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":"2004-09-01","authors":[{"authorId":"2844450","name":"Stephen L. Reed"}]},{"paperId":"0293e8c58298d73d5864a35ba1af3ae063e7353c","title":"MapReduce-Based Algorithms for Managing Big RDF Graphs: State-of-the-Art Analysis, Paradigms, and Future Directions","abstract":"Big RDF (Resource Description Framework) graphs, which populate the emerging Semantic Web, are the core data structure of the so-called Big Web Data, the \"natural\" transposition of Big Data on the Web. Managing big RDF graphs is gaining momentum, essentially due to the fact that this task represents the \"baseline operation\" of fortunate Web big data analytics. Here, it is required to access, manage and process large-scale, million-node (big) RDF graphs, thus dealing with severe spatio-temporal complexity challenges. A possible solution to this problem is represented by the so-called MapReduce-model-based algorithms for managing big RDF graphs, which try to exploit the computational power offered by the MapReduce processing model in order to tame the complexity above. In this so-depicted scientific context, this paper provides a critical survey on MapReduce-based algorithms for managing big RDF graphs, with analysis of state-of-the-art proposals, paradigms and trends, along with a comprehensive overview of future research trends in the investigated scientific area.","venue":"IEEE\/ACM International Symposium on Cluster, Cloud and Internet Computing","year":2017.0,"referenceCount":46,"citationCount":10,"fieldsOfStudy":["Computer Science"],"publicationDate":"2017-05-14","authors":[{"authorId":"145046124","name":"A. Cuzzocrea"},{"authorId":"1709598","name":"R. Buyya"},{"authorId":"17833412","name":"Vincenzo Passanisi"},{"authorId":"1708205","name":"G. Pilato"}]},{"paperId":"0297cd6b8b7d126cd3c2311b225c517ee49c7ee4","title":"Recommending tags with a model of human categorization","abstract":"When interacting with social tagging systems, humans exercise complex processes of categorization that have been the topic of much research in cognitive science. In this paper we present a recommender approach for social tags derived from ALCOVE, a model of human category learning. The basic architecture is a simple three-layers connectionist model. The input layer encodes patterns of semantic features of a user-specific resource, such as latent topics elicited through Latent Dirichlet Allocation (LDA) or available external categories. The hidden layer categorizes the resource by matching the encoded pattern against already learned exemplar patterns. The latter are composed of unique feature patterns and associated tag distributions. Finally, the output layer samples tags from the associated tag distributions to verbalize the preceding categorization process. We have evaluated this approach on a real-world folksonomy gathered from Wikipedia bookmarks in Delicious. In the experiment our approach outperformed LDA, a well-established algorithm. We attribute this to the fact that our approach processes semantic information (either latent topics or external categories) across the three different layers. With this paper, we demonstrate that a theoretically guided design of algorithms not only holds potential for improving existing recommendation mechanisms, but it also allows us to derive more generalizable insights about how human information interaction on the Web is determined by both semantic and verbal processes.","venue":"International Conference on Information and Knowledge Management","year":2013.0,"referenceCount":38,"citationCount":39,"fieldsOfStudy":["Computer Science"],"publicationDate":"2013-10-27","authors":[{"authorId":"1800363","name":"Paul Seitlinger"},{"authorId":"1803040","name":"Dominik Kowald"},{"authorId":"1752070","name":"C. Trattner"},{"authorId":"152241455","name":"Tobias Ley"}]},{"paperId":"02985d816582bfb96bc4769719692a639cdba1a6","title":"Improving Internal Consistency in Conditional Probability Estimation With an Intelligent Tutoring System and Web-Based Tutorials","abstract":"Three Web-based laboratory experiments explored the efficacy of three different Web-based tutorials designed to improve performance on Bayesian conditional probability estimation problems. In each experiment, participants estimated the probability of two events, and two conditional probabilities P(A|B) and P(B|A). Problems reflected five distinct relationships between two sets: identical sets, mutually exclusive sets, subsets, overlapping sets, and independent sets. Performance was measured against two benchmarks: internal inconsistency, a type of fallacy, and semantic coherence, a constellation of estimates of P(A), P(B), P(A|B), and P(B|A) that are consistent with the relationship among sets presented in the problem statement. As predicted by fuzzy-trace theory, in all three experiments, problems depicting identical sets, mutually exclusive sets, and independent sets yielded superior performance with respect to inconsistency and semantic coherence than problems depicting subsets and overlapping sets. In Experiment 1, a Web-based tutorial teaching the logic of the 2 \u2715 2 table reduced internal inconsistency for overlapping sets problems. In Experiment 2, a Web-based tutorial using Euler diagrams was effective in reducing inconsistency and increasing semantic coherence for overlapping sets and subsets problems. Experiment 3 employed AutoTutor Lite, the first Web-based Intelligent Tutoring System with two-way interactions with people in natural language (English). AutoTutor Lite is cross-platform enabled with talking animated agents that converse with learners using Latent Semantic Analysis to \u201cunderstand\u201d natural language. AutoTutor Lite elicits verbal responses from the learner through a textbox and encourages them to further elaborate their understanding. AutoTutor Lite tutorial significantly reduced internal inconsistency on overlapping sets and subsets problems.","venue":"","year":2012.0,"referenceCount":37,"citationCount":16,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"2849671","name":"C. Wolfe"},{"authorId":"31462760","name":"Christopher R. Fisher"},{"authorId":"2436806","name":"V. Reyna"},{"authorId":"3350316","name":"Xiangen Hu"}]},{"paperId":"02987ad15be853f661ebc1fc2053e30c19eb6203","title":"Toward intention aware semantic Web service systems","abstract":"A goal driven intention extraction approach is proposed to automate the process of extracting user intention from the original Web service request terms. We introduce a method for analyzing the request terms to fit user intension, so that the service provided is more suitable for the user. The input terms are parsed into different word sense sets. With the lexical dictionary and domain ontology, possible senses of the terms are identified. A goal structure is constructed to help the identification of goal models which represent the user intention. By combining the information of request terms and goal structures, one or more goal models are identified. A goal selector selects a candidate goal model from generated goal models to represent the user intention. A service request agent is designed to generate and execute plans to satisfy the goals.","venue":"2005 IEEE International Conference on Services Computing (SCC'05) Vol-1","year":2005.0,"referenceCount":18,"citationCount":20,"fieldsOfStudy":["Computer Science"],"publicationDate":"2005-07-11","authors":[{"authorId":"1678987","name":"Chiung-Hon Leon Lee"},{"authorId":"2148770481","name":"Alan Liu"}]},{"paperId":"0298c94c55bbf6a02113c1512e0336c45c52bc92","title":"Semantic Web Ontologies based Knowledge Management Framework for IT Service Management","abstract":": Technology driven organisations are investing hugely in training and knowledge enrichment of their employees. This is due to the fact that knowledge is now considered as an asset by organisations. Additionally, with emerging technologies, organisations are also spending heavily in Information and Communication Technology (ICT) to enhance their internal operations and processes. Among the various internal processes, Knowledge Management is an area which has been there since many years but when it is about the application of latest technology and innovations for Knowledge Management practices, there are huge opportunities. This paper presents an analysis of various KM frameworks available for different domains and based on current state and limitation identified, it proposes a Semantic Web Ontology based Knowledge Management System for IT Service Industry","venue":"","year":2019.0,"referenceCount":31,"citationCount":0,"fieldsOfStudy":null,"publicationDate":null,"authors":[]},{"paperId":"0299031f8d486eddad5fd2cb15e60183ed7c3664","title":"APPLICATION FOR SEMANTIC E-MAIL ADDRESSING","abstract":": Today, the most effective method of marketing is e-mail marketing. Any company, who wants to achieve business success, can not ignore the marketing potential of the e-mail marketing. Due to specific kind of work, and necessity of automating communication with employers, in the Employment Agency of Montenegro has been made its own system for conducting e-mail campaign, in which, due to the latest trends in the development of e-mail marketing and the needs of the Employment Agency, semantic e-mail addressing was applied. This document presents architecture of the applied system for semantic e-mail addressing. It explores the possibilities for creating and updating the knowledge base system about employers and job vacancies, which is created based on domain ontologies. It also describes in details the process of publishing database on the Semantic Web and plans for further updating and improving the existing knowledge base system.","venue":"","year":2015.0,"referenceCount":36,"citationCount":0,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"2104171528","name":"Tanja Rasovic"}]},{"paperId":"029b20b851d081c8120382481587adccb04cdafe","title":"The SemSPM approach: fine integration of WS-SecurityPolicy semantics to enhance matching security policies in SOA","abstract":null,"venue":"Service Oriented Computing and Applications","year":2016.0,"referenceCount":29,"citationCount":3,"fieldsOfStudy":["Computer Science"],"publicationDate":"2016-09-01","authors":[{"authorId":"2947371","name":"M. B. Brahim"},{"authorId":"1960702","name":"T. Chaari"},{"authorId":"8354281","name":"M. B. Jemaa"},{"authorId":"1709086","name":"M. Jmaiel"}]},{"paperId":"029b2edc1a1bfa8e49e65009accb168e5bd98c1e","title":"An ontology similarity algorithm for BioAgent","abstract":"In the last years, the Web has been evolving, transforming itself in a semantic Web [1]. The new Web aims at guaranteeing almost completely automatic access to information sources, by introducing ontologies [6, 7, 4] and using mobile agents [8]. Ontologies, representing agents\u2019 knowledge, will allow integration of heterogenous resources to support global information systems. The use of ontologies in agent framework is not an easy task, especially as a measurement of ontological similarity. Although several ontology models [3, 2] and several measurements for semantics similarity have been presented in the literature, there is a need for more sensitive measurements which can provide a degree of similarity between concepts in order to perform semantic matching. Such measurements should take into account the structure of the concepts description and the relationships between concepts. Starting from the graphoriented model proposed in ONION [10], the present work proposes an algorithm to assess the semantic similarity between two concepts. The resulting data structure is used to represent agent knowledge, while the similarity algorithm compares concepts placed on different agent platforms. The proposed algorithm has been designed for a biological domain and developed for BioAgent [12], a mobile agent platform for distributed biological applications. Ontology model A lexicon L consists of a finite set of semantically meaningful Concepts, denoted by C and a finite set of Relationships R, i.e. L = C \u222a R. An ontology is a formal specification of a shared conceptualisation, that is, the knowledge structure that describes the semantics of an information source by using a lexicon L. Formally, an ontology can be represented by an ontological graph G = (N,A, \u03bb, \u03b4), a labelled directed graph in which the set of nodes N represents concepts and the set of arcs A \u2282 N \u00d7N \u00d7R represents relationships between concepts. The univocal association of a node to a concept is given by the \u03bb : N \u2192 C mapping function, whereas the association of arcs to relationships is given by a \u03b4 : A \u2192 R mapping function. The \u03b4 function is neither injective nor surjective mapping, allowing for unexpressed relationships in the ontological graph. For ease of notation and without missing any meaning, the ontological graph will be addressed by G = (N,A) in the sequel to this paper. BioAgent A BioAgent is a mobile agent framework designed to support the definition of distributed applications in a biological domain. An application consists of one or more agents, properly created to elaborate several tasks such as the retrieval and integration of heterogeneous information. Any information source is interfaced by a BioAgent platform, whose software architecture is sketched in Figure 1. The Core Layer contains features exposed to service agents such as security and resource access and features exposed to agents such as mobility, communication, creation-cloning and domain descriptors. The Service Agents Layer consists of a community of agents have been created to support the access to services locally available. Actually, the BioAgent prototype provides four services of general and wide applicability: Broker Agent, Web Interface, Wrapper and Ontology. The broker agent is a special agent which keeps trace of each running service agents and provides to any new agent the list of all locally ac-","venue":"","year":2002.0,"referenceCount":10,"citationCount":24,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"1708192","name":"E. Merelli"},{"authorId":"1998736","name":"R. Culmone"},{"authorId":"2112629835","name":"G. Rossi"}]},{"paperId":"029c2585e7f0a37a223b33e8018776a74caae97b","title":"Personalized Access to Semantic Web Agents Using Smart Cards","abstract":null,"venue":"European Conference on Parallel Processing","year":2005.0,"referenceCount":12,"citationCount":3,"fieldsOfStudy":["Computer Science"],"publicationDate":"2005-08-30","authors":[{"authorId":"2596894","name":"Riza Cenk Erdur"},{"authorId":"1734324","name":"G. Kardas"}]},{"paperId":"029dee067821276a6d9f9752c5e487f08b3bf1eb","title":"Digital libraries for the preservation of research methods and associated artifacts","abstract":"New digital artifacts are emerging in data-intensive science. For example, scientific workflows are executable descriptions of scientific procedures that define the sequence of computational steps in an automated data analysis, supporting reproducible research and the sharing and replication of best-practice and know-how through reuse. Workflows are specified at design time and interpreted through their execution in a variety of situations, environments, and domains. Hence it is essential to preserve both their static and dynamic aspects, along with the research context in which they are used. To achieve this, we propose the use of multidimensional digital objects (Research Objects) that aggregate the resources used and\/or produced in scientific investigations, including workflow models, provenance of their executions, and links to the relevant associated resources, along with the provision of technological support for their preservation and efficient retrieval and reuse. In this direction, we specified a software architecture for the design and implementation of a Research Object preservation system, and realized this architecture with a set of services and clients, drawing together practices in digital libraries, preservation systems, workflow management, social networking and Semantic Web technologies. In this paper, we describe the backbone system of this realization, a digital library system built on top of dLibra.","venue":"DPRMA '13","year":2013.0,"referenceCount":27,"citationCount":7,"fieldsOfStudy":["Computer Science"],"publicationDate":"2013-07-25","authors":[{"authorId":"144027454","name":"Ra\u00fal Palma"},{"authorId":"70053552","name":"\u00d3scar Corcho"},{"authorId":"11131369","name":"Piotr Hotubowicz"},{"authorId":"2067620425","name":"Sara P\u00e9rez"},{"authorId":"49193745","name":"Kevin R. Page"},{"authorId":"1705262","name":"C. Mazurek"}]},{"paperId":"029f1a6478280c2efa81b7cac4aa389178160df3","title":"A defeasible reasoning web service","abstract":"In this article we outline a research line whose main goal is to give access to the software agents inhabiting the Web to a powerful inference service built around Defeasible Logic Programming (DeLP), a formalism that combines features of Logic Programming with Defeasible Argumentation. To do so, the web service prototype we proposed is the next logical step to take in order to allow agents to draw conclusions through DeLP within the Semantic Web.","venue":"","year":2006.0,"referenceCount":2,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"3170951","name":"Nicol\u00e1s D. Rotstein"},{"authorId":"3339548","name":"F. Sagui"},{"authorId":"1834505","name":"A. G. Stankevicius"},{"authorId":"2578572","name":"A. Garc\u00eda"},{"authorId":"69362913","name":"Guillermo Ricardo Simari"}]},{"paperId":"02a055b1d0e3bb62887ce6439cdb0f4fcf8bde74","title":"Semantic web topic models","abstract":null,"venue":"","year":2016.0,"referenceCount":0,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":"2016-08-01","authors":[{"authorId":"3042884","name":"M. Allahyari"}]},{"paperId":"02a0a5efd9c94f858997885164e585549ed31779","title":"Virtual Communities and the Alignment of Web Ontologies","abstract":"The World Wide Web (WWW) is a global, ubiquitous, and fundamentally dynamic environment for information exchange and processing. By connecting vast numbers of individuals, the Web enables creation of virtual communities, and during the last 10 years, became a universal collaboration infrastructure. The so-called Semantic Web, a concept proposed by Tim Berners-Lee, is a new WWW architecture that enhances content with formal semantics (Berners-Lee, Hendler, & Lassila, 2001). Hence, the Web content is made suitable for machine processing (i.e., it is described by the associated metadata), as opposed to HTML documents available only for human consumption. Languages such as Resource Description Framework (RDF) and Ontology Web Language (OWL) along with well-known XML are used for description of Web resources. In other words, the Semantic Web is a vision of the future Web in which information is given explicit meaning. This will enable autonomous software agents to reason about Web content and produce intelligent responses to events (Staab, 2002). The ultimate goal of the next generation's Web is to support the creation of virtual communities which will be composed of software agents and humans cooperating within the same environment. Sharing knowledge within such a community requires a shared conceptual vocabularies\u2014ontologies, which represent the formal common agreement about the meaning of data (Gomez-Perez & Corcho, 2002). Artificial intelligence defines ontologies as explicit, formal specification of a shared conceptualization (Studer, Benjamins, & Fensel, 1998). In this case, a conceptualization stands for an abstract model of some concept from the real world; explicit means that the type of concept used is explicitly defined. Formal refers to the fact that an ontology should be machine readable; and finally shared means that ontology expresses knowledge that is accepted by all the subjects. In short, an ontology defines the terms used to describe and represent an area of knowledge.","venue":"","year":2006.0,"referenceCount":8,"citationCount":8,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"1748693","name":"K. Juszczyszyn"}]},{"paperId":"02a163f15d2e05e29bd73215479c0af585b21493","title":"Flexible Modeling and Execution of Semantic Manufacturing Processes for Robot Systems","abstract":"The potential benefits of digital transformation for manufacturing companies include reduced costs, increased interconnectedness, and improved adaptability. Semantic Web technologies such as IRIs, RDF graphs, OWL ontologies, and SPARQL requests are a well-known and actively researched ap-proach for supporting these transformation efforts. One challenge with this concept of knowledge augmentation is identifying where and how to integrate such semantic technologies into a manu-facturing system, as it could require frequent translations into other non-semantic representations, which may entail a loss of expressivity and other disadvantages. Therefore, this work aims to use semantic technologies in a knowledge-augmented robotic manufacturing platform as directly and natively as possible. This approach includes the semantic modeling of manufacturing processes (similarly to flow charts) and context knowledge such as generalized mechanisms of how to apply them. All of this semantic knowledge is instantiated and persistently stored in a Robot Knowledge Base application, which implements mecha-nisms to automatically derive the next robot skill invocations and their parameter values during process execution. These semantic description models and the Robot Knowledge Base were tested in simulation as well as integrated into a physical mobile robot system with an articulated arm tackling an industrial use case.","venue":"IEEE International Conference on Emerging Technologies and Factory Automation","year":2024.0,"referenceCount":21,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":"2024-09-10","authors":[{"authorId":"8785814","name":"Ingmar Kessler"},{"authorId":"2326127869","name":"A. Perzylo"}]},{"paperId":"02a1750364a147bd9b970a8cca5da38ea09c56d3","title":"Usability evaluation in the SEWASIE ( SEmantic Webs and AgentS in Integrated Economies ) project","abstract":"In this paper we describe the usability evaluation experiments of the Query tool system done in the context of the SEWASIE (SEmantic Webs and AgentS in Integrated Economies) project. The usability evaluation is an important step of the User-Centered Design Methodology, followed to develop the SEWASIE system. This European IST project aims at enabling a uniform access to heterogeneous data sources through an integrated ontology. From the architectural point of view, it is composed of different tools, in particular, the Query tool allows the user to construct the query by a focus plus context diagrammatic interface generating precise and unambiguous query expressions. The main goal of our experiment is to demonstrate the easy of use of the Query tool independently of the domain user experience. This study confirms that the Query tool system is usable as for the end users (domain-expert users) as for the non-domain expert users.","venue":"","year":2005.0,"referenceCount":10,"citationCount":11,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"1772402","name":"T. Catarci"},{"authorId":"1681850","name":"T. D. Mascio"},{"authorId":"1768087","name":"Paolo Dongilli"},{"authorId":"1809261","name":"Enrico Franconi"},{"authorId":"144222000","name":"G. Santucci"},{"authorId":"2182320","name":"Sergio Tessaris"}]},{"paperId":"02a21e2d8f6e87cefa6a76716a6e1e26ff7ea288","title":"A Brief State of the Art for Ontology Authoring","abstract":"One of the main challenges for building the Semantic web is Ontology Authoring. Controlled Natural Languages CNLs offer a user friendly means for non-experts to author ontologies. This paper provides a snapshot of the state-of-the-art for the core CNLs for ontology authoring and reviews their respective evaluations.","venue":"arXiv.org","year":2014.0,"referenceCount":31,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":"2014-06-11","authors":[{"authorId":"1953876","name":"Hazem Safwat"},{"authorId":"145566729","name":"Brian Davis"}]},{"paperId":"02a2af3ea0cb4d07d1d4dffd0a32e830500b698d","title":"Rapid Prototyping of Mobile Apps for Clinical Research using Semantic Web Technologies","abstract":". This paper provides a demo of the Punya framework, introduced in our resource track paper titled \u201cThe Punya Platform: Building Mobile Research Apps with Linked Data and Semantic Features.\u201d In this demo, we focus on using the Punya framework to build clinical research apps with a particular focus on Type 2 diabetes research. We demonstrate how Semantic Web and biomedical researchers can utilize Punya to rapidly prototype mobile semantic apps. Apps developed with Punya can consume Linked Data, thus exploiting the vast biomedical data sources available on the Web; while producing RDF from the app for downstream analysis. Researchers can also write semantic rules to encode clinical guideline recommendations in a visual manner within the Punya framework. Due to the intuitive and visual editing environment, researchers can easily tweak complex decision-logic rules.","venue":"International Workshop on the Semantic Web","year":2021.0,"referenceCount":10,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"1693195","name":"O. Seneviratne"},{"authorId":"9049067","name":"W. V. Woensel"},{"authorId":"3205335","name":"G. Loseto"},{"authorId":"1696528","name":"Floriano Scioscia"},{"authorId":"2538510","name":"E. Patton"},{"authorId":"1735243","name":"Lalana Kagal"}]},{"paperId":"02a3f7fe6f420a36944818e5e40512b5540ed1b5","title":"Induction on the Semantic Web","abstract":"The Semantic Web is increasingly populated with instance data, nowadays often in the form of Linked Data. Consequently, machine learning and other instance driven approaches are of increasing relevance. In this special issue we have collected various inductive approaches and approaches from relational learning for solving a number of tasks. In particular, inductive methods are applied to learn the definition of ontological concepts, for the support of ontology construction and for the continuous support of ontology evolution. The paper by Luca Cagliero, Tania Cerquitelli, and Paolo Garza is on the semi-automatic ontology construction by exploiting functional dependencies and association rules. The approach supports domain experts in the construction of meaningful Description Logic ontologies. Functional dependencies are first identified to infer a schema ontology graph (SOnG) that represents conceptual relationships between attributes. Subsequently, the dependency-driven ontology generator (DOnG) framework analyzes XML content to discover schema ontology instance graphs (SOnIG) exploiting the association rules holding between data items. The experimental evaluation focuses on the semi-automatic generation of ontologies from XML data, a research area that certainly deserves further attention. The paper by Nicola Fanizzi presents DL-FOIL for ontology construction by learning concept descriptions in Description Logics. DL-FOIL is an extension to the well known ILP algorithm FOIL and is applied to ontologies from eBanking, bioinformatics, and characters and places mentioned in the New Testament. A particular challenge is that in the paper's open world assumption (OWA) there are instances that are neither positive nor negative examples for the concept under consideration and specific performance measures are introduced and discussed. The paper by Maryam Ramezani discusses similarity-based approaches to assist users in the continuous development of ontologies. The paper presents a method for learning new relationships from an existing concept hierarchy with the goal of assisting the user in adding new concepts in this concept hierarchy. Semantic relations are learned from an existing ontology or concept hierarchy. This approach is experimentally evaluated on the development of ontologies in social semantic bookmarking, semantic wiki and can be beneficial in other Web 2.0 style semantic applications as well.","venue":"","year":2011.0,"referenceCount":0,"citationCount":0,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"8315951","name":"Claudia d\u2019Amato"},{"authorId":"145704191","name":"A. Bernstein"},{"authorId":"1700754","name":"Volker Tresp"}]},{"paperId":"02a40008a94cd4d633c6f22155195c124152cd2b","title":"Storage, Querying and Inferencing for Semantic Web Languages","abstract":null,"venue":"","year":2005.0,"referenceCount":0,"citationCount":64,"fieldsOfStudy":["Computer Science"],"publicationDate":"2005-07-04","authors":[{"authorId":"3037266","name":"J. Broekstra"}]},{"paperId":"02a61cbd64e6da72d83c2551511918e8ede77944","title":"Innovative Methodology for Personalized 3D Representation and Big Data Management in Cultural Heritage","abstract":null,"venue":"Transdisciplinary Multispectral Modelling and Cooperation for Preservation Cultural Heritage","year":2018.0,"referenceCount":11,"citationCount":5,"fieldsOfStudy":["Computer Science"],"publicationDate":"2018-10-10","authors":[{"authorId":"19297260","name":"E. Alexakis"},{"authorId":"30431925","name":"E. Kapassa"},{"authorId":"46193382","name":"M. Touloupou"},{"authorId":"1681006","name":"D. Kyriazis"},{"authorId":"2507579","name":"A. Georgopoulos"},{"authorId":"3044601","name":"A. Moropoulou"}]},{"paperId":"02a695bae76fb173ca764785e3399a3cccc9b4bd","title":"A Fuzzy Linguistic Multi-agent Model Based on Semantic Web Technologies and User Profiles","abstract":null,"venue":"Soft Computing in Web Information Retrieva","year":2006.0,"referenceCount":40,"citationCount":4,"fieldsOfStudy":["Computer Science","Engineering"],"publicationDate":null,"authors":[{"authorId":"1397996912","name":"E. Herrera-Viedma"},{"authorId":"1961505","name":"E. Peis"},{"authorId":"1403909155","name":"Jos\u00e9 M. Morales-del-Castillo"}]},{"paperId":"02a6a9d849b8ad2ea869f04b72c14637456b76f2","title":"Developing web-resource development technologies for preparing education documentation in e-learning system","abstract":"The research suggests the technology of creating a web-resource for the preparation of documentation on educational discipline in the e-learning system. A detailed analysis of document circulation in electronic learning was conducted. The choice of technologies for the creation of a Web-resource for the preparation of documentation on the discipline has been substantiated. The questions of the choice of the format for the description of the discipline are analyzed. A model of documentation of the discipline with a generalized indication of the elements and contents of documents was designed, on the basis of which it is possible to find out the semantic interconnection between the information blocks.","venue":"ScienceRise","year":2018.0,"referenceCount":26,"citationCount":0,"fieldsOfStudy":null,"publicationDate":"2018-11-23","authors":[{"authorId":"2134708276","name":"Viktor Klymniuk"}]},{"paperId":"02a7b0a3de9016783e2d673b07352e204b1b99ae","title":"Third workshop on exploiting semantic annotations in information retrieval (ESAIR): CIKM 2010 workshop","abstract":"There is an increasing amount of structure on the Web as a result of modern Web languages, user tagging and annotation, and emerging robust NLP tools. These meaningful, semantic, annotations hold the promise to significantly enhance information access, by enhancing the depth of analysis of today's systems. Currently, we have only started exploring the possibilities and only begin to understand how these valuable semantic cues can be put to fruitful use. Unleashing the potential of semantic annotations requires us to think outside the box, by combining the insights of natural language processing (NLP) to go beyond bags of words, the insights of databases (DB) to use structure efficiently even when aggregating over millions of records, the insights of information retrieval (IR) in effective goal-directed search and evaluation, and the insights of knowledge management (KM) to get grips on the greater whole. The Workshop aims to bring together researchers from these different disciplines and work together on one of the greatest challenges in the years to come. The desired result of the workshop will be concrete insight into the potential of semantic annotations, and in concrete steps to take this research forward; synchronize related research happening in NLP, DB, IR, and KM, in ways that combine the strengths of each discipline; and have a lively, interactive workshop were everyone contributes and that inspires attendees to think \"outside the box\".","venue":"International Conference on Information and Knowledge Management","year":2010.0,"referenceCount":33,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":"2010-10-26","authors":[{"authorId":"2253609971","name":"Jaap Kamps"},{"authorId":"1742359","name":"Jussi Karlgren"},{"authorId":"2241803154","name":"Ralf Schenkel"}]},{"paperId":"02a80f6883beae1e60110117d6de8c76735a0319","title":"Empowering Enterprise Data Governance with the Business Semantics Glossary an illustration in the Flemish Public Administration","abstract":"For businesses to obtain good data governance, references to the instances used in the application domain, and domain rules are often required. The technologies on which LD is based, RDF and URI, are insufficient for enterprise data governance as common domain rules can either not be imposed nor not always properly modeled. As the Web is gaining a prominent role for enterprises and other types of communities, appropriate semantic methods and tools are required for data governance. This paper presents the Business Semantics Glossary, a tool currently being validated by industry that supports the Business Semantics Management methodology, based on the OMG SBVR standard and the DOGMA ontology framework. Our examples and claims are drawn from a case study at the Flemish Institute of Education and Training, where the tool is currently in use.","venue":"","year":2010.0,"referenceCount":23,"citationCount":1,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"2217868","name":"C. Debruyne"},{"authorId":"7331202","name":"P. Leenheer"},{"authorId":"1733861","name":"R. Meersman"}]},{"paperId":"02a90238535d6b55430845680ca13475a48433e4","title":"A comparative evaluation of an ontological medical decision support system (OMeD) for critical environments","abstract":"Modern medical decision making systems require users to manually collect and process information from distributed and heterogeneous repositories to facilitate the decision making process. There are many factors (such as time, volume of information and technical ability) that can potentially compromise the quality of decisions made for patients. In this work we demonstrate and evaluate a new medical decision making support system, called OMeD, which automatically answers medical queries in real time, by collecting and processing medical information. OMeD utilizes a natural-language-like user interface (for querying) and semantic web techniques (for knowledge representation and reasoning) to answer queries. We compare OMeD to a set of standard machine learning techniques across a series of benchmarks based on simulated patient data. The conventional techniques attempt to learn the answer to a query by analyzing simulated patient records. The sparsity of the simulated data leads conventional techniques to frequently misidentify the relationships between medical concepts. In contrast, OMeD is able to reliably provide correct answers to queries. Unlike conventional automated decision support systems, OMeD also generates independently verifiable proofs for its answers, providing healthcare workers with confidence in the system's recommendations.","venue":"International Health Informatics Symposium","year":2012.0,"referenceCount":13,"citationCount":16,"fieldsOfStudy":["Computer Science"],"publicationDate":"2012-01-28","authors":[{"authorId":"2042480","name":"J. Doucette"},{"authorId":"143810127","name":"Atif Khan"},{"authorId":"144860558","name":"R. Cohen"}]},{"paperId":"02a95e054859dace6f3509c568fe6f7699e9a2b4","title":"Semantic Complex Event Detection System of Express Delivery Business with Data Support from Multidimensional Space","abstract":"The express delivery industry of China is relatively backward in the automation degree of critical business processes. The basic reason is that the business-related supporting data, which is scattered in the multidimensional space, is difficult to utilize and process. This paper proposes an automatic data acquisition framework to resolve such difficulty, which synthetically utilize intelligent inernet of things (IoT), semantic web and complext event processing (CEP) technology. We also implement a SCEP prototype system with the capability of real-time detecting complex business events on the goods sorting line, which adopts a detection method consisting of four stages. The simulation results show that the system has good performance and feasible enough to deal with the complex business which need data support from multidimensional space.","venue":"","year":2014.0,"referenceCount":7,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":"2014-01-03","authors":[{"authorId":"2004761409","name":"Xinlin Jing"},{"authorId":"2155703907","name":"Jing Zhang"},{"authorId":"2152749438","name":"Jun Li"}]},{"paperId":"02adf908d7babd4ce3ae71fe2e8801269774f2cd","title":"A Personalized Hotel Selection Engine","abstract":"In this poster we describe the results of our work in the Reisewissen project which adopts Semantic Web (SW) technologies for the tourism domain. In the prototypical implementation of a SW based portal for hotel booking we use RDF as a shared data representation scheme utilized by evaluation components written in Java and Prolog. We apply Prolog to transform data between external and internal ontologies and to represent expert knowledge. Since our prototypical implementation is to be integrated into a real world production system where performance plays a crucial role, the developed solution is based on a mix of SW technologies and classical knowledge representation tools.","venue":"","year":2006.0,"referenceCount":3,"citationCount":17,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"145156481","name":"J\u00f6rg Garbers"}]},{"paperId":"02ae958f10b89c953e7f62d1d6c3481ac7df70d6","title":"PROSE: A Plugin-Based Paraconsistent OWL Reasoner","abstract":null,"venue":"Joint International Conference of Semantic Technology","year":2015.0,"referenceCount":44,"citationCount":4,"fieldsOfStudy":["Computer Science"],"publicationDate":"2015-11-11","authors":[{"authorId":"80776867","name":"Wenrui Wu"},{"authorId":"145774078","name":"Zhiyong Feng"},{"authorId":"1780738","name":"Xiaowang Zhang"},{"authorId":"122024145","name":"Xin Wang"},{"authorId":"143661036","name":"Guozheng Rao"}]},{"paperId":"02aef0c35ef82a992175497cb97bf2877302d505","title":"Knowledge Graphs, Metadata Practices, and Badiou's Mathematical Ontology","abstract":"Metadata practices in libraries have been shifting towards a graph-centric data model for a number of years due to the influence of the Semantic Web on metadata standards as well as the ongoing engagement of libraries with linked data. This trend is likely to be sustained by the growth of the knowledge graph domain, which is animated by the interests of large technology companies and which represents a continuation of earlier programmes such as expert systems and the Semantic Web. Given the role of Semantic Web ontologies in knowledge graph development and the relevance of philosophical questions of ontology to cataloguing theory, metadata practitioners require theoretical frameworks suitable for conceptualizing the knowledge graph data model\u2019s mixture of data and ontology. To that end, this paper considers the mathematical ontology of philosopher Alain Badiou, which employs set theory to schematize a theory of the multiple. It outlines how Badiou\u2019s ontology is compatible with the graph data model and what it offers to metadata practitioners seeking to critically engage the knowledge graph paradigm.","venue":"KULA knowledge creation dissemination and preservation studies","year":2022.0,"referenceCount":70,"citationCount":0,"fieldsOfStudy":null,"publicationDate":"2022-07-27","authors":[{"authorId":"117858548","name":"J. Huck"}]},{"paperId":"02afaf65764fc9a90646794aea7d9178a6e8550c","title":"Semantic web technologies and social searching for librarians (The Tech Set series, #20)","abstract":"This is another title in the excellent Tech Set series, jointly written by a database expert from the University of Georgia Libraries and a \u2018technology innovation librarian\u2019 at the Nebraska Library Commission. And it certainly delivers on the series editor\u2019s promise to \u2018explain the principles behind theSemanticWeb, howyoucan structure your owndata for better retrieval by today\u2019s semantic search engines, and the secrets of finding hidden content online\u2019. In format, it is almost identical to the fourteenth and fifteenth volumes in the series (Drupal in Libraries and Strategic Planning for Social Media in Libraries), with the same chapter headings, the same hands-on emphasis (the implementation chapter is half the book), and the same companion website with author updates, comments section and podcasts. Unfortunately, it also has the same variable print quality, especially noticeable with reproduced monochrome screenshots. Spot colour would have been good, and perhaps possible within the price. But let\u2019s not be too picky, for this is an enthralling read. This is about the arrival of the web\u2019s future. The Semantic Web involves giving context to data, using metadata and linked data to encompass multiple formats such as images and video, and drawing social media into the picture to make sense of the information explosion. Through the new framework and standards embodied in FRBR (Functional Requirements for Bibliographic Records), RDA (ResourceDescription andAccess) and the implementation of linked data projects (search for \u2018Linked data for libraries\u2019 on YouTube), major players like the National Library of Australia, the Library of Congress and OCLC are already exposing their collections to the web. Fay and Sauers want us to get in there. Step-by-step exercises include tracking trends in Twitter; Google Alerts as a social media monitor; using Spezify to display search results in visual form; advanced tips for extracting hidden content via Google Blogs, Google Scholar, Google News Timeline, Bing Social and Silobreaker; WolframAlpha for analysing data and statistics; creating searchable metadata in Flickr; revealing content with Google\u2019s Rich Snippets; and contributing linked data with the US Civil War sesquicentennial project as the example. In their concluding chapter on developing trends, the authors observe:","venue":"","year":2013.0,"referenceCount":0,"citationCount":0,"fieldsOfStudy":["Engineering"],"publicationDate":"2013-02-01","authors":[{"authorId":"2969337","name":"I. Mccallum"}]},{"paperId":"02b02c0216e7e8dc259940458550e4829bd7a19e","title":"Using JavaScript RDFa Widgets for Model\/View Separation inside Read\/Write Websites","abstract":"As more and more websites start to embed RDFa content in their web application view, the need arises to provide a more extensive way for viewing and editing this semantic content independently from the remainder of the application. We present a JavaScript API that allows the independent creation of editing widgets for embedded RDFa, which adds a new edge to Web development in the context of the Semantic Web. As an addition, the API also provides sound update methods that allow on-the-spot model synchronization between client and server.","venue":"","year":2008.0,"referenceCount":6,"citationCount":17,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"2574714","name":"Sebastian Tramp"},{"authorId":"2024066","name":"Sebastian Hellmann"},{"authorId":"15138065","name":"M. Peklo"}]},{"paperId":"02b031ee81e7886ab8e6104732742b4e177d4739","title":"SR Workshop 2015: International Workshop on Stream Reasoning","abstract":null,"venue":"KI - K\u00fcnstliche Intelligenz","year":2016.0,"referenceCount":0,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":"2016-03-14","authors":[{"authorId":"2068714068","name":"Markus Brenner"}]},{"paperId":"02b20736c1bdf444cc30d8548f767b777d8a1566","title":"Towards Efficient Sport Data Integration through Semantic Annotation","abstract":"In news genre, the sport domain is one of great interest to audiences on many occasions. The explosion of Internet these days leads to many obstacles for users in searching information due to enormous amount of data collected from multiple media streams. In this case, Semantic Web is believed to bring a solution for information integration. In this paper, we introduce a novel approach for an integration system of sports information using semantic web. Semantic annotation of sport news on the web is a way to bring success to our system. We propose an algorithm to generate semantic annotations of sport news that relies on the ontology. Named entities recognition is improved by integrating the KIM information extraction system with this ontology, which is dedicated for sport domain. The concepts and relations of ontology detected in the text are combined with these entities to capture the semantic. Initial experiments on soccer news demonstrated promising results.","venue":"2012 Fourth International Conference on Knowledge and Systems Engineering","year":2012.0,"referenceCount":11,"citationCount":5,"fieldsOfStudy":["Computer Science"],"publicationDate":"2012-08-17","authors":[{"authorId":"2046003","name":"Quang-Minh Nguyen"},{"authorId":"2467367","name":"T. Cao"},{"authorId":"1888696","name":"Hoang-Cong Nguyen"},{"authorId":"34636567","name":"T. Hagino"}]},{"paperId":"02b66b86ffc6d106abf6fff14183bb72712f578b","title":"Semantic web: a new approach for the information organization and retrieval in the Web","abstract":null,"venue":"","year":2005.0,"referenceCount":0,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":"2005-12-01","authors":[{"authorId":"2095171807","name":"Keilyn Rodr\u00edguez Perojo"},{"authorId":"2073680002","name":"Rodrigo Ronda Le\u00f3n"}]},{"paperId":"02b7354625441c35e69c345cbfa24ef62ce8cbaf","title":"Comparison of the Baseline Knowledge-, Corpus-, and Web-based Similarity Measures for Semantic Relations Extraction","abstract":"Unsupervised methods of semantic relations extraction rely on a similarity measure between lexical units. Similarity measures differ both in kinds of information they use and in the ways how this information is transformed into a similarity score. This paper is making a step further in the evaluation of the available similarity measures within the context of semantic relation extraction. We compare 21 baseline measures -- 8 knowledge-based, 4 corpus-based, and 9 web-based metrics with the BLESS dataset. Our results show that existing similarity measures provide significantly different results, both in general performances and in relation distributions. We conclude that the results suggest developing a combined similarity measure.","venue":"GEometrical Models of Natural Language Semantics","year":2011.0,"referenceCount":47,"citationCount":6,"fieldsOfStudy":["Computer Science"],"publicationDate":"2011-07-31","authors":[{"authorId":"144033941","name":"Alexander Panchenko"}]},{"paperId":"02b962be6ea8c641e663cd8dd6ab99d757269813","title":"A Conceptual Paper: Proposed Search of Intelligent Disease Information System Using Semantic Web","abstract":"Purpose: The purpose of this study is to optimize the search for disease records using the semantic web model. \nBackground: The development of Information Technology is not only on hardware and software, but also in the development of technology based on Artificial Intelligent (AI).\u00a0 In the field of medicine, the AI is developing rapidly.\u00a0 Information and Communication Technology (ICT) in the health field is widely used, one of which is disease\u00a0 information data. Disease information data availability has increased electronically but the data is not categorized and stored semantically. No categorization and semantic store make the data difficult to find. Semantic Web is an intelligent service as an information intermediary, search agent, and information filter, which offers more functionality and interoperability than a standalone service. The Semantic Web context is meta-data which allows the machine to interpret it where the query execution time depends on this order. A good algorithm for determining query paths can thus contribute to making queries fast and efficient. \nDesign\/Methodology\/Approach: Methods and analysis will use Ontology Web Language (OWL) for disease domain modeling and meta-search systems for ontology mapping and Web services. The Mapping component includes domain ontologies, taxonomic information and collection databases and changes them in the Resource Description Framework (RDF). The study will also create semantic web ontology models and optimize disease information search using genetic algorithms that allow automatic in meta-data matching. \nResults\/Findings: The results of this study is a repository of knowledge related to such a mapping that disease information search can be found. \nConclusion and Implications:\u00a0A new algorithms or model will be proposed and it can optimize disease finding with information needed and semantic Web ontology. \n.","venue":"","year":2020.0,"referenceCount":0,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":"2020-01-20","authors":[{"authorId":"1576410515","name":"S.R.Candra Nursari"},{"authorId":"48087207","name":"Setyawan Widyarto"},{"authorId":"3190475","name":"H. Nawi"}]},{"paperId":"02b9bf96a40c5a0392bcc9898666568680a716b6","title":"Research on All-for-One Tourism Image Perception Based on Web Text and IPA","abstract":"Based on the combination of content analysis and IPA, the web text is used to study the all-for-one tourism image perception in Luanchuan County. With the help of the Octopus collector, the online travel notes of Luanchuan County are crawled from large-scale online travel websites such as Ctrip and Mafengwo, combined with Rost Content Mining text analysis software, the high-frequency lexical analysis of the text data is carried out, and the semantic network analysis diagram is drawn. Based on this, the tourism image perception factor coding was performed, and a total of 4 first-level coding elements and 21 second-level coding elements were obtained. The IPA is used to further analyze the tourist image perception quality. The results show that tourists have a good overall perception of the all-for-one tourism image of Luanchuan County, but the importance and performance scores are quite different, and the degree of perception of 10 secondary coding elements such as entertainment and scenic traffic is low. Therefore, tourism management department of Luanchuan County should actively improve, so as to enhance the all-for-one tourism perception image of tourists to Luanchuan County, and strengthen the construction of Luanchuan County's all-for-one tourism demonstration zone.","venue":"2020 International Conference on Modern Education and Information Management (ICMEIM)","year":2020.0,"referenceCount":11,"citationCount":0,"fieldsOfStudy":null,"publicationDate":"2020-09-01","authors":[{"authorId":"2145378857","name":"Yanhong Sun"},{"authorId":"2109025174","name":"Qingnan Wang"}]},{"paperId":"02bcca63f0bc52dd03bd204f1d74e134f6a36cfd","title":"Exploring and Exploiting(?) the Awkward Connections Between SKOS and OWL","abstract":"In the Semantic Web, the Web Ontology Language (OWL) vocabulary is used for the representation of formal ontologies, while the Simple Knowledge Organisation System (SKOS) is a vocabulary designed for thesauri or concept taxonomies without formal semantics. Despite their different nature, on the Web these two vocabularies are often used together. Here, we try to explore and exploit the joint usage of OWL and SKOS. More precisely, we first define usage patterns to detect problematic modeling from connections between SKOS and OWL. Next, we also investigate if additional information can be inferred from joint usage with SKOS in order to enrich semantic inferences through OWL alone \u2013 although SKOS was designed without formal semantics, we argue for this heretic approach by applicability \u201cin the wild\u201d: the patterns for modeling errors and inference of new information are transformed to SPARQL queries and applied to real world data from the Billion Triple Challenge 2014; we manually evaluate this corpus and assess the quality of the defined patterns empirically.","venue":"International Workshop on the Semantic Web","year":2015.0,"referenceCount":6,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"35881103","name":"S. Belk"},{"authorId":"1724374","name":"G. Wohlgenannt"},{"authorId":"1708607","name":"A. Polleres"}]},{"paperId":"02bf117222a24f3bd26ff824eca3830a06fe35e8","title":"Annual Progress in Bioinformatics 2006","abstract":"In this issue, Briefings in Bioinformatics is happy to present the next installment of our special annual issue devoted to reviews of very active subdisciplines within our field. The editors surveyed recent publications in order to identify fields that are moving rapidly and would be good targets for summary and review. We asked authors to provide brief introductions to their field, and then to concentrate on contributions in the last 12\u201324 months of particular interest. In some cases, they also provided annotated bibliographies in which they highlighted papers of particularly high interest. The result is seven outstanding reviews. The influence of high-throughput genomic experimental techniques and the increasing interest on synthesis of information comes through strongly in this year's selections. We have ordered the reviews starting with those discussing tools close to the genome (the HapMap project, function prediction, graph methods for analyzing cellular networks), and then toward tool-oriented organization and sharing of knowledge (biological ontologies, the semantic web and open source software). The first set of reviews focuses on tools for understanding the central dogma and basic biological processes. The second set focuses on tools to assist scientists in the process of doing their work. In many ways, these are the two primary foci of bioinformatics, and it is reassuring to see that progress is balanced along both fronts. In the first review, Barnes provides an overview of the HapMap project for cataloging human genetic diversity. Understanding variation in the human genome is critical for understanding the variation in human phenotypes. The HapMap project is the natural follow-up to the human genome sequencing project, and seeks to characterize the variations in the human genome\u2014initially in four groups of different geographic origin. The review describes the HapMap project's motivation, strategy, data resources and analytic challenges. Not surprisingly, variation in the human genome is not entirely independent, but shows a correlation structure (expressed as linkage disequilibrium or LD) that is critical for the design of studies that aim to understand the relationship between genotype and phenotype. In addition, this LD structure can be examined in the context of human population history to understand our origins. In the second review, Iddo Friedberg presents the challenges associated with annotating genes with their biological functions. It seems that nothing is easy about this task. First, genes are typically polyfunctional and therefore multiple experimental and theoretical sources are used to characterize their function. Annotation techniques \u2026","venue":"Briefings Bioinform.","year":2006.0,"referenceCount":0,"citationCount":1,"fieldsOfStudy":["Biology","Computer Science"],"publicationDate":"2006-09-01","authors":[{"authorId":"144446128","name":"R. Altman"}]},{"paperId":"02c0528a17a845c747a763037d9514ca50b834fd","title":"KGSnap! in Practice: a Block-based Programming Environment for Enabling Knowledge Graph Literacy","abstract":"The growing availability of (linked) open data requires lay users to master how to deal with data effectively, yet SPARQL presents a barrier to leveraging data represented as knowledge graphs. As the block programming paradigm has been successfully used to teach programming skills, we demonstrate how to use KGSnap! , an extension of the block-based programming environment Snap!, to foster knowledge graph literacy among individuals lacking expertise in query languages. This work mainly focuses on the visualization and interaction aspects of KGSnap! , a visual SPARQL query builder, when experienced by users without expertise in the Semantic Web technologies. The reported experience is discussed as a learning-by-doing protocol aimed at facilitating the reproducibility and transparency of the performed evaluation. KGSnap! ease of use has been verified by 14 Snap! experts and 24 high-school learners. The findings indicate that lay users perceived it as a promising approach to acquaint themselves with knowledge graphs.","venue":"VOILA@ISWC","year":2024.0,"referenceCount":31,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"31736099","name":"Alessia Antelmi"},{"authorId":"2311903445","name":"Vincenzo Offertucci"},{"authorId":"2215252710","name":"Maria Angela Pellegrino"}]},{"paperId":"02c0b242593f76d1ad22bc2d4210e94e58d21ad6","title":"Xcerpt and XChange: Deductive Languages for Data Retrieval and Evolution on the Web","abstract":"In this article, two deductive languages are introduced: the language Xcerpt, for querying data and reasoning with data on the (Semantic) Web, and the language XChange, for evolution and reactivity on the (Semantic) Web. A small application scenario is given as a motivation for these languages.","venue":"GI Jahrestagung","year":2004.0,"referenceCount":5,"citationCount":3,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"1767012","name":"Fran\u00e7ois Bry"},{"authorId":"2504214","name":"Paula-Lavinia Patr\u00e2njan"},{"authorId":"1777556","name":"Sebastian Schaffert"}]},{"paperId":"02c1adbd4203ebdf612d2b95585c9e927a48205b","title":"Contextualized recommendations for the socio-semantic web","abstract":"In recent years, recommender systems have been widely used for a variety of different kinds of items such as books, movies, and music. However, current recommendation approaches have often been criticized to suffer from overspecialization thus not enough considering a user\u2019s diverse topics of interest. In this thesis we present a novel approach to extracting contextualized user profiles which enable recommendations taking into account a user\u2019s full range of interests. The method applies algorithms from the domain of topic detection and tracking to automatically identify diverse user interests and to represent them with descriptive labels. That way manual annotations of interest topics by the users, e. g., from a predefined domain taxonomy, are no longer required. The approach has been tested in two scenarios: First, we implemented a content-based recommender system for an Enterprise 2.0 resource sharing platform where the contextualized user interest profiles have been used to generate recommendations with a high degree of inter-topic diversity. In an effort to harness the collective intelligence of the users, the resources in the system were described by making use of user-generated metadata. The evaluation experiments show that our approach is likely to capture a multitude of diverse interest topics per user. The labels extracted are specific for these topics and can be used to retrieve relevant on-topic resources. Second, a slightly adapted variation of the algorithm has been used to target music recommendations based on the user\u2019s current mood. In this scenario music artists are described by using freely available Semantic Web data from the Linked Open Data cloud thus not requiring expensive metadata annotations by experts. The evaluation experiments conducted show that many users have a multitude of different preferred music styles. However a correlation between these music styles and music mood categories could not be observed. An integration of our proposed user profiles with existing user model ontologies seems promising for enabling context-sensitive recommendations.","venue":"","year":2013.0,"referenceCount":83,"citationCount":2,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"1853700","name":"Rafael Schirru"}]},{"paperId":"02c26878706ae60c1894c11dee391e8e1f96ff39","title":"City Research Online","abstract":"Semantic annotation of multimedia content is important for training, testing, and assessing content-based algorithms for indexing, organization, browsing, and retrieval. To this end, an annotated multimodal movie corpus, the so called MUSCLE movie database, has been collected to be used as a test bed for development and assessment of content-based multimedia processing, such as speaker clustering, speaker turn detection, visual speech activity detection, face detection, facial feature detection, face clustering, scene segmentation, saliency detection, and multimodal dialogue detection. All metadata are saved in xml format following the MPEG-7 ISO prototype to ensure data compatibility and reusability by different users and applications. The entire database can be downloaded through the web for research purposes. Furthermore, we describe a novel annotation tool called Anthropos7 Editor.","venue":"","year":null,"referenceCount":10,"citationCount":3,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"2285397290","name":"D. Spachos"},{"authorId":"2285403507","name":"A. Zlatintsi"},{"authorId":"2285390626","name":"V. Moschou"},{"authorId":"117194685","name":"P. Antonopoulos"},{"authorId":"2109397","name":"Emmanouil Benetos"},{"authorId":"1800944","name":"M. Kotti"},{"authorId":"2285390306","name":"K. Tzimouli"},{"authorId":"2285397377","name":"C. Kotropoulos"},{"authorId":"2285403691","name":"N. Nikolaidis"},{"authorId":"2285397187","name":"P. Maragos"},{"authorId":"2239292395","name":"I. Pitas"}]},{"paperId":"02c34d2769d1acb4aa2de17a69cbead221249418","title":"A high-level specification for Semantic Web Service Discovery Services","abstract":"We define a high-level model to mathematically capture the semantical meaning of Semantic Web Service Discovery Locations (SWS Discovery Services), their distribution and communication mechanisms. This model captures, to our best knowledge, all published semantic web service discovery approaches relying on capability-based semantic matchmaking.","venue":"International Conference on Web Engineering","year":2006.0,"referenceCount":19,"citationCount":9,"fieldsOfStudy":["Computer Science"],"publicationDate":"2006-07-10","authors":[{"authorId":"143628103","name":"A. Friesen"},{"authorId":"1692943","name":"E. B\u00f6rger"}]},{"paperId":"02c37c27fdcdca250320aa4b0b0183bf79041796","title":"Semantic web and web knowledge management","abstract":null,"venue":"","year":2012.0,"referenceCount":0,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":"2012-05-21","authors":[{"authorId":"2482430","name":"P. Sajja"},{"authorId":"1854500","name":"R. Akerkar"}]},{"paperId":"02c3959023e68a3b5aec6d597f62559d7e27dc65","title":"The Third Generation of Internet: The Semantic Web as a Component of Web 3.0","abstract":". The current web supports mainly human browsing for sharing the information. This current trend has become less and less adequate as the mass of available information increases in the world. For that required integrated and uniform access to information sources and services as well as intelligent applications for information processing on the web. To support this require standard mechanisms for interchanging data and handling different data semantics which is commonly referred as a Semantic Web. The Semantic Web is a component of Web 3.0 in which it provides web of data that can be processed directly and indirectly by machines. In this article we elaborated and discussed the Semantic Web as a component of Web 3.0 which is the third generation of Internet.","venue":"","year":2012.0,"referenceCount":41,"citationCount":1,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"2287912390","name":"Rajan Patel"},{"authorId":"14833537","name":"Nimisha Patel"}]},{"paperId":"02c71b11227e5e3a33383da01f66b750a6fe6488","title":"A Fast and Simple Path Index Based Retrieval Approach for Graph Based Semantic Descriptions","abstract":". The Semantic Web is a quite controversial concept, which is discussed extensively. Nevertheless most discussions showed that ways handling semantic metadata are needed urgently. Semantic metadata allows the storage of information which not only includes a set of concepts, but also the relations between the concepts in computable way. Within this paper an indexing and retrieval technique for semantic metadata is presented. The paper includes the discussion of a graph based data model for MPEG-7 based semantic metadata and an indexing technique for this model is outlined. Details on the implementation are given and a preliminary evaluation of the retrieval performance is included. As a last chapter related work is compared to our approach and pointers to related projects are given.","venue":"","year":2005.0,"referenceCount":31,"citationCount":4,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"1786883","name":"M. Lux"},{"authorId":"2389675","name":"M. Granitzer"}]},{"paperId":"02c7e4301d1e0f7d1b986c4ef988fac1ce605db2","title":"Proceedings of the Second Workshop on Semantic Web Technologies for the Internet of Things co-located with 16th International Semantic Web Conference (ISWC 2017)","abstract":null,"venue":"SWIT@ISWC","year":2017.0,"referenceCount":0,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[]},{"paperId":"02c8c5a23c1168d4e69f37af6bf13e390e363b8b","title":"Annotator 1 : Persons Dog Sea Tree Annotator 2 : Man Woman Beach Dog Sea Forest Annotator","abstract":"In the quest for models that could help to represent the meaning of images, some approaches have used contextual knowledge by building semantic hierarchies. Others have resorted to the integration of images analysis improvement knowledge and images interpretation using ontologies. The images are often annotated with a set of keywords (or ontologies), whose relevance remains highly subjective and related to only one interpretation (one annotator). However, an image can get many associated semantics because annotators can interpret it differently. The purpose of this paper is to propose a collaborative annotation system that brings out the meaning of images from the different interpretations of annotators. The different works carried out in this paper lead to a semantic model of an image, i.e. the different means that a picture may have. This method relies on the different tools of the Semantic Web, especially ontologies.","venue":"","year":2014.0,"referenceCount":23,"citationCount":0,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"3176757","name":"D. Zomahoun"}]},{"paperId":"02ca6ce2d2ec4eb65cfb096c67aa8dfded080304","title":"Proceedings of the international conference on human-centric computing 2011 and embedded and multimedia computing 2011 : HumanCom & EMC 2011","abstract":"Keynote Speech. Graph-based Structure Search X.Lin. Location Significance Ranking from Quality Enhanced Trajectory Data X.Zhou. Ubiquitous Neural Interface B.Hu. HumanCom 2011. Session 1: Computer-assisted Learning, Cognition and Semantic Systems. Dynamic Recommendation in Collaborative Filtering Systems: A PSO Based Framework J.Yao, B.Li. Automatic Chinese Topic Term Spelling Correction in Online Pinyin Input S.Sha, et al. An Ontology-Based Approach for Semantic Web Service Searching S.Shen , et al. Applying Data Visualization to Improve the e-Health Decision Making Md.A.Rahman, S.Komiak. A Psychological Decision Making Model Based Personal Fashion Style Recommendation System J.Li, et al. A multi-modal augmented reality based virtual assembly system C.Wu, H.Wang. A Novel Memory-based Storage Optimization Approach for RDF Data Supporting SPARQL Query F.Zhao, et al. An Extended Supervised Term Weighting Method for Text Categorization B.Wei, et al. Session 2: Human-computer Interaction and Social Computing. Building Ontology for Mashup Services Based on Wikipedia K.Xiao, B.Li. A Hybrid Model for Simulating Human Crowd M.Xiong, et al. Automatic Inference of Interaction Occasion in Multiparty Meetings: Spontaneous or Reactive Z.Yu, X.Zhou. Managing Interactions in the Collaborative 3D DocuSpace for Enterprise Applications T.Sun, et al. Dempster-Shafer Theory Based Consensus Building in Collaborative Conceptual Modeling L.Jia, et al. Session 3: Network or distributed algorithms, applications. Research Application of the Internet of Things Monitor Platform in Meat Processing Industry T.Hu, et al. S-Rsync: An Efficient Differencing Algorithm With Locally Chunk Digests Generating For File Synchronization Services H.Zhang, et al. VESS: An Unstructured Data-Oriented Storage System for Multi-Disciplined Virtual Experiment Platform W.Jiang, et al. PKLIVE: A Peer-to-Peer Game Observing System H.YAO, L.YU. Session 4: Privacy, Security and trust management. Provably Secure Two-party Password-based Key Agreement Protocol H.Zhou, et al. Subjective Logic based Trust Update for Wireless Sensor Networks Y.Zhang, et al. A Detection Method for Replication Attacks in Wireless Sensor Networks C.-Y.Ku, et al. VIsolator: An Intel VMX-Based Isolation Mechanism L.He, et al. Graph-Based Authorization Delegation Model J.Lei, et al. Session 5: Ubiquitous computing, mobile systems and applications. A Multiple Response Approach for Adaptive Learning Service with Context-Based Multimedia Contents X.Zhao, et al. Enhancing the Experience and Efficiency at a Conference with Mobile Social Networking: Case Study with Find & Connect L.Chang, et al. Tools for Ubiquitous PACS System D.Dragan, D.Ivetic. Contact-based Congestion Avoidance Mechanism in Delay Tolerant Networks C.Yu, et al. Session 6:Virtualization Technologies for Desktop Applications. Visualization of Knowledge Map: a Focus and Context Approach J.Wang, et al. A Think on Security and Trusty Measurement for Virtualized Environment X.Wang, et al. EMC 2011 Session 1: Cyber-Physical Systems and Real-time systems. An Efficient Deadline and Period Assignment Scheme for Maintaining Temporal Consistency Under EDF F.Zhu, et al. Scheduling Performance of Real-time Tasks on MapReduce Cluster F.Teng, et al. An Efficient Metadata Management Method in Large Distributed Storage Systems L.Ran, H.Jin. Study on Methods for Extracting Comprehensive Information Based on the Sequential Dynamic Weighted Fusion B.Sun, et al. Session 2: Distributed Multimedia Systems. A scalable multithreaded BGP architecture for next generation router K.Wang, et al. Meta Level Component-Based Framework for Distributed Computing Systems A.Shui-Yu Lai, A.Beaumont. Session 3: Embedded Systems, Software and Applications. Design of Remote Engine Room Monitoring System Based on Niche Stack TCP\/IP S.Liu, et al. Design of an Efficient Low-Power Asynchronous Bus for Embedded System G.Zhang, et al. Exploring Options for Modeling of Real-Time Network Communication in an Industrial Component Model for Distributed Embedded Systems S.Mubeen, et al. A Low-Latency Virtual-Channel Router with Optimized Pipeline Stages for On-Chip Network S.Ren, et al. Towards A Web Service Based HCI Migration Framework Y.Shen, et al. Session 4: Multimedia Computing & Intelligent Services. Fast Clustering of Radar Reflectivity Data on GPUs W.Zhou, et al. A Compiler Framework for Translating Standard C into Optimized CUDA Code Q.Zhu, et al. A Dynamic Balancing Algorithm for VOD Based on Cloud Computing S.Chang, et al. High-quality Sound Device Virtualization in Xen Paravirtualized Environment K.Hu, et al. Emotional Communication Efficacy, Group Cohesion, and Group performance L.Dong, B.Shah. PDC 2011 A Robust Audio Aggregation Watermark Based on Vector Quantization J.Li, et al. A Service Giving a Case-based Instruction of Bioinformatics Workflow Running on High Performance Computer for Engineering Design and Education F.Lu, et al. A Fast Broadcast Protocol for Wireless Sensor Networks Y.Zhang, Y.Wang. Survey of Load Balancing Strategies on Heterogeneous Parallel System W.Wang, et al. Data Management and Application on CPSE-Bio X.Cheng, et al. ENC 2011 Implementation of SOAS for SDR processor L.Yang, et al. Design of Greenhouse Monitoring System Based on ZigBee Technology Yong Chen. Preheating Simulation of Power Battery M.Li, et al. Intelligent Guide System Based on the Internet of Things J.Jiao, H.Lin.","venue":"","year":2011.0,"referenceCount":0,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"40499494","name":"J. Park"},{"authorId":"145914251","name":"Hai Jin"},{"authorId":"144925807","name":"Xiaofei Liao"},{"authorId":"50734657","name":"Ran Zheng"}]},{"paperId":"02cb6562a0e15d0d60cd416ee3bfdd18cdad3e1b","title":"Proximity Matrix Completion and Ranking Ant Colony Optimization technique in Semantic web","abstract":"The semantic web consists of a large number of data that is difficult to retrieve the answer for the user queries. An existing method in the query processing in the semantic web has three main limitations namely, query flexibility, query relevancy or lack of ranking method and high query cost. In this study, Proximity Matrix Completion technique (PMC) is applied to impute the missing data in the dataset that helps to increase the query flexibility and Ranking Ant Colony Optimization (RACO) technique is used to select the relevant features from the dataset and arrange them to increase relevancy. The result shows that the PMC-RACO method has a higher performance compared to the exiting method in semantic web. The mean precision value of the PMC-RACO method in sports data is 87%, while the existing method has the precision value of 83%","venue":"International journal of recent technology and engineering","year":2019.0,"referenceCount":0,"citationCount":0,"fieldsOfStudy":null,"publicationDate":"2019-09-30","authors":[]},{"paperId":"02cbfb52089552a55d5a7ba0ec811d01de2c6e83","title":"Editorial message: special track on web and E-business applications","abstract":"The World WideWeb has become the standard computing platform for the development of new-generation information systems. A new tide of Web-based e-business applications (such as corporate portals, network-based supply chains and market places, etc.) is driving the need for a more open, flexible and distributed infrastructure, together with appropriate development methodologies and theoretical settings. Today's web applications involve skills from many different areas of computer science, including databases, AI and agent based applications, programming languages and algorithms, distributed computing, information retrieval, semantic modeling, etc. For this reason we proposed a track on Web and E-business applications based on the following main topics: data models for the World Wide Web, Web data management, languages for the World Wide Web and XML, E- business and Web services, transactions on the World Wide Web, security and integrity issues for the WWW, query systems for the World Wide Web, management and storage of Web information, information retrieval and search engines for the Web, Web semantics, data integration over the World Wide Web, data-intensive applications on the World Wide Web, Web architectures.We received 30 submissions, which were extensively reviewed for originality, significance, technical soundness and clarity of presentation. The submitted papers covered most of the proposed topics. The number of submissions distributed on each continent has been the following: 16 from Europe (53%), 9 from North America (30%), 3 from Asia (10%), 1 from Africa (3%) and 1 from Australia (3%). 12 papers corresponding to the 40% of the submitted papers have been selected for presentation at the conference, with the following distribution: 7 from Europe, 3 from America, 1 from Asia and 1 from Australia.","venue":"ACM Symposium on Applied Computing","year":2002.0,"referenceCount":0,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":"2002-03-11","authors":[{"authorId":"1742363","name":"S. Comai"},{"authorId":"1779997","name":"L. Tanca"}]},{"paperId":"02cc22847752f1aac6f920913adf3443f0614f48","title":"Implementing Power System Management via Semantic Web Services Composition","abstract":null,"venue":"International Symposium on Neural Networks","year":2009.0,"referenceCount":8,"citationCount":1,"fieldsOfStudy":["Computer Science"],"publicationDate":"2009-05-20","authors":[{"authorId":"2116620442","name":"Qing Liu"},{"authorId":"7798003","name":"J. Wen"},{"authorId":"34679687","name":"Haishun Sun"}]},{"paperId":"02cce23fb4d2e2b1e9190bc8c7d7042757f6722f","title":"Information Management for Unmanned Systems: Combining DL-Reasoning with Publish\/Subscribe","abstract":null,"venue":"SGAI Conferences","year":2008.0,"referenceCount":19,"citationCount":5,"fieldsOfStudy":["Computer Science"],"publicationDate":"2008-12-09","authors":[{"authorId":"33777760","name":"Herwig Moser"},{"authorId":"2422599","name":"T. Reichelt"},{"authorId":"1905419","name":"Norbert Oswald"},{"authorId":"118831019","name":"S. F\u00f6rster"}]},{"paperId":"02cd264b69380e08983276af63c52eee813b6caa","title":"Domain-Driven Visual Query Formulation over RDF Data Sets","abstract":null,"venue":"Parallel Processing and Applied Mathematics","year":2013.0,"referenceCount":14,"citationCount":5,"fieldsOfStudy":["Computer Science"],"publicationDate":"2013-09-08","authors":[{"authorId":"1960359","name":"B. Bali\u015b"},{"authorId":"2099250774","name":"Tomasz Grabiec"},{"authorId":"1752409","name":"M. Bubak"}]},{"paperId":"02cdb5283126625f9e46bf634b0dd4a123bf5fc9","title":"Text Understanding Agents and the Semantic Web","abstract":"We discuss the challenges involved in adapting the OntoSem natural language processing system to the Web. One set of tasks involves processing Web documents, translating their computed meaning representations from the OntoSem\u2019s native KR language into the Semantic Web language OWL, and publishing the results as Web pages and RSS feeds. Another set of tasks works in reverse \u2014 querying the Web for facts needed by OntoSem, translating them from OWL into OntoSem\u2019s native KR language and importing the results. A central problem underlying both sets of tasks is that of translating knowledge between OntoSem\u2019s KR language and ontologies and those of the Semantic Web. OntoSem2OWL has been developed as a translation system to support these translations. We describe SemNews, an implemented prototype application that demonstrates the process. It monitors RSS feeds of news stories, applies OntoSem to understand the text, and exports the computed facts back to the Web in OWL.","venue":"Proceedings of the 39th Annual Hawaii International Conference on System Sciences (HICSS'06)","year":2006.0,"referenceCount":32,"citationCount":26,"fieldsOfStudy":["Computer Science"],"publicationDate":"2006-01-04","authors":[{"authorId":"1778214","name":"Akshay Java"},{"authorId":"144121212","name":"Timothy W. Finin"},{"authorId":"1689693","name":"S. Nirenburg"}]},{"paperId":"02cf3c1b4c12ba03b55389c0907ec3442d45ecd4","title":"ParaQG: A System for Generating Questions and Answers from Paragraphs","abstract":"Generating syntactically and semantically valid and relevant questions from paragraphs is useful with many applications. Manual generation is a labour-intensive task, as it requires the reading, parsing and understanding of long passages of text. A number of question generation models based on sequence-to-sequence techniques have recently been proposed. Most of them generate questions from sentences only, and none of them is publicly available as an easy-to-use service. In this paper, we demonstrate ParaQG, a Web-based system for generating questions from sentences and paragraphs. ParaQG incorporates a number of novel functionalities to make the question generation process user-friendly. It provides an interactive interface for a user to select answers with visual insights on generation of questions. It also employs various faceted views to group similar questions as well as filtering techniques to eliminate unanswerable questions.","venue":"Conference on Empirical Methods in Natural Language Processing","year":2019.0,"referenceCount":21,"citationCount":9,"fieldsOfStudy":["Computer Science"],"publicationDate":"2019-09-04","authors":[{"authorId":"2112128933","name":"Vishwajeet Kumar"},{"authorId":"2066282161","name":"Sivaanandh Muneeswaran"},{"authorId":"145799547","name":"Ganesh Ramakrishnan"},{"authorId":"4495301","name":"Yuan-Fang Li"}]},{"paperId":"02d0e6e6c4b1e0987cd4ff94c9023a08b26b5a75","title":"A personalized recommender agent for the world wide web--a semantic perspective","abstract":null,"venue":"","year":2010.0,"referenceCount":0,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":"2010-12-01","authors":[{"authorId":"2113641866","name":"Pei-Chia Chang"}]},{"paperId":"02d174122ae41428e60a55ba9b72d85ac7ceef32","title":"R ATIONALITY AND S OCIAL R EPRESENTATIONS : SOME N OTES ON THE R ELATIONSHIP BETWEEN R ATIONAL C HOICE T HEORY AND S OCIAL R EPRESENTATIONS T HEORY","abstract":"This paper analyses the problem of unidirectional causal explanations in conceptions of rationality. First, three classical conceptions in social science are presented: the cultural-ideological conception, the formal logical conception and the theory of games. Second, the problem of the consistency between beliefs and decisions is discussed with regard to expectancy-value models. We consider that social psychology's approaches to rational choice are framed within methodological individualism. The model of social representations offers the possibility to analyze in depth the relations between the macro and micro processes playing a role in rational choice. It helps us to embed rational choice in a more social context. The analysis of the relationship between belief systems and behaviour in social sciences in general and in social psychology specifically has been as productive and heuristic as it has been confusing and problematic. It is productive and heuristic because a substantial number of concepts, theories and processes developed in social psychology are based on the relationship between beliefs and behaviour. According to this approach, which is anchored in common sense and founded on Indo-European thought (McGuire 1986) there is a relationship between what people (say they) think and what they (say they) do. This 'rationality' that human behaviour supposedly has is also confusing and problematic and from the beginning of modern social science it has been severely criticized at the metatheoretical, methodological and theoretical levels. What is understood by 'rational' when discussing belief systems and their relationship to behaviour(al decisions) can still be considered as 'a problem to be solved'. Lukes (1970), for example, emphasizes that 'the use of the term rational and its cognates has caused great confusion and obscurity', as it conveys different meanings and semantic uses (for example: rational decision making, rational behaviour, etc.). In fact, this term has become one of the most complex terms of social sciences (Seliktar 1986). This paper focuses on identifying the problems inherent in unidirectional causal explanatory models when applied to rationality and to models of consistency between beliefs and behaviours. Later, some heuristic perspectives that Social Representation Theory can offer regarding these issues will be discussed. 2 J. F. Valencia & F. Elejabarrieta Three conceptions of rationality In this section we present three conceptions of rationality. The first is cultural-ideological (Boudon 1986), the second formal logical (Langer 1967) and the third one is based on Von Neumann & Morgenstern's theory of games (1944). According to Boudon (1986) there are two basic conceptions of rationality. One is culture-based and the other utilitarian. The first, which is wider, stems from Weber and has a strong culturalistic connotation. It integrates the Weberian concepts of axiological rationality, i.e. behaviour that is suitable for certain values, and of teleological rationality, i.e. behaviour suitable for the achievement of goals by efficient means. So, a rational decision or behaviour would be one which is based on 'good reasons' (attitudes, beliefs) in a specific situation and culture. A second and more restrictive conception is that of utilitarian rationality. In this case, the rational actor is somebody who, using the most appropriate means, tries to achieve the goals that are in agreement with his or her interests. This is a specific form of the aforementioned culturalistic rationality. In fact, this 'utilitarian rationality' would be a specific case of the social conventions that are culturally situated. According to Harr\u00e9 (1986, 13) 'Human rationality is not an individual phenomenon and it has to be understood in terms of social conventions'. Social psychology, for example, emphasizes this last type of restrictive utilitarian rationality when referring to rational decision making. The definition which stems from formal logic is founded on some 'basic propositions' (Langer 1967). In this way the requirements of formal logic would define the parameters of rational decision. The first parameter is that of consistency in preferences for outcomes: if Outcome O1 is preferred to O2, outcome O2 cannot simultaneously be preferred to O1. The second parameter is the instrumentality of actions relative to results: if O1 is preferred to O2, decision D1 should be preferred to decision D2, given that D1 leads to O1 and D2 leads to O2. The third parameter is that of transitivity: if O1 is preferred to O2 and O2 to O3, then O1 should be preferred to O3. Experimental and cross-cultural findings, however, provide evidence against these propositions because of their restrictive nature. The idea of restriction is important here. If it is not properly considered, a certain behaviour could be labeled as irrational if one does not take into account other elements. For instance, Rapoport (1969) refers to the continual violation of the consistency parameter by those Catholics who prefer having meat to fish but choose to have fish on Fridays. The third definition of rationality comes from Von Neumann & Morgenstern's work on the theory of games. According to this theory the paradigm of rational behaviour of an individual is based on the Minimax principle. This principle claims that the rational decision maker tries to maximize his utilities at minimum cost. The problem with this approach is the existence of individual and cross-cultural differences and the fact that it was developed within laboratory contexts. Billig (1976), for example, observed deviations from expected rational behaviour when working with the Prisoner's Dilemma and the ACME-BOLT trucks. Nowadays rationality is usually seen as a process by which people select their means to achieve their goals. This 'means-goals' rationality is based on a phenomenological postulate which assumes that the subjects' individual and social perceptions define the context of the decision. According to this view, decision makers are 'intuitive scientists' who use causal explanations and formal logic (Gross-Stein et al 1980). Rationality and Social Representations 3 Expectancy-value models and the issue of consistency between beliefs and decisions Decision Making and Expected Value The theory of 'rational' decision making considers the analysis of the choices made by 'rational' subjects as the main phenomenon to be investigated. Here, the term 'rationality' does not necessarily have ethical or conscious connotations as, for example, in the relationship between decisions and expected consequences. To a great extent this is an utilitarian concept based on the comparison between costs and expected benefits. The most developed models within this approach are the utility and expectancy value models. Although there have been different proposals, recent developments tend to focus on reformulating the value and expectation parameters rather than building alternative paradigms. These developments are basically rooted in three principles (Abelson & Levy 1985): a) The principle of Expected Value. This principle prescribes the maximization of expected value and it is the corner-stone of the utilitarian theories of rationality as well as the origin of the algebraic-axiomatic models of utility and expectancy. . b) The principle of expected utility. Bernoulli, a mathematician in the eighteenth century, already recognized the difficulty to predictive human choices by the expected value principle (see Sommer 1954). He proposed the alternative principle of expected utility. Bernoulli came to the conclusion that the psychological value of money did not increase proportionally to the increase of its nominal amount. He suggested a logarithmic function to relate the utility U of money to its amount X. This function pictures a concave rather than a linear or a decreasing value of marginal utility. Thus, he found that adding more and more money results in a decreasing added utility. That is to say, the subject's decision is better predicted by expected utility than by the nominal expected value. The term utility differs from value because the same amount can be evaluated differently by different people in different situations. However, according to the principle of expected utility, it is difficult to see why gambling is so popular. Gambling, when there are small chances to win a great amount of money (lottery, the pools etc.), should not appeal to people because of the concavity of the function. It implies a lower utility for the chance to win a great amount of money than for a higher chance to win less money. Another example is that of smokers. If smokers accepted the evidence that smoking produces lung cancer, giving up smoking would be the 'rational' behaviour to follow. However, some smokers tend to minimize their subjective estimation of risk or in other cases they do not feel confident enough about their capacity for giving up smoking. If the decision to make is to give up smoking or not, the decision to continue can be subjectively rational for those smokers who are convinced that if they gave up smoking they would soon start again. c) The principle of Subjective Expected Utility : Savage (1954) suggests a model which has the same structure as Von Neumann & Morgenstern's but which solves some of the empirical difficulties inherent in the theory of expected utility. These difficulties are: i) The model of expected utility cannot be applied to situations in which the decision maker does not know 'a priori' how likely the results are to happen. ii) The model of expected utility does not consider the possibility of the decision maker using a probability that is different from the objective probability of the results. In order to solve these problems Savage presents the concept of 'subjective probability' 4 J. F. Valencia & F. Elejabarrieta instead of 'objective probability' as used befo","venue":"","year":1999.0,"referenceCount":42,"citationCount":0,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"46988282","name":"J. Valencia"},{"authorId":"113567392","name":"F. Elejabarrieta"}]},{"paperId":"02d206d973afa8f0878dadbed9c83df3fedd3dac","title":"Information Technology Management 2B","abstract":"Code Title Credits Required 15 BUS ADM 744 Information Technology Strategy and Management BUS ADM 747 Service-Oriented Analysis and Design BUS ADM 748 Managing Information Technology Projects (capstone course) BUS ADM 749 Data and Information Management BUS ADM 810 Development of Web-Based Solutions Electives 15 Select at least five of the following: BUS ADM 741 Web Mining and Analytics BUS ADM 743 Information Privacy, Security & Continuity BUS ADM 746 Topics in Information Technology Management: (subtitled) BUS ADM 811 Process and Work-Flow Management BUS ADM 812 Emerging Information Technologies for Business BUS ADM 814 Enterprise Knowledge & Semantic Management BUS ADM 816 Business Intelligence Technologies & Solutions BUS ADM 817 Infrastructure for Information Systems BUS ADM 818 Information Systems Practicum BUS ADM 819 Information Technology Management Internship BUSMGMT 732 Enterprise Resource Planning BUSMGMT 733 Enterprise Simulation Game","venue":"","year":2015.0,"referenceCount":0,"citationCount":0,"fieldsOfStudy":["Engineering"],"publicationDate":"2015-11-01","authors":[{"authorId":"83074028","name":"N. Joseph"},{"authorId":"2957930","name":"I. Strydom"}]},{"paperId":"02d20dd6d4546de5089ca2ef0648d8cc448a2ccf","title":"Discovery Strategy and Method for Remanufacturing Service Demand Using Situational Semantic Network","abstract":"Due to customer individual difference, limitation of cognitive process and insufficient real-time response of cloud-based remanufacturing service platform, the problems such as disordered demand expression, difficulty in extracting implicit customer demand, and insufficient real-time performance of demand acquisition may be encountered. To this end, this paper presents an edge computing-based dynamic demand discovery and acquisition strategy. On the basis of existing methods and experimental results of implicit demand acquisition, a potential demand discovery method based on situational semantic network is proposed in this study. Firstly, the semantic similarity of ontology concept is used to calculate the correlation strength of registered keywords, and then registration keyword semantic network is constructed accordingly within the edge computing server. Afterwards, the keywords matrix of all web pages within single search behavior is obtained by data aggregation, the core attribute keywords of single search behavior are procured by the Kmeans algorithm and the retrieval keyword semantic network is constructed. After aggregating the two types of keywords semantic networks, the core semantics of aggregated semantic network are extracted by the pangrank method and customer situation semantic network reflecting current potential requirements is formed. Finally, an application example was demonstrated to verify the correctness and practicability of the remanufacturing service demand discovery strategy. This method has the potential to be applied in the intelligent management demand acquisition system of enterprises and urban communities, which provides reference for realization of intelligence technology in digital cities.","venue":"IEEE Access","year":2019.0,"referenceCount":0,"citationCount":11,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"145131942","name":"Lei Wang"},{"authorId":"2118883248","name":"Wenbin Zhou"},{"authorId":"50316061","name":"Zelin Zhang"},{"authorId":"2027280","name":"Xuhui Xia"},{"authorId":"2048836542","name":"Jianhua Cao"}]},{"paperId":"02d28fc3f0f14f864170ba15c120d5180d724c7c","title":"Intrusion Recovery Using Selective Re-execution","abstract":"RETRO repairs a desktop or server after an adversary compromises it, by undoing the adversary's changes while preserving legitimate user actions, with minimal user involvement. During normal operation, RETRO records an action history graph, which is a detailed dependency graph describing the system's execution. RETRO uses refinement to describe graph objects and actions at multiple levels of abstraction, which allows for precise dependencies. During repair, RETRO uses the action history graph to undo an unwanted action and its indirect effects by first rolling back its direct effects, and then reexecuting legitimate actions that were influenced by that change. To minimize user involvement and re-execution, RETRO uses predicates to selectively re-execute only actions that were semantically affected by the adversary's changes, and uses compensating actions to handle external effects. \n \nAn evaluation of a prototype of RETRO for Linux with 2 real-world attacks, 2 synthesized challenge attacks, and 6 attacks from previous work, shows that RETRO can often repair the system without user involvement, and avoids false positives and negatives from previous solutions. These benefits come at the cost of 35-127% in execution time overhead and of 4-150 GB of log space per day, depending on the workload. For example, a HotCRP paper submission web site incurs 35% slowdown and generates 4 GB of logs per day under the workload from 30 minutes prior to the SOSP 2007 deadline.","venue":"USENIX Symposium on Operating Systems Design and Implementation","year":2010.0,"referenceCount":43,"citationCount":127,"fieldsOfStudy":["Computer Science"],"publicationDate":"2010-10-04","authors":[{"authorId":"3254849","name":"Taesoo Kim"},{"authorId":"2108249416","name":"Xi Wang"},{"authorId":"1789973","name":"Nickolai Zeldovich"},{"authorId":"1681493","name":"M. Kaashoek"}]},{"paperId":"02d3a168e5d199b45ae4da94b8515a0a18ebabd0","title":"Ontologies in Risk Management","abstract":"The problem of syntactic heterogeneity among geographic\ndatasets emerged as a result of native data formats and the\ndevelopment of monolithic and proprietary systems. Although\nSDIs provide the basis for syntactic interoperability the\nusability of information that is created in one context has\noften limited use in other contexts. One important reason for\nthis is semantic heterogeneity. This problem could be solved\nusing ontologies and their implementation in the context of\ncartographic visualization. The first step is to identify and\nanalyze existing problems caused by semantic heterogeneity in\nseveral risk management use cases. Based on results of this\nanalysis, the project focuses on developing methods for\novercoming these problems during service discovery, composition\nand execution. The viability of the developed approaches will\nbe illustrated by prototypically implemented web services for\nintelligent search and semantic translation and by applying\nthem to the use cases. This paper describes the basis of the\ncontext cartographic visualization and also ontologies with\nfocus on geographic ontologies. There is a need for explicit\nspecification of ontology that supports understanding, sharing\nand exchange between different users and databases. The basic\nrequirement is the possibility of ontology formulation in other\nlanguages. A key aim in geographic ontology is the development\nof a search engine that displays some intelligence in the\ninterpretation of geographical terminology. The assumption is\nthat people may wish to find information about something that\nrelates to somewhere. It is also proposed that ontology should\nbe used to assist in a process of metadata extraction whereby\nthe geographical context of resources is determined for the\npurpose of search engine indexing as well as providing the\npotential to annotate a resource to improve its future\ngeographical visibility. One aspect of generalization concerns\nthe semantic level of detail. In general it can be assumed that\npeople are interested in information at different levels of\nsemantic detail. In order to be really useful and beneficial,\nthe ontology should therefore be able to encode geographic data\nat multiple levels of semantic generalization. This research\nhas been supported by funding from Project No. MSM0021622418\ncalled Dynamic geovisualization in risk management.","venue":"","year":2007.0,"referenceCount":0,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"32039060","name":"M. Kone\u010dn\u00fd"},{"authorId":"34651030","name":"T. \u0158ezn\u00edk"}]},{"paperId":"02d48a5b55b3268bcda73cdcfe697151c6eae835","title":"UvA-DARE (Digital Academic Repository) SWI-Prolog and the web","abstract":"Prolog is an excellent tool for representing and manipulating data written in formal languages as well as natural language. Its safe semantics and automatic memory management make it a prime candidate for programming robust Web services. Where Prolog is commonly seen as a component in a Web application that is either embedded or communicates using a proprietary protocol, we propose an architecture where Prolog communicates to other components in a Web application using the standard HTTP protocol. By avoiding embedding in external Web servers development and deployment become much easier. To support this architecture, in addition to the transfer protocol, we must also support parsing, representing and generating the key Web document types such as HTML, XML and RDF. This paper motivates the design decisions in the libraries and extensions to Prolog for handling Web documents and protocols. The design has been guided by the requirement to handle large documents e\ufb03ciently. The described libraries support a wide range of Web applications ranging from HTML and XML documents to Semantic Web RDF processing. The bene\ufb01ts of using Prolog for Web related tasks is illustrated using three case studies.","venue":"","year":2008.0,"referenceCount":25,"citationCount":0,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"1741900","name":"J. Wielemaker"},{"authorId":"2272605847","name":"Lourens Van Der Meij ZHISHENG HUANG"}]},{"paperId":"02d4e7d002074bd303c121dac9da88f3b1866506","title":"Automatic Facet Extraction Based on Multidimensional Semantic Index","abstract":"Faceted search on web pages needs exact facets. However, it is difficult to extract facets exactly from web pages because the web pages are unstructured and lack of facet information. Therefore, facet extraction is a key to faceted search. This paper proposed a method of extracting facets automatically from unstructured web pages to improve the faceted search on web. The Multidimensional Semantic Index (MDSI) of web pages is constructed by mining all kinds of semantic relations among the words from web pages, which creates a semantic-rich index for web pages. In MDSI, the differently dimensional semantic indexes are bridged by mining the semantic mapping between them. Based on the MDSI of web pages, the facets are extracted by analyzing semantic mapping relations in MDSI. To validate the effect of the proposed method, two datasets are constructed and the experimental results show that the proposed method is feasible and comparatively precise.","venue":"2012 Eighth International Conference on Semantics, Knowledge and Grids","year":2012.0,"referenceCount":23,"citationCount":2,"fieldsOfStudy":["Computer Science"],"publicationDate":"2012-10-22","authors":[{"authorId":"143781776","name":"Xiao Wei"},{"authorId":"2167614","name":"Xiangfeng Luo"},{"authorId":"2117897440","name":"Qing Li"}]},{"paperId":"02d59c7deb5a01cd824df2da786335768308c42b","title":"QUEXME: A Query Expansion Method Applied to Water Information System","abstract":"The aim of the paper is to present and apply a QUery EXpansion MEthod called QUEXME while querying the Euro-Mediterranean Information System (EMWIS) on know-how in the Water sector. EMWIS provides a strategic tool for exchanging information and knowledge in the water sector between and within the Euro Mediterranean partnership countries (www.emwis.net). Information retrieval on the web or through some cooperation of information sources or some general knowledge bases is a complex process and a great challenge with the emergence of the semantic web. The aim of the query expansion method is to help and guide users to build their requests giving them some usually related terms close to their queries. Information retrieval in EMWIS is based on the use of a thesaurus to query the information system and to find relevant documents on some specific topics in the water sector. This thesaurus can be viewed as a light-weight web ontology. It is multilingual. This paper proposes an experimentation of our query expansion method within the framework of the EMWIS information system.","venue":"2009 Fifth International Conference on Signal Image Technology and Internet Based Systems","year":2009.0,"referenceCount":12,"citationCount":3,"fieldsOfStudy":["Computer Science"],"publicationDate":"2009-11-29","authors":[{"authorId":"3065133","name":"Guillermo Valente G\u00f3mez Carpio"},{"authorId":"1702628","name":"L. Abrouk"},{"authorId":"1706642","name":"N. Cullot"}]},{"paperId":"02d6a6252b6e08f1b3af59c15721f4402526d5ba","title":"Experiences and pictures : using visual imagery and background knowledge to improve reading comprehension","abstract":"Background knowledge and visual imagery can be combined to improve comprehension through discussions, semantic webbing, retelling and summarizing. Both parts of the brain store experiences. Language ignites the left side of the brain which is sequential, while senses and feelings are stored on the right side which is abstract and wholistic. Both sides need to be activated when reading to develop comprehension to the fullest. By picturing a story in your mind, you activate schema that activates feelings, and sensory impressions of experiences you have had. Knowing how to activate, monitor and question or change schema is what makes a good reader. This case study is with a fourth grade boy who is reading independently at a mid-grade two level. The study consisted of 26, one-hour sessions conducted twice a week after school. Strategies using background knowledge and visual imagery were taught to improve his reading level to a fifth grade level as measured by Alberta Diagnostic Reading, 1986. Discussion brought forth the student's background know ledge. A semantic web of the plot, characters, and setting was drawn before reading of the text. Throughout the story, the student was asked to keep a movie of the story going in his head. Oral retelling, predicting and inferencing took place throughout the story with a full retelling of the story at the end. Character comparisons were made between the books and experiences the student had. A fully developed movie of the story was created by using experiences the student had and combining the sensory","venue":"","year":2001.0,"referenceCount":61,"citationCount":3,"fieldsOfStudy":["Psychology"],"publicationDate":null,"authors":[{"authorId":"2056011170","name":"S. Mcdonald"}]},{"paperId":"02d82378cdbb1af6c6fb95cba771c0620f4aa7c1","title":"Deep Saliency Hashing","abstract":"In recent years, hashing methods have been proved efficient for large-scale Web media search. However, existing general hashing methods have limited discriminative power for describing fine-grained objects that share similar overall appearance but have subtle difference. To solve this problem, we for the first time introduce attention mechanism to the learning of hashing codes. Specifically, we propose a novel deep hashing model, named deep saliency hashing (DSaH), which automatically mines salient regions and learns semantic-preserving hashing codes simultaneously. DSaH is a two-step end-to-end model consisting of an attention network and a hashing network. Our loss function contains three basic components, including the semantic loss, the saliency loss, and the quantization loss. The saliency loss guides the attention network to mine discriminative regions from pairs of images. We conduct extensive experiments on both fine-grained and general retrieval datasets for performance evaluation. Experimental results on Oxford Flowers-17 and Stanford Dogs-120 demonstrate that our DSaH performs the best for fine-grained retrieval task and beats the existing best retrieval performance (DPSH) by approximately 12%. DSaH also outperforms several state-of-the-art hashing methods on general datasets, including CIFAR-10 and NUS-WIDE.","venue":"arXiv.org","year":2018.0,"referenceCount":36,"citationCount":13,"fieldsOfStudy":["Computer Science"],"publicationDate":"2018-07-04","authors":[{"authorId":"2108913411","name":"Sheng Jin"}]},{"paperId":"02d970cb0da853cd8790b6b274d6ca2cc71556d8","title":"How to Learn in a Noisy World? Self-Correcting the Real-World Data Noise on Machine Translation","abstract":"The massive amounts of web-mined parallel data contain large amounts of noise. Semantic misalignment, as the primary source of the noise, poses a challenge for training machine translation systems. In this paper, we first study the impact of real-world hard-to-detect misalignment noise by proposing a process to simulate the realistic misalignment controlled by semantic similarity. After quantitatively analyzing the impact of simulated misalignment on machine translation, we show the limited effectiveness of widely used pre-filters to improve the translation performance, underscoring the necessity of more fine-grained ways to handle data noise. By observing the increasing reliability of the model's self-knowledge for distinguishing misaligned and clean data at the token-level, we propose a self-correction approach which leverages the model's prediction distribution to revise the training supervision from the ground-truth data over training time. Through comprehensive experiments, we show that our self-correction method not only improves translation performance in the presence of simulated misalignment noise but also proves effective for real-world noisy web-mined datasets across eight translation tasks.","venue":"arXiv.org","year":2024.0,"referenceCount":32,"citationCount":1,"fieldsOfStudy":["Computer Science"],"publicationDate":"2024-07-02","authors":[{"authorId":"2218732291","name":"Yan Meng"},{"authorId":"2269697385","name":"Di Wu"},{"authorId":"2062908179","name":"C. Monz"}]},{"paperId":"02d9b8d78504675e816d09411c3613a53abfc540","title":"Supporting Business Workflows in Smart Grids: An Intelligent Nodes-Based Approach","abstract":"This paper presents an application of business intelligence (BI) for electricity management systems in the context of the Smart Grid domain. Combining semantic Web technologies (SWT) and elements of grid computing (GC), we have designed a distributed architecture of intelligent nodes, which are called power grid distributed nodes (PGDINs). This distributed architecture supports the majority of the grid management activities in an intelligent and collaborative way by means of distributed processing of semantic data. A node collaborative scheme is defined based on logical states that each node presents according to the events occurring in the grid. A specific BPEL business-workflow is formally defined for each logical state, based on the node's knowledge base (an electrical model) and the distributed data. The introduced core workflows allow the potential grid behavior to be predefined when a business requirement is triggered. Thus, this approach supports the grid to react and reach over again a stable state, which is defined as a working state that facilitates the provision of the required business tasks. We have validated our approach with the simulation of a well-known use case, the energy balancing verification, fed with real data from the Spanish electrical grid.","venue":"IEEE Transactions on Industrial Informatics","year":2013.0,"referenceCount":51,"citationCount":13,"fieldsOfStudy":["Computer Science"],"publicationDate":"2013-04-04","authors":[{"authorId":"145841105","name":"Angelina Espinoza"},{"authorId":"2487089","name":"Yoseba K. Penya"},{"authorId":"35024461","name":"J. Nieves"},{"authorId":"40596725","name":"Mariano Ortega"},{"authorId":"2784355","name":"Aitor Pe\u00f1a"},{"authorId":"2249725061","name":"Daniel Rodriguez"}]},{"paperId":"02d9c310dbdb59f46e33adaaf28805603b98751e","title":"A Framework for Ontologies-based User Interface Integration","abstract":"Application integration can be carried out on three different levels: the data source level, the business logic level, and the user interface level. With ontologies-based integration on the data source level dating back to the 1990s and semantic web services for integrating on the business logic level coming of age, it is time for the next logical step: employing ontologies for integration on the user interface level. Such an approach will improve both the development times and the usability of integrated applications. In this poster, we present an approach employing ontologies for integrating applications on the user interface level.","venue":"","year":2009.0,"referenceCount":7,"citationCount":2,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"1802726","name":"Heiko Paulheim"},{"authorId":"1846350","name":"F. Probst"}]},{"paperId":"02d9fb6a4a7b58b3ab3d06c35676cfb15f03e5f9","title":"Interactive search over Web scale RDF data using predicates as constraints","abstract":null,"venue":"Journal of Intelligence and Information Systems","year":2014.0,"referenceCount":0,"citationCount":0,"fieldsOfStudy":null,"publicationDate":"2014-10-17","authors":[{"authorId":"35350945","name":"Mingyan Teng"},{"authorId":"2114036586","name":"Guangtian Zhu"}]},{"paperId":"02dbaaf3efe2c73032b9db02d051f7a021ea6493","title":"Association Rule Mining of Kansei Knowledge Using Rough Set","abstract":null,"venue":"","year":2007.0,"referenceCount":11,"citationCount":4,"fieldsOfStudy":["Mathematics"],"publicationDate":null,"authors":[{"authorId":"153356992","name":"Fuqian Shi"},{"authorId":"2286539438","name":"Shouqian Sun"},{"authorId":"2144282355","name":"Xu Jiang"}]},{"paperId":"02dc1d5c8ea3025e480a3a71c47e7710a084a2ef","title":"RDF-based Peer-to-Peer-Networks for Distributed (Learning) Repositories","abstract":"Metadata for the World Wide Web are important, but metadata for Peer-to-Peer (P2P) networks are absolutely crucial. In this paper we discuss the open source project Edutella, which combines semantic web and peer-to-peer technologies in order to make distributed learning repositories possible and useful. We describe the main services of the Edutella network infrastructure and its architecture based on the exchange of RDF metadata, and specify the query service (based on the Edutella Common Data Model and Query Exchange Language RDFQEL) as one of the core services of Edutella. As a schema-based peer-to-peer network, Edutella extends conventional peer-to-peer networks by allowing different and extensible schemas to describe peer content, a necessary feature for information rich peer-to-peer networks. We describe and discuss the HyperCuP topology, which implements an optimal broadcast topology, and show how it can be used to form the backbone of a super-peer-based topology suitable for schema-based peer-to-peer networks, including appropriate routing indices for super-peer\/superpeer connections as well as for super-peer\/peer connections. We also discuss an extension of this architecture providing additional capabilities for inferences and model transformation based on the TRIPLE language. Finally, we discuss the use of the Edutella infrastructure in the EU\/IST ELENA project which aims to create smart spaces for learning.","venue":"","year":2002.0,"referenceCount":35,"citationCount":8,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"1744808","name":"W. Nejdl"},{"authorId":"1933611","name":"M. Schlosser"},{"authorId":"1685548","name":"W. Siberski"},{"authorId":"3244825","name":"M. Wolpers"},{"authorId":"49012649","name":"Bernd Simon"},{"authorId":"1685642","name":"S. Decker"},{"authorId":"1681568","name":"Michael Sintek"}]},{"paperId":"02dd854bdec49790b84a82fb8d1e05d4db868885","title":"A Survey on Different Techniques of Text Categorization","abstract":"\u2014 In the Constitution of India, a provision is made for each of the Indian states to choose their own official language for communicating at the state level for official purpose. The availability of constantly increasing amount of textual data of various Indian regional languages in electronic form has accelerated. So the Classification of text documents based on languages is essential. The objective of the work is the representation and categorization of Indian language text documents using text mining techniques. Several text mining techniques such as naive Bayes classifier, k-Nearest-Neighbor classifier and decision tree for text categorization have been used. This paper describes various techniques used for semantic text classification. Text classification (Also called Text Categorization) is one of the important research issues in the field of text mining. Due to the rapid increase in addition of text documents on the web or internet, the text classification became a serious issue to retrieve the desired text from the huge amount of data placed in unstructured form on the internet. Categorization is a process of objects and ideas are differentiated, recognized and understood. For some specific purpose, the categorization implies the objects are grouped into categories. The text classification acts as a key function to organize and deal with million of documents. This paper covers different classification techniques along with their advantages and limitations.","venue":"","year":null,"referenceCount":24,"citationCount":0,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"2286842990","name":"M. BhavnaRani"},{"authorId":"2286572812","name":"Tech"},{"authorId":"2260908798","name":"Student"}]},{"paperId":"02dd913b44d4be39d7b7b6ff36b1c6b94d03c14d","title":"A Suite of Daml+Oil Ontologies to Describe Bioinformatics Web Services and Data","abstract":"The growing quantity and distribution of bioinformatics resources means that finding and utilizing them requires a great deal of expert knowledge, especially as many resources need to be tied together into a workflow to accomplish a useful goal. We want to formally capture at least some of this knowledge within a virtual workbench and middleware framework to assist a wider range of biologists in utilizing these resources. Different activities require different representations of knowledge. Finding or substituting a service within a workflow is often best supported by a classification. Marshalling and configuring services is best accomplished using a formal description. Both representations are highly interdependent and maintaining consistency between the two by hand is difficult. We report on a description logic approach using the web ontology language DAML+OIL that uses property based service descriptions. The ontology is founded on DAML-S to dynamically create service classifications. These classifications are then used to support semantic service matching and discovery in a large grid based middleware project . We describe the extensions necessary to DAML-S in order to support bioinformatics service description; the utility of DAML+OIL in creating dynamic classifications based on formal descriptions; and the implementation of a DAML+OIL ontology service to support partial user-driven service matching and composition.","venue":"International Journal of Cooperative Information Systems","year":2003.0,"referenceCount":49,"citationCount":203,"fieldsOfStudy":["Computer Science"],"publicationDate":"2003-06-01","authors":[{"authorId":"2481778","name":"C. Wroe"},{"authorId":"144560289","name":"R. Stevens"},{"authorId":"46555127","name":"C. Goble"},{"authorId":"49185510","name":"A. Roberts"},{"authorId":"2169393478","name":"Robert Mark Greenwood"}]},{"paperId":"02ddfe2a85f3812fdd415d479f51a30280d0d314","title":"Bio2RDF: Convert, Provide And Reuse.","abstract":null,"venue":"","year":2010.0,"referenceCount":0,"citationCount":2,"fieldsOfStudy":["Computer Science"],"publicationDate":"2010-10-20","authors":[{"authorId":"9171464","name":"Marc-Alexandre Nolin"},{"authorId":"145970628","name":"J. Corbeil"},{"authorId":"145385361","name":"Luc Lamontagne"},{"authorId":"1736389","name":"M. Dumontier"}]},{"paperId":"02ddfe4c6da5890fcba72e2273ccdab156e5c654","title":"TIPS: Text-Image Pretraining with Spatial Awareness","abstract":"While image-text representation learning has become very popular in recent years, existing models tend to lack spatial awareness and have limited direct applicability for dense understanding tasks. For this reason, self-supervised image-only pretraining is still the go-to method for many dense vision applications (e.g. depth estimation, semantic segmentation), despite the lack of explicit supervisory signals. In this paper, we close this gap between image-text and self-supervised learning, by proposing a novel general-purpose image-text model, which can be effectively used off-the-shelf for dense and global vision tasks. Our method, which we refer to as Text-Image Pretraining with Spatial awareness (TIPS), leverages two simple and effective insights. First, on textual supervision: we reveal that replacing noisy web image captions by synthetically generated textual descriptions boosts dense understanding performance significantly, due to a much richer signal for learning spatially aware representations. We propose an adapted training method that combines noisy and synthetic captions, resulting in improvements across both dense and global understanding tasks. Second, on the learning technique: we propose to combine contrastive image-text learning with self-supervised masked image modeling, to encourage spatial coherence, unlocking substantial enhancements for downstream applications. Building on these two ideas, we scale our model using the transformer architecture, trained on a curated set of public images. Our experiments are conducted on 8 tasks involving 16 datasets in total, demonstrating strong off-the-shelf performance on both dense and global understanding, for several image-only and image-text tasks.","venue":"arXiv.org","year":2024.0,"referenceCount":81,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":"2024-10-21","authors":[{"authorId":"2027105","name":"Kevis-Kokitsi Maninis"},{"authorId":"2238016251","name":"Kaifeng Chen"},{"authorId":"2319006822","name":"Soham Ghosh"},{"authorId":"30899347","name":"Arjun Karpur"},{"authorId":"2327166758","name":"Koert Chen"},{"authorId":"2327118351","name":"Ye Xia"},{"authorId":"2072987566","name":"Bingyi Cao"},{"authorId":"3821662","name":"Daniel M. Salz"},{"authorId":"2327047819","name":"Guangxing Han"},{"authorId":"2327051671","name":"Jan Dlabal"},{"authorId":"2318986818","name":"Danushen Gnanapragasam"},{"authorId":"2237806111","name":"Mojtaba Seyedhosseini"},{"authorId":"2319291317","name":"Howard Zhou"},{"authorId":"2302855463","name":"Andre Araujo"}]},{"paperId":"02df3588d14ec4af57266a10bcaea10ba0015893","title":"Enhancing WIKISTIM.org Using Machine Learning Approaches","abstract":"To the Editor: The number of published scientific papers has climbed by 8\u20139% each year over the past several decades. In the biomedical field alone, more than 1 million papers deluge the PubMed data base each year (1). In addition to this, there are at present 49,194 recruiting clinical trials registered on ClinicalTrials.gov and there are 283 currently recruiting studies matching the terms spinal cord stimulation or deep brain stimulation alone in this registry. There exists a clear and pressing need for methods that allow neuromodulation specialists and researchers to access and use research evidence in their clinical routines and in dayto-day decision making. As such, we read with interest, the recent article by North and Shipley concerning their development of WIKISTIM.org, a collaborative website that abstracts data from clinical studies across the breadth of therapeutic neuromodulation into structured data tables, with the apparent aim of enhancing the dissemination, clinical application, and opportunities for critique of research findings from this rapidly developing field (2). Nevertheless, we have concerns regarding the sustainability and utility of this resource for practicing clinicians and researchers. First, concerning sustainability of the database, there seems to be minimal, if any, current or planned implementation of automation technologies for study identification, screening, data abstraction, and data entry validation. At present, relevant studies seem to be identified manually and nonsystematically by section editors (\u201ccurated\u201d), with subsequent data abstraction and validation also undertaken manually. Automation tools, which are being developed at a rapid rate, may provide superior results. Progress in related endeavors within evidence-based medicine has demonstrated that technologies that automate those workflow elements that can be reliably automated are required to maximize the use of scarce and valuable human capital. Efforts to establish and optimize the use of artificial intelligence and machine learning techniques for the development of systematic reviews and other forms of evidence synthesis such as rapid reviews, meta-analyses, and evidence overviews such as scoping reviews and health technology assessments are already well underway (3). As an example, it is clear that screening references from biomedical data bases such as the NCBI\u2019s PubMed or Clarivate Analytics\u2019 Web of Science is a lengthy and effortful process. Moreover, in the context of systematic reviews, screening by two reviewers is recommended to avoid missing relevant references. Adoption by the WIKISTIM developers of a software tool such as RobotAnalyst, one of many options in this space, could be a tremendous catalyst for growth of their database. RobotAnalyst is a Web-based screening system that leverages algorithms for information retrieval, text mining, natural language processing (NLP), and machine learning (ML) to assist reviewers in prioritizing references and exploring biomedical data bases using automatic terminology extraction, topic modeling, and descriptive clustering. In a recent study of the software, RobotAnalyst was associated with an up to 71% decrease in screening effort (4). WIKISTIM could then exploit semantic technologies, including NLP and ML techniques, to extract the appropriate datapoints from relevant identified papers, with a certain degree of human oversight required for this stage. Given the authors\u2019 acknowledgement that the vast majority of WIKISTIM\u2019s datasheets are currently empty or incomplete, adoption of this approach has the potential has considerable potential to accelerate datasheet completion. We, therefore, invite the authors to consider how the development and implementation of automation methods could reduce the time and, therefore, costs of screening and data abstraction for WIKISTIM, while at the same time potentially enhancing the comprehensiveness and currency of the WIKISTIM data base through rapid, real-time, systematic screening of the neuromodulation literature with ML-assisted data extraction. Second, the authors do not outline how the effortfully produced WIKISTIM datasheets might feed into evidence summaries and recommendations that work for clinicians at the point of care, with the ultimate aim of facilitating shared decision making with patients. WIKISTIM\u2019s developers have previously stated that their data base has transformative potential to \u201cextend the useful life of clinical reports and improve patient care,\u201d for example by leading to fruitful critical discussion on their website (5). However, review of the WIKISTIM discussion pages reveals a current total of two threads and seven individual posts. In our view, there exists great and hitherto unrealized potential in integrating WIKISTIM into a technology-supported research pipeline with the ability to synthesize the datapoints from their effortfully produced datasheets, with the aim of producing systematic reviews and other contemporary forms of evidence synthesis or feeding directly into clinician decision support systems, for example within structured electronic medical records. Clinicians could use such syntheses to guide clinical decision making and they could also be used more broadly by policy makers to inform funding and policy decisions.","venue":"Neuromodulation (Malden, Mass.)","year":2019.0,"referenceCount":5,"citationCount":0,"fieldsOfStudy":["Medicine"],"publicationDate":"2019-03-25","authors":[{"authorId":"48709757","name":"A. Lawson McLean"},{"authorId":"46561794","name":"J. Walter"}]},{"paperId":"02e0b693671c78da9be99c9d8131d63cb769d04a","title":"OntoYield: A Semantic Approach for Context-Based Ontology Recommendation Based on Structure Preservation","abstract":null,"venue":"","year":2018.0,"referenceCount":15,"citationCount":28,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"2064875480","name":"G. Giri"},{"authorId":"144292620","name":"G. Deepak"},{"authorId":"145665790","name":"S. Manjula"},{"authorId":"1781331","name":"K. Venugopal"}]},{"paperId":"02e124c8329aa5444f349cb27f95548a25e060a5","title":"DAML Enabled Web Services and Agents in the Semantic Web","abstract":null,"venue":"Web, Web-Services, and Database Systems","year":2002.0,"referenceCount":7,"citationCount":32,"fieldsOfStudy":["Computer Science"],"publicationDate":"2002-10-07","authors":[{"authorId":"1892165","name":"M. Montebello"},{"authorId":"143636346","name":"C. Abela"}]},{"paperId":"02e13d352d1a299ce31e9621346718ec707724bb","title":"Systems chemical biology and the Semantic Web: what they mean for the future of drug discovery research.","abstract":null,"venue":"Drug Discovery Today","year":2012.0,"referenceCount":43,"citationCount":83,"fieldsOfStudy":["Computer Science","Medicine"],"publicationDate":"2012-05-01","authors":[{"authorId":"144688641","name":"D. Wild"},{"authorId":"144481316","name":"Ying Ding"},{"authorId":"144463965","name":"A. Sheth"},{"authorId":"2772446","name":"L. Harland"},{"authorId":"1741204","name":"E. Gifford"},{"authorId":"2166998","name":"M. Lajiness"}]},{"paperId":"02e185e94edecd272577ca7424fcf77a4f005416","title":"Data Extraction and Semantic Assignment for Web Databases","abstract":null,"venue":"The Web Conference","year":2003.0,"referenceCount":0,"citationCount":2,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"2110165806","name":"Jiying Wang"},{"authorId":"2182929","name":"F. Lochovsky"}]},{"paperId":"02e1cc35c61b5d5568344b2e0b8a228eb094c1b4","title":"Accessibility Issues in HTML5:A comparison of HTML5 websites and those coded in earlier versions","abstract":"It is estimated that by 2020 there could be as many as 4 million visually impaired or blind people living in the UK. These visually impaired or blind people will use assistive technologies such as screen readers to access website content on the internet. Currently the governing body of the internet, the World Wide Web Consortium has released and continues to develop a new standard of the HTML markup language which is used to code website content. This new HTML standard, HTML 5 has been heralded as a new semantically correct markup language. HTML 5 should be more accessible to users of assisted technologies and should also facilitate the incorporation into websites of rich internet applications and other media in a more accessible way. However the Royal National Institute for Blind People (RNIB) have suggested that the opposite may be proving to be true and that HTML 5 websites may be more inaccessible than websites coded in earlier versions of HTML. This study employs a mixed methods methodology, including screen reader accessibility testing and web developer interviews. This methodology will establish the accessibility of HTML 5 coded websites and prove or disprove the hypothesis of the RNIB while adding granularity and perspective to the results of the testing","venue":"","year":2014.0,"referenceCount":14,"citationCount":2,"fieldsOfStudy":["Computer Science"],"publicationDate":"2014-11-30","authors":[{"authorId":"98386236","name":"H. Bryan"},{"authorId":"2109787119","name":"Mark W. R. Anderson"}]},{"paperId":"02e24b641030c3680f95472c81e0a3f8f497f129","title":"KNOWLEDGE ORGANIZATION SYSTEMS AND CULTURAL INTEROPERABILITY IN OPEN HUMANITARIAN SETTINGS","abstract":"Objectives: Knowledge organization systems (KOS) have long been used as a means of information exchange and have functioned as standard in knowledge organization and resource discovery. The effective utilization of KOSs in digital environments would facilitate integration of the large corpora of recorded knowledge and digitally born resources on the Web. In the domain of humanitarian needs and action, especially in the emerging field of digital humanitarian, KOSs are enabling humanitarian organizations to improve the collection, communication, and analysis of data, in order to more effectively coordinate the international response to crises (Meier, 2015; Di Maio, 2007; Jian & Segev, 2013). However, prior attempts that focused on building centralised knowledge representation systems or standardised forms for the rapid response have had limited success (Kesler & Hendrix, 2015). What often happens in the case of humanitarian data is that an \u201contology of dynamic data requires several domain ontologies for reference from which to obtain the exact definitions of data in certain application domains\u201d (Fan & Zlatanova, 2011). This paper discusses the challenges of creating a theoretic framework within the context of an intercultural and ethically responsible KOS in emergencies and conflict settings. The first objective is to explore cultural and societal concerns linked to the development of KOSs in the humanitarian domain. Next it is aimed to develop a mode of access and organization of knowledge which respects cultural diversity on a global scale. This kind of approach should be attentive to intersectionality and cultural interoperability. Methods: A great deal efforts in finding solutions to linguistic and cultural barriers in knowledge organization are being put on the development of multilingual\/multicultural systems and local adaptations to feed those systems. Language, however, is only one of the many aspects. This paper applies the concept of cultural interoperability in knowledge organization, which can be briefly defined as \u201cthe degree to which knowledge and information is anchored to a unified model of meaning across cultures\u201d (Vossen et al., 2011). It examines the potential for creating and monitoring ethically and globally accessible, and culturally acceptable KOSs for humanitarian assistance in emergencies and conflict settings. Using a large collection of datasets from the Humanitarian Data Exchange (HDX) platform [https:\/\/data.humdata.org\/dataset], an international open data repository for crisis and humanitarian needs, we examine the knowledge maps of the communities of practice (CoP) in the field. These data are selected because they can represent various actual humanitarian impacts and humanitarian needs from multiple and interdisciplinary perspectives. The notion of CoP, according to Wenger (1998), refers to all the social, information and communication practices put in place by groups or communities. Focusing on the processes of creating and sharing knowledge, Wenger distinguished three dimensions of CoP: the symbolic dimension that generates the feeling of belonging to a group and provokes mutual commitment, the cognitive dimension based on the sharing of available tools and resources by the whole community and the social dimension that is responsible for the common work around a shared vision. These three dimensions relate to the concept of interoperability which, particularly in the field of information sciences, relies on the openness, sharing, adaptation, reconciliation of components, policies and practices. From this perspective, the tools and resources built in a CoP, which could be remobilized in various situations, allow the continuity and sustainability of the work activities for the actors within the domain. Using this approach, we emphasize the importance of opening up the notion of cultural inclusiveness, to weigh not only linguistic diversity, but also other intangibles aspects such as historical elements, racial mix, political system, gender, etc. Main results: We learn about Humanitarian Data objects and concepts by grouping HDX datasets into three categories: (1) macro-level concepts implying global datasets on humanitarian action (interpretations, principles, actors and trends), (2) meso-leve data gathered at the organizational level, and (3) micro-level population-based datasets. The mixed and multi-level methods used to define boundaries, enrich and reconciliate existing data, and assemble new data in HDX platform are discussed. This multi-level perspective permits the use of innovative evaluations methods, and representations of humanitarian needs and recommendations for humanitarian assistance in emergencies and conflict settings. The limit of our research, however, is that we have not integrated all possible open resources that can yield rich insight into emerging digital humanitarian practices. Our research did not include other sources of community and public datasets (such as Data.World or Datahub.io) on which we plan to perform future work. Conclusions: Cultural interoperability is a significant issue for any emerging community of practice. The goal of open humanitarian data initiative is to improve information exchange during extreme situations and the effectiveness of humanitarian response (Di Maio, 2007). Although significant efforts has been made regarding the systemic and semantic heterogeneity of data, culture heterogeneity in this domain remains largely unaddressed. In this work, we take into consideration the cultural diversity in designing KOSs and access modes to humanitarian knowledge. Our underlying objective to identify the landscape of knowledge organization and representation applications developed in the open humanitarian data movement and to consider how the high level of cultural interoperability can improve information exchange, the evaluation of humanitarian needs and the prioritization of humanitarian responses. Keywords: digital humanitarian, culture interoperability, knowledge organization systems References Di Maio, P. (2007). An open ontology for open source emergency response system. Opensource. Mit. Edu , (May), 1\u201312. Fan, Z., & Zlatanova, S. (2011). Exploring ontologies for semantic interoperability of data in emergency response. Applied Geomatics , 3 (2), 109\u2013122. Jihan, S. H., & Segev, A. (2013). Context Ontology for Humanitarian Assistance in Crisis Response. International Conference on Information Systems for Crisis Response and Management (ISCRAM-13) . Kesler, C., & Hendrix, C. (2015). The Humanitarian eXchange Language: Coordinating disaster response with semantic web technologies. Semantic Web , 6 (1), 5\u201321. Meier, P. (2015). Digital Humanitarians: How Big Data Is Changing the Face of Humanitarian Response . Routledge. Vossen, P., et al. (2011). KYOTO: A wiki for establishing semantic interoperability for knowledge sharing across languages and cultures. In Handbook of Research on Culturally-Aware Information Technology: Perspectives and Models (pp. 265\u2013293). Hershey, New York: Information Science Reference. Wenger, E. (1999). Communities of Practice: Learning, Meaning, and Identity . Cambridge University Press.","venue":"","year":2017.0,"referenceCount":26,"citationCount":2,"fieldsOfStudy":["Sociology"],"publicationDate":"2017-12-04","authors":[{"authorId":"144604282","name":"Quoc-Tan Tran"}]},{"paperId":"02e29d98288be32fe8f1db21931d621fbf735251","title":"Automatic Extraction of Semantic Relations by Using Web Statistical Information","abstract":null,"venue":"International Conference on Conceptual Structures","year":2014.0,"referenceCount":26,"citationCount":2,"fieldsOfStudy":["Computer Science"],"publicationDate":"2014-07-27","authors":[{"authorId":"14647273","name":"Valeria Borz\u00ec"},{"authorId":"3710129","name":"S. Faro"},{"authorId":"34471975","name":"Arianna Pavone"}]},{"paperId":"02e32c040ea9dcbd9b4495e6e1ae0a63d0797426","title":"From \"First Person Shooter\" to Multi-User Knowledge Spaces","abstract":"multi-user game engines such as Epic Megagames' UNREAL engine to be extremely useful tools for the design of knowledge spaces. For a collaborative project with 10 Viennese museums 1 we developed a semantic matrix for a cross-disciplinary exhibition showing items from different collections (Sigmund Freud Museum, Jewish Museum, Museum of Natural History...). The content provided by these museums had to be made accessible and comprehensible to users of different ages, educational backgrounds and computer literacy. We developed a system of connotations amongst the objects, which then was translated into a spatial structure of rooms, corridors and places of different sizes, shapes, remotenesses or proximities. The viewer\/listener of our knowledge space explores a semantic structure by navigating virtual spaces with the topics being contained in these rooms. The connecting architecture between these rooms resembles staircases, passages, elevators, hidden doors or portals, each of them referring to the nature of the connotation. Quite contrary to web-based databases and hypertext structures, the links therefore possess a quality of their own, carrying much more information than just \"is connected with\".","venue":"","year":2001.0,"referenceCount":11,"citationCount":9,"fieldsOfStudy":["Engineering"],"publicationDate":null,"authors":[{"authorId":"82457926","name":"Mathias Fuchs"},{"authorId":"71454655","name":"Sylvia Eckermann"}]},{"paperId":"02e57e902bd97b66d7b450cbe452d75475e40f68","title":"ICCSCI 2017 , 13-14 October 2017 , Bali , Indonesia Analysis of Affecting Factors Technology Acceptance Model in The Application Of Knowledge Management for Small Medium Enterprises in Industry Creative","abstract":"This paper explains the factors of affecting the technology acceptance model (TAM) in the application of Knowledge Management to small medium enterprises in creative economy. The objective of this research is to analyze the correlation among the perceived ease of use(PEOU) variable, voluntaries use(VU) variable, perceived entertainment value (PEV) variable, perceived usefulness (PU) variable and factor of Web usage attitude (WU) which is a factor influencing the technology acceptance model of knowledge management in small and medium enterprises. The method of research is explanatory research which aims to analyze the relationship between one variable stage above. The Data collection techniques used in this study is a questionnaire using semantic differential scale and explained the research design, data retrieval, data processing and data analysis. Data analysis used in analyzing factors of technological acceptance model (TAM) in the application of Knowledge Management in small medium enterprises in creative economy is descriptive statistics to consider a frequency distribution the size and spread of data on characteristics of the sample (respondents) and indicator variable endogenous and provide explanation of its mean value, standard deviations, variant, maximum, range, skewness and kurtosis. Statistical analysis inferential using structural equation model (SEM). The result of this paper is the technology acceptance model of knowledge management small medium enterprises influenced by the ease of use (PEOU) which will cause the advantage in using ( PU) because of advantage in using the user will be willing (have willingness) in using (VU), so that have an attitude of the use of Web Knowledge Management (WU)","venue":"","year":2018.0,"referenceCount":0,"citationCount":27,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"52596517","name":"Junita Juwita Siregar"},{"authorId":"51203479","name":"R. Puspokusumo"},{"authorId":"2005519233","name":"Anita Rahayu"}]},{"paperId":"02e8eaea96ed49456bd1b28269db53c6700122fd","title":"StarFL : a new metadata language for sensor descriptions : or : why do we need yet another metadata language for sensor descriptions","abstract":"An ever-increasing number of sensor resources are being exposed via the World Wide Web. Discovery, selection and use of these sensors and their observations require a robust sensor information model, but the homogenous description of sensor metadata is a complex and difficult task. Currently, the only available robust model is SensorML, which is intentionally designed in a very generic way. Due to this genericness, interoperability can hardly be achieved without the definition of application profiles that further constrain the use and expressiveness of the root language. So far, such SensorML profiles have only been developed up to a limited extent. This work describes a new approach for defining sensor metadata, the StarFL model. This language follows a more restrictive approach and incorporates concepts from the recently published Semantic Sensor Network Ontology to overcome the key issues users are experiencing with SensorML. StarFL defines a restricted vocabulary and model for sensor metadata to achieve a high level of interoperability and a straightforward reusability of sensor","venue":"","year":2011.0,"referenceCount":22,"citationCount":6,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"2644373","name":"C. Malewski"},{"authorId":"2393842","name":"I. Simonis"},{"authorId":"2180905","name":"A. Terhorst"},{"authorId":"2705581","name":"A. Broering"}]},{"paperId":"02e927a98b3b2a67d63c44826cf5d494d03b4e00","title":"Languages and Ontologies","abstract":"As the World Wide Web continues to expand, it becomes increasingly difficult for users to obtain information efficiently. Because most search engines read format languages such as HTML or SGML, search results reflect formatting tags more than actual page content, which is expressed in natural language. Spinning the Semantic Web describes an exciting new type of hierarchy and standardization that will replace the current \"web of links\" with a \"web of meaning.\" Using a flexible set of languages and tools, the Semantic Web will make all available information -- display elements, metadata, services, images, and especially content -- accessible. The result will be an immense repository of information accessible for a wide range of new applications.This first handbook for the Semantic Web covers, among other topics, software agents that can negotiate and collect information, markup languages that can tag many more types of information in a document, and knowledge systems that enable machines to read Web pages and determine their reliability. The truly interdisciplinary Semantic Web combines aspects of artificial intelligence, markup languages, natural language processing, information retrieval, knowledge representation, intelligent agents, and databases.","venue":"","year":2005.0,"referenceCount":0,"citationCount":1,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"1766239","name":"D. Fensel"},{"authorId":"1701341","name":"J. Hendler"},{"authorId":"145507148","name":"H. Lieberman"},{"authorId":"1980198","name":"W. Wahlster"},{"authorId":null,"name":"Tim Berners-Lee"}]},{"paperId":"02e9dd3a382458c7b552a731569379c9a8138f6b","title":"The curious identity of Michael Field and its implications for humanities research with the semantic web","abstract":"This paper uses the case of author Michael Field, the shared writing identity of two late Victorian women, to consider the implications of embracing the semantic web for humanities research. It is argued that the ontologies prevalent today reveal a lack of nuance when it comes to the complex relationships that are the focus of much humanities research, such as the connection of names to persons, particularly with respect to authorship. Further, the current state of ontology use aside, even the sophisticated use of OWL, SKOS, or ontology alignment techniques for linking big semantic web collections stands to hinder humanities research by hiding rather than exposing difference. We use the outlier Michael Field to highlight what much of the valuable work of the humanities is about and in doing so bring to the fore the challenge of formalizing complex social meanings that can otherwise be overlooked or dismissed as a trivial technicality. As a solution the humanities community is encouraged to begin engaging more directly in the construction of semantic web tools and infrastructure.","venue":"IEEE BigData","year":2013.0,"referenceCount":23,"citationCount":1,"fieldsOfStudy":["Computer Science"],"publicationDate":"2013-10-01","authors":[{"authorId":"2260183833","name":"Susan Brown"},{"authorId":"50630051","name":"J. Simpson"}]},{"paperId":"02eab2be82c374deb68eb00e1ad3dda03669790c","title":"Ontology-based Representation of Simulation Models","abstract":"Ontologies have been used in a variety of domains for multiple purposes such as establishing common terminology, organizing domain knowledge and describing domain in a machine-readable form. Moreover, ontologies are the foundation of the Semantic Web and often semantic integration is achieved using ontology. Even though simulation demonstrates a number of similar characteristics to Semantic Web or semantic integration, including heterogeneity in the simulation domain, representation and semantics, the application of ontology in the simulation domain is still in its infancy. This paper proposes an ontology-based representation of simulation models. The goal of this research is to facilitate comparison among simulation models, querying, making inferences and reuse of existing simulation models. Specifically, such models represented in the domain simulation engine environment serve as an information source for their representation as instances of an ontology. Therefore, the ontology-based representation is created from existing simulation models in their proprietary file formats, consequently eliminating the need to perform the simulation modeling directly in the ontology. The proposed approach is evaluated on a case study involving the I2Sim interdependency","venue":"International Conference on Software Engineering and Knowledge Engineering","year":2012.0,"referenceCount":16,"citationCount":13,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"2222599","name":"Katarina Grolinger"},{"authorId":"1711826","name":"Miriam A. M. Capretz"},{"authorId":"2086701036","name":"Jos\u00e9 R. Mart\u00ed"},{"authorId":"3019300","name":"K. D. Srivastava"}]},{"paperId":"02ecf6d4a1d2da76f378213f0a2d264e1281c1e7","title":"Enhancing pest management strategy by the computerization of agro-ecosystem interactions","abstract":"Pest management strategy aims to minimize the adverse impact of pests on the crop. Basically its building requires a balance of knowledge about farming practices, crops, pests, soil, and their interactions in regard to the landscape structure. New technologies to develop ecologically based pest management require additional knowledge about functional biodiversity in a given agrosystem. In the case of the conservation biological control, knowledge about the local landscape, i.e. natural vegetation and mosaic of crops, and its management also have to be considered to ensure the survival of natural enemies. Thus, many interactions in population dynamics have to be investigated simultaneously, with the possibility of conflicting interactions. In order to identify potential conflicts and provide sound evidence, interactions affecting sugarcane health were implemented in Cogui software for modeling. Using this software, all these interactions were represented as semantic graph, and their automatic combination reveals pest management strategy for a specific location. The interactions concerned food webs regarding different communities such as Lepidoptera, Coleoptera, Hemiptera, Hymenoptera, entomopathogens etc. and the impact of agricultural practices comprising IPM strategies, soil preparation, cultivar, irrigation, fertilization, harvest etc. on the agro-ecosystem. Using this knowledge-based system can help analyses pest problems and propose IPM solutions through thorough comprehension of the pest-natural enemy interactions in a complex landscape structure. (Texte integral)","venue":"","year":2015.0,"referenceCount":0,"citationCount":0,"fieldsOfStudy":["Engineering"],"publicationDate":null,"authors":[{"authorId":"145190092","name":"Pierre Martin"},{"authorId":"16017262","name":"S. Auzoux"},{"authorId":"32901113","name":"F. Goebel"}]},{"paperId":"02edf60d37bb49725e4e03f0602b0bec114fc91e","title":"Framework for Ontology Alignment and Mapping","abstract":"Semantic alignment between ontologies is a necessary precondition to establish interoperability between agents or services using different individual ontologies. This cannot be done manually beyond a certain complexity and size of ontologies. The core contribution in this article is the Framework for Ontology Alignment and Mapping (FOAM). With FOAM we address requirements from an application-based perspective such as high quality results, efficiency, high degree of automation with optional user-interaction, flexibility with respect to use cases, and easy adjusting and parameterizing. FOAM consists of a general alignment process based on the ontology-encoded semantics, different instantiations of the process focusing on various aspects of ontology alignment, and finally the concrete implementation as a powerful but easy to use Open Source tool. The evaluation results show that the different instantiations individually outperform existing approaches. However, best results can be gained when combining them. We expect that the findings suit not only the Semantic Web community, but may solve integration problems of related computer science fields as well.","venue":"","year":2006.0,"referenceCount":0,"citationCount":12,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"1728476","name":"M. Ehrig"},{"authorId":"1752093","name":"Steffen Staab"}]},{"paperId":"02ee364435285ae1ad2aabd7a5f74d94b07ef153","title":"The curious identity of Michael Field and its implications for humanities research with the semantic web","abstract":"This paper uses the case of author Michael Field, the shared writing identity of two late Victorian women, to consider the implications of embracing the semantic web for humanities research. It is argued that the ontologies prevalent today reveal a lack of nuance when it comes to the complex relationships that are the focus of much humanities research, such as the connection of names to persons, particularly with respect to authorship. Further, the current state of ontology use aside, even the sophisticated use of OWL, SKOS, or ontology alignment techniques for linking big semantic web collections stands to hinder humanities research by hiding rather than exposing difference. We use the outlier Michael Field to highlight what much of the valuable work of the humanities is about and in doing so bring to the fore the challenge of formalizing complex social meanings that can otherwise be overlooked or dismissed as a trivial technicality. As a solution the humanities community is encouraged to begin engaging more directly in the construction of semantic web tools and infrastructure.","venue":"BigData Congress [Services Society]","year":2013.0,"referenceCount":41,"citationCount":14,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"2108812549","name":"Susan Brown"},{"authorId":"50630051","name":"J. Simpson"}]},{"paperId":"02ef40a2a63a2e8b83bc336b08b0503161704dce","title":"Representing USDL for Humans and Tools","abstract":null,"venue":"Handbook of Service Description","year":2012.0,"referenceCount":14,"citationCount":1,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"2824907","name":"K. Duddy"},{"authorId":"48249251","name":"Matthias Heinrich"},{"authorId":"1724443","name":"Steffen Heinzl"},{"authorId":"2913801","name":"M. Knechtel"},{"authorId":"1791113","name":"C. Pedrinaci"},{"authorId":"2288256","name":"Benjamin Schmeling"},{"authorId":"2056036545","name":"Virginia Smith"}]},{"paperId":"02f0b09f933fc03675e900cf3ee88e958515e0ae","title":"Enhanced reproducibility of SADI web service workflows with Galaxy and Docker","abstract":null,"venue":"GigaScience","year":2015.0,"referenceCount":36,"citationCount":12,"fieldsOfStudy":["Computer Science","Medicine"],"publicationDate":"2015-12-03","authors":[{"authorId":"3946134","name":"Mikel Ega\u00f1a Aranguren"},{"authorId":"31764087","name":"Mark D. Wilkinson"}]},{"paperId":"02f0d3ced328c9126274aa6e27bd8d8d06456785","title":"A FLEXIBLE APPROACH FOR RANKING COMPLEX RELATIONSHIPS ON THE SEMANTIC WEB by CHRISTIAN HALASCHEK-WIENER","abstract":"SEMANTIC WEB by CHRISTIAN HALASCHEK-WIENER (Under the Direction of I. Budak Arpinar and Amit P. Sheth) ABSTRACT The focus of contemporary Web information retrieval systems has been to provide efficient support for the querying and retrieval of relevant documents. More recently, information retrieval over semantic metadata extracted from the Web has received an increasing amount of interest in both industry and academia. In particular, discovering complex and meaningful relationships among this metadata is an interesting and challenging research topic. Just as the ranking of documents is a critical component of today\u2019s search engines, the ranking of complex relationships will be an important component in tomorrow\u2019s Semantic Web analytics engines. Building upon our recent work on specifying and discovering complex relationships in RDF (Resource Description Framework) data, called Semantic Associations, we present a flexible ranking approach which can be used to identify more interesting and relevant relationships on the Semantic Web. Additionally, we demonstrate our ranking scheme\u2019s effectiveness through an empirical evaluation over a real-world dataset.","venue":"","year":2004.0,"referenceCount":41,"citationCount":2,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"144463965","name":"A. Sheth"}]},{"paperId":"02f10f4f46940cb08e59c09261169e7ab38a8453","title":"Web-based service brokerage for robotic devices","abstract":"In this position paper we describe how technologies from the Web of Things domain could help to simplify and automate the interaction between robotic devices and their surroundings. Specifically, we discuss how Web patterns like Resource-oriented Architectures or Representational State Transfer together with semantic metadata could help to create environments where robots seamlessly interact with other devices in their vicinity: Using services provided by other devices and offering services themselves. One of the main goals in the Web of Things community is to furnish smart environments with sensors and actuators that offer self-described interfaces and are openly accessible from other devices -- Robots should be enabled to make use of this wealth of instrumentation of their surroundings!","venue":"Ubiquitous Computing","year":2012.0,"referenceCount":14,"citationCount":2,"fieldsOfStudy":["Computer Science"],"publicationDate":"2012-09-05","authors":[{"authorId":"47299473","name":"S. Mayer"}]},{"paperId":"02f319710433eb36d087b67d7d3926837300375f","title":"Entity Typing and Linking Using SPARQL Patterns and DBpedia","abstract":null,"venue":"SemWebEval@ESWC","year":2016.0,"referenceCount":14,"citationCount":10,"fieldsOfStudy":["Computer Science"],"publicationDate":"2016-05-29","authors":[{"authorId":"1409857780","name":"Lara Haidar-Ahmad"},{"authorId":"47921394","name":"L. Font"},{"authorId":"145698212","name":"A. Zouaq"},{"authorId":"40055057","name":"M. Gagnon"}]},{"paperId":"02f3f8ef1fd1b92d552e554069e282960d0e79cd","title":"Software Languages","abstract":null,"venue":"Cambridge International Law Journal","year":2018.0,"referenceCount":139,"citationCount":16,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"41130626","name":"Prof. Dr. Ralf L\u00e4mmel"}]},{"paperId":"02f544b950749fca917de3234f440a645f2b07ac","title":"Resource Discovery in a European Spatial Data Infrastructure","abstract":"The geospatial community is moving toward distributed databases and Web services by following the general developments in information and communication technology. The sharing of resources across multiple information communities raises the need of new technologies that support resource discovery and information retrieval. This paper investigates if a common ontology is desirable and feasible for information retrieval in a European spatial data infrastructure. It does so by reviewing relevant literature and proposes an approach for the automatic updating of existing ontologies, designed to facilitate access to multilingual descriptors of geospatial resources. We demonstrate by means of a prototype of an experimental system that the proposed approach is feasible. The experimental system is unique because it integrates a gazetteer, the EuroVoc multilingual vocabulary, the GEMET multilingual thesaurus, an automatic concept space generator, and graph matching into one system. Based on our study, we conclude that it will be impractical to rely only on one common ontology for resource discovery. We also conclude that the approach of using human-created ontologies in combination with automatic concept space generation and associative retrieval is a powerful means to the discovery of geospatial resources. In the absence of a consistent use of semantic Web technologies, a centralized approach to indexing of metadata is required, which has consequences for architectural choices","venue":"IEEE Transactions on Knowledge and Data Engineering","year":2007.0,"referenceCount":38,"citationCount":65,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"32666118","name":"P. Smits"},{"authorId":"1399145044","name":"Anders Friis-Christensen"}]},{"paperId":"02f609691f06238f7785cb108a15a1259968072b","title":"Infrastructure for the Semantic Web: Lessons from Symbolic Artificial Intelligence","abstract":null,"venue":"","year":2002.0,"referenceCount":0,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"2253826","name":"D. Bodoff"},{"authorId":"1403828719","name":"M. Ben-Menachem"}]},{"paperId":"02f7250a4a35b38f9444e0eb81ebfa9a4b584018","title":"PERSWADE-CORE: A Core Ontology for Communicating Socio-Environmental and Sustainability Science","abstract":"The Centre on Persuasive Systems for Wise Adaptive Living (PERSWADE) aims at developing and applying persuasive technologies and system science for social innovation that can help humanity to move toward sustainable, wise, adaptive living. The PERSWADE collaborative knowledge base needs to be designed with the intent to bring together, enrich and logically relate heterogeneous content, such as datasets, scientific literature and any kind of multimedia and social content, to support a participatory approach and help to translate science into action. PERSWADE-CORE, the foundation ontology described in this paper, plays a critical role in this by providing the backbone semantic infrastructure to enable collaboration through efficient data and knowledge integration, sharing and reuse. It also serves the purpose of clarifying and explaining the goals, functions and operations of the Centre. Because of its purpose, PERSWADE-CORE has been designed to be easy-to-use and easy-to-adapt by allowing generic, as well as more specific, relationships among concepts. The PERSWADE approach prioritizes interoperability and relies on the Semantic Web infrastructure. Furthermore, its design is intrinsically aimed at collaborative environments in which ontologies are expected to evolve as a response to users\u2019 activity.","venue":"IEEE Access","year":2019.0,"referenceCount":48,"citationCount":4,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"1685748","name":"S. F. Pileggi"},{"authorId":"2090847899","name":"A. Voinov"}]},{"paperId":"02f7521297669e25517fa210b0c800e5963528d2","title":"Ontology-Based Querying with Bio2RDF\u2019s Linked Open Data","abstract":null,"venue":"Journal of Biomedical Semantics","year":2013.0,"referenceCount":39,"citationCount":72,"fieldsOfStudy":["Medicine","Computer Science"],"publicationDate":"2013-04-01","authors":[{"authorId":"2840689","name":"A. Callahan"},{"authorId":"1403851557","name":"Jose Cruz-Toledo"},{"authorId":"1736389","name":"M. Dumontier"}]},{"paperId":"02f842f0c6226d44e74ca122e2c4f02dfdf4d829","title":"Search informed by a semiotic approach in Social Network Services","abstract":"Social Network Services (SNS) represent an opportunity to access information and knowledge through the Web. These systems allow individuals to constitute communities of common interests with wide cultural diversity, sharing information and vocabularies. Search engines in SNS should take info account the meanings created, shared and used by people through the use of the system. This paper investigates a new approach to adequate search in SNS based on these characteristics. We propose a Dove) search mechanism grounded in Semantic Web technologies combined with a method coming from Organisational Semiotics (OS). We illustrate a process and techniques to improve semantic search results in SNS, with practical and technological results that could be achieved using the proposed approach.","venue":"NOuvelles TEchnologies de la REpartition","year":2010.0,"referenceCount":15,"citationCount":5,"fieldsOfStudy":["Computer Science"],"publicationDate":"2010-08-03","authors":[{"authorId":"144278875","name":"J\u00falio Cesar dos Reis"},{"authorId":"2335286","name":"R. Bonacin"},{"authorId":"3277372","name":"M. Baranauskas"}]},{"paperId":"02f89d10bcf6e87d76dc60a4f6c5c4c75f2083ea","title":"A High Performance Semantic Web Query Answering Engine","abstract":"We present an (extensively revised) semantic web query language called nRQL as well as a working high performance implementation of this language in the RacerPro system. We present the features of this query answering engine.","venue":"Description Logics","year":2005.0,"referenceCount":9,"citationCount":72,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"145546968","name":"Michael Wessel"},{"authorId":"145442792","name":"Ralf M\u00f6ller"}]},{"paperId":"02fa2ce0b19914704ab1ff3ddb62c05652db7733","title":"KnowGL: Knowledge Generation and Linking from Text","abstract":"We propose KnowGL, a tool that allows converting text into structured relational data represented as a set of ABox assertions compliant with the TBox of a given Knowledge Graph (KG), such as Wikidata. \nWe address this problem as a sequence generation task by leveraging pre-trained sequence-to-sequence language models, e.g. BART.\nGiven a sentence, we fine-tune such models to detect pairs of entity mentions and jointly generate a set of facts consisting of the full set of semantic annotations for a KG, such as entity labels, entity types, and their relationships.\nTo showcase the capabilities of our tool, we build a web application consisting of a set of UI widgets that help users to navigate through the semantic data extracted from a given input text. We make the KnowGL model available at https:\/\/huggingface.co\/ibm\/knowgl-large.","venue":"AAAI Conference on Artificial Intelligence","year":2022.0,"referenceCount":25,"citationCount":17,"fieldsOfStudy":["Computer Science"],"publicationDate":"2022-10-25","authors":[{"authorId":"3415700","name":"Gaetano Rossiello"},{"authorId":"69039022","name":"Faisal Chowdhury"},{"authorId":"2689774","name":"Nandana Mihindukulasooriya"},{"authorId":"2159497740","name":"Owen Cornec"},{"authorId":"1711133","name":"A. Gliozzo"}]},{"paperId":"02fa8b01b4c5fd5c9bc758949a76718864c02890","title":"NATURAL LANGUAGE PROCESSING METHODS AND CORPORA IN TRANSLATION, LEXICOGRAPHY, AND LANGUAGE LEARNING","abstract":"Abstract TerminoWeb is a web-based platform designed to find and explore specialized domain knowledge on the Web. An important aspect of this exploration is the discovery of domain-specific collocations on the Web and their presentation in a concordancer to provide contextual information. Such information is valuable to a translator or a language learner presented with a source text containing a specific terminology to be understood. The purpose of this article is to show a proof of concept that TerminoWeb, as an integrated platform, allows the user to extract terms from the source text and then automatically build a related specialized corpus from the Web in which collocations will be discovered to help the user understand the unknown specialized terms. Keywords term extraction, collocation extraction, concordancer, Web as corpus, domain-specific corpus 1. Introduction Collocations and concordances found in corpora provide valuable information for both acquiring the sense and usage of a term or word. Corpora resources are usually complementary to dictionaries, and provide a more contextual understanding of a term. Collocations and concordances are rarely viewed as \u0093static\u0094 resources, the way dictionary definitions would, but are rather often considered the disposable result of a tool\u0092s process (a concordancer, a collocation extractor) on a particular corpus. The use and value of corpora for vocabulary acquisition and comprehension is quite known. In language learning mostly [2], its use obviously has advantages and disadvantages compared to dictionaries, and its context of usage might influence its value (self-learning or classroom). Early work on vocabulary acquisition [21] argued that the learning of a new word is frequently related to the incidence of reading or repetitive listening. Even earlier [23], one experiment illustrated that the frequency of a word and the richness of the context facilitates the identification of a word by a novice reader. Even so, computer-assisted techniques for the understanding of unknown words [15] in second language learning are still not widely studied. In translation studies, the value of corpora has been repeatedly shown [6, 19, 22, 28] and concordancers are the tools of choice for many translators to view a word in its natural surrounding. Concordances are usually defined clearly as a window of text surrounding a term or expression of interest. Most often, a fixed small window size is established (ex. 50 characters) and the results are called KWIC (KeyWord In Context). Such KWIC views are usually supplemented one-click away by a larger context view (a paragraph), potentially even another click away to access the source text. Collocations are words which tend to co-occur with higher than random probability. Although conceptually the definition is quite simple, results will largely differ because of two main variables. A first variable is the window size in which co-occurrences are measured. A small window (2-3 words maximum before or after) is usually established for collocations. Longer distances are considered associations, or semantically-related words, which tend to be together in sentences or paragraphs or even documents. A second variable is the actual measure of association used, and there have been multiple measures suggested in the literature, such as Overlap, Mutual Information, Dice Coefficient, etc [10]","venue":"","year":2009.0,"referenceCount":15,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"2125732","name":"Iustina Ilisei"},{"authorId":"34734346","name":"Viktor Pekar"},{"authorId":"46715576","name":"Silvia Bernardini"}]},{"paperId":"02fb37dd251d68cbf4208ca8403e2364575df0cf","title":"Knowledge Representation and Reasoning of Cataloging Based on Domain Ontology and Rule","abstract":"The study of audio-video material cataloging on domain ontology and rule reasoning will carve out a brand-new realm. Nowadays, the situation of setting many general rules only out of data without domain knowledge will generate substantial useless information. Concerning such problem, this paper builds the knowledge base of catalogue concepts and rules on SWRL (Semantic Web Rule Language), which realizes the sharing of knowledge of audio-video material catalogue and the integration with relative information. Then, the improvement of rete algorithm is used to improve the efficiency of rule-based matching and the reasoning production rule using Jess is given as well. At last, the experiment on reasoning examples is carried out in prot\u00e9g\u00e93.4.1. Keywordscataloging ; ontology ; rule ; reasoning","venue":"2009 International Conference on Management and Service Science","year":2009.0,"referenceCount":9,"citationCount":4,"fieldsOfStudy":["Computer Science"],"publicationDate":"2009-10-30","authors":[{"authorId":"2151572619","name":"Qi Wang"},{"authorId":"2141432474","name":"Ai-na Sui"},{"authorId":"49415706","name":"Yong-Bin Wang"}]},{"paperId":"02fc1443e5917a56c7a86ae5e79af918b005662c","title":"OBO 2 OWL : Roundtrip between OBO and OWL","abstract":"Ontologies have traditionally been used in biomedicine for representing relationships among biological concepts, and as a result, large knowledge-bases like Gene Ontology (GO) have emerged. We believe use of Semantic Web technologies can allow better querying and collaboration of biomedical ontologies. As a migration path for biomedical ontologies, we have developed a mechanism for lossless roundtrip transformations between Open Biomedical Ontologies (OBO) format and OWL. We have methodically examined each of the constructs of OBO and mapped them to constructs in the Semantic Web stack. We have also enumerated constructs in each system that do not have simple syntactic equivalent in the other, important ones being GUIDs, various kinds of synonyms and subsets. We have implemented a tool that uses our transformation rules to translate OBO ontologies into OWL, and back, without loss of knowledge.","venue":"","year":2006.0,"referenceCount":17,"citationCount":4,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"1678609","name":"S. H. Tirmizi"},{"authorId":"1710994","name":"Daniel P. Miranker"}]},{"paperId":"02fdcf2e3c19d1fda3269736ac280335326443e8","title":"Semantic Web Services","abstract":null,"venue":"Handbook of Semantic Web Technologies","year":2010.0,"referenceCount":106,"citationCount":76,"fieldsOfStudy":["Computer Science"],"publicationDate":"2010-12-15","authors":[{"authorId":"2248188079","name":"Carlos Pedrinaci"},{"authorId":"2073452805","name":"John Domingue"},{"authorId":"2260919353","name":"Amit P. Sheth"}]},{"paperId":"02ffd27370f0e9845f707d4c50e0b1acc965e6a8","title":"Introduction to semantic e-Science in biomedicine","abstract":null,"venue":"BMC Bioinformatics","year":2007.0,"referenceCount":28,"citationCount":20,"fieldsOfStudy":["Computer Science"],"publicationDate":"2007-05-09","authors":[{"authorId":"1729778","name":"Huajun Chen"},{"authorId":"2108773566","name":"Yimin Wang"},{"authorId":"144437322","name":"Zhaohui Wu"}]},{"paperId":"02ffd387b7cee92aafb4d0c5315aa7ec3bd64a16","title":"Storage schema and ontology-independent SPARQL to HiveQL translation","abstract":null,"venue":"Journal of Supercomputing","year":2015.0,"referenceCount":48,"citationCount":6,"fieldsOfStudy":["Computer Science"],"publicationDate":"2015-07-01","authors":[{"authorId":"144191918","name":"Naila Karim"},{"authorId":"145614790","name":"K. Latif"},{"authorId":"2074657","name":"Z. Anwar"},{"authorId":"40161908","name":"Sharifullah Khan"},{"authorId":"32503138","name":"Amir Hayat"}]},{"paperId":"02ffd942328cb2ec283ffeb3d36923973cb4f7fe","title":"Tag-Recommender gest\u00fctzte Annotation von Web-Dokumenten","abstract":null,"venue":"Social Semantic Web","year":2009.0,"referenceCount":11,"citationCount":3,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"2078335597","name":"Andreas Blumauer"},{"authorId":"2096613343","name":"M. Hochmeister"}]},{"paperId":"030021b0df799db558ab2e1cdbd809ee81cd2a8f","title":"Storing and Manage RDF Data In Semantic Web","abstract":"To realize Semantic Web,Must to settle issue is describe resource,RDF is describe resource foundation,Manage and Store RDF data become a must solve question.If RDF data store in the relational database,This method can effectively utilize existing database resources to manage RDF data.The text structure RDF data store table utilize vertical Scheme patterns,And RDF data mapped record in the relational database table use Model mapping;Besides also give a method utilize RDF view to query RDF data and this method is foundation to implement Semantic Query structure.","venue":"","year":2007.0,"referenceCount":0,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"152566879","name":"Zhang Zhi-hon"}]},{"paperId":"0300ea53033865971ffa2f961f9438df1f731406","title":"Plenary Speeches and Networks of Politicians of the Parliament of Finland as Open Data Services","abstract":"This paper presents a new open infrastructure called ParliamentSampo for studying the parliamentary culture, language, and activities of politicians in Finland. For the first time, the entire time series of some million plenary speeches of the Parliament of Finland (PoF) have been converted into data and data services in unified formats, including CSV, Parla-CLARIN, ParlaMint, and RDF Linked Open Data (LOD). The speech data have been interlinked with a knowledge graph about the activities of the Members of Parliament (MP) and other speakers in the plenary sessions of the PoF, enriched by data linking from external data sources into a broader ontology-based LOD service. Knowledge extraction techniques based on Natural Language Processing (NLP) were used for automatic semantic annotations and topical classification of the speeches. The data and data services have been used in Digital Humanities (DH) research projects and for application development, especially for developing the in-use semantic portal ParliamentSampo. The infrastructure is openly available on the Web using the CC BY 4.0 license.","venue":"","year":2023.0,"referenceCount":68,"citationCount":3,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"2930307","name":"E. Hyv\u00f6nen"},{"authorId":"33287766","name":"Petri Leskinen"},{"authorId":"2100843016","name":"Laura Sinikallio"},{"authorId":"3144240","name":"Senka Drobac"},{"authorId":"2063770137","name":"Rafael Leal"},{"authorId":"88695644","name":"Matti La Mela"},{"authorId":"31004511","name":"J. Tuominen"},{"authorId":"2167630500","name":"Henna Poikkim\u00e4ki"},{"authorId":"2076478900","name":"Heikki Rantala"}]},{"paperId":"0302be4d4ada287cc242cdb4f3253da3c0706849","title":"A multi-level semantic web for hard-to-specify domain concept, Pedestrian, in ML-based software","abstract":null,"venue":"Requirements Engineering","year":2022.0,"referenceCount":55,"citationCount":9,"fieldsOfStudy":["Computer Science"],"publicationDate":"2022-01-08","authors":[{"authorId":"117965603","name":"H. Barzamini"},{"authorId":"1477286384","name":"Murtuza Shahzad"},{"authorId":"2122345729","name":"Hamed Alhoori"},{"authorId":"34728357","name":"Mona Rahimi"}]},{"paperId":"0303811676382e56f33a579beca4e9bc12036a27","title":"Pathway Width Estimation Method using Images and Pathway Information Provision Method for Wheelchair Users","abstract":"To provide pathway width information and ride comfort information to wheelchair users, we mounted a web camera, an acceleration sensor, and a GPS sensor to a wheelchair. To estimate the path width, we first performed semantic segmentation on the captured images. We then focused on the boundary between the estimated pathway area and other areas in the image, and we propose a simple and automatic pathway width estimation method by extending that boundary line to the wheelchair position. In addition, we evaluated the ride comfort from the obtained acceleration signal, acquired the position information from the GPS signal, and represented this information as lines on a map. We visualized the obtained path information by associating the estimated path width and ride comfort information with the thickness and color of the lines.","venue":"Global Conference on Consumer Electronics","year":2023.0,"referenceCount":6,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":"2023-10-10","authors":[{"authorId":"98804144","name":"K. Kaneda"},{"authorId":"2267051119","name":"Kengo Itou"}]},{"paperId":"0303a50adc9adc514bc1b883c9d3545855a97414","title":"Knowledge Graph Approach to Combustion Chemistry and Interoperability","abstract":"In this paper, we demonstrate through examples how the concept of a Semantic Web based knowledge graph can be used to integrate combustion modeling into cross-disciplinary applications and in particular how inconsistency issues in chemical mechanisms can be addressed. We discuss the advantages of linked data that form the essence of a knowledge graph and how we implement this in a number of interconnected ontologies, specifically in the context of combustion chemistry. Central to this is OntoKin, an ontology we have developed for capturing both the content and the semantics of chemical kinetic reaction mechanisms. OntoKin is used to represent the example mechanisms from the literature in a knowledge graph, which itself is part of the existing, more general knowledge graph and ecosystem of autonomous software agents that are acting on it. We describe a web interface, which allows users to interact with the system, upload and compare the existing mechanisms, and query species and reactions across the knowledge graph. The utility of the knowledge-graph approach is demonstrated for two use-cases: querying across multiple mechanisms from the literature and modeling the atmospheric dispersion of pollutants emitted by ships. As part of the query use-case, our ontological tools are applied to identify variations in the rate of a hydrogen abstraction reaction from methane as represented by 10 different mechanisms.","venue":"ACS Omega","year":2020.0,"referenceCount":48,"citationCount":28,"fieldsOfStudy":["Computer Science","Medicine"],"publicationDate":"2020-07-16","authors":[{"authorId":"2422137","name":"Feroz Farazi"},{"authorId":"115999190","name":"M. Salamanca"},{"authorId":"3037931","name":"S. Mosbach"},{"authorId":"93404234","name":"J. Akroyd"},{"authorId":"1912137","name":"A. Eibeck"},{"authorId":"115702401","name":"L. Aditya"},{"authorId":"145280961","name":"A. Chadzynski"},{"authorId":"9899162","name":"K. Pan"},{"authorId":"2302615858","name":"Xiaochi Zhou"},{"authorId":"2116579602","name":"Shaocong Zhang"},{"authorId":"94623991","name":"Mei Qi Lim"},{"authorId":"145605868","name":"M. Kraft"}]},{"paperId":"0303c9d91954673f653c517aa516de88baf402d7","title":"Solving Relational Similarity Problems Using the Web as a Corpus","abstract":"We present a simple linguistically-motivated method for characterizing the semantic relations that hold between two nouns. The approach leverages the vast size of the Web in order to build lexically-specific features. The main idea is to look for verbs, prepositions, and coordinating conjunctions that can help make explicit the hidden relations between the target nouns. Using these features in instance-based classifiers, we demonstrate state-of-the-art results on various relational similarity problems, including mapping noun-modifier pairs to abstract relations like TIME, LOCATION and CONTAINER, characterizing noun-noun compounds in terms of abstract linguistic predicates like CAUSE, USE, and FROM, classifying the relations between nominals in context, and solving SAT verbal analogy problems. In essence, the approach puts together some existing ideas, showing that they apply generally to various semantic tasks, finding that verbs are especially useful features.","venue":"Annual Meeting of the Association for Computational Linguistics","year":2008.0,"referenceCount":28,"citationCount":80,"fieldsOfStudy":["Computer Science"],"publicationDate":"2008-12-01","authors":[{"authorId":"1683562","name":"Preslav Nakov"},{"authorId":"1716902","name":"Marti A. Hearst"}]},{"paperId":"03041c1bc622951acf5d9fc6a4971d7aa9a4aabb","title":"Initiatives to make standard library metadata models and structures available to the Semantic Web","abstract":"This paper describes recent initiatives to make standard library metadata models and structures available to the Semantic Web, including IFLA standards such as Functional Requirements for Bibliographic Records (FRBR), Functional Requirements for Authority Data (FRAD), and International Standard Bibliographic Description (ISBD) along with the infrastructure that supports them. The FRBR Review Group is currently developing representations of FRAD and the entityrelationship model of FRBR in resource description framework (RDF) applications, using a combination of RDF, RDF Schema (RDFS), Simple Knowledge Organisation System (SKOS) and Web Ontology Language (OWL), cross-relating both models where appropriate. The ISBD\/XML Task Group is investigating the representation of ISBD in RDF. The IFLA Namespaces project is developing an administrative and technical infrastructure to support such initiatives and encourage uptake of standards by other agencies. The paper describes similar initiatives with related external standards such as RDA \u2013 resource description and access, REICAT (the new Italian cataloguing rules) and CIDOC Conceptual Reference Model (CRM). The DCMI RDA Task Group is working with the Joint Steering Committee for RDA to develop Semantic Web representations of RDA structural elements, which are aligned with FRBR and FRAD, and controlled metadata content vocabularies. REICAT is also based on FRBR, and an object-oriented version of FRBR has been","venue":"","year":2010.0,"referenceCount":7,"citationCount":9,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"2058642","name":"G. Dunsire"},{"authorId":"3378341","name":"M. Willer"}]},{"paperId":"0305661d32e256f42de12ef24599aafcdb976dd1","title":"Large-Scale Reasoning with OWL","abstract":"With the growth of the Semantic Web in size and importance, more and more knowledge is stored in machine-readable formats such as the Web Ontology Language OWL. This paper outlines common approaches for efficient reasoning on large-scale data consisting of billions ($10^9$) of triples. Therefore, OWL and its sublanguages, as well as forward and backward chaining techniques are presented. The WebPIE reasoner is discussed in detail as an example for forward chaining using MapReduce for materialisation. Moreover, the QueryPIE reasoner is presented as a backward chaining\/hybrid approach which uses query rewriting. Furthermore, an overview on other reasoners is given such as OWLIM and TrOWL.","venue":"arXiv.org","year":2016.0,"referenceCount":50,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":"2016-02-14","authors":[{"authorId":"47976020","name":"Michael Ruster"}]},{"paperId":"030748679e9806b6f3eebcd4f87971a34eaf3da4","title":"University of Hagen at QA@CLEF 2008: Efficient Question Answering with Question Decomposition and Multiple Answer Streams","abstract":null,"venue":"Conference and Labs of the Evaluation Forum","year":2008.0,"referenceCount":32,"citationCount":25,"fieldsOfStudy":["Computer Science"],"publicationDate":"2008-09-17","authors":[{"authorId":"3021200","name":"Sven Hartrumpf"},{"authorId":"1716883","name":"Ingo Gl\u00f6ckner"},{"authorId":"1725514","name":"Johannes Leveling"}]},{"paperId":"0307a478c5234cd91719fec1b5a011e85fbd8630","title":"SWWS Studio - a WSMO compliant editor","abstract":"The Web Services Modelling Framework (WSMF) and the Web Services Modelling Ontology (WSMO) provide a unique, highly innovative perspective onto Semantic Web and Web Service technologies. We present in this paper the SWWS Studio \u2013 a prototype that supports and elaborates that perspective, making the technology easy to use and transparent for the end user. At present the SWWS Studio is comprised of two components: a graphical designer for modelling WSML specifications and a graphical tool for modelling compositions of services.","venue":"WSMO Implementation Workshop","year":2004.0,"referenceCount":9,"citationCount":3,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"1884415","name":"M. Dimitrov"},{"authorId":"34478509","name":"Zlatina Marinova"},{"authorId":"2525485","name":"Peter Radkov"}]},{"paperId":"0309ce598d8e515c086bd8acd25a8444e6f73906","title":"Optimized AI-Driven Semantic Web Approach for Enhancing Phishing Detection in E-Commerce Platforms","abstract":"For e-commerce systems, phishing attempts remain a major threat, so sophisticated detection techniques using Semantic Web and artificial intelligence are very necessary. An efficient AI-driven Semantic Web method for phishing detection enhancement is presented in this work. The approach uses the Chi-square feature selection approach along with the Adaptive Differential Evolution with Optional External Archive (JADE) algorithm to optimize the hyperparameters of a Convolutional Neural Network (CNN) model. Having grown up on a large collection of more than 11,000 webpages, the model attained 93% accuracy. Although alternative models sometimes exceeded it in accuracy, the suggested method always showed the lowest loss values throughout all epochs, therefore stressing its stability and efficiency. Comparative study using conventional models confirms its resilience against phishing attacks for protecting e-commerce systems.","venue":"International Journal on Semantic Web and Information Systems (IJSWIS)","year":2024.0,"referenceCount":10,"citationCount":0,"fieldsOfStudy":null,"publicationDate":"2024-11-15","authors":[{"authorId":"32658806","name":"Akshat Gaurav"},{"authorId":"1977592","name":"Kwok Tai Chui"},{"authorId":"2179650524","name":"Varsha Arya"},{"authorId":"1581753953","name":"R. Attar"},{"authorId":"2279074821","name":"Shavi Bansal"},{"authorId":"2308364052","name":"Ahmed Alhomoud"},{"authorId":"41037178","name":"Konstantinos E. Psannis"}]},{"paperId":"030b148c9850f60cacb0c6262a87b8d4b1d468fb","title":"Learning Objects Reusability and Retrieval through Ontological Sharing: A Hybrid Unsupervised Data Mining Approach","abstract":"Ontologies add semantics and context to learning objects (LOs), enabling LO sharing and reuse in a contextual learning environment and providing better navigation and retrieval of LOs. However, the effectiveness of LO reuse from LO repositories is compromised due to the use of different ontological schemes in each LO repository. This paper presents an algorithmic framework for ontology mapping and merging, OntoDNA, which employs hybrid unsupervised data mining techniques to resolve the semantic and structural differences between ontologies to subsequently create a merged ontology to facilitate LO reuse and retrieval from the Web or from different LO repositories such as ARIADNE, MERLOT, CAREO or Educause. Experimental results on several real ontologies and comparisons with other ontology mapping and merging tools demonstrate the viability of the OntoDNA in terms of precision, recall and f-measure to interoperate LOs in the LO repositories.","venue":"International Conference on Advanced Learning Technologies","year":2007.0,"referenceCount":11,"citationCount":10,"fieldsOfStudy":["Computer Science"],"publicationDate":"2007-07-18","authors":[{"authorId":"66819471","name":"Ching Kiu"},{"authorId":"32471529","name":"Chien-Sing Lee"}]},{"paperId":"030bfede168dafc7279b4e852fb85ebcc28cad91","title":"2-DOM: A 2-Dimensional Object Model towards Web Image Annotation","abstract":"The automatic annotation of images is still a non-reliable process due to the well-known semantic gap dominating between the physical representation of images and their high level semantics. To avoid the confrontation with the semantic gap several approaches restrict the image dataset to web images. Web images mostly appear on websites with other text contents which can deliver important information about the image semantics. Popular image search engines use text contents surrounding the image to generate annotation keywords. Also emphasized text contents like headlines are assumed to be important description providers. Otherwise we discover false positive results in high ranking positions of this search engines which are the effect of incorrect text-to-image mappings. This paper addresses the problem of finding correct matches between text elements and images in HTML-documents by extending the DOM model tree of a web-page to a 2-dimensional object model (2-DOM) tree. This model adapts to the two dimensional manner of web documents and thus allows a better mapping of text articles to images. The evaluation results show that with a precision over 90 percent text articles are well assigned to web images. This leads intuitive to better textual information about the presented events on the images and thus yields to a better image retrieval quality in querying-by-keyword scenarios.","venue":"2008 Third International Workshop on Semantic Media Adaptation and Personalization","year":2008.0,"referenceCount":11,"citationCount":2,"fieldsOfStudy":["Computer Science"],"publicationDate":"2008-12-15","authors":[{"authorId":"2784634","name":"S. Alcic"},{"authorId":"143966331","name":"Stefan Conrad"}]},{"paperId":"030cb5fcde608ac4afbc8bee57f8e6f93bab1bfa","title":"Experience report: ocsigen, a web programming framework","abstract":"The evolution of Web sites towards very dynamic applications makes it necessary to reconsider current Web programming technologies. We believe that Web development would benefit greatly from more abstract paradigms and that a more semantical approach would result in huge gains in expressiveness. In particular, functional programming provides a really elegant solution to some important Web interaction problems, but few frameworks take advantage of it.\n The Ocsigen project is an attempt to provide global solutions to these needs. We present our experience in designing this general framework for Web programming, written in Objective Caml. It provides a fully featured Web server and a framework for programming Web applications, with the aim of improving expressiveness and safety. This is done by taking advantage of functional programming and static typing as much as possible.","venue":"ACM SIGPLAN International Conference on Functional Programming","year":2009.0,"referenceCount":24,"citationCount":31,"fieldsOfStudy":["Computer Science"],"publicationDate":"2009-08-31","authors":[{"authorId":"3240921","name":"V. Balat"},{"authorId":"2468087","name":"J\u00e9r\u00f4me Vouillon"},{"authorId":"2192101","name":"Boris Yakobowski"}]},{"paperId":"030cc8466fd97a7f37bd1ad7ce5d9d3f1068085f","title":"Semantic and Conceptual Context-Aware Information Retrieval","abstract":null,"venue":"International Conference on Signal-Image Technology and Internet-Based Systems","year":2009.0,"referenceCount":24,"citationCount":15,"fieldsOfStudy":["Computer Science"],"publicationDate":"2009-04-24","authors":[{"authorId":"1746981","name":"B. L. Grand"},{"authorId":"1679110","name":"Marie-Aude Aufaure"},{"authorId":"144996036","name":"M. Soto"}]},{"paperId":"030d3934872fab914b54adaed699991ec22cfe2f","title":"Web Data Management: Ontologies, RDF, and OWL","abstract":"INTRODUCTION The vision of the Semantic Web is that of a world-wide distributed architecture where data and services easily interoperate. This vision is not yet a reality in the Web of today, in which given a particular need, it is difficult to find a resource that is appropriate to it. Also, given a relevant resource, it is not easy to understand what it provides and how to use it. To solve such limitations, facilitate interoperability, and thereby enable the Semantic Web vision, the key idea is to also publish semantics descriptions of Web resources. These descriptions rely on semantic annotations , typically on logical assertions that relate resources to some terms in predefined ontologies . This is the topic of the chapter. An ontology is a formal description providing human users a shared understanding of a given domain. The ontologies we consider here can also be interpreted and processed by machines thanks to a logical semantics that enables reasoning. Ontologies provide the basis for sharing knowledge, and, as such, they are very useful for a number of reasons: Organizing data. It is very easy to get lost in large collections of documents. An ontology is a natural means of \u201corganizing\u201d (structuring) it and thereby facilitates browsing through it to find interesting information. It provides an organization that is flexible, and that naturally structures the information in multidimensional ways. For instance, an ontology may allow browsing through the courses offered by a university by topic or department, by quarter or time, by level, and so forth.","venue":"","year":2011.0,"referenceCount":0,"citationCount":1,"fieldsOfStudy":["Computer Science"],"publicationDate":"2011-11-01","authors":[{"authorId":"69026873","name":"S. Abiteboul"},{"authorId":"1739309","name":"I. Manolescu"},{"authorId":"1744491","name":"P. Rigaux"},{"authorId":"144986814","name":"M. Rousset"},{"authorId":"1734682","name":"P. Senellart"}]},{"paperId":"030ebb9fc07308dc3a5318742f9d9e700d16adef","title":"Federating learning management systems for medical education: A persuasive technologies perspective","abstract":"In the current explosion of internet technologies and exponentially increasing usage of the web there exists a need for effective searching and retrieval of information and resources. This is particularly true in medical and health care education. In the mEducator EUC funded project (www.mEducator.net), the collbaorators are attempting to develop technologies that will enable the above notion by means of multiple technological approaches, including one based on Web 2.0 principles and mashup technologies, and another based on web 3.0 and semantic (or linked) services. In this paper we view this problem through the recent notions of persuasive technologies and we explain how these are taken into account in the problem of metadata completion, a necessary action for linking resources in open educational repositories or learning management systems. The basic principles of persuasive technologies taken into account together with their application in the above field are explained and demonstrated with examples","venue":"Computer-Based Medical Systems","year":2011.0,"referenceCount":16,"citationCount":14,"fieldsOfStudy":["Computer Science"],"publicationDate":"2011-06-01","authors":[{"authorId":"1718645","name":"P. Bamidis"},{"authorId":"8850658","name":"S. Konstantinidis"},{"authorId":"1775631","name":"Charalampos Bratsas"},{"authorId":"145296567","name":"M. S. Iyengar"}]},{"paperId":"030f2ae5f47544bbadfb04a955e42a9e900876f5","title":"Multi-layer SOA implementation pattern with service and data proxies for distributed data-intensive application system","abstract":"Web service is becoming a widely solution used to realize Service Oriented Architecture (SOA). It enables application's business logics interoperable with each other by extending XML flexibility. Current early standardized web service technologies show significant progress in functional aspects interaction, but they are lack of data aspect considerations, such as transferring and integrating large amount of data that are distributed throughout different locations. In this research, we propose a SOA implementation pattern improving coordination of both functional and data aspects to be used across distributed environment by combining several advances in SOA and distributed systems. We define synchronization, replication, and routing mechanism to support distributed systems. This paper introduces the design as preliminary result of our research. It is designed by analyzing previous approach to avoid semantic contradictions of SOA principles and its existing standards and technologies. Next, we need to realize and evaluate them in order to be used in the real application.","venue":"International Conferences on Information Science and System","year":2014.0,"referenceCount":28,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":"2014-09-01","authors":[{"authorId":"2277373964","name":"Takdir"},{"authorId":"1717867","name":"A. I. Kistijantoro"}]},{"paperId":"0310f6541acb04b0600e4808a4b314e6fccca89e","title":"FoodWiki: a Mobile App Examines Side Effects of Food Additives Via Semantic Web","abstract":null,"venue":"Journal of medical systems","year":2016.0,"referenceCount":20,"citationCount":28,"fieldsOfStudy":["Business","Computer Science"],"publicationDate":"2016-02-01","authors":[{"authorId":"2388163","name":"Duygu \u00c7elik Ertugrul"}]},{"paperId":"03134b8896f937a4267ad88fc2fad7e68658554a","title":"LSA based approach to TASS 2013 \u2217 LSA aplicado a TASS 2013","abstract":"This work describes the participation of the CESA team of the SINAI research group in the TASS 2013 workshop, organized as part of the SEPLN congress in 2013. Our system proposes a solution based on Information Retrieval, by applying Latent Semantic Analysis. Results are not very promising compared to other competitors, but the method opens a new approach in the use of social web publications as resource for sentiment polarity classification.","venue":"","year":2013.0,"referenceCount":7,"citationCount":2,"fieldsOfStudy":null,"publicationDate":null,"authors":[]},{"paperId":"0313ea3d846088658467b508c7f99758f3cf3073","title":"User Centered Neuro-Fuzzy Energy Management Through Semantic-Based Optimization","abstract":"This paper presents a cloud-based building energy management system, underpinned by semantic middleware, that integrates an enhanced sensor network with advanced analytics, accessible through an intuitive Web-based user interface. The proposed solution is described in terms of its three key layers: 1) user interface; 2) intelligence; and 3) interoperability. The system\u2019s intelligence is derived from simulation-based optimized rules, historical sensor data mining, and a fuzzy reasoner. The solution enables interoperability through a semantic knowledge base, which also contributes intelligence through reasoning and inference abilities, and which are enhanced through intelligent rules. Finally, building energy performance monitoring is delivered alongside optimized rule suggestions and a negotiation process in a 3-D Web-based interface using WebGL. The solution has been validated in a real pilot building to illustrate the strength of the approach, where it has shown over 25% energy savings. The relevance of this paper in the field is discussed, and it is argued that the proposed solution is mature enough for testing across further buildings.","venue":"IEEE Transactions on Cybernetics","year":2019.0,"referenceCount":50,"citationCount":18,"fieldsOfStudy":["Medicine","Computer Science"],"publicationDate":"2019-09-01","authors":[{"authorId":"26859859","name":"Shaun K. Howell"},{"authorId":"2383958","name":"H. Wicaksono"},{"authorId":"2000176","name":"B. Yuce"},{"authorId":"3171598","name":"K. McGlinn"},{"authorId":"1757067","name":"Y. Rezgui"}]},{"paperId":"03154b67d3a7f5f13bb40a5d474678ebe0ec8a3f","title":"Demo: Swip, a Semantic Web Interface using Patterns","abstract":"Our purpose is to provide end-users with a means to query ontology based knowledge bases using natural language queries and thus hide the complexity of formulating a query expressed in a graph query language such as SPARQL. The main originality of our approach lies in the use of query patterns. Our contribution is materialized in a system named SWIP, standing for Semantic Web Interface Using Patterns. The demo will present use cases of this system.","venue":"International Workshop on the Semantic Web","year":2013.0,"referenceCount":4,"citationCount":1,"fieldsOfStudy":["Computer Science"],"publicationDate":"2013-10-23","authors":[{"authorId":"2619539","name":"Camille Pradel"},{"authorId":"2958656","name":"Ollivier Haemmerl\u00e9"},{"authorId":"143789213","name":"Nathalie Hernandez"}]},{"paperId":"0315a1ca19b46d4c515f7166bcd5faf2f8d67e1f","title":"Automatic Relationship Construction in Domain Ontology Engineering using Semantic and Thematic Graph Generation Process and Convolution Neural Network","abstract":"In recent studies, Ontology construction plays an important role in translating raw text into useful knowledge. The proposed methodology supports efficient retrieval using multidimensional theory and implements integrated data training techniques before enter the trial process. The proposed approach has used the Semantic and Thematic Graph Generation Process to extract useful knowledge, and uses data mining techniques and web solutions to present knowledge as well as improve search speed and information retrieval accuracy. Established ontology can help clarify what it means for different ideas and relationships. Due to the rise of the ontology repository, the process of matching can take a long time. To avoid this, the method produces a hierarchical structure with in-depth interpretation of the data. A system is designed to remove domain dependencies using a dynamic labeling scheme using basic theorem, and the results show that it is possible to automatically and independently construct an independent domain","venue":"International journal of recent technology and engineering","year":2019.0,"referenceCount":0,"citationCount":4,"fieldsOfStudy":null,"publicationDate":"2019-09-30","authors":[]},{"paperId":"0315d02cb38b1821c03eca4f839189e1b7212162","title":"Eswc 2008 Ph.d. Symposium Program Committee Additional Reviewers towards Semantic Web-based Adaptive Hypermedia Model","abstract":"At present, most hypermedia systems display the same content for all users. To allow users working effectively, we need adaptive personalization. We are developing a general model for adaptive hypermedia that should provide a formal description and allow simple development of such systems. We use an innovative approach of utilizing Semantic Web technologies to enable data reuse and system interoperability. In this work we give the description of the research problem, introduce our General Ontological Model for Adaptive Web Environments (GOMAWE), demonstrate experiments used for evaluations and indicate the steps leading to completion of the work.","venue":"","year":2008.0,"referenceCount":155,"citationCount":0,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"2098097445","name":"Philippe Cudr\u00e9-Mauroux Eswc"}]},{"paperId":"0315d6a56f4e186c107faafff20f3fe76d2dd68b","title":"Crowdsourcing techniques to create a fuzzy subset of SNOMED CT for semantic tagging of medical documents","abstract":null,"venue":"Soft Computing - A Fusion of Foundations, Methodologies and Applications","year":2010.0,"referenceCount":40,"citationCount":11,"fieldsOfStudy":["Computer Science"],"publicationDate":"2010-07-18","authors":[{"authorId":"47522124","name":"D. Parry"},{"authorId":"3010470","name":"Tsung-Chun Tsai"}]},{"paperId":"0316dcc9721e02635007019196f8cdbe65d1090b","title":"Ontology-based semantic search on the Web and its combination with the power of inductive reasoning","abstract":null,"venue":"Annals of Mathematics and Artificial Intelligence","year":2012.0,"referenceCount":44,"citationCount":23,"fieldsOfStudy":["Computer Science"],"publicationDate":"2012-07-01","authors":[{"authorId":"8315951","name":"Claudia d\u2019Amato"},{"authorId":"1743194","name":"N. Fanizzi"},{"authorId":"1726971","name":"Bettina Fazzinga"},{"authorId":"1684745","name":"G. Gottlob"},{"authorId":"1690572","name":"Thomas Lukasiewicz"}]},{"paperId":"031804ebff73570676f4e7611728a70773f2e75f","title":"Peer Reviewing Revisited: Assessing Research with Interlinked Semantic Comments","abstract":"Scientific publishing seems to be at a turning point. Its paradigm has stayed basically the same for 300 years but is now challenged by the increasing volume of articles that makes it very hard for scientists to stay up to date in their respective fields. In fact, many have pointed out serious flaws of current scientific publishing practices, including the lack of accuracy and efficiency of the reviewing process. To address some of these problems, we apply here the general principles of the Web and the Semantic Web to scientific publishing, focusing on the reviewing process. We want to determine if a fine-grained model of the scientific publishing workflow can help us make the reviewing processes better organized and more accurate, by ensuring that review comments are created with formal links and semantics from the start. Our contributions include a novel model called Linkflows that allows for such detailed and semantically rich representations of reviews and the reviewing processes. We evaluate our approach on a manually curated dataset from several recent Computer Science journals and conferences that come with open peer reviews. We gathered ground-truth data by contacting the original reviewers and asking them to categorize their own review comments according to our model. Comparing this ground truth to answers provided by model experts, peers, and automated techniques confirms that our approach of formally capturing the reviewers' intentions from the start prevents substantial discrepancies compared to when this information is later extracted from the plain-text comments. In general, our analysis shows that our model is well understood and easy to apply, and it revealed the semantic properties of such review comments.","venue":"International Conference on Knowledge Capture","year":2019.0,"referenceCount":45,"citationCount":6,"fieldsOfStudy":["Computer Science"],"publicationDate":"2019-09-23","authors":[{"authorId":"2232589","name":"C. Bucur"},{"authorId":"145727607","name":"Tobias Kuhn"},{"authorId":"2776924","name":"D. Ceolin"}]},{"paperId":"0318602907f590c4645e1e4020d09de7854fd5de","title":"How to make web sites talk together: web service solution","abstract":"Integrating web sites to provide more efficient services is a very promising way in the Internet. For example searching house for rent based on train system or preparing a holiday with several constrains such as hotel, air ticket, etc... From resource view point, current web sites in the Internet already provide quite enough information. However, the challenge is these web sites just provide information but do not support any mechanism to exchange them. As a consequence, it is very often that a human user has to take the role to \"link\" several web sites by browsing each one and get the concrete information. The reason comes from a historical objective. Web sites were developed for human users browsing and so, they do not support any machine-understandable mechanism.Current researches in WWW environment already propose several solutions to make newly web sites become understandable to other web sites so that they can be integrated. However, the question is how to integrate existing web sites to these new one. Evidently, redeveloping all of them is an unacceptable solution. In this paper, we propose a solution of Web Service Gateway to \"wrap\" existing web sites in Web services. Thus, without any efforts to duplicate the Web sites code, these services inherit all features from the sites while can be enriched with other Web service features like UDDI publishing, semantic describing, etc. This proposal was developed in Toshiba with Web Service Gateway and Wrapper Generator System. By using these systems, several integrated-applications were built and they are also presented and evaluated in this paper.","venue":"The Web Conference","year":2005.0,"referenceCount":13,"citationCount":10,"fieldsOfStudy":["Computer Science"],"publicationDate":"2005-05-10","authors":[{"authorId":"3292801","name":"H. Huy"},{"authorId":"1689972","name":"Takahiro Kawamura"},{"authorId":"2114881979","name":"Tetsuo Hasegawa"}]},{"paperId":"031873fc3ab5ae9c91f9fdb82b8af66dbc5d3772","title":"Intelligent interactions for multimedia processing: an editorial","abstract":null,"venue":"Multimedia tools and applications","year":2013.0,"referenceCount":2,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":"2013-07-01","authors":[{"authorId":"145888300","name":"Jason J. Jung"}]},{"paperId":"03190569e339d149808caad8cfd8732526aa7e16","title":"Ontology-Based Reasoning for Educational Assistance in Noncommunicable Chronic Diseases","abstract":"Noncommunicable chronic diseases (NCDs) affect a large part of the population. With the emergence of COVID-19, its most severe cases impact people with NCDs, increasing the mortality rate. For this reason, it is necessary to develop personalized solutions to support healthcare considering the specific characteristics of individuals. This paper proposes an ontology to represent the knowledge of educational assistance in NCDs. The purpose of ontology is to support educational practices and systems oriented towards preventing and monitoring these diseases. The ontology is implemented under Prot\u00e9g\u00e9 5.5.0 in Ontology Web Language (OWL) format, and defined competency questions, SWRL rules, and SPARQL queries. The current version of ontology includes 138 classes, 31 relations, 6 semantic rules, and 575 axioms. The ontology serves as a NCDs knowledge base and supports automatic reasoning. Evaluations performed through a demo dataset demonstrated the effectiveness of the ontology. SWRL rules were used to define accurate axioms, improving the correct classification and inference of six instantiated individuals. As a scientific contribution, this study presents the first ontology for educational assistance in NCDs.","venue":"De Computis","year":2021.0,"referenceCount":89,"citationCount":3,"fieldsOfStudy":["Medicine"],"publicationDate":"2021-10-12","authors":[{"authorId":"82871768","name":"Andr\u00easa Vargas Larentis"},{"authorId":"2117627407","name":"E. G. A. Neto"},{"authorId":"2065349788","name":"J. Barbosa"},{"authorId":"1697250","name":"D. Barbosa"},{"authorId":"1693868","name":"V. Leithardt"},{"authorId":"51474390","name":"S. D. Correia"}]},{"paperId":"031982a454e3ace51b7e648ef38a3fc2e806c0d8","title":"ETL Processes in the Era of Variety","abstract":null,"venue":"Trans. Large Scale Data Knowl. Centered Syst.","year":2018.0,"referenceCount":37,"citationCount":4,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"2523232","name":"Nabila Berkani"},{"authorId":"1684379","name":"Ladjel Bellatreche"},{"authorId":"2747270","name":"L. Guittet"}]},{"paperId":"031a0987e85a775593ea22d29c8e0f0eeb5cac7a","title":"Sense induction in folksonomies: a review","abstract":null,"venue":"Artificial Intelligence Review","year":2013.0,"referenceCount":0,"citationCount":0,"fieldsOfStudy":null,"publicationDate":"2013-01-01","authors":[{"authorId":"5657660","name":"Pierre Yves Andrews"},{"authorId":"145925694","name":"Juan Pane"}]},{"paperId":"031a460e3ecc682df5191639c66cf809cc65ce83","title":"A Semantic Mobile Web Application for Radiation Safety in Contaminated Areas","abstract":"After a nuclear disaster, people living in contaminated areas encounter numerous questions concerning the risk they face and how to reduce it. In this paper, we present a mobile web application designed to facilitate knowledge sharing amongst the affected population. The system allows querying and browsing a base of documents gathered both by experts and through crowdsourcing. The information needs are modeled as set of use-cases, starting from existing reports on the long-term radiation safety. A semantic search engine is used to retrieve the resources annotated with a thesaurus of the concepts relevant to long-term radiation safety. The application is part of a larger crisis monitoring and management system, which also includes social media aspect-based emotion and sentiment analysis.","venue":"","year":2015.0,"referenceCount":0,"citationCount":1,"fieldsOfStudy":["Computer Science"],"publicationDate":"2015-04-30","authors":[{"authorId":"2805410","name":"Liviu-Adrian Cotfas"},{"authorId":"1867467","name":"Antonin Segault"},{"authorId":"2657252","name":"Federico Tajariol"},{"authorId":"2654507","name":"I. Roxin"}]},{"paperId":"031a888525a9a4ff089dc11c8e4298d1e2737004","title":"Semantic Browsing of Large Distributed Document Spaces","abstract":"Hypermedia retrieval in combination with querying is a very powerful document access metaphor for digital library systems. Lar ge distributed hypermedia systems, however , sufer from some wellknown problems that make ef f ctive, goal-directed document retrieval and maintenance impossible. On the one hand, relationships between documents are modeled on a very low level of abstraction preventing knowledge re-use and user -adapted navigation through document space. On the other hand, huge static web structures are prone to redundancies, inconsistencies and costly to maintain. In this paper , we introduce an approach of a distributed resource discovery and delivery system that offers access to information through querying and knowledge-based hypermedia browsing. Relationship knowledge is partitioned into handy , independent structures, modeled on a high level of abstraction apart from documents. Navigation paths are computed by the system, combining semantic networks with information retrieval.","venue":"","year":null,"referenceCount":7,"citationCount":0,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"1900148","name":"S. Wiesener"},{"authorId":"2316027","name":"W. Kowarschick"}]},{"paperId":"031cef14e8a3261d14cff2daae85df00013b107b","title":"A Framework-based Approach for the Integration of Web-based Information Systems on the Semantic Web","abstract":"For the vision of the Semantic Web to become a reality and its benefits harnessed, data available on the Web must also be published in the form of linked data. Moreover, the quality of the abstract conceptual models behind this data, i.e., their ontology, can also have a big influence in the adoption of linked data sets and their vocabularies. In this paper, we propose FrameWeb-LD, an approach for the integration of Web-based Information Systems on the Semantic Web, which uses well-founded languages and methods for the modeling of ontologies and aids developers in publishing their application's data and services on the Web of Data.","venue":"Brazilian Symposium on Multimedia and the Web","year":2016.0,"referenceCount":28,"citationCount":4,"fieldsOfStudy":["Computer Science"],"publicationDate":"2016-11-08","authors":[{"authorId":"2081663879","name":"Danillo R. Celino"},{"authorId":"7658201","name":"L. Reis"},{"authorId":"2338740","name":"B. F. Martins"},{"authorId":"1726735","name":"V. Souza"}]},{"paperId":"031e0f78ff08f7ae0a7189189f6f576c73394981","title":"Using the Rhizomer Platform for Semantic Decision Support Systems Development","abstract":"Decision support systems get more useful as they manage to make decisions more informed. However, the cost of information and of combining and making it available in the appropriate context make this a tricky trade-off. Fortunately, Semantic Web technologies make it possible to easily publish and reuse data. But this is not simple data, it is semantic data, which makes it easier to query, browse and combine it. Apart from semantic data, it is also important a user interface that carries all this potential to the user. Rhizomer is a framework for semantic data publishing and user interaction that facilitates building semantic dashboards. It is possible, for instance, to build a simple dashboard on top of semantic data generated from financial reports and incorporate web services that provide specialised ways to interact with semantic data, like showing geo-located resources in a map or events in a timeline.","venue":"International Journal of Decision Support System Technology","year":2010.0,"referenceCount":54,"citationCount":7,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"143667487","name":"Roberto Garc\u00eda"}]},{"paperId":"031e61f3e8f74fd8bbb728a31c0f2f07b65c5c71","title":"Yves Moreau and Jaap Heringa, on behalf of the ECCB10 organizing and steering committees","abstract":"This special issue of Bioinformatics contains the proceedings of the ninth European Conference on Computational Biology 2010 (ECCB10), which was held from September 26 to 29 at the International Conference Center in Ghent, Belgium. Details of the conference are available through the conference web site (www.eccb10.org) and will later be archived at eccb.iscb.org\/2010. This year\u2019s conference also served as the sixth Benelux Bioinformatics Conference (BBC10), the annual meeting of the regional computational biology community. ECCB is the top European conference in computational biology and bioinformatics, and a major international conference series in computational biology, alongside ISMB and RECOMB. It covers computational methods for analysis and modeling of an explosively increasing volume and variety of data for molecular biology, medicine and pharmaceutical research. The scope of the conference evolves each year to accommodate the latest developments in biological applications of mathematical modeling and computational methods. ECCB is held in a different country or region each year, and incorporates the annual national or regional meeting where it is held. It is currently held jointly with the Intelligent Systems in Molecular Biology every other year. Past editions of ECCB have been held in Stockholm (SE) (joint with ISMB), Cagliari (IT), Vienna (AT) (with ISMB), Eilat (IL), Madrid (ES), Glasgow (UK) (with ISMB), Paris (FR) and Saarbr\u00fccken (DE). The conference papers are available in open access electroniconly format, both through online open access to the journal Bioinformatics and through the conference CD. Poster abstracts are available both through the conference CD and the conference web site. The conference topics span all areas of methodological developments for computational biology and innovative applications of computational methods to molecular biology. They were divided into nine areas, ranging from sequence analysis to text mining and from comparative genomics to molecular networks. The selected contributions are included in this special issue. A Scientific Program Committee of 208 reviewers and 114 coreviewers selected full manuscript submissions from those nine areas. Each of the nine areas was coordinated by two area chairs and all nine areas were coordinated by the Proceedings and Conference Chairs. We received a record 215 submissions, of which 36 papers (17%) were accepted for oral presentation and publication in Bioinformatics. The area chairs distributed the papers among the referees within each area. Each paper was assigned to three or four reviewers and we received three reports for most of the papers, with a few cases where we could only secure two referee reports. The whole process was carried out through the EasyChair conference reviewing system. The same system was used for discussing papers in cases where the reviewers had different opinions about the relevance or quality of the contribution. After consensus was reached by the reviewers, a final selection was carried out by the area chairs and the proceedings chairs. Poster submission closed shortly after the selection of the oral presentations, so that authors whose manuscript could not be accepted had the opportunity to resubmit their work as poster. After evaluation of the abstracts for scientific relevance and quality, 392 posters were accepted. Those abstracts are available through the conference CD and web site. A call for late-breaking poster abstracts was also opened shortly before the conference to give researchers a final opportunity to submit their work. This process has not been completed at the time of writing. Those abstracts will be available only at the conference web site. The conference featured keynote lectures by distinguished speakers: Peer Bork (European Molecular Biology Laboratory, Heidelberg, Germany), Elaine Mardis (Washington University Genome Center, St Louis, MO, USA), Michael J. E. Sternberg (Imperial College, London, UK), Yves Van de Peer (Flemish Institute of Biotechnology and University of Ghent, Belgium) and Hans Westerhoff (University of Manchester, UK and VU University Amsterdam, The Netherlands). One-day workshops and tutorials were held on Sunday, September 25. The International Society for Computational Biology Student Council (www.iscbsc.org) organized its first European Student Council Symposium (ESCS1). The meeting gave students the opportunity to present their work to an international audience and to build a network and exchange ideas and knowledge within the computational biology community. It was organized under the coordination of Magali Michaut, Thomas Abeel, and Jeroen De Ridder. Two full-day workshops were organized as well. The workshop \u2018Learning from perturbation effects\u2019 focused on computational methods to leverage perturbation techniques (such as target-specific inhibitors and RNA interference) toward reverse engineering biological networks. It was chaired by Holger Fr\u00f6hlich [BonnAachen International Center for IT (B-IT), Bonn, Germany)] The second workshop \u2018Annotation, Interpretation and Management of Mutations (AIMM)\u2019 focused on extraction and reuse of genotype\u2013phenotype knowledge from scientific literature and databases. It was chaired by Christopher Baker (University of New Brunswick, Saint John, Canada), Dietrich Rebholz-Schuhmann (European Bioinformatics Institute, Cambridge, UK) and Ren\u00e9 Witte (Concordia University, Montreal, Canada). Four tutorials were presented: (i) \u2018Working with nextgeneration sequencing data\u2019 by Thomas Keane and Jan Aerts (Sanger Institute, Cambridge, UK), (ii) \u2018Use of semantic web resources in computational biology and bioinformatics\u2019 by Paolo Romano (National Cancer Research Institute of Genoa, Italy) and Andrea Splendiani [Rothamsted Research (BBSRC), Harpenden, UK], (iii) \u2018Current methods and applications for regulatory sequence analysis\u2019 by Jacques Van Helden (Free University","venue":"Bioinformatics","year":2010.0,"referenceCount":0,"citationCount":2,"fieldsOfStudy":["Engineering","Medicine"],"publicationDate":"2010-09-04","authors":[{"authorId":"1732750","name":"Y. Moreau"},{"authorId":"1699372","name":"J. Heringa"}]},{"paperId":"031f1e93412d900a19d8d15fd357956e92691068","title":"Visualizing intellectual connections among philosophers using the hyperlink & semantic data from Wikipedia","abstract":"Wikipedia, with its unique structural features and rich usergenerated content, is being increasingly recognized as a valuable knowledge source that can be exploited for various applications. The objective of the ongoing project reported in this paper is to create a Web-based knowledge portal for digital humanities based on the data extracted from Wikipedia (and other data sources). In this paper we present the interesting results we have obtained by extracting and visualizing various connections among 300 major philosophers using the structured data available in Wikipedia.","venue":"Int. Sym. Wikis","year":2009.0,"referenceCount":3,"citationCount":3,"fieldsOfStudy":["Computer Science"],"publicationDate":"2009-10-25","authors":[{"authorId":"2257203","name":"Sofia J. Athenikos"},{"authorId":"145724540","name":"Xia Lin"}]},{"paperId":"031f79b4381a1939c79cfcce54c01d0b96eeb45f","title":"Topic mining on web-shared videos","abstract":"Internet videos have grown exponentially with the help from video sharing Websites. Automatic topic mining is therefore increasingly important for organizing and navigating such large video databases. Most of current solutions of topic detection and mining were done on news videos and cannot be directly applied on Web videos, because of their limited and noisy semantic information. In this paper, we will try to address this problem and propose an automatic topic mining framework on Web videos. We develop an iterative weight-updated co-clustering scheme to filter \"noisy\" tags and mine the \"hot\" topics. We then propose a visual-based clustering approach to further group the videos with similar content, and rank the visual-similar groups by their similarity to the topic center. Experiments on a large Web video database demonstrate the superior performance of our weight-updated co-clustering to both of the traditional co-clustering and k-means. The experiments also demonstrate significant improvement of users' experience by our visual-based clustering and ranking.","venue":"IEEE International Conference on Acoustics, Speech, and Signal Processing","year":2008.0,"referenceCount":8,"citationCount":7,"fieldsOfStudy":["Computer Science"],"publicationDate":"2008-05-12","authors":[{"authorId":"2118466809","name":"Lu Liu"},{"authorId":"145459057","name":"Y. Rui"},{"authorId":"1720782061","name":"Lifeng Sun"},{"authorId":"2119657909","name":"Bo Yang"},{"authorId":"1739414","name":"Jianwei Zhang"},{"authorId":"1689674","name":"Shiqiang Yang"}]},{"paperId":"031fc07a40e1dd92c7abf821d82db1457d7f198c","title":"Breaking the Paper Barrier and Publishing At the Speed of Thought","abstract":"We are starting to see Semantic Web technologies being used in our research papers and data. The next revolution will be publishing knowledge at the speed of thought.","venue":"NoISE@ESWC","year":2015.0,"referenceCount":3,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"123640845","name":"K. Chapman"},{"authorId":"2013698367","name":"C. Chapman"}]},{"paperId":"03226c3eb0f3b954f61c9c2a28978141d7e03fab","title":"WEB INFORMATION RETRIEVAL USING AUTOMATIC MULTI-DOCUMENT SUMMARIZATION","abstract":"Today, internet has become the most important source of information. People are highly accustomed to the use of internet for acquiring information which they need. Many times, it is revealed that, the information seeker does not get relevant information very easily due to the presence of non-relevant web pages. This paper addresses the problem of effective information retrieval from the web. In this paper, the notion of Web Information Retrieval using Automatic Multi-document Summarization is presented. The proposed work is blend of Web technology and Natural Language Processing. When user will fire the query, the system tries to fetch web pages from different web servers, and they are indexed as per the order of relevance. The degree of relevance is not determined by the how many times the keywords of query is present in the document but it is determined on the basis of semantic content of the document and the user query","venue":"","year":2014.0,"referenceCount":9,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"144982286","name":"R. Khokale"},{"authorId":"145818764","name":"M. Atique"}]},{"paperId":"03229db16beb2e9090da86d564ede39ad1a9e5ba","title":"Repositorien und das Semantic Web - Repositorieninhalte als Linked Data bereitstellen","abstract":"Repositories are systems to safely store and publish digital objects and their descriptive metadata. Repositories mainly serve their data by using web interfaces which are primarily oriented towards human consumption. They either hide their data behind non-generic interfaces or do not publish them at all in a way a computer can process easily. At the same time the data stored in repositories are particularly suited to be used in the Semantic Web as metadata are already available. They do not have to be generated or entered manually for publication as Linked Data. The main topics of this thesis are how metadata and digital objects stored in repositories can be woven into the Linked (Open) Data Cloud and which characteristics of repositories have to be considered while doing so. DOI: http:\/\/dx.doi.org\/10.14279\/depositonce-5015 Dieses Werk ist lizenziert unter einer Creative Commons Namensnennung 4.0 International Lizenz.","venue":"","year":2014.0,"referenceCount":7,"citationCount":1,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"144676268","name":"P. Becker"}]},{"paperId":"032374cb7a7d66a092dcf81b0ee3eaa9a08fd9ae","title":"Anonymizing user profiles for personalized web search","abstract":"We study the problem of anonymizing user profiles so that user privacy is sufficiently protected while the anonymized profiles are still effective in enabling personalized web search. We propose a Bayes-optimal privacy notion to bound the prior and posterior probability of associating a user with an individual term in the anonymized user profile set. We also propose a novel bundling technique that clusters user profiles into groups by taking into account the semantic relationships between the terms while satisfying the privacy constraint. We evaluate our approach through a set of preliminary experiments using real data demonstrating its feasibility and effectiveness.","venue":"The Web Conference","year":2010.0,"referenceCount":24,"citationCount":92,"fieldsOfStudy":["Computer Science"],"publicationDate":"2010-04-26","authors":[{"authorId":"2117077275","name":"Yun Zhu"},{"authorId":"145719374","name":"Li Xiong"},{"authorId":"2372893","name":"C. Verdery"}]},{"paperId":"032625879d9df8f7d4332a313d8393acea6b30df","title":"Knowledge Management and Semantic Web Services","abstract":"Information reliability and automatic computation are two important aspects that are continuously pushing the Web to be more semantic. Information uploaded to the Web should be reusable and extractable automatically to other applications, platforms, etc. Several tools exist to explicitly markup Web content. The Web services may also have a positive role on the automatic processing of Web contents, especially when they act as flexible and agile agents. However, Web services themselves should be developed with semantics in mind. They should include and provide structured information to facilitate their use, reuse, composition, query, etc. In this chapter, the authors focus on evaluating state-of-the-art semantic aspects and approaches in Web services. Ultimately, this contributes to the goal of Web knowledge management, execution, and transfer.","venue":"","year":2013.0,"referenceCount":25,"citationCount":1,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"1770016","name":"I. Alsmadi"},{"authorId":"1970011","name":"S. Alda"}]},{"paperId":"03263546c244299de29a8beb4bc153ef432ee42e","title":"Semi-Automatic Ontology Extension Method for Semantic Web Services","abstract":"this paper provides a novel semi-automatic ontology extension method for Semantic Web Services (SWS). This is significant since ontology extension methods those existing in literature mostly deal with semantic description of static Web resources such as text documents. Hence, there is a need for methods that can serve dynamic Web resources such as SWS. The developed method in this paper avoids redundancy and respects consistency so as to assure high quality of the resulting shared ontologies.","venue":"","year":2011.0,"referenceCount":14,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"1397413838","name":"Mutaz M. Al-Debei"},{"authorId":"1407040453","name":"M. Asswad"}]},{"paperId":"032676aa8b6b5141fc4284097c0e2e94332f43bc","title":"Evolutionary Computation for Multifaceted Web Service Composition","abstract":"Automated Web service composition is one of the holy grails of service-oriented computing, since it allows users to create an application simply by specifying the inputs the resulting application should require, the outputs it should produce, and any constraints it should observe. The composition problem has been handled using a variety of techniques, from AI planning to optimisation algorithms, however no work so far has focused on handling multiple composition facets simultaneously, producing solutions that: (1) are fully functional (i.e. fully executable, with semantically-matched inputs and outputs), (2) employ a variety of composition constructs (e.g. sequential, parallel, and choice constructs), and (3) are optimised according to non-functional Quality of Service (QoS) measurements. The overall goal of this thesis is to propose hybrid Web service composition approaches that consider elements from all three facets described above when generating solutions. These approaches combine elements of AI planning and of Evolutionary Computation to allow for the creation of compositions that meet all of these requirements.\u00a0\u00a0Firstly, this thesis proposes two novel approaches for Web service composition with direct representations. The first one is a tree-based approach where the leaf nodes are the atomic services included in the composition and the inner nodes are the structural constructs that shape the composition workflow. The second one is a graph-based approach where the atomic services are the vertices and the edges connecting them form the composition workflow. The two approaches are compared to determine which is most suitable to the QoS-aware fully automated Web service composition problem.\u00a0\u00a0Secondly, this thesis proposes novel sequence-based approaches for Web service composition that use an indirect representation, i.e. they encode solutions as sequences of services. By representing solutions in this way, it is possible to initialise and evolve them without having to enforce their functional correctness. Then, before evaluating the fitness of each solution, a decoding algorithm is used to transform the sequence into the corresponding composition. The decoding algorithm builds the workflow using the ordering in the sequence as closely as possible when selecting the next service to be added, while at the same time generating a functionally correct structure.\u00a0\u00a0Thirdly, this thesis treats Web service composition as a multi-objective problem, generating a set of trade-off solutions the user can choose from. More specifically, it proposes multi-objective approaches to fully automated Web service composition, which means that conflicting QoS attributes are independently optimised using a variety of representations that support flexible workflow structures. Additionally, a multi-objective and fully automated memetic approach that uses a local search operator to further improve the quality of solutions is proposed.\u00a0\u00a0The following major contributions have been made in this thesis. Firstly, two approaches for Web service composition with direct representations were proposed. When the choice construct is not considered, the graph-based approach produces solutions of higher quality than those of the tree-based approach, but the opposite is true when the choice construct is included. Secondly, indirect representation approaches for Web service composition were proposed. These approaches perform well and can produce solutions with better quality than those found by the graph-based approach. Finally, we propose multi-objective approaches to fully automated service composition, employing different problem representations and a local search operator. The multi-objective approaches using the sequence-based representation were found to produce solutions with better overall quality.","venue":"","year":null,"referenceCount":0,"citationCount":0,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"2121931213","name":"Alexandre Sawczuk da Silva"}]},{"paperId":"03276a6c147cb712fce9cf59f34cbf25b0da8ed2","title":"The Taming of the Polysemy: Automated Word Sense Frequency Estimation for Lexicographic Purposes","abstract":"Although word sense frequency information is important for theoretical study of polysemy and practical purposes of lexicography, the problem of sense frequency distribution is a neglected area in linguistics. It is probably because sense frequency is not easy to estimate. In this paper we deal with the problem of automated word sense frequency estimation for Russian nouns. We developed and tested an automated system based on semantic context vectors, supplied with contexts and collocations from the Active Dictionary of Russian \u2013 a full-fledged production dictionary that reflects contemporary Russian. The study was performed on RuTenTen11 web-corpus. This allows us to reach a frequency estimation error of 11% without any additional labelled data. We compared sense frequencies obtained automatically with sense ordering in different dictionaries for several words. The method presented in this paper can be applied to any language with a sufficiently large corpus and a good dictionary that provides examples for each sense. The results may enrich language learning resources and help lexicographers order senses within a word according to frequency if needed.","venue":"","year":2016.0,"referenceCount":21,"citationCount":5,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"66584864","name":"\u041b\u043e\u043f\u0443\u0445\u0438\u043d\u0430 \u0410\u043d\u0430\u0441\u0442\u0430\u0441\u0438\u044f \u0410\u043b\u0435\u043a\u0441\u0430\u043d\u0434\u0440\u043e\u0432\u043d\u0430"},{"authorId":"71196825","name":"Iomdin Boris Leonidovich"},{"authorId":"66550181","name":"\u041b\u043e\u043f\u0443\u0445\u0438\u043d \u041a\u043e\u043d\u0441\u0442\u0430\u043d\u0442\u0438\u043d \u0410\u043b\u0435\u043a\u0441\u0430\u043d\u0434\u0440\u043e\u0432\u0438\u0447"},{"authorId":"67114736","name":"\u041d\u043e\u0441\u044b\u0440\u0435\u0432 \u0413\u0440\u0438\u0433\u043e\u0440\u0438\u0439 \u0412\u0438\u043a\u0442\u043e\u0440\u043e\u0432\u0438\u0447"}]},{"paperId":"0327f54a6960a727be47b565d33e2c8a8dad56ab","title":"Geospatial Ontology Development and Semantic Analytics","abstract":"Geospatial ontology development and semantic knowledge discovery addresses the need for modeling, analyzing and visualizing multimodal information, and is unique in offering integrated analytics that encompasses spatial, temporal and thematic dimensions of information and knowledge. The comprehensive ability to provide integrated analysis from multiple forms of information and use of explicit knowledge make this approach unique. This also involves specification of spatiotemporal thematic ontologies and populating such ontologies with high quality knowledge. Such ontologies form the basis for defining the meaning of important relations and terms, such as near or surrounded-by, and enable computation of spatiotemporal thematic proximity measures we define. SWETO (Semantic Web Technology Evaluation Ontology) and its geospatial extension SWETO-GS are examples of these ontologies. Two enabler for what we term geospatial analytics (GSA) are (a) the ability to automatically and semi-automatically extract metadata from syntactically (including unstructured, semi-structured and structured data) and semantically heterogeneous and multimodal data from diverse sources, and (b) analytical processing that exploits these ontologies and associated knowledge bases, with integral support for what we term spatiotemporal thematic proximity (STTP) reasoning and interactive visualization capabilities. This chapter covers results of our geospatial ontology development efforts as well as some new semantic analytics methods on this ontology such as STTP.","venue":"","year":2004.0,"referenceCount":65,"citationCount":0,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"1750148","name":"I. Arpinar"},{"authorId":"144463965","name":"A. Sheth"},{"authorId":"1710172","name":"Cartic Ramakrishnan"},{"authorId":"2240169723","name":"Lynn Usery"},{"authorId":"153472232","name":"Molly Azami"}]},{"paperId":"0328038febc6d4a7b662731b3223639c0538c195","title":"OntoFIS as a NLP Resource in the Drug-Therapy Domain: Design Issues and Solutions Applied","abstract":null,"venue":"International Conference on Applications of Natural Language to Data Bases","year":2011.0,"referenceCount":16,"citationCount":1,"fieldsOfStudy":["Computer Science"],"publicationDate":"2011-06-28","authors":[{"authorId":"2091143710","name":"M. T. Rom\u00e1-Ferri"},{"authorId":"40285903","name":"J. Hermida"},{"authorId":"144730147","name":"M. Palomar"}]},{"paperId":"0329241c3ce65aae34ac4bce6e40c95c1643fe12","title":"Call for papers","abstract":null,"venue":"","year":1990.0,"referenceCount":0,"citationCount":0,"fieldsOfStudy":null,"publicationDate":null,"authors":[]},{"paperId":"032952bfa602e438adf925eae23c69a75868e60c","title":"The Computer Science Ontology: A Large-Scale Taxonomy of Research Areas","abstract":null,"venue":"International Workshop on the Semantic Web","year":2018.0,"referenceCount":28,"citationCount":137,"fieldsOfStudy":["Computer Science"],"publicationDate":"2018-10-08","authors":[{"authorId":"40520756","name":"Angelo Salatino"},{"authorId":"27103994","name":"Thiviyan Thanapalasingam"},{"authorId":"2043406","name":"Andrea Mannocci"},{"authorId":"2052329","name":"Francesco Osborne"},{"authorId":"1721851","name":"E. Motta"}]},{"paperId":"032a2a9f13bd5893fd64f320ace575be99498c86","title":"User-friendly ontology authoring using a controlled language","abstract":"In recent years, following the rapid development in the Semantic Web and Knowledge Management research, ontologies have become more in demand in Natural Language Processing. An increasing number of systems use ontologies either internally, for modelling the domain of the application, or as data structures that hold the output resulting from the work of the system, in the form of knowledge bases. While there are many ontology editing tools aimed at expert users, there are very few which are accessible to users wishing to create simple structures without delving into the intricacies of knowledge representation languages. The approach described in this paper allows users to create and edit ontologies simply by using a restricted version of the English language. The controlled language described within is based on an open vocabulary and a restricted set of grammatical constructs. Sentences written in this language unambiguously map into a number of knowledge representation formats including OWL and RDF-S to allow round-trip ontology management.","venue":"International Conference on Language Resources and Evaluation","year":2006.0,"referenceCount":14,"citationCount":45,"fieldsOfStudy":["Computer Science"],"publicationDate":"2006-05-01","authors":[{"authorId":"2968188","name":"V. Tablan"},{"authorId":"2417051","name":"T. Polajnar"},{"authorId":"145435830","name":"H. Cunningham"},{"authorId":"1723649","name":"Kalina Bontcheva"}]},{"paperId":"032ab4966465facd284531865529b124ef173a0e","title":"Web image prediction using multivariate point processes","abstract":"In this paper, we investigate a problem of predicting what images are likely to appear on the Web at a future time point, given a query word and a database of historical image streams that potentiates learning of uploading patterns of previous user images and associated metadata. We address such a Web image prediction problem at both a collective group level and an individual user level. We develop a predictive framework based on the multivariate point process, which employs a stochastic parametric model to solve the relations between image occurrence and the covariates that influence it, in a flexible, scalable, and globally optimal way. Using Flickr datasets of more than ten million images of 40 topics, our empirical results show that the proposed algorithm is more successful in predicting unseen Web images than other candidate methods, including forecasting on semantic meanings only, a PageRank-based image retrieval, and a generative author-time topic model.","venue":"Knowledge Discovery and Data Mining","year":2012.0,"referenceCount":26,"citationCount":15,"fieldsOfStudy":["Computer Science"],"publicationDate":"2012-08-12","authors":[{"authorId":"1743920","name":"Gunhee Kim"},{"authorId":"48004138","name":"Li Fei-Fei"},{"authorId":"143977260","name":"E. Xing"}]},{"paperId":"032b3db9b36592cf639f9e46a501b527f7d4bc86","title":"Effective Model Integration Algorithm for Improving Prediction Accuracy of Healthcare Ontology","abstract":null,"venue":"","year":2019.0,"referenceCount":19,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":"2019-09-25","authors":[{"authorId":"2092892151","name":"P. Monika"},{"authorId":"145583623","name":"G. Raju"}]},{"paperId":"032d1b8e6803bc63b2a59ee2c8925d09d67fea5e","title":"A reverse engineering approach for specifying Semantic Web Service with respect to MDA","abstract":"The semantic Web promises automates invocation, discovery and composition of Web services by enhancing services with semantic descriptions. This paper describes a model driven approach to facilitate the construction of OWL-S specifications. The methodology is divided into three main steps. In the first step we reverse engineered WSDL documents into UML profile models that enable the use of high-level graphical models as an integration platform for semantic Web services. In the second step, suitable domain ontologies are used for the semantic annotation of the UML models. Finally, in the third step a conversion tool will generate automatically the OWL-S description from these UML models. The UML profile provides flexibility as it can expresses multiple semantic Web service concepts.","venue":"2008 3rd International Conference on Information and Communication Technologies: From Theory to Applications","year":2008.0,"referenceCount":24,"citationCount":9,"fieldsOfStudy":["Computer Science"],"publicationDate":"2008-04-07","authors":[{"authorId":"9425148","name":"A.B. Djamel"},{"authorId":"88726829","name":"B. Djamal"},{"authorId":"34163364","name":"M. Mimoun"}]},{"paperId":"032e0b670baa6d0ab16320fe156764b01880cdab","title":"Innovation Development using a Semantic Web Platform : A case-study from the National Health Service in England","abstract":"The National Innovation Centre, which is part of England\u2019s National Health Service, has developed a Semantic Web Platform to improve the speed and quality of health technology innovation development. This platform links data from multiple sources, via automated, semi-automated and manual processes. The collected data and information is rendered on the NIC\u2019s Triple Store using the NIC\u2019s Open Health Innovation Ontology (OHIO). Powered by Solr, OHIO-based results generate highly context specific information for end-users. End-users are able to visualise data via a range of open-source visualisation tools, and these visualisations can then be exported and re-deployed on new platforms via the NIC\u2019s dataShuttle widget.","venue":"","year":2010.0,"referenceCount":0,"citationCount":0,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"46407762","name":"M. Birbeck"},{"authorId":"2058287114","name":"Dr Michael Wilkinson"}]},{"paperId":"032eb8d496cb9bd1fb6b9d850a92ee4a87a410b8","title":"The role of linked data and the semantic web in building operation","abstract":"Effective Decision Support Systems (DSS) for building service managers require adequate performance data from many building data silos in order to deliver a complete view of building performance. Current performance analysis techniques tend to focus on a limited number of data sources, such as BMS measured data (temperature, humidity, C02), excluding a wealth of other data sources increasingly available in the modern building, including weather data, occupant feedback, mobile sensors & feedback systems, schedule information, equipment usage information. This paper investigates the potential for using Linked Data and Semantic Web technologies to improve interoperability across AEC domains, overcoming many of the roadblocks hindering information transfer currently.","venue":"","year":2013.0,"referenceCount":27,"citationCount":7,"fieldsOfStudy":["Engineering"],"publicationDate":null,"authors":[{"authorId":"144201036","name":"Edward Corry"},{"authorId":"3005541","name":"D. Coakley"},{"authorId":"1410266687","name":"James O\u2019Donnell"},{"authorId":"39454836","name":"P. Pauwels"},{"authorId":"144661259","name":"M. Keane"}]},{"paperId":"0330c9681e6497e4c3c1cad0b553500a811e1c19","title":"A concise method for modeling profiles using semantic approach","abstract":"The web is a huge collection of unstructured data, where a large amount of data is added each and every day from multiple sources in various forms. We are actually drowning in information and starving for knowledge. The present day web (web 2.0) helps us to fetch any type of information what we wanted. But most of the information is irrelevant to the user\u2019s perspective. The user has to refine, extract knowledge from the obtained bulk of information. Hence web is not smart enough to fetch the exact information for the user. To make the web smarter, efficient and effective, semantics have been introduced to the web, which can fetch the exact information what a user wanted. To achieve smartness in web 3.0 few components like XML, RDF, Ontology, and Owl are used. One of the most important challenges faced by the web developers is personalizing a social web, it means extracting data from different sources of information. Ontology based representations are used to obtain relevant information to create meaningful relations among those data. The main aim of this paper is to generate profiles for a person, from a scientific point of view. The generated profile shows all the research made by the person, and with whom he has done the research and the time period to complete research. This model is based on FOAF (Friend of a Friend) model. The generated profiles are made for a small community which belongs to the computer science domain. The information present in the profile consists of the research activity of the person and his \/ her area of interests and publi198 Senduru Srinivasulu and P. Sakthivel cations of that person. The publications can be added by the author to his profile with some access policies to restrict the access to the full document. Some information's based on scientific performance extract from digital libraries, for example DBLP and ACM digital libraries. This paper demonstrates a user friendly graphical interface which allows the client to perform their actions. On one hand the client enters the name of the person and the server shows the FOAF profile of the name which is entered and it also highlights the attributes and collaborations of that person. On the other hand client can give a list of people and they can receive the articles which are common between them. The main impact of this approach has kept track of the research activities within us and also the relations and collaborations between people within their community. The paper must have abstract.","venue":"","year":2015.0,"referenceCount":13,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"2103522","name":"S. Srinivasulu"},{"authorId":"50597065","name":"P. Sakthivel"}]},{"paperId":"03317c5710c8a88ee01187fef9ea1087dea8a9cc","title":"Social and semantic web integration","abstract":"The purpose of the following thesis is to present the key concepts of Social and Semantic Web, to examine the possibilities of their integration and to develop and implement on the basis of good practice a concrete example of an application that combines the advantages of both areas. \nThe thematic area of social web, its basic forms and examples of popular web applications are presented more thoroughly. These applications offer a range of technologies for content syndication, networking, mutual communication and content sharing. Building blocks of semantic web architecture are also presented, where ontologies and languages for their implementation play a significant role. \nAs an option of integration of the two areas, three contact points are identified. The concept of the most logical contact point is developed and implemented as an application that creates added value, based on the unstructered data from the social web with the help of semantic web technologies. \nFor a given set of users the application searches within different internet sites for eventual data, e.g. group names to which these users are subscribed within the popular online social network Facebook. Based on specific area ontology, the colleccted data is compared with the labels of ontology classes. People in whose a match is found, are recorded as entities in the appropriate ontology classes. \nWith the help of an ontology handling tool it is possible to obtain a list of people that are connected to the specific area in the context of social web easiliy, on any level of the ontology. \nAs a potential use case example the area of targeted advertising is presented.","venue":"","year":2009.0,"referenceCount":0,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":"2009-05-27","authors":[{"authorId":"2092951858","name":"M. Trop"}]},{"paperId":"033189bc12a4fc264a59e7f8aed540017e698e65","title":"Datasets for generic relation extraction*","abstract":"Abstract A vast amount of usable electronic data is in the form of unstructured text. The relation extraction task aims to identify useful information in text (e.g. PersonW works for OrganisationX, GeneY encodes ProteinZ) and recode it in a format such as a relational database or RDF triplestore that can be more effectively used for querying and automated reasoning. A number of resources have been developed for training and evaluating automatic systems for relation extraction in different domains. However, comparative evaluation is impeded by the fact that these corpora use different markup formats and notions of what constitutes a relation. We describe the preparation of corpora for comparative evaluation of relation extraction across domains based on the publicly available ACE 2004, ACE 2005 and BioInfer data sets. We present a common document type using token standoff and including detailed linguistic markup, while maintaining all information in the original annotation. The subsequent reannotation process normalises the two data sets so that they comply with a notion of relation that is intuitive, simple and informed by the semantic web. For the ACE data, we describe an automatic process that automatically converts many relations involving nested, nominal entity mentions to relations involving non-nested, named or pronominal entity mentions. For example, the first entity is mapped from \u2018one\u2019 to \u2018Amidu Berry\u2019 in the membership relation described in \u2018Amidu Berry, one half of PBS\u2019. Moreover, we describe a comparably reannotated version of the BioInfer corpus that flattens nested relations, maps part-whole to part-part relations and maps n-ary to binary relations. Finally, we summarise experiments that compare approaches to generic relation extraction, a knowledge discovery task that uses minimally supervised techniques to achieve maximally portable extractors. These experiments illustrate the utility of the corpora.1","venue":"Natural Language Engineering","year":2011.0,"referenceCount":50,"citationCount":24,"fieldsOfStudy":["Computer Science"],"publicationDate":"2011-03-09","authors":[{"authorId":"2753838","name":"Ben Hachey"},{"authorId":"144003169","name":"Claire Grover"},{"authorId":"144439277","name":"R. Tobin"}]},{"paperId":"03325d233ce6b4aa1a2d938762b3872adaa6fae7","title":"Designing an ontology-based multi-agent system for supply chain performance measurement using graph traversal","abstract":"Previous studies have not provided any information system (IS) solution for the supply chain (SC) performance measurement based on the Global Supply Chain Forum (GSCF) reference model due to the complexities of interoperability among the ISs in the SC. As an innovation, this paper has proposed an architecture that allows the SC Performance Measurement System (SCPMS) components to have multi-level interoperability by integrating the multi-agent technology as well as ontology technology. It has also proposed a method to develop the required ontologies for the PMS agents and developed the ontologies in the Web Ontology Language (OWL) to provide the semantic level interoperability. The syntax-level interoperability has been provided by a number of agent interaction protocols (AIPs). As another innovation, the authors have developed the SCPMS algorithms for the link analysis method by the Breadth-First Search (BFS) method and proved those algorithms. The authors have created the PMS agents based on those algorithms and prototyped a Multi-Agent System (MAS) for the SC of a tile manufacturer as a case study. The proposed multi-level architecture supports the GSCF model in the SC performance measurement, and improves the interoperability and the integration of the SCPMS.","venue":"International journal of computer integrated manufacturing (Print)","year":2014.0,"referenceCount":33,"citationCount":2,"fieldsOfStudy":["Computer Science","Engineering"],"publicationDate":"2014-02-06","authors":[{"authorId":"2063225","name":"E. Teimoury"},{"authorId":"3101206","name":"Issa Chambar"},{"authorId":"1828064","name":"M. Gholamian"},{"authorId":"1820947","name":"M. Fathian"}]},{"paperId":"0333476866d3b795a4234d456193a2e4aac0deab","title":"JXTA & Web Services Using Secret Key Based Encryption","abstract":"JXTA is a P2P (Peer-to-Peer) Semantic Web application, which is aimed to accommodate heterogeneous resource metadata repositories in a P2P manner.,the main focus of research in cellular domain has shifted to \"Web Service Security\" The aim of this thesis will be to develop a distributed service discovery mechanism. JXTA's P2P provides perfect solution for service (Web Service) discovery and Algorithm for Web Service Security. Here I have implemented an algorithm for web service security by using RSA Cryptographic Library and AES Encryption technology. Because most of the attackers may have easy access to Web Services that do not have adequate protection against unauthorized access. So, as the business needs to be protected against unauthorized infiltration, we need to implement some security measures in the Web Services. RSA Laboratories implemented a 330 bit security algorithm on March 18, 1991 named RSA-100. But that was factored within two weeks. Since then RSA has been improving the strength of the algorithm and the latest RSA has 2048 bit key based encryption system. So, in this thesis I have proposed the implementation of an algorithm that is a composition of RSA and AES Encryption that is believed to be strong enough for today's hardware to be factored with.","venue":"","year":2011.0,"referenceCount":9,"citationCount":1,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"2054306278","name":"Sabiha Hossain"},{"authorId":"145967293","name":"Upama Kabir"},{"authorId":"150305230","name":"S. Rahman"},{"authorId":"3215034","name":"A. K. Saha"}]},{"paperId":"033692a6ddfe3ff6563d1587f23c46d4b254b5fc","title":"Deconstructing Domain Names to Reveal Latent Topics","abstract":"Measurement of the lexical properties of domain names enables many types of relatively fast, lightweight web mining analyses. These include unsupervised learning tasks such as automatic categorization and clustering of websites, as well as supervised learning tasks, such as classifying websites as malicious or benign. In this paper we explore whether these tasks can be better accomplished by identifying semantically coherent groups of words in a large set of domain names using a combination of word segmentation and topic modeling methods. By segmenting domain names to generate a large set of new domain-level features, we compare three different unsupervised learning methods for identifying topics among domain name keywords: spherical k-means clustering (SKM), Latent Dirichlet Allocation (LDA), and the Biterm Topic Model (BTM). We successfully infer semantically coherent groups of words in two independent data sets, finding that BTM topics are quantitatively the most coherent. Using the BTM, we compare inferred topics across data sets and across time periods, and we also highlight instances of homophony within the topics. Finally, we show that the BTM topics can be used as features to improve the interpretability of a supervised learning model for the detection of malicious domain names. To our knowledge this is the first large-scale empirical analysis of the co-occurrence patterns of words within domain names.","venue":"International Conference on Data Science and Advanced Analytics","year":2016.0,"referenceCount":41,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":"2016-10-01","authors":[{"authorId":"24440615","name":"Cheryl J. Flynn"},{"authorId":"2867637","name":"Kenneth E. Shirley"},{"authorId":"2158624366","name":"Wei Wang"}]},{"paperId":"033830e9ca21ba3e14bf45561c1b8911a216d863","title":"An Intelligent Tracking System: Application to Acute Respiratory Tract Infection (TrackARTI)","abstract":"This article proposes an Intelligent Tracking System for Acute Respiratory Tract Infection (TrackARTI) via a smart mobile for monitoring disease term of 0-6 age group child patients remotely (e.g. home, clinics). It is possible to maximize the quality of life of the child patients and decrease parental anxiety by keeping the child under control during monitoring stage and achieve a proper distant diagnose by the patient's clinician. This is possible with the designs of intelligent M-Health systems that can be used for diagnosing and monitoring the child patients away from hospitals by presenting the instant medical data to their registered doctors. Intelligent M-Health systems require strong knowledge management technology and ease of extension to provide information from additional medical tools. With the contribution of intelligent M-Health systems, it is possible to infer new facts from the certain gathered medical data during examination from child patients. This article mentions an intelligent and easy medical data gathering system that can be used by pediatricians or parents any time. In addition, the system has its own inferencing mechanism that involves two main steps, inferencing on image processing and Semantic Web rule knowledge base.","venue":"Annual International Computer Software and Applications Conference","year":2017.0,"referenceCount":21,"citationCount":5,"fieldsOfStudy":["Computer Science"],"publicationDate":"2017-07-01","authors":[{"authorId":"2388163","name":"Duygu \u00c7elik Ertugrul"},{"authorId":"1723633","name":"Atilla El\u00e7i"},{"authorId":"2428674","name":"Y. Bi\u0307ti\u0307ri\u0307m"}]},{"paperId":"0338b170b09e264dcc4f2153f75de02c7daf4f36","title":"Moving to dynamic computational lexicons with LeXFlow","abstract":"In this paper we present LeXFlow, a web application framework where lexicons already expressed in standardised format semi-automatically interact by reciprocally enriching themselves. LeXFlow is intended for, on the one hand, paving the way to the development of dynamic multi-source lexicons; and on the other, for fostering the adoption of standards. Borrowing from techniques used in the domain of document workflows, we model the activity of lexicon management as a particular case of workflow instance, where lexical entries move across agents and become dynamically updated. To this end, we have designed a lexical flow (LF) corresponding to the scenario where an entry of a lexicon A becomes enriched via basically two steps. First, by virtue of being mapped onto a corresponding entry belonging to a lexicon B, the entry(LA) inherits the semantic relations available in lexicon B. Second, by resorting to an automatic application that acquires information about semantic relations from corpora, the relations acquired are integrated into the entry and proposed to the human encoder. As a result of the lexical flow, in addition, for each starting lexical entry(LA) mapped onto a corresponding entry(LB) the flow produces a new entry representing the merging of the original two.","venue":"International Conference on Language Resources and Evaluation","year":2006.0,"referenceCount":23,"citationCount":10,"fieldsOfStudy":["Computer Science"],"publicationDate":"2006-05-01","authors":[{"authorId":"47437846","name":"C. Soria"},{"authorId":"2704289","name":"Maurizio Tesconi"},{"authorId":"1682806","name":"F. Bertagna"},{"authorId":"1707466","name":"N. Calzolari"},{"authorId":"2053963821","name":"Andrea Marchetti"},{"authorId":"1763416","name":"M. Monachini"}]},{"paperId":"0338c4efadb17a9ec0f52c63dbfb366e0b029068","title":"A Semantic Representation for Domain-Specific Patterns","abstract":null,"venue":"Metainformatics","year":2004.0,"referenceCount":22,"citationCount":22,"fieldsOfStudy":["Computer Science"],"publicationDate":"2004-09-15","authors":[{"authorId":"144224131","name":"Susana Montero"},{"authorId":"145429731","name":"P. D\u00edaz"},{"authorId":"1708076","name":"I. Aedo"}]},{"paperId":"033abf4588507f0ba03505e3c12b5715ce85618e","title":"Improving Searchability of a Music Digital Library with Semantic Web Technologies","abstract":null,"venue":"International Conference on Software Engineering and Knowledge Engineering","year":2009.0,"referenceCount":0,"citationCount":3,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"1893882","name":"Paloma de Juan"},{"authorId":"1697135","name":"C. Iglesias"}]},{"paperId":"034070d14474176c573c9394fa1c130ba94e8562","title":"An XML to WSML Adapter","abstract":"This paper describes an implementation of an Adapte r that converts XML to a Web Service Modeling Language (WSML) [1]. WSML is the l anguage used to describe Web Service Modeling Ontology (WSMO) [2] concepts, related to Semantic Web services (SWS). SWS are web services that are seman tically annotated. The semantic annotation is necessary to address various business logic in an appropriate manner, thus allowing complex business applications to be b uilt and executed. The Web Service Execution Environment (WSMX) [3] is an exec ution environment for dynamic discovery, selection, mediation and invocat i n of semantic web services. WSMX is a reference implementation for WSMO.","venue":"WSMO Implementation Workshop","year":2005.0,"referenceCount":7,"citationCount":1,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"3174026","name":"B. Sapkota"},{"authorId":"145542202","name":"D. Aiken"},{"authorId":"1793558","name":"Laurentiu A. Vasiliu"},{"authorId":"2257342","name":"Edward Kilgarriff"}]},{"paperId":"0341936dff1f5dd64e219c5ca2d29973079bd2c4","title":"Distributed Geographic Information Retrieval Based on the Geospatial Semantic Web","abstract":"This paper builds an Ontology-based Geographic Information Inquiry System OGIIS.At first,GeoOntology Building Algorithm GOBA creates the geographic ontology instance according to the reference ontology.Then,indexes are built and inference are done on these geographic ontology instance.Through reasoning and semantic description,OGIIS can perform precisely and intelligently.","venue":"","year":2006.0,"referenceCount":0,"citationCount":1,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"2081093277","name":"Chen Jun-peng"}]},{"paperId":"0342c7a697e504bf7c6acecf8c29537cbe180341","title":"Searching and ranking method of relevant resources by user intention on the Semantic Web","abstract":null,"venue":"Expert systems with applications","year":2012.0,"referenceCount":24,"citationCount":19,"fieldsOfStudy":["Computer Science"],"publicationDate":"2012-03-01","authors":[{"authorId":"1732270","name":"Myungjin Lee"},{"authorId":"145883782","name":"Wooju Kim"},{"authorId":"2107883145","name":"Sangun Park"}]},{"paperId":"03465d28e575ac8273887f0f56b67b890230d788","title":"MAGIC: Mining an Augmented Graph using INK, starting from a CSV","abstract":". A large portion of structured data does not yet reap the ben-e\ufb01ts of the Semantic Web. Therefore, The \u201cTabular Data to Knowledge Graph Matching\u201d competition at ISWC tries to bridge this gap by evaluating and promoting the creation of such semantic annotations tools. Besides annotating data semantically, the system should also be able to further augment the datasets based on the provided annotations. In this paper, we propose a system that is capable of both annotating and augmenting a dataset by using the interpretable embedding technique INK. The \u201cTabular Data to Knowledge Graph Matching\u201d competition was used to evaluate the proposed annotation capabilities of our proposed system.","venue":"SemTab@ISWC","year":2021.0,"referenceCount":18,"citationCount":11,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"51138839","name":"Bram Steenwinckel"},{"authorId":"1715957","name":"F. Turck"},{"authorId":"1726557","name":"F. Ongenae"}]},{"paperId":"0346796c08f648bbd80f379386afe179c560e9d2","title":"Teachers and Students Perception of Technology and Sustainable Adoption Framework in the Pedagogical Process: A Systematic Review","abstract":"The adoption of technology remains a persistent challenge, but it is an essential endeavour in the pursuit of fostering inclusivity, equity, and a steadfast commitment to providing high-quality learning opportunities for all. This study conducts a systematic review to explore how teachers and students perceive the role of technology in the classroom. It also investigates the key factors that influence teachers\u2019 perceptions of technology and the barriers they encounter when adopting technology in the pedagogical process. Following the preferred reporting items for systematic reviews and meta-analyses (PRISMA) guideline, reputable databases were thoroughly examined, including Google Scholar, Semantic Scholar, Web of Science, and Scopus. The search identified 83 relevant publications spanning the years 2010 to 2023. After a comprehensive evaluation, we identified 41 publications most relevant to the study. The study revealed that both teachers and students view technology as a valuable tool to improve the quality of learning and encourage active participation in the classroom. The findings also uncovered the key factors influencing students\u2019 and teachers\u2019 technology perceptions in education and highlighted the barriers to technology adoption in the pedagogical process. A sustainable framework was provided to ensure the sustainability of technology in the pedagogical process.","venue":"International Journal of Learning, Teaching and Educational Research","year":2023.0,"referenceCount":75,"citationCount":4,"fieldsOfStudy":null,"publicationDate":"2023-12-30","authors":[{"authorId":"2278319597","name":"Sri Utaminingsih Nur Fajrie"},{"authorId":"2265302592","name":"Nurudeen Babatunde Bamiro"},{"authorId":"2265422686","name":"Mohamed Nor Azhari Azman"}]},{"paperId":"0347fa9cd2f55880c518026e21666e4ceec41548","title":"First steps towards WikiPathways RDF","abstract":null,"venue":"","year":2011.0,"referenceCount":0,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":"2011-08-30","authors":[{"authorId":"48709451","name":"A. Waagmeester"}]},{"paperId":"034953066a6489b98dce6d4ba74d9445141fafe9","title":"An ontology-based approach for providing multimedia personalised recommendations","abstract":"This paper provides a service-oriented solution that explores the ontology-based modelling of users and documents in order to provide users with personalised recommendations of resources. Alongside the adoption of semantic web technologies for ontology-based modelling, our approach aims at a better relevance for recommendations by adopting a hybrid recommendation technique, combining a collaborative filtering and a content-based approach. The collaborative filtering module adopts a Markov Decision Process (MDP) in order to predict the next concept which will be focused on by the user, tracking the user navigation through an ontology instead of through the structure of a particular site. The content-based recommender module adopts a k nearest neighbours approach and exploits the similarities between the user and document modelling.","venue":"International Journal of Web and Grid Services","year":2008.0,"referenceCount":13,"citationCount":4,"fieldsOfStudy":["Computer Science"],"publicationDate":"2008-11-01","authors":[{"authorId":"1736859","name":"Mihaela Brut"},{"authorId":"1804438","name":"F. S\u00e8des"},{"authorId":"1732283","name":"Romulus Grigoras"},{"authorId":"1747107","name":"Vincent Charvillat"}]},{"paperId":"034ae5cefa5d2b782a9476d06cd3725264dc7c26","title":"Semantic Search and Recommendation of e-Catalog Documents through Concept Network","abstract":"Until now, popular paradigms to provide e-catalog documents that are adapted to users' needs are keyword search or collaborative filtering based recommendation. Since users' queries are too short to represent what users want, it is hard to provide the users with e-catalog documents that are adapted to their needs(i.e., queries and preferences). Although various techniques have beenproposed to overcome this problem, they are based on index term matching. A conventional Bayesian belief network-based approach represents the users' needs and e-catalog documents with their corresponding concepts. However, since the concepts are the index terms that are extracted from the e-catalog documents, it is hard to represent relationships between concepts. In our work, we extend the conventional Bayesian belief network based approach to represent users' needs and e-catalog documents with a concept network which is derived from the Web directory. By exploiting the concept network, it is possible to search conceptually relevant e-catalog documents although they do not contain the index terms of queries. Furthermore, by computing the conceptual similarity between users, we can exploit a semantic collaborative filtering technique for recommending e-catalog documents.","venue":"","year":2010.0,"referenceCount":23,"citationCount":2,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"2108480220","name":"Jae-won Lee"},{"authorId":"2107889021","name":"Sungchan Park"},{"authorId":"2108049553","name":"S. Lee"},{"authorId":"2052729","name":"Jaehui Park"},{"authorId":"2118625237","name":"Han-joon Kim"},{"authorId":"3013044","name":"Sang-goo Lee"}]},{"paperId":"034b06f307358e1b47566144857e04fb2c4bdc40","title":"Institutionalization and internationalization of research on the applications of the geographical information systems in health planning","abstract":null,"venue":"Scientometrics","year":2012.0,"referenceCount":30,"citationCount":8,"fieldsOfStudy":["Sociology","Computer Science"],"publicationDate":"2012-04-01","authors":[{"authorId":"3221795","name":"A. Murad"},{"authorId":"144316769","name":"D. Tomov"}]},{"paperId":"034ceb5a764f7678c34419289a13f4656e6e69e4","title":"Ranking Semantic Similarity Association in Semantic Web","abstract":"Discovering and ranking complex relationships in the semantic web is an important building block of semantic search applications. Although semantic web technologies define relations between objects but there are some complex (hidden) relationships that are valuable in different applications. Currently, users need to discover the relations between objects and find the level of semantic similarity between them. (I.e. find two similar papers). \n \nThis paper presents a new approach for ranking semantic similarity association in semantic web document, based on semantic association concept.","venue":"International Workshop on the Semantic Web","year":2008.0,"referenceCount":9,"citationCount":3,"fieldsOfStudy":["Computer Science"],"publicationDate":"2008-10-28","authors":[{"authorId":"2078025","name":"S. Shariatmadari"},{"authorId":"2760630","name":"A. Mamat"},{"authorId":"87656074","name":"H. Ibrahim"},{"authorId":"143866399","name":"N. Mustapha"}]},{"paperId":"034d9f89c4114ce0161400566837773c2a215725","title":"Institutional Knowledge at Singapore Management University Institutional Knowledge at Singapore Management University Towards verification of computation orchestration Towards verification of computation orchestration","abstract":". Recently, a promising programming model called Orc has been proposed to support a structured way of orchestrating distributed Web Services. Orc is intuitive because it offers concise constructors to manage concurrent communication, time-outs, priorities, failure of Web Services or communication and so forth. The semantics of Orc is precisely de\ufb01ned. However, there is no automatic veri\ufb01cation tool available to verify critical properties against Orc programs. Our goal is to verify the orchestration programs (written in Orc language) which invoke web services to achieve certain goals. To investigate this problem and build useful tools, we explore in two directions. Firstly, we de\ufb01ne a Timed Automata semantics for the Orc language, which we prove is semantically equivalent to the operational semantics of Orc. Consequently, Timed Automata models are systematically constructed from Orc programs. The practical implication is that existing tool supports for Timed Automata, e.g., Uppaal , can be used to simulate and model check Orc programs. An experimental tool has been implemented to automate this approach. Secondly, we start with encoding the operational semantics of Orc language in Constraint Logic Programming (CLP), which allows a systematic translation from Orc to CLP. Powerful constraint solvers like CLP( R ) are then used to prove traditional safety properties and beyond, e.g., reachability, deadlock-freeness, lower or upper bound of a time interval, etc. Counterexamples are generated when properties are not satis\ufb01ed. Furthermore, the stepwise execution traces can be automatically generated as the simulation steps. The two different approaches give an insight into the veri\ufb01cation problem of Web Service orchestration. The Timed Automata approach has its merits in visualized simulation and ef\ufb01cient veri\ufb01cation supported by the well developed tools. On the other hand, the CPL approach gives better expressiveness in both modeling and veri\ufb01cation. The two approaches complement each other, which gives a complete solution for the simulation and veri\ufb01cation of Computation Orchestration.","venue":"","year":2020.0,"referenceCount":60,"citationCount":0,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"8644752","name":"Jinlu Dong"},{"authorId":"144090485","name":"Yang Liu"},{"authorId":"39838927","name":"Jun Sun"},{"authorId":"2108304040","name":"Xian Zhang"}]},{"paperId":"034eb16a111626ec4399dff4a91d9d2e6a6e66c9","title":"Introduction: transdisciplinary learning for digital creative practice","abstract":"The Institute of Creative Technologies (IOCT) at De Montfort University, Leicester, UK, was founded in 2006 with a \u00a31.3 million award from the Higher Education Funding Council for England under its \u2018Science Research Infrastructure Fund\u2019. The aim was to provide a catalyst for research at the intersection of science and technology, and the arts and humanities. The IOCT was situated outside the faculty structure of the university with a mission to pull together high-quality research from all areas and to present a public face to the most creative and innovative research at De Montfort University (DMU). The IOCT rapidly formed a network of partners across the university and established a large collection national and international links. These are detailed on its website at http:\/\/www.ioct.dmu.ac.uk. Since its inception, it has housed over 100 projects, conducted by over 100 researchers, and funded from a range of sources including research councils, charities and other agencies. All IOCT projects are either interdisciplinary (applying the methods from one discipline to another), multidisciplinary (teams from various disciplines combining to investigate a research question) or transdisciplinary (across and beyond all disciplines) (Nicolescu 2002; Nowotny et al. 2001; Thompson Klein 1990). The emphasis on collaboration and networking has led to some notable successes in areas such as: computational intelligence; digital writing; sonic art; pervasive media; digital heritage; interactivity in health; cultural visualisation; semantic web; and many more. Current research in the IOCT is clustered into three main areas:","venue":"Digital Creativity","year":2013.0,"referenceCount":5,"citationCount":1,"fieldsOfStudy":["Sociology","Computer Science"],"publicationDate":"2013-09-01","authors":[{"authorId":"34913815","name":"A. Hugill"}]},{"paperId":"034f0171d9854c08f409940c98f5b7aefaaa138d","title":"Automated Semantic Enrichment of Ontologies in the Construction Domain","abstract":"Technologies built by the Semantic Web (SW) community are more and more adopted by experts in the Construction domain. Indeed, SW languages like Resource Description Framework (RDF) and the Web Language Ontology (OWL) have been used for various purposes like information modeling, automatic rules\u2019 checking. Their massive adoption is due mainly to their ability to capture deep semantics, their standardization and their large adoption. At the base of semantic applications, we find ontologies. Their construction is time consuming and involves domain experts and SW engineers. It is thus interesting for experts to have tools which could help them enrich automatically ontologies from textual resources. In this paper, we bridge this gap through an approach which aims to provide automatically an OWL expression of a given concept from its natural language definition. This formalization process uses foremost Industry Foundation Classes entities. A first evaluation of this approach gives promising results.","venue":"","year":2015.0,"referenceCount":6,"citationCount":6,"fieldsOfStudy":["Computer Science"],"publicationDate":"2015-10-27","authors":[{"authorId":"1776064","name":"Cheikh Kacfah Emani"},{"authorId":"2213767859","name":"C. F. D. Silva"},{"authorId":"1724451","name":"B. Fi\u00e9s"},{"authorId":"71300895","name":"P. Ghodous"},{"authorId":"3108027","name":"M. Bourdeau"}]},{"paperId":"034f4511f31ecccd52936c8ba263f2597fd88e02","title":"Constructing Virtual Documents for Keyword Based Concept Search in Web Ontology","abstract":"-Web ontologies are structural frameworks for organizing information in semantics web and provide shared concepts. Ontology formally represents knowledge or information about particular entity as a set of concepts within a particular domain on semantic web. Web ontology helps to describe concepts within domain and also help us to enables semantic interoperability between two different applications by using Falcons concept search. We can facilitate concept searching and ontologies reusing. Constructing virtual documents is a keyword based search in ontology. The proposed method helps us to find how search engine help user to find out ontologies in less time so we can satisfy their needs. It include some supportive technologies with new technique is to constructing virtual documents of concepts for keyword based search and based on population scheme we rank the concept and ontologies, a way to generate structured snippets according to query. In this concept we can report the user feedback and usability evolution.","venue":"","year":2013.0,"referenceCount":18,"citationCount":1,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"1620245524","name":"Sapna Paliwal"}]},{"paperId":"034f96e14882182831569bd36bbb4eeb4904eb5f","title":"Concepts for an Intelligent Information Portal in Pharmaceutical Research","abstract":"Once upon a time scientists were experts in their field. They knew not only the \u201chot questions\u201d but also the scientists involved and the various approaches investigated. More important, they were well informed of novel research results. Gone are these favorable times! Hot issues and active research teams emerge with high pace and being informed within days or even hours might be essential for success. Furthermore, no one can any longer keep an eye on the research publications, patents, and other information that might be relevant for one\u2019s research. As a consequence, scientists often feel and in fact they sometimes are rather unaware of areas that are of prime importance for their research. High diversity, considerable amounts of information and extremely fast communication are key characteristics of today\u2019s research especially in medical biology. An automatic tracking of technical and scientific information is a way to cope with these aspects of today\u2019s research. Such a system is made possible by emerging techniques such as \u201cSemantic Web\u201d. This article describes the corner stones of such an \u201cIntelligent Information Portal\u201d currently developed at Roche Diagnostics GmbH for scientists in Pharmaceutical Research. The article stresses the salient aspects of the envisioned system and its focus on personalization\/adaptation.","venue":"","year":2007.0,"referenceCount":8,"citationCount":1,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"36859428","name":"Alex Kohn"},{"authorId":"1767012","name":"Fran\u00e7ois Bry"},{"authorId":"38165280","name":"S. Klostermann"},{"authorId":"2064116752","name":"Alexander Manta"}]},{"paperId":"035031befc839a73d9ebe5542537bac0d97ac2c4","title":"Design and Development of Semantic-Based Search Engine Model","abstract":"With the rapid development of World Wide Web, search engines have become the main tool for people to get network information. However, the search results are widely criticized due to the poor accuracy and redundancy disadvantages. After the advent of semantic Web, new search engine with the ability of understanding queries and documents has attracted more and more attentions. This paper starts from the traditional search engine, and firstly introduces its classification, popular technology, advantages and disadvantages, thus leads to the semantic search engine model. Then we research the semantic search technology in depth, which can be divided into enhanced semantic search based on traditional search, knowledge semantic search based on ontology inference and other semantic search types. In addition, key techniques in semantic search engine development, such as automated inference technique, ontology knowledge system and expert system are presented in this paper. Lastly, we conclude the current research and forecast the prospect of future research.","venue":"International Conference on Intelligent Computation Technology and Automation","year":2014.0,"referenceCount":14,"citationCount":4,"fieldsOfStudy":["Computer Science"],"publicationDate":"2014-10-25","authors":[{"authorId":"2052926470","name":"Cai Bo"},{"authorId":"152405435","name":"Li Yang-mei"}]},{"paperId":"03506d70e4f254d46b9b19721ff2526adb6a3953","title":"A Fuzzy Clustering Based Approach for Heavy Tail Weight in Web Data","abstract":"A distributed frameworks cluster is a gathering of machines that are for all intents and purposes or topographically isolated and that cooperate to give a similar services or application to customers in web application. It is conceivable that huge numbers of the services you keep running in your system today are a piece of a distributed system cluster. Cluster is a vital information mining procedure which expects to isolate the information objects into important gatherings called as groups. It is the way toward gathering objects into bunches to such an extent that items from a similar group are comparable and objects from various groups is unique. In information mining, information bunching has been examined for long time utilizing diverse calculations and ordinary patterns are proposed for better results around tailed data. The fuzzy semantic strategy is look at to group the overwhelming followed information by utilizing some technique for remove. An appraisal thinks about is introduced in view of time and exactness. In this method proposed here is evaluated to other relational clustering schemes using various propinquity matrices as input. Simulations demonstrate the scheme to be very effectual.","venue":"International Journal of Data Mining Techniques and Applications","year":2019.0,"referenceCount":0,"citationCount":0,"fieldsOfStudy":null,"publicationDate":"2019-06-05","authors":[{"authorId":"2204916977","name":"Janani K Ms"}]},{"paperId":"0351279b020b329b2974386ef49f85efdcb8e54f","title":"Developing Consensus Ontologies for the Semantic Web","abstract":"This paper describes a methodology for associating, organizing, and merging large numbers of independently developed information sources. The hypothesis is that a multiplicity of ontology fragments, representing the semantics of the independent sources, can be related to each other automatically without the use of a global ontology. The methodology has been tested by merging small, independently developed ontologies for the domains of Humans, Buildings, and Sports. The methodology, which reinforces common parts of the component ontologies and deemphasizes unique parts, produces a consensus ontology.","venue":"","year":2003.0,"referenceCount":14,"citationCount":1,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"34791304","name":"L. Stephens"},{"authorId":"2313932","name":"Aurovinda K. Gangam"},{"authorId":"1744170","name":"M. Huhns"}]},{"paperId":"0352b79701f1b3d86d0739fefc64bfa37ec86ea5","title":"TopEx: topic exploration of COVID-19 corpora - Results from the BioCreative VII Challenge Track 4","abstract":"Abstract TopEx is a natural language processing application developed to facilitate the exploration of topics and key words in a set of texts through a user interface that requires no programming or natural language processing knowledge, thus enhancing the ability of nontechnical researchers to explore and analyze textual data. The underlying algorithm groups semantically similar sentences together followed by a topic analysis on each group to identify the key topics discussed in a collection of texts. Implementation is achieved via a Python library back end and a web application front end built with React and D3.js for visualizations. TopEx has been successfully used to identify themes, topics and key words in a variety of corpora, including Coronavirus disease 2019 (COVID-19) discharge summaries and tweets. Feedback from the BioCreative VII Challenge Track 4 concludes that TopEx is a useful tool for text exploration for a variety of users and tasks. Databse URL http:\/\/topex.cctr.vcu.edu","venue":"Database J. Biol. Databases Curation","year":2022.0,"referenceCount":18,"citationCount":5,"fieldsOfStudy":["Computer Science","Medicine"],"publicationDate":"2022-01-01","authors":[{"authorId":"2308169001","name":"Amy L. Olex"},{"authorId":"2114323960","name":"E. French"},{"authorId":"2140014349","name":"Peter Burdette"},{"authorId":"2140014205","name":"Srilakshmi Sagiraju"},{"authorId":"143993045","name":"Thomas Neumann"},{"authorId":"2067068118","name":"Tamas S. Gal"},{"authorId":"49460508","name":"Bridget Mcinnes"}]},{"paperId":"0353a48d600d9e482504d92c9f5ad3253e3dd32a","title":"COVID-19: Disease Pattern Study based on Semantic-Web Approach using Description Logic","abstract":"Description Logic elucidates statement using the methodology of reasoning. Description logic combined with semantics, forms the treasured Description logic ontology. Several studies have depicted semantics of Description Logic, using concepts and roles. In this paper, the disease pattern with respect to pandemic COVID-19 is studied. The proposed study aims to give semantically rich meaning to the disease pattern of COVID-19. The outbreak of Coronavirus has deeply devastated all forms of human pursuit. The main aim of our paper is to use Description Logic ontologies and the semantic web-based approach to remove ambiguity developed around spread of COVID-19. Semantics combined with Description Logic, thus serves the purpose of imparting meaning to words, so that their interpretation is correctly done. In this paper, proper reasoning is provided to facts so that they can be trusted without any further doubt or thought.","venue":"2020 IEEE International Conference for Innovation in Technology (INOCON)","year":2020.0,"referenceCount":32,"citationCount":3,"fieldsOfStudy":["Medicine"],"publicationDate":"2020-11-06","authors":[{"authorId":"2006630842","name":"Ria Rawal"},{"authorId":"2007367027","name":"Kartik Goel"},{"authorId":"46667135","name":"Charu Gupta"}]},{"paperId":"0354adb4bf8ace77bd1fbd35a7b629937bb54ccd","title":"The Content of Accounts and Registers in their Digital Edition. XML\/TEI, Spreadsheets, and Semantic Web Technologies","abstract":"Introduction This article considers the use of semantic web technologies in the context of everyday historians##. It deduces from theoretical considerations needs for the actual implementation of a digital edition. It explains some of the basic concepts of the semantic web more extensively than necessary for the digital humanities scholar already familiar with these technologies. I\u2019ve argued elsewhere why a digital edition can be considered the best method to publish economic records as historical sources. This argument is based on the insight that historical accounting records can only be understood when their documentary properties are fully considered: Their palaeographical and codicological features (\u201cviusal\u201d layer) and the linguistics of the text (\u201clinguistic\u201d layer) contribute to their understanding as a formal representation of the facts recorded (\u201ccontent\u201d layer). The following first discusses the drawbacks of reducing digital edition of accounts and economic records to the encoding offered by the TEI. I will compare the text oriented approach of the TEI with other digital representations of accounts that are oriented primarily on the economic facts accounted. The second part of the article discusses the opportunities offered by the usage of semantic web technologies (RDF, RDFs\/OWL, SKOS and SPARQL) to encode and expose the content layer of digital editions. I have described elsewhere in more detail my own proposal how a customized XML\/TEI transcription can be transformed into a XML serialisation of RDF facts, and there are other projects interlacing RDF structures into TEI. This article focus on an introduction into the semantic web technologies as","venue":"","year":2016.0,"referenceCount":0,"citationCount":5,"fieldsOfStudy":["Computer Science"],"publicationDate":"2016-09-12","authors":[{"authorId":"2065072809","name":"Georg Vogeler"}]},{"paperId":"0355966ce10ee8f51e0afed8afc65613adcf16f7","title":"Big Data and Privacy Issues","abstract":null,"venue":"","year":2012.0,"referenceCount":0,"citationCount":5,"fieldsOfStudy":["Computer Science"],"publicationDate":"2012-09-19","authors":[{"authorId":"1913990","name":"B. Karabey"}]},{"paperId":"0355bcd7d85b86b79f9669c2874a635b8fff01d4","title":"A Fuzzy Logic Based Synonym Resolution Approach for Automated Information Retrieval","abstract":"Precise semantic similarity measurement between words is vital from the viewpoint of many automated applications in the areas of word sense disambiguation, machine translation, information retrieval and data clustering, etc. Rapid growth of the automated resources and their diversified novel applications has further reinforced this requirement. However, accurate measurement of semantic similarity is a daunting task due to inherent ambiguities of the natural language, spread of web documents across various domains, localities and dialects. All these issues render to the inadequacy of the manually maintained semantic similarity resources (i.e. dictionaries). This article uses context sets of the words under consideration in multiple corpora to compute semantic similarity and provides credible and verifiable semantic similarity results directly usable for automated applications in the intelligent manner using fuzzy inference mechanism. It can also be used to strengthen the existing lexical resources by augmenting the context set and properly defined extent of semantic similarity.","venue":"International Journal on Semantic Web and Information Systems (IJSWIS)","year":2018.0,"referenceCount":18,"citationCount":1,"fieldsOfStudy":["Computer Science"],"publicationDate":"2018-10-01","authors":[{"authorId":"40458522","name":"Mamta Kathuria"},{"authorId":"47802917","name":"C. K. Nagpal"},{"authorId":"2768818","name":"Neelam Duhan"}]},{"paperId":"03569552401b8a17cc9252fe1d9e434e5a490cb2","title":"Using Semantic Web Technologies to Support Enhanced Situation Awareness","abstract":"The AKTiveSA project is using Semantic Web technologies to support information fusion and en-hanced situational awareness in a simulated hu-manitarian relief scenario. We have developed an application that shows how situational awareness can be supported during humanitarian relief situa-tions; often occurring alongside military conflict. Semantic Web technologies provide new opportu-nities for harvesting information from numerous, disparate and often heterogeneous information sources and can be used to better support complex knowledge fusion.","venue":"","year":2005.0,"referenceCount":0,"citationCount":1,"fieldsOfStudy":["Engineering"],"publicationDate":null,"authors":[{"authorId":"8530169","name":"Max L. Wilson"},{"authorId":"2085536","name":"A. Russell"},{"authorId":"37836120","name":"P. Smart"},{"authorId":"1705314","name":"N. Shadbolt"},{"authorId":"1727183","name":"L. Carr"},{"authorId":"50331281","name":"M. Schraefel"}]},{"paperId":"0358f8f08d7d1a5dd008b8298640c14fa7389e11","title":"Produce and Consume Linked Data with Drupal!","abstract":null,"venue":"International Workshop on the Semantic Web","year":2009.0,"referenceCount":23,"citationCount":104,"fieldsOfStudy":["Computer Science"],"publicationDate":"2009-11-06","authors":[{"authorId":"1939158","name":"S. Corlosquet"},{"authorId":"1789456","name":"Renaud Delbru"},{"authorId":"145469718","name":"Tim Clark"},{"authorId":"1708607","name":"A. Polleres"},{"authorId":"1685642","name":"S. Decker"}]},{"paperId":"0359c41a85df16df029d4834abcbea70ad3dc26d","title":"An Ontology-Driven Mediator for Querying Time-Oriented Biomedical Data","abstract":"Most biomedical research databases contain considerable amounts of time-oriented data. However, temporal knowledge about the contextual meaning of such data is not usually represented in a principled fashion. As a result, investigators often develop custom techniques for temporal data analysis that are difficult to reuse. We addressed this problem by developing a set of knowledge-driven methods and tools for temporally representing and querying biomedical data, and have integrated them using a mediator approach. A central issue driving our work is a need to integrate temporal representations of data in relational databases with the domain-specific semantics of temporal patterns used in querying. This paper presents a formal temporal knowledge model using the semantic Web ontology and rule languages, OWL and SWRL, respectively. The model informs the mediator of the temporal semantics used for data analysis. We show that our approach provides the computational foundation for much-needed software to make sense of complex temporal patterns in two biomedical research domains","venue":"Computer-Based Medical Systems","year":2006.0,"referenceCount":22,"citationCount":15,"fieldsOfStudy":["Computer Science"],"publicationDate":"2006-06-22","authors":[{"authorId":"1397042086","name":"M. O'Connor"},{"authorId":"2249270","name":"R. Shankar"},{"authorId":"145521072","name":"Amar K. Das"}]},{"paperId":"0359f6452f0ad50c814cf849924471283253c39f","title":"Time Series Analyst: Interactive Online Visualization of Standards Based Environmental Time Series Data","abstract":": Visualization is a common need of many researchers, organizations, and projects that collect and use environmental sensor data. Web-based tools can provide screening-level visualization and data analysis functionality for users with a range of technical expertise. However, it is difficult to integrate data from multiple sources due to syntactic and semantic differences in data formats and different data delivery mechanisms that are not always interoperable. We developed an open-source time series visualization tool called the Time Series Analyst (TSA) that integrates data from multiple sources using web service interfaces and a standardized data encoding format. The TSA provides multiple types of visualization presented through a web browser. Important functionality includes a map-based interface and faceted filters to narrow the selection and display of a large number of data series. Data are retrieved using web services that comply with standards established by the Consortium of Universities for the Advancement of Hydrologic Science, Inc. (CUAHSI) Hydrologic Information System (HIS), and any time series dataset published using the CUAHSI HIS can be visualized using TSA. Finally, we present a case study demonstrating how TSA can be used to visualize data from a large-scale environmental sensor network.","venue":"","year":2016.0,"referenceCount":11,"citationCount":2,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"1760798","name":"J. Horsburgh"},{"authorId":"34685788","name":"A. Jones"},{"authorId":"34965260","name":"M. Ram\u00edrez"},{"authorId":"46487354","name":"J. Caraballo"}]},{"paperId":"035cc8fe77f94873eb708b2f8d399163d3abf366","title":"A unified framework improving interoperability and symbiosis in the field of Systems Engineering","abstract":"This dissertation is about improving performance of projects delivering complex systems. Examples of such systems are ships, infrastructure systems and process plants. Mostly these systems are one of a kind, so called \u2018one-offs\u2019 and are the \u2018product\u2019 of one or more coherent projects each executed by a consortium of enterprises. The lifecycle of these systems is characterized by a sequence of lifecycle stages (in headlines specification, creation and usage) and requires involvement of different parties with different interests and competences, e.g. the client, (sub) contractors, end users and stakeholders and disciplines like construction, electrical, mechanical and information technology. In actual practice many of these kinds of projects exceed the planned budget and time and do not meet the quality and needs expected by the client, end users and\/or stakeholders. This dissertation considers this problem from an overall perspective, and not from the perspective of only e.g. the client or contractor. In this dissertation three issues have been identified concerning today\u2019s creation of systems: \u2022Imperfections in the creation process of both systems and the project teams that create the system, \u2022Lack of reflection, \u2022Lack of semantic ability. The objective of this dissertation is to provide a framework in which the backgrounds of these three issues are expressed and offer a way to overcome these issues. The framework can be utilized by enterprises to improve interoperability and symbiosis in the field of Systems Engineering enabling them to improve performance of projects in all lifecycle stages of a system. The framework addresses interoperability barriers and integrates Systems Engineering principles, organization science, system science, complexity science and cognitive science. The framework has been visualized by means of six symmetrically connected tetrahedrons, supported by an ontology. Additional terms of reference has been drawn up for the purpose of implementation of the framework. A prototype of a collaboration tool based on a specific semantic WEB technology as published in several papers by the author, supporting the framework, was part of the work done for this dissertation. The framework is based on years of experiences of author with complex projects and knowledge as captured in ISO standards and fundamental theories.","venue":"","year":2018.0,"referenceCount":33,"citationCount":1,"fieldsOfStudy":["Computer Science"],"publicationDate":"2018-12-17","authors":[{"authorId":"2265713607","name":"Leo van Ruijven"},{"authorId":"2265713607","name":"Leo van Ruijven"},{"authorId":"2265712314","name":"Cornelis van Ruijven"},{"authorId":"2265712431","name":"Hans Hopman"},{"authorId":"41192798","name":"H. Veeke"}]},{"paperId":"035d7396e58cafee088a8e19ed705f810c6e0e35","title":"Learning Semantic Relations from Text","abstract":"Every non-trivial text describes interactions and relations between people, institutions, activities, events and so on. What we know about the world consists in large part of such relations, and that knowledge contributes to the understanding of what texts refer to. Newly found relations can in turn become part of this knowledge that is stored for future use.To grasp a text\u2019s semantic content, an automatic system must be able to recognize relations in texts and reason about them. This may be done by applying and updating previously acquired knowledge. We focus here in particular on semantic relations which describe the interactions among nouns and compact noun phrases, and we present such relations from both a theoretical and a practical perspective. The theoretical exploration sketches the historical path which has brought us to the contemporary view and interpretation of semantic relations. We discuss a wide range of relation inventories proposed by linguists and by language processing people. Such inventories vary by domain, granularity and suitability for downstream applications.On the practical side, we investigate the recognition and acquisition of relations from texts. In a look at supervised learning methods, we present available datasets, the variety of features which can describe relation instances, and learning algorithms found appropriate for the task. Next, we present weakly supervised and unsupervised learning methods of acquiring relations from large corpora with little or no previously annotated data. We show how enduring the bootstrapping algorithm based on seed examples or patterns has proved to be, and how it has been adapted to tackle Web-scale text collections. We also show a few machine learning techniques which can perform fast and reliable relation extraction by taking advantage of data redundancy and variability.","venue":"Conference on Empirical Methods in Natural Language Processing","year":2015.0,"referenceCount":83,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":"2015-09-01","authors":[{"authorId":"1683562","name":"Preslav Nakov"},{"authorId":"2256003","name":"Vivi Nastase"},{"authorId":"1709389","name":"Diarmuid \u00d3 S\u00e9aghdha"},{"authorId":"1795595","name":"Stan Szpakowicz"}]},{"paperId":"035de9683b3d60fc3c641a4fce4e2508a03c5dc3","title":"On the Current State of Linked Open Data: Issues, Challenges, and Future Directions","abstract":"This article describes how Linked Open Data (LOD), under the umbrella of the Semantic Web, integrates the openly-published semantic information making it easily understandable and consumable by humans and machines. Currently, researchers have applied the principles of LOD in several domains including e-government, media, publications, geography, and life sciences. Besides the fast pace of research, the field is still an emerging one, where researchers face several prominent challenges and issues that need to resolve to exploit LOD to its fullest. In this article, the authors have identified challenges, issues, and research opportunities in the publishing, management, linking, and consumption of LOD. The research work presented here will grab the attention of researchers and may aid to the current state-of-the-art in this area.","venue":"International Journal on Semantic Web and Information Systems (IJSWIS)","year":2018.0,"referenceCount":87,"citationCount":11,"fieldsOfStudy":["Computer Science"],"publicationDate":"2018-10-01","authors":[{"authorId":"80236432","name":"N. Fayyaz"},{"authorId":"51453868","name":"Irfan Ullah"},{"authorId":"3351931","name":"Shah Khusro"}]},{"paperId":"035e03d4dc98a89453edc2d9de2d260849af856a","title":"\u03a3\u03c7\u03b5\u03b4\u03af\u03b1\u03c3\u03b7 \u03ba\u03b1\u03b9 \u03b1\u03bd\u03ac\u03c0\u03c4\u03c5\u03be\u03b7 \u03c0\u03bb\u03b1\u03c4\u03c6\u03cc\u03c1\u03bc\u03b1\u03c2 \u03c0\u03b1\u03c1\u03bf\u03c7\u03ae\u03c2 \u03b7\u03bb\u03b5\u03ba\u03c4\u03c1\u03bf\u03bd\u03b9\u03ba\u03ce\u03bd \u03c5\u03c0\u03b7\u03c1\u03b5\u03c3\u03b9\u03ce\u03bd \u03b2\u03b1\u03c3\u03b9\u03c3\u03bc\u03ad\u03bd\u03b7\u03c2 \u03c3\u03b5 \u03c4\u03b5\u03c7\u03bd\u03b9\u03ba\u03ad\u03c2 \u03b1\u03bd\u03bf\u03b9\u03ba\u03c4\u03ce\u03bd \u03c0\u03c1\u03bf\u03c4\u03cd\u03c0\u03c9\u03bd \u03c3\u03c7\u03b5\u03b4\u03af\u03b1\u03c3\u03b7\u03c2","abstract":"Modern building design approaches require interactive amenities provision to people \nwho live and work within them. Home and Building Automation, however, is characterized \nby great diversity among most installed systems, which are non-open systems. \nIt is necessary therefore to find methods for integration between them, and \nmove to more open systems that provide flexibility and interoperability. \nA number of systems and applications have been developed towards this direction, \nand every day there are new more \"smart\" devices with multiple networking technologies \nusing Internet and wireless communication. These features appear to constitute \nthe ingredients for a successful delivery of electronic services in the area. \nThis thesis is to investigate the creation and use of semantic descriptions in the environment \nof building automation, implement an ontology describing a LonWorks \nnetwork, and extended it to more general equipment and procedures that characterize \nthe area. Moreover, a survey is performed around the methodology for the \nuse of these descriptions along with network services, resulting in the design and \nimplementation of a platform. The platform incorporates a set of tools enabling the \nnetwork engineer to design and develop the necessary web services needed to create \ne-services. Specifically, it describes the implementation methodology of web \nservices that will draw information from the underlying automation network, regardless \nof each heterogeneity degree, and each amongst combination to create web \nservices.","venue":"","year":2010.0,"referenceCount":0,"citationCount":0,"fieldsOfStudy":["Computer Science","Engineering"],"publicationDate":null,"authors":[{"authorId":"2277751389","name":"Konstantinos J. Charatsis"}]},{"paperId":"035ec9670ba52ff95637c28b39314d622262a1d5","title":"Finding Suitable Course Material through a Semantic Search Agent for Learning Management Systems of Distance Education","abstract":"Developing technology and increasing usage of computers around the world make Internet a convenient tool for Distance Education (DE) systems. Learning Management Systems-(LMSs) of DE around the world serve content-based courses to students\/users via static pages on the Web. Additionally, querying for specific course content of an entire course in LMS is only possible by syntactic-based search agents which limit the search. Therefore, it is thought that querying of contents through semantic-based approaches would make LMSs more helpful for a student\/user through the Semantic Web (SW) approach. Queries can be meaning based and this can enable the system to make meaningful inference in human-computer interaction. In this article, we propose a system architecture that performs semantic -- based searches through an agent in order to plan student-based schedule of course documents automatically according to student's performance in the course of a semester. OWL language of the SW technology is used during the development of the ontology of the LMS system that is used as a knowledgebase and queried to obtain required data. In this article, we concentrate on developing the system as a module for a LMS currently in use.","venue":"2011 IEEE 35th Annual Computer Software and Applications Conference Workshops","year":2011.0,"referenceCount":15,"citationCount":10,"fieldsOfStudy":["Computer Science"],"publicationDate":"2011-07-01","authors":[{"authorId":"21543653","name":"D. \u00c7elik"},{"authorId":"1723633","name":"Atilla El\u00e7i"},{"authorId":"40640997","name":"Eray Elverici"}]},{"paperId":"035f0462ef622d835fa4c084b368d97276efe541","title":"Semantic Extract-Transform-Load framework for Big Data Integration","abstract":"Big Data researchers are dealing with the Variety of data that includes various formats such as structured, numeric, unstructured text data, email, video, and audio. The proposed Semantic Extract-Transform-Load (ETL) framework that uses semantic technologies to integrate and publish data from multiple sources as open linked data provides an extensible solution for effective data integration, facilitating the creation of smart urban apps for smarter living. A case study that integrates datasets, using the proposed framework, from various Massive Open Online Courses and Household travel data along with Fuel Economy data is presented. Keywords\u2014data integration; linked data; ontology engineering; semantic technologies Big Data comprises of data consisting of billions to trillions of records of millions of people all from different sources (e.g. Web, customer contact center, social media, mobile data, sales, etc.). The data is typically loosely structured and is often incomplete and inaccessible. Big Data is transforming science, engineering, medicine, healthcare, finance, business, and ultimately society itself. Massive amounts of data are available to be harvested for competitive business advantage, government policies, and new insights into a broad array of applications (including healthcare, biomedicine, energy, smart cities, genomics, transportation, etc.). Yet, most of this data is inaccessible to users, as we need technology and tools to find, transform, analyze, and visualize data in order to make it consumable for decisionmaking [1]. The research community also agrees that it is important to engineer Big Data meaningfully [2]. Meaningful data integration in a schema-less, and complex Big Data world of databases is a big open challenge. Big Data research is usually discussed in the areas of 3V\u2019s \u2013 Volume (storage of massive amount of data streaming in from social media, sensors, and machine-to-machine data being collected), Velocity (reacting quickly enough to deal with data in near-real time), and Variety (data is in various formats such as structured, numeric, unstructured text data, email, video, audio, stock ticker, etc.). Big Data challenges are not only in storing and managing this variety of data but also extracting and analyzing consistent information from it. Researchers are working on creating a common conceptual model for the integrated data [3]. The method of publishing and linking structured data on the web is called Linked Data. This data is machinereadable, its meaning is explicitly defined, it is linked to other external data sets, and it can be linked to from other data sets as well. The Linked Open Data (LOD) community effort has led to a huge data space, with 31 billion Resource Description Framework (RDF) [4] triples, and a W3C specification for data interchange on the web [5]. LOD can be used in a number of interesting Web and mobile applications. Linking Open Government Data (LOGD) project [6] investigates translating government-related data using Semantic web technologies. LOD has gained significant adoption and momentum, though the quality of the interconnecting relationships remains questionable [7]. IBM Smarter City initiative aims at creating cities that are vital and safe for its citizens and businesses. Their focus is on building the infrastructure for fundamental services\u2014 such as roadways, mass transit and utilities that make a city desirable and livable. IEEE Smart Cities Initiative brings together technology, government and society to enable smart economy, mobility, environment, living, and governance. Both these initiatives have to integrate and use information from various data sources in addition to setting up the required infrastructure. Government agencies are also increasingly making their data accessible through initiatives such as data.gov to promote transparency and economic growth [8]. We need ways to organize variety of data such that concepts with similar meaning are related through links, while the concepts that are distinct are clearly represented as well with semantic metadata. This will allow effective and creative use of query engines and analytic tools for Big Data, which is absolutely essential to create smart and sustainable environments. Figure 1 shows the future vision of a web portal with Linked Open Urban data integrated and published from various sources and domains. The need to integrate Big Data has been heightened in recent years due to a growing demand and interest in mobile applications for improving quality of life in urban cities. Here is an example where various data sources can be used: a traffic jam that emerges due to an unplanned protest may be captured through a Twitter stream, but missed when examining weather conditions, event databases, reported roadwork, etc. Additionally, weather sensors in the city tend to miss localized events such as flooding. These views of the city combined however, can provide a richer and more complete view of the state of the city, by merging traditional data sources with messy and unreliable social media streams thereby contributing to smart living, environment, economy, mobility, and governance. Such applications rely on Big Data available to the public via the cloud. As outlined in the latest McKinsey Global Institute report, we\u2019re now seeing the global economy beginning to operate in real time [9]. The total value generation for the impact of new data technologies will be measured in trillions of dollars globally according to this report. The National Academies press published Visionary Grand Challenges of Manufacturing for 2020 that included as one of the challenges \u2013 ability to instantaneously transform information gathered from a vast array of sources into useful knowledge for making effective decisions. Work has been done on data abstraction and visualization tools for Big Data [10]; analysis of Big Data using various algorithms such as influence-based module mining (IBMM) algorithm, online association rule mining, graph analytics, and provenance analysis support framework all of which are applicable after the data integration phase. Use of semantic technologies has known to improve user interaction with the system, simplified data integration and extensibility, improved search, and improved discovery of knowledge [11]. Figure 1: Linked Open Urban Data portal with integrated data from various sources and domains Traditionally Data Integration has been defined as the problem of combining data residing at different sources, and providing the user with a unified view of these datasets [1314]. A data integration system exposes to its users a schema for posing queries. This schema is typically referred to as a mediated schema (or global schema). To answer queries using the various information sources the system needs mappings that describe the semantic relationships between the mediated schema and the schemas of the sources. Two basic approaches have been proposed for this purpose. The first approach, called global-as-view, requires that the global schema be expressed in terms of the data sources. The second approach, called local-as-view, requires the global schema to be specified independently from the sources, and the relationships between the global schema and the sources are established by defining every source as a view over the global schema [14-15]. These existing approaches were applicable to relational data models and an integrated global schema was determined manually. The proposed framework in this paper is for integration of linked data that is available on the web. MOTIVATING SCENARIO: Consider the following scenario where a typical driver, John gets into his car in the morning and turns on the ignition. A built-in innovative application in the car greets him and asks him if he is going to work based on the time of the day. John responds by saying \u201cyes\u201d and the app replies that the vehicle performance has been optimized for the trip. The built-in system uses the GIS system, road grade data, and speed limits data to create an optimal velocity profile. As John starts driving and is approaching Recker road to turn left, the app informs John about a road repair on Recker road for a 1-mile stretch on his route up to 3pm that day. The app suggests that John should continue driving and take the next left on Power road. John follows the suggestion and answers a text message that he receives from his collaborator. As he is answering the text message, his car drifts into the neighboring lane. The app immediately notifies John of the drift who quickly adjusts his driving. As John approaches his workplace he drives towards Lot 1 where he usually parks. The app informs John that there are only 2 parking spots open in Lot 1. As John is already running late for a meeting, he decides to directly drive to the next parking lot, Lot 2, to avoid spending the time looking for the 2 empty spots in Lot 1. As John enters Lot 2 and is driving towards one of the empty spots, he gets too close to one of the parked cars. The app immediately warns John of a collision. John quickly adjusts his car away from the parked cars and parks in an empty spot. The app logs tracking data about John\u2019s style of driving on the server for future use. In order to build apps for automobiles, access to a number of data sets from various sources is required. Some of this is real-time data that is continuously being updated. Data related to traffic, road repairs, emergencies, accidents, driving habits, maps, parking, fuel economy data, household data, diagnosis data, etc. would be required. Various automotive apps could be built that focus on reducing energy consumption, reducing emissions, provide fuel economy guidance that is based on actual vehicle data, road conditions, traffic, and most importantly personal driving habits and ways to improve them. It is important to effectively integrate data such that the data is tied to a meaningful","venue":"","year":2014.0,"referenceCount":14,"citationCount":5,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"1720381","name":"S. Bansal"}]},{"paperId":"035fce16d65f54131b39c6386ba58675f409a5cb","title":"Using a Dictionary Production System to impose a WordNet on a Dictionary. A Software Presentation","abstract":"In this demonstration, we will make a practical presentation of how a semantic web \u2013 a WordNet \u2013 can be imposed on a dictionary using a Dictionary Production System. Using a WordNet structure makes a lot of sense as there are already several WordNets for different languages which can be used freely. We will demonstrate how we first impose the structure in a rather crude way allowing for lots of ambiguities and then use the various tools in the Dictionary Production System to target the dubious areas and refine them through manual intervention, either as part of a usual editing of a new edition or in a separate run. Finally we will demonstrate how the data can be extracted and made available to a Dictionary Publishing System.","venue":"","year":2010.0,"referenceCount":0,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"72987530","name":"H. Hvelplund"},{"authorId":"52497510","name":"Allan \u00d8rsnes"}]},{"paperId":"03602c8f9b5d599d6f2d6210d7c5d7850598227f","title":"Developing a Modular Hydrogeology Ontology Extending the Sweet Ontologies","abstract":"Application of ontologies in the environmental science will allow experts in this field to model their domain knowledge for more efficient exchange and reuse. This thesis presents a modular approach in reengineering existing upper-level ontologies to conceptualize specific domain knowledge. The aim of extending these upper-level ontologies is to tailor and transform the existing conceptual models into new ones designed for the use in a specific domain in the earth sciences. This thesis extends the upper-level Semantic Web for Earth and Environmental Terminology (SWEET) ontologies to develop ontologies for part of the hydrogeology domain. The existing SWEET ontologies are developed by NASA\u2019s Jet Propulsion lab for Earth system science (http:\/\/sweet.jpl.nasa.gov\/ontology\/). In the new model, presented in this thesis, the architecture and orthogonal design of the SWEET ontologies is not disturbed but restructured at certain levels. New concepts are added to the old structure and the consistency is maintained for use by other domains. This thesis discusses the useful steps, necessary tools and other procedures involved in ontological reengineering of existing upper-level ontologies. The hydrogeology domain modeled in this thesis by means of reengineering, exemplifies the reusability methodology for the Earth system science knowledge base. Base. DEVELOPING A MODULAR HYDROGEOLOGY ONTOLOGY EXTENDING THE","venue":"","year":2005.0,"referenceCount":38,"citationCount":2,"fieldsOfStudy":["Engineering"],"publicationDate":null,"authors":[{"authorId":"2064395471","name":"A. Tripathi"}]},{"paperId":"03603f0f29bbf9c0dd90a311a43d694e689109a8","title":"Adaptation of software engineering to semantic web based system development","abstract":"Recent web technology transitions have forced the software research community and industry alike, to ponder upon adaptation of various aspects of software engineering, in order to maintain their relevance in present scenario. It is imperative to adapt the software engineering paradigm to technologies such as semantic web for quality software. In this report, various attempts at developing software engineering process for semantic web services have been evaluated. Few works are hybrid in nature, dealing with semantic web and software engineering benefits to each other and the interplay of semantic web and software as a service on cloud. This report presents an analysis of such approaches and highlights some issues that need to be addressed. It is revealed that semantic web services are not just a promising future of the web, but a realization in current web too; therefore, by developing a software engineering process for them, we can develop and deploy quality software (as service) on the web.","venue":"2013 International Conference on Emerging Trends in Communication, Control, Signal Processing and Computing Applications (C2SPCA)","year":2013.0,"referenceCount":34,"citationCount":6,"fieldsOfStudy":["Computer Science"],"publicationDate":"2013-10-01","authors":[{"authorId":"2250122","name":"Niyati Baliyan"},{"authorId":"2109726349","name":"Sandeep Kumar"}]},{"paperId":"03611a9d1e0da759d5aca79a5e89c5dc7ac6be79","title":"Using Semantic Web Tools for Context Interchange","abstract":"The Context Interchange Strategy (COIN) is an approach to solving the problem of interoperability of semantically heterogeneous data sources through context mediation. The existing implementation of COIN uses its own notation and syntax for representing ontologies. More recently, the OWL Web Ontology Language is becoming established as the W3C recommended ontology language. A bridge is needed between these two areas and an explanation on how each of the two approaches can learn from each other. We propose the use of the COIN strategy to solve context disparity and ontology interoperability problems in the emerging Semantic Web both at the ontology level and at the data level. In this work we showcase how the problems that arise from context-dependent representation of facts can be mitigated by Semantic Web techniques, as tools of the conceptual framework developed over 15 years of COIN research.","venue":"","year":2007.0,"referenceCount":12,"citationCount":3,"fieldsOfStudy":["Computer Science"],"publicationDate":"2007-09-01","authors":[{"authorId":"1689081","name":"S. Madnick"},{"authorId":"144307089","name":"M. Lupu"}]},{"paperId":"0361344d61bdec00f4fc0030c2c3b0da7c52b03a","title":"A Semantic Web Approach to Experience Management in Public Organisations","abstract":"The Pellucid project is developing a customisable platform for experience management in public organisations. This paper introduces the Pellucid model of experience management, relates it to the design of the platform, and discusses how Semantic Web technologies have been applied in the project. The principal idea is the active hint as a transmitter of experience, generated spontaneously according to the employee\u2019s working context. The working context is modelled using ontologies for work processes and specific domains of work.","venue":"","year":2004.0,"referenceCount":13,"citationCount":1,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"10947435","name":"S. Lambert"},{"authorId":"35809384","name":"\u00c1. Arenas"},{"authorId":"1779087","name":"A. Miles"}]},{"paperId":"03619cefbab1bbfb714e7ebf7fc72d7b4aeae85c","title":"Semantic social networks analysis","abstract":null,"venue":"Social Network Analysis and Mining","year":2013.0,"referenceCount":34,"citationCount":14,"fieldsOfStudy":["Computer Science"],"publicationDate":"2013-03-02","authors":[{"authorId":"2035567","name":"Christophe Thovex"},{"authorId":"2784580","name":"F. Trichet"}]},{"paperId":"03621f504a471376f70cf737b51248117d97f19c","title":"SemanticOrganizer: A Customizable Semantic Repository for Distributed NASA Project Teams","abstract":null,"venue":"International Workshop on the Semantic Web","year":2004.0,"referenceCount":22,"citationCount":26,"fieldsOfStudy":["Computer Science"],"publicationDate":"2004-11-07","authors":[{"authorId":"50337526","name":"R. Keller"},{"authorId":"3278335","name":"D. Berrios"},{"authorId":"3259892","name":"R. Carvalho"},{"authorId":"2082342007","name":"David R. Hall"},{"authorId":"2067553755","name":"Stephen J. Rich"},{"authorId":"2701250","name":"I. Sturken"},{"authorId":"144472627","name":"Keith J. Swanson"},{"authorId":"1766433","name":"S. Wolfe"}]},{"paperId":"036228d2dc2e7bf2a64bf120a42b81a7edf3f5c2","title":"Verifying OWL and ORL Ontologies in PVS","abstract":null,"venue":"International Colloquium on Theoretical Aspects of Computing","year":2004.0,"referenceCount":22,"citationCount":3,"fieldsOfStudy":["Computer Science"],"publicationDate":"2004-09-20","authors":[{"authorId":"50812829","name":"J. Dong"},{"authorId":"2137363","name":"Yuzhang Feng"},{"authorId":"4495301","name":"Yuan-Fang Li"}]},{"paperId":"036269086c498e7e6c6a38b43bc083c5b4f2b632","title":"The Summary of Spatial Interoperability Architecture Integrated Mode","abstract":"In the research of sharing of geographic information, spatial interoperability has become a very important content of space sharing technology. Gradually, general spatial interoperability has become a pronoun of space sharing technology. As the research progressing, the modes and methods of spatial interoperability become diverse. On the basis of analyzing semantic spatial interoperability mode, open geographical data interoperability criterion and distributed isomerous database interoperability architecture, the mainstream GIS platform interoperability products, as well as ISO\/TC211 spatial interoperability service architecture, this paper puts forward a new way to advance the capability of interoperability by improving various interoperability technology and proposes the regularities and trends of spatial interoperability architecture's development. From data transformation to open file format, from standard transformation format to application program interface, from spatial database to web service integration, as well as the rapid development of interoperability technology, the capability of interoperability has improved gradually.","venue":"","year":2006.0,"referenceCount":0,"citationCount":2,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"9421421","name":"Lv Guonian"}]},{"paperId":"036389efcf67baebef8e6da62fc0e4e3c9cc9e98","title":"Research on knowledge service matching method based on semantic similarity","abstract":"For the issue that knowledge services support for business process dynamic building, this paper presents a knowledge service model which regards business activities as clues. The model uses Web Service as its media, it describes enterprise knowledge resources uniformly, packages knowledge resources with a certain function to services. It uses a knowledge service matching algorithm based on semantic similarity, considers service quality similarity and service function similarity, sort ad services in accordance with the similarity in descending order, the highest similarity service is the best service. This method improves the recall and precision, better support for business process building.","venue":"","year":2014.0,"referenceCount":10,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"72470228","name":"XingangWang"},{"authorId":"2058147350","name":"C. Ge"}]},{"paperId":"03640ccb11dc438e192ee28b84ee0bca370eb955","title":"From product data technology to applications: an illustrative case in the AEC domain","abstract":"Handling the fragmentation of the Building industry stands for one of the major challenge of this predominant economic sector in Europe and interoperability between a various range of dedicated applications is the main end-user requirement at a practical level. In that context Product Data Technologies are regarded as a the most promising route to meet the objective. However, the elaboration and further deployment of PDT based applications requires the availability of both suitable Product Data models that conveys the underlying semantics of these applications and software platforms allowing an easy usage of such data models at the implementation level.\n CSTB STEP Platform is first presented that offers an implementation of STEP Standard Data Access Interface. Focus is set on the generic aspect of the platform regarding its ability to support any EXPRESS schema, but also on its architecture that encompasses among others persistence, OLE support and WEB compliance. Attention is then brought to the semantic level and the Industry Foundation Classes are depicted as a promising product data model regarding the needs of the Architecture, Engineering and Construction domain. Building upon these two components, a illustrative application is detailed that evidences the interest of PTD in the Building sector. Elaborated under the auspices of the French chapter of the International Alliance for Interoperability, this application acts as a Building Project Server and allows the co-operation of various AEC software toolkits handling respectively the Architecture design, the HVAC design and the edition of technical documents.","venue":"","year":1998.0,"referenceCount":0,"citationCount":0,"fieldsOfStudy":["Engineering"],"publicationDate":null,"authors":[{"authorId":"70441191","name":"P. Debras"},{"authorId":"95226077","name":"L. MonceyronJ"},{"authorId":"123635648","name":"F. Bauer"},{"authorId":"40186298","name":"P. Ballesta"},{"authorId":"95003973","name":"X. RoccaF"}]},{"paperId":"0364551e8ace294281cbaa2ba09bb719749b3c1a","title":"Application of Ontology and Multivariate Decision Diagram in Cloud Monitor Systems","abstract":"Cloud computing is different from distributed computing and grid computing and has its own characteristics. The existing cloud system is not sufficient in the unified identification of cloud resources and the dynamic joining management of new resources. According to the characteristics of cloud computing, this paper introduces the idea of ontology on cloud monitor system (CMS) based on bionic autonomic nervous system (BANS) and uses ontology web language (OWL) language to describe the resources of the system. It also establishes a reusable extended resource expression model. At the same time, the use of the third-party tool Jena for OWL semantic query also gives the monitoring system the characteristics of a rapid semantic query, which further enhances the convenience of cloud resource management. In addition, based on the application of ontology, we also introduce multivariate decision diagram (MDD) multi-valued decision graph technology, which allows B-CMS to self-diagnose complex system faults. The combination of ontology and MDD greatly simplifies the monitoring and management of large-scale systems, providing a fast and standardized means for the intelligent diagnosis of systems.","venue":"International Journal of Performability Engineering","year":2019.0,"referenceCount":13,"citationCount":1,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"2110982058","name":"Xu Han"},{"authorId":"2112882509","name":"Chul Chung"},{"authorId":"2056595836","name":"L. Jie"}]},{"paperId":"036459344bd01c957a052dd78556379b6830e76d","title":"Semantically enabled exploratory video search","abstract":"With the exponential growth of video data on the World Wide Web comes the challenge of efficient methods in video content management, content-based video search, filtering and browsing. But, video data often lacks sufficient meta-data to open up the video content and to enable pinpoint content-based search. With the advent of the 'web of data' as an extension of the current WWW new data sources can be exploited by semantically interconnecting video meta-data with the web of data. Thus, enabling better access to video repositories by deploying semantic search technologies and improving the user's search experience by supporting exploratory search strategies. We have developed the prototype semantic video search engine 'yovisto' that demonstrates the advantages of semantically enhanced exploratory video search and enables investigative navigation and browsing in large video repositories.","venue":"SEMSEARCH '10","year":2010.0,"referenceCount":36,"citationCount":13,"fieldsOfStudy":["Computer Science"],"publicationDate":"2010-04-26","authors":[{"authorId":"2810514","name":"J. Waitelonis"},{"authorId":"144196238","name":"Harald Sack"},{"authorId":"2282589","name":"Johannes Hercher"},{"authorId":"2104824917","name":"Zalan Kramer"}]},{"paperId":"03676a835f63ba288e67047c65b85656a7c90d6f","title":"Web Service Composition in Mobile Environment: A Survey of Techniques","abstract":"Today, with the exponential rise in the use of the internet, the trend of the massive use of mobile devices (tablets, laptops, computers, iPads etc...) the user has become inseparable from his smartphone, which facilitates the use of several services in different fields (work, research, commerce, etc.). Besides, with the proliferation of data, the needs of consumers are becoming increasingly complex. So the composition of web services remains a necessary process allowing to combine several atomic services aggregating different functionalities to answer a complex request. Several techniques in the literature like, AI planning, work flow, Agent, Mathematics and Semantic. These techniques are mainly involved in the automation and improvement of the composition process. In this article, we will survey several context aware web service composition approaches based on these techniques. Remember that the Mobile environment is characterized by software, hardware and space constraints and Web Service Composition in mobile environment must respect these conditions.","venue":"IEEE Transactions on Services Computing","year":2024.0,"referenceCount":66,"citationCount":1,"fieldsOfStudy":["Computer Science"],"publicationDate":"2024-03-01","authors":[{"authorId":"2975484","name":"Cheyma Ben Njima"},{"authorId":"66149236","name":"Chirine Ghedira Gu\u00e9gan"},{"authorId":"2022098","name":"Youssef Gamha"},{"authorId":"9109307","name":"L. Romdhane"}]},{"paperId":"03679fd63ecb0b54e855bf6a9c1dcab22ff0b470","title":"Tecnolog\u00edas sem\u00e1nticas aplicadas al an\u00e1lisis de redes sociales en el \u00e1mbito de la salud = Semantical technologies applied to social network analysis in health domains","abstract":"Muchos de los investigadores del campo de la salud, aunque tambien de otros campos, se ven en la necesidad de realizar estudios epidemiologicos y mas concretamente estudios transversales. Este tipo de estudios estan basados principalmente en la obtencion de informacion sobre distintos grupos de personas mediante el uso de diferentes encuestas o cuestionarios. Tras la obtencion de los datos generados por los usuarios y sus respuestas a los cuestionarios, es posible aplicar tecnicas de Analisis de Redes Sociales (ARS). Gracias a este tipo de analisis, es posible estudiar las distintas relaciones entre los actores de una red, asi como, mediante una interpretacion exhaustiva por parte de un experto, obtener una serie de conclusiones que pueden ayudar a resolver un problema. Hasta el momento, la recopilacion de datos se ha podido automatizar gracias a la existencia de distintas herramientas. Sin embargo, tras la recopilacion de dichos datos, el experto del dominio en el cual se desea aplicar ARS, debe utilizar aplicaciones para llevar a cabo el analisis y, posteriormente, interpretar dichos valores para obtener una serie de conclusiones concretas.\nA raiz del escenario anteriormente expuesto, surge como objetivo principal de esta investigacion, crear una una solucion informatica capaz de ser utilizada por cualquier profesional del sector de la salud o de cualquier otro sector, que este interesado en realizar estudios mediante cuestionarios personalizados. Para la consecucion de estos objetivos, se ha planteado un modelo conceptual multi-dominio, asi como se han generado una serie de reglas en lenguaje SWRL (Semantic Web Rule Language) y consultas en lenguaje SPARQL (Protocol and RDF Query Language) que pertenecen al ambito de la Web Semantica y en general a las Tecnologias Semanticas, tras la revision bibliografica realizada previamente. Se han elegido estas tecnologias porque gracias a ellas, es posible trasladar un modelo a distintos dominios con relativa facilidad, mientras que, si se hubiera elegido un sistema realizado con tecnologias no semanticas, la escalabilidad y reutilizacion del mismo se hubieran visto perjudicados.\nTras la validacion del modelo y verificacion de los objetivos planteados, se destacan una serie de conclusiones sobre el modelo conceptual multi-dominio. Una de ellas es, la apertura de nuevas posibilidades en el area de la Web Semantica, Sistemas Basados en Conocimiento y los modelos formales semanticos pertenecientes al area de la Inteligencia Artificial, de manera mas especifica, en la concepcion y desarrollo de un nuevo modelo conceptual multi-dominio. Ademas de lo descrito, a partir de dicho modelo, se facilita la busqueda de soluciones en la informacion, la toma de decisiones y el empleo del conocimiento especializado en diferentes dominios de aplicacion de ARS. Tambien, en la utilizacion de dicho conocimiento especializado en diferentes dominios de aplicacion de contenido estructurado y semantico, a su vez, destaca la generacion de informacion relevante sobre distintos ARS aplicados a diferentes ambitos. De esta forma, se permite obtener conclusiones sin disponer de conocimiento directo sobre ARS mediante un Sistema de Recomendacion o Sistema Basado en el Conocimiento.","venue":"","year":2017.0,"referenceCount":0,"citationCount":0,"fieldsOfStudy":["Sociology","Philosophy"],"publicationDate":"2017-12-01","authors":[{"authorId":"1471366789","name":"Ben\u00edtez Andrades"},{"authorId":"2052893399","name":"J. Alberto"}]},{"paperId":"0368a1c43d3cad072dcc6346a3e3fb57fea5382e","title":"Ontology Learning for Semantic Web using Lexical-Semantic Method","abstract":null,"venue":"","year":2014.0,"referenceCount":0,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":"2014-03-25","authors":[{"authorId":"2103522","name":"S. Srinivasulu"},{"authorId":"50597065","name":"P. Sakthivel"},{"authorId":"2104159827","name":"T. Amala"}]},{"paperId":"03695225a13919ca2e7355e1fc6620e8c0112937","title":"Semantify.it, a Platform for Creation, Publication and Distribution of Semantic Annotations","abstract":"The application of semantic technologies to content on the web is, in many regards, important and urgent. Search engines, chatbots, intelligent personal assistants and other technologies increasingly rely on content published as semantic structured data. Yet, the process of creating this kind of data is still complicated and widely unknown. The this http URL platform implements an approach to solve three of the most challenging question regarding the publication of structured semantic data, namely: a) what vocabulary to use, b) how to create annotation files and c) how to publish or integrate annotations within a website without programming. This paper presents the idea and the development of the this http URL platform. It demonstrates that the creation process of semantically annotated data does not have to be hard, shows use cases and pilot users of the created software and presents where the development of this platform or alike projects lead to in the future.","venue":"arXiv.org","year":2017.0,"referenceCount":24,"citationCount":18,"fieldsOfStudy":["Computer Science"],"publicationDate":"2017-06-30","authors":[{"authorId":"2939293","name":"Elias K\u00e4rle"},{"authorId":"3190155","name":"Umutcan Simsek"},{"authorId":"1766239","name":"D. Fensel"}]},{"paperId":"0369f81ae4f569c47d31880ce0cd2653a1945dd7","title":"Proceedings of the International Joint Workshop on Semantic Web and Ontology Design for Cultural Heritage co-located with the Bolzano Summer of Knowledge 2021 (BOSK 2021), Virtual Event \/ Bozen-Bolzano, Italy, September 20-21, 2021","abstract":null,"venue":"International Joint Workshop on Semantic Web and Ontology Design for Cultural Heritage","year":2021.0,"referenceCount":0,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[]},{"paperId":"036aaa7e4e821ad404abfbe6d7920ce45976ead3","title":"Searching Documents on the Intranet","abstract":"Searching for documents on the internet with today\u2019s search engines, which are mainly based on words in a document, is not satisfactory. Results can be improved by also taking the content of a document into account. The Extensible Markup Language (XML) enables us to do semantic tagging and to make the structure of a document explicit. But this describes a document only at the syntactical level. A more ideal situation would be when the XML tagging is also used to define the document at the semantical level. To realize this we allow an author of a document to describe the relevant concepts by means of tags like he would design an object-oriented database schema. In our approach a user searching for a particular document is presented a graphical description of such a schema, that describes the concepts defined for the webspace of an intranet. Via this interface the user can formulate OO-like queries or navigate to relevant web pages. To realize our ideas we are building an architecture based on the concept of an index-database. A prototype is up and running. keywords: concept-based search, intranet, schema, semantic tagging, organizing webspace.","venue":"WOWS","year":1999.0,"referenceCount":15,"citationCount":9,"fieldsOfStudy":["Computer Science"],"publicationDate":"1999-02-18","authors":[{"authorId":"1747340","name":"R. V. Zwol"},{"authorId":"1688692","name":"P. Apers"}]},{"paperId":"036ab3d032fe39c733bf13c43989094a11d3cb4b","title":"Introduction to the 36th International Conference on Logic Programming Special Issue I","abstract":"Applications: Databases, Big Data, Data Integration and Federation, Software Engineering, Natural Language Processing, Web and Semantic Web, Agents, Arti\ufb01cial Intelligence, Bioinformatics, Education, Computational life sciences, Education, Cybersecurity","venue":"Theory and Practice of Logic Programming","year":2020.0,"referenceCount":2,"citationCount":1,"fieldsOfStudy":["Computer Science"],"publicationDate":"2020-09-01","authors":[{"authorId":"17858580","name":"F. Ricca"},{"authorId":"145277911","name":"A. Russo"}]},{"paperId":"036cc3918942bf59f2d3ea6364e7c2a5f0ecbe94","title":"Frontiers of WWW Research and Development - APWeb 2006, 8th Asia-Pacific Web Conference, Harbin, China, January 16-18, 2006, Proceedings","abstract":null,"venue":"Asia-Pacific Web Conference","year":2006.0,"referenceCount":0,"citationCount":128,"fieldsOfStudy":["Computer Science","Medicine"],"publicationDate":"2006-03-01","authors":[{"authorId":"48667278","name":"Xiaofang Zhou"},{"authorId":"2109112886","name":"Jianzhong Li"},{"authorId":"1724393","name":"Heng Tao Shen"},{"authorId":"1716799","name":"M. Kitsuregawa"},{"authorId":"2145048155","name":"Yanchun Zhang"}]},{"paperId":"036e4f2cd159ca742fbe22ee0abf83270bed87d5","title":"An IMAP plugin for SquirrelRDF","abstract":"The Semantic Web aims to make information accessible to both humans and machines, using standard formats for data and making information available in a formal and structured way. Since the advent of RDF (Resource Description Framework) there have been many efforts to extract and convert existing information in this format. In this paper we describe an adapter tool for the IMAP protocol, developed as a plugin of SquirrelRDF1, which allows users to query IMAP mailboxes using SPARQL. The information returned looks like RDF, is always current, and can be reused and integrated inside other applications","venue":"","year":2007.0,"referenceCount":12,"citationCount":3,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"2285858538","name":"Davide Eynard"},{"authorId":"2065372365","name":"John Recker"},{"authorId":"2076459205","name":"Craig Sayers"}]},{"paperId":"036efb5d0f78a4fa2cd95eef36d24ab468e33db1","title":"Top-k Retrieval in Description Logic Programs Under Vagueness for the Semantic Web","abstract":null,"venue":"Scalable Uncertainty Management","year":2007.0,"referenceCount":23,"citationCount":50,"fieldsOfStudy":["Computer Science"],"publicationDate":"2007-10-10","authors":[{"authorId":"1690572","name":"Thomas Lukasiewicz"},{"authorId":"1731970","name":"U. Straccia"}]},{"paperId":"036f71bf428fae2920b251057558a6e9337f8db7","title":"Approximate Knowledge Retrieval","abstract":null,"venue":"","year":2010.0,"referenceCount":0,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"2492793","name":"T. Cao"}]},{"paperId":"03702c882a2b95780f1e5468ced3c66adf1d4467","title":"International Journal \"information Theories & Applications\" Vol.11 a Two Layered Model for Evolving Web Resources","abstract":"In this paper the key features of a two-layered model for describing the semantic of dynamical web resources are introduced. In the current Semantic Web proposal [Berners-Lee et al., 2001] web resources are classified into static ontologies which describes the semantic network of their interrelationships [Kalianpur, 2001][Handschuh & Staab, 2002] and complex constraints described by logical quantified formula [Boley et al., 2001][McGuinnes & van Harmelen, 2004][McGuinnes et al., 2004], the basic idea is that software agents can use techniques of automatic reasoning in order to relate resources and to support sophisticated web application. On the other hand, web resources are also characterized by their dynamical aspects, which are not adequately addressed by current web models. Resources on the web are dynamical since, in the minimal case, they can appear or disappear from the web and their content is upgraded. In addition, resources can traverse different states, which characterized the resource life-cycle, each resource state corresponding to different possible uses of the resource. Finally most resources are timed, i.e. they information they provide make sense only if contextualised with respect to time, and their validity and accuracy is greatly bounded by time. Temporal projection and deduction based on dynamical and time constraints of the resources can be made and exploited by software agents [Hendler, 2001] in order to make previsions about the availability and the state of a resource, for deciding when consulting the resource itself or in order to deliberately induce a resource state change for reaching some agent goal, such as in the automated planning framework [Fikes & Nilsson, 1971][Bacchus & Kabanza,1998].","venue":"","year":null,"referenceCount":5,"citationCount":0,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"1986966","name":"A. Milani"},{"authorId":"2050719","name":"S. Suriani"}]},{"paperId":"03717b0c5a093062ec91c20a6d37157c26cd3974","title":"Comparing DBpedia, Wikidata, and YAGO for Web Information Retrieval","abstract":null,"venue":"Intelligent and Interactive Computing","year":2019.0,"referenceCount":11,"citationCount":15,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"134748069","name":"Sini Govinda Pillai"},{"authorId":"47247517","name":"Lay-Ki Soon"},{"authorId":"2392472","name":"S. Haw"}]},{"paperId":"0372a6f3eac8437d7219d7a203d065cee1badc6b","title":"A fuzzy ontology for medical document retrieval","abstract":"Ontologies represent a method of formally expressing a shared understanding of information, and have been seen by many authors as a prerequisite for the \"Semantic web\". A mapping between query terms and members of an ontology is usually a key part of any ontology enhanced searching tool. However the relative importance of a particular mapping to an overloaded term may be different for different users, and this information is vital for accurate satisfaction of a query.One way of overcoming this problem is the postulation of a \"fuzzy ontology\". By adding a value for degree of membership to each term that is \"overloaded\", for each user or group of users then the recovered documents from ontology mediated search can reflect the likely information need. The author will discuss means of ontology fuzzification, by both analysis of a corpus of documents and the use of a relevance feedback mechanism and some possible extensions to this scheme.","venue":"Australasian Computer Science Week","year":2004.0,"referenceCount":20,"citationCount":103,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"47522124","name":"D. Parry"}]},{"paperId":"03740cfa10857e31765762d2ef448968b0925d93","title":"SWSCE - An automatic Semantic Web Service composition engine","abstract":"In several scenarios, Semantic Web technologies are gaining momentum as the most promising ones to address the issue of integrating services among different entities, possibly belonging to different location. In particular, Semantic Web Service composition can be used when no individual available service can satisfy a specific client request, but (parts of) available services can be composed and orchestrated in order to do it. In this paper we describe SWSCE, a Semantic Web Service Composition Engine, able to automatically performs the composition of Semantic Web Services.","venue":"","year":2008.0,"referenceCount":31,"citationCount":2,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"1970469","name":"Silvia Bonomi"},{"authorId":"69062655","name":"V. Colaianni"},{"authorId":"1698994","name":"F. Patrizi"},{"authorId":"4157002","name":"D. Pozzi"},{"authorId":"2055531701","name":"R. Russo"},{"authorId":"143990588","name":"Massimo Mecella"}]},{"paperId":"03754c25f99f0bdf938616d7b6fee20068a66de1","title":"A net-centric approach to tacit knowledge management","abstract":"Capturing and managing tacit knowledge creates a collective organizational intelligence capability that is the differential for high performance enterprises. Traditional tacit knowledge capture methods are labor-intensive, some of which include mentoring, interviewing and direct observation that rely on the accuracy of those collecting the information. The researchers set out to prove traditional approaches to capturing knowledge assets could be replaced using Web 2.0\/3.0 technologies. This paper introduces an innovative approach to harvest, share and manage tacit knowledge created as a by-product of normal cognitive and technical workflow activities within a net-centric environment. The innovative proto-type model, Most Important Knowledge and Expertise (MIKE), utilizes network sensor, integrated semantic, natural language and computational analysis technologies that incorporate the design of classifiers, corpus and taxonomies to identify tacit knowledge embedded in explicit knowledge found in workforce transactional activity containing both formal content (policy, training, and process guides) and unstructured content (emails, wikis, blogs, instant messaging, and social media). Using this combination of Web 2.0\/3.0 tools and processes to harvest the tacit-to-explicit knowledge from network transactions and then sharing it via a trusted social network offers human resource, learning and knowledge management practitioner's a new solution design and enterprise tacit knowledge management capability. MIKE is a prototype designed to promote tacit knowledge transfer and high performance using a simple yet robust framework of Web 2.0\/3.0 tools to improve expert connectiveness and establish trust networks.","venue":"eChallenges e-2010 Conference","year":2010.0,"referenceCount":1,"citationCount":1,"fieldsOfStudy":["Computer Science"],"publicationDate":"2010-10-01","authors":[{"authorId":"2215696618","name":"Michael L. Brown"},{"authorId":"32376283","name":"Michael J. Kruger"}]},{"paperId":"037572bf9b1ec42320477d6a5423079abd64ce9f","title":"Semantic Image Retrieval based on Ontology and Relevance Model - A Preliminary Study","abstract":"Modern Web search engines index hundreds of millions of images. To search these images is a daunting task for the user who can, realistically, only visually inspect a handful. In general, the way the user responds to an information need depends on the task at hand. Further, some tasks will require browsing, while others are targeted and require a more directed approach. In this paper, we present the preliminary results of research to develop a framework for applying semantics to enhance image retrieval. We consider this problem on two separate levels. First, we consider the application of an Ontology to define the semantic query space for image search and navigation, as well as to approximate the users context for the search. Secondly, in order to further improve upon the search results we apply the Relevance model, using data from the web to train the model. The role of the Relevance Model is to rank images from the search engine. The study also investigates how application of an ontology affects the quantity and quality the retrieved images and also the effects to the exp erience of the user in image search. We then contrast the results with those obtained by the Relevance Model for exactly similar search terms. The Relevance Model is based on a probabilistic model, which applies user definable language models to the text linking to the image. In our Relevance Model, the relevance of a HTML document linking to an image is evaluated and assigned with respect to highly ranked textual documents from the web. The ranking of the HTML document, is also assigned to ranking of the respective image. The main advantage here is that the Relevance Model can be learnt from the Web without any preparation of training data and is independent of the underlying algorithm of the image search engines. We show that navigation is indeed a very powerful tool for image browsing and that using the ontology dramatically enhances recall for specialized terms. Relevance feedback mainly improves precision by effective re-ranking. Keyword: Web Image Search, Language Model, Relevance Model, Wordnet, Ontology","venue":"Journal of Digital Information Management","year":2005.0,"referenceCount":8,"citationCount":6,"fieldsOfStudy":["Computer Science"],"publicationDate":"2005-12-01","authors":[{"authorId":"27521927","name":"Ernest Weke Maina"},{"authorId":"46592126","name":"Manabu Ohta"},{"authorId":"1700219","name":"Kaoru Katayama"},{"authorId":"145102331","name":"H. Ishikawa"}]},{"paperId":"03757899f1439627c31f00a53ef2860dae39a907","title":"Exploring Web Semantic Knowledge and User Feedback to Improve Ontology Matching","abstract":"The first step to integrate multiple data sources is to decrease the heterogeneity between their schemas. This task can be facilitated if data source schemas are represented as ontologies. In this case, ontology matching enables the identification of correspondences between elements of data source schemas. We propose an ontology matching approach to improve the accuracy of correspondences using an additional source of knowledge. We take advantage of the knowledge available on the Semantic Web obtaining an ontology to be used as background knowledge. Semantic rules are executed in order to discover new correspondences between ontology elements. Our approach also offers to the users the possibility of rejecting invalid correspondences. These rejections are stored and used on further executions of the ontology matching to remove invalid correspondences.","venue":"2011 22nd International Workshop on Database and Expert Systems Applications","year":2011.0,"referenceCount":21,"citationCount":7,"fieldsOfStudy":["Computer Science"],"publicationDate":"2011-08-29","authors":[{"authorId":"145935908","name":"Thiago Pach\u00eaco"},{"authorId":"1725475","name":"Carlos Eduardo S. Pires"},{"authorId":"2792154","name":"A. Salgado"}]},{"paperId":"0378d5af1e81b91c9b441372fa803bb50f04ea12","title":"Ontology Creation towards an Intelligent Web: Some Key Issues Revisited","abstract":"44 Abstract \u2014As we are aware that there is a need of extending the current web to an intelligent web which may result in meaningful or efficient retrieval of information on web. Sir Tim Berner\u2019s Lee, the father of web, has proposed a layered architecture of such a web known as semantic web where Ontology layer is of prime significance. One of the primary goal of Semantic Web is to store data in distributed locations and to use ontologies to aggregate or use it. There is a need of global information sharing and establishment of an appropriate standard known as Ontology to define the conceptual level of a metalanguage,which is described as sharable conceptualization of a specific domain of interest in a machine-understandable format which is also the goal of semantic web. Now, Ontology has several issues among which Ontology creation is the first and the most fundamental and significant aspect. Ontology creation is abstract and has various key issues concerned. It may be created in several ways where creating an ontology using some ontology building tool\/editor is one of the methodology. Prot\u00e9g\u00e9 is one of the most widely used tool or editor for ontology creation. Sometimes, large team-engineered ontologies are not sufficient to illustrate semantic web\u2019s full potential. There is a need of a specification for expressing personal and relationship information within the Semantic Web community. Using Semantic Web applications for social networks, automated aggregation of a user\u2019s distributed social connections will give a better picture of their profile and improve the functioning of the applications. FOAF(Friend-Of-A-Friend) Ontology\/vocabulary may be a good solution for it. There are millions of FOAF profiles online, hosted at a number of websites. The way it is used satisfies the goal of using an ontology to represent considerable amounts of distributed data in a standard form. In this paper, first, we revisit, discuss and analyse about Ontology creation and it\u2019s various key aspects. Second , we illustrate an aspect of an Ontology creation using prot\u00e9g\u00e9 3.4 for the \u201cUniversity School of Information Technology(USIT)\u201d of Indraprastha University, Delhi, India. Third, it also illustrates the query retrieval using query tab of prot\u00e9g\u00e9 and TGviz tab for providing the route of the ontology with a graph to reach to any classes or subclasses. Finally,FOAF(Friend-ofA-Friend) Ontology has been revisited and highlighted illustrating a FOAF profile snippet generation using an online tool, Foaf-a-Matic.","venue":"","year":2011.0,"referenceCount":15,"citationCount":7,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"2286200736","name":"S. K. Malik"},{"authorId":"2054198297","name":"N. Prakash"},{"authorId":"11606312","name":"S. Rizvi"}]},{"paperId":"03794fbddee142b484dddfd3fc5d77cef8386ce8","title":"Emir : Semantics in Multimedia Retrieval and Annotation","abstract":"As shown by recent studies it is estimated that there will be nearly 300 million digital image capture devices in use worldwide through 2004, capturing about 29 billion digital pictures, most of which will be organised in some kind of multimedia repository and available via the World Wide Web or through some other means of sharing data [Infotrend, 04]. Many of these images need to be stored, sorted and retrieved by using personal digital library applications. MPEG-7 offers a range of standardized description methods for generating metadata for multimedia content and allows ontology-like semantic descriptions. Caliph & Emir is a pair of applications that use MPEG-7 for annotation and search of digital photos focusing on semantic descriptions.","venue":"","year":2004.0,"referenceCount":9,"citationCount":23,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"1786883","name":"M. Lux"},{"authorId":"2389675","name":"M. Granitzer"},{"authorId":"2386755","name":"W. Klieber"}]},{"paperId":"03795ce51480f465fba9bf84a18d488dbbb3aa56","title":"Generating and Querying Semantic Web Environments for Photo Libraries (2005)","abstract":"Online photo libraries require a method to efficiently search a collection of photographs, and retrieve photos with similar attributes. Our motivation was to incorporate an existing collection of over 250 photographs of over 200 faculty members and events spanning 7 decades into a library called CS PhotoHistory that is available in hypertext and on the Semantic Web. In this paper, we identify challenges related to making this repository available on the Semantic Web, including issues of automation, modeling, and expressivity. Using CS PhotoHistory as a case study, we describe the process of creating an ontology and a querying interface for interacting with a digital photo library on the Semantic Web.","venue":"","year":2005.0,"referenceCount":17,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"46313718","name":"A. Axelrod"},{"authorId":"1713898","name":"J. Golbeck"},{"authorId":"1740403","name":"B. Shneiderman"}]},{"paperId":"037d708acdba33c55bee5a209c3c87a71266022c","title":"LinkProbe: Probabilistic inference on large-scale social networks","abstract":"As one of the most important Semantic Web applications, social network analysis has attracted more and more interest from researchers due to the rapidly increasing availability of massive social network data. A desired solution for social network analysis should address the following issues. First, in many real world applications, inference rules are partially correct. An ideal solution should be able to handle partially correct rules. Second, applications in practice often involve large amounts of data. The inference mechanism should scale up towards large-scale data. Third, inference methods should take into account probabilistic evidence data because these are domains abounding with uncertainty. Various solutions for social network analysis have existed for quite a few years; however, none of them support all the aforementioned features. In this paper, we design and implement LinkProbe, a prototype to quantitatively predict the existence of links among nodes in large-scale social networks, which are empowered by Markov Logic Networks (MLNs). MLN has been proved to be an effective inference model which can handle complex dependencies and partially correct rules. More importantly, although MLN has shown acceptable performance in prior works, it is also reported as impractical in handling large-scale data due to its highly demanding nature in terms of inference time and memory consumption. In order to overcome these limitations, LinkProbe retrieves the k-backbone graphs and conducts the MLN inference on both the most globally influencing nodes and most locally related nodes. Our extensive experiments show that LinkProbe manages to provide a tunable balance between MLN inference accuracy and inference efficiency.","venue":"IEEE International Conference on Data Engineering","year":2013.0,"referenceCount":33,"citationCount":18,"fieldsOfStudy":["Computer Science"],"publicationDate":"2013-04-08","authors":[{"authorId":"50689114","name":"Haiquan Chen"},{"authorId":"1758909","name":"Wei-Shinn Ku"},{"authorId":"2109590665","name":"Haixun Wang"},{"authorId":"144961763","name":"L. Tang"},{"authorId":"1717206","name":"Min-Te Sun"}]},{"paperId":"037f372e9696120ec5b3e31ff1555d24fd2dd835","title":"Exploring New Ways for Personalized E-Commerce through Digital TV","abstract":null,"venue":"Semantic Hyper\/Multimedia Adaptation","year":2013.0,"referenceCount":38,"citationCount":1,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"1397828435","name":"Y. Blanco-Fern\u00e1ndez"},{"authorId":"1785864","name":"Mart\u00edn L\u00f3pez Nores"},{"authorId":"1397828437","name":"J. Pazos-Arias"},{"authorId":"1398392509","name":"M. I. Mart\u00edn-Vicente"}]},{"paperId":"037f4fb4431c3c42bf1ea79f59020576de2b7583","title":"Enhancing Data and Processes Integration and Interop- Erability in Emergency Situations: a Sws Based Emer- Gency Management System Conference Item Enhancing Data and Processes Integration and Interoperability in Emergency Situations: a Sws Based Emergency Management System","abstract":"(2006). Enhancing data and processes integration and interoperability in emergency situations: a SWS based emergency management system. Copyright and Moral Rights for the articles on this site are retained by the individual authors and\/or other copyright owners. For more information on Open Research Online's data policy on reuse of materials please consult the policies page. Abstract. In this paper we describe a powerful use case application in the area of emergency situations management in which to illustrate the benefits of a system based on Semantic Web Services (SWS), through the automation of the business processes involved. After creating Web services to provide spatial data to third parties through the Internet, semantics and domain ontologies were added to represent the business processes involved, allowing: ease of access and combination of heterogeneous data from different providers; and automatic discovery, access and composition to perform more complex tasks. In this way, our prototype contributes to better management of emergency situations by those responsible. The work described is supported by the DIP (Data, Information and Process Integration with Semantic Web Services) project. DIP (FP6 \u2013 507483), an Integrated Project funded under the European Union's IST programme.","venue":"","year":null,"referenceCount":13,"citationCount":0,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"1789746","name":"A. Gugliotta"},{"authorId":"2066790081","name":"R. Davies"},{"authorId":"2286060654","name":"Leticia Gutiez-Villar"},{"authorId":"1790006","name":"Vlad Tanasescu"},{"authorId":"2285064885","name":"J. Domingue"},{"authorId":"2142181","name":"M. Rowlatt"},{"authorId":"40429767","name":"M. Richardson"},{"authorId":"2286048589","name":"Stincic"},{"authorId":"2286067349","name":"Sandra"},{"authorId":"1789746","name":"A. Gugliotta"},{"authorId":"1403976238","name":"Leticia Guti\u00e9rrez-Villar\u00edas"},{"authorId":"1790006","name":"Vlad Tanasescu"},{"authorId":"2285064885","name":"J. Domingue"},{"authorId":"2142181","name":"M. Rowlatt"},{"authorId":"1893494","name":"Sandra Stincic"}]},{"paperId":"037f5fc589696473926d77a1e0fa6ac3a16cc83b","title":"Design Environment for Adaptive Web Application Development","abstract":"This master thesis, along with the Hera Studio application, is the result of my graduation project at the Hera research group [1] of the Technische Universiteit Eindhoven. The Hera research group focuses on research in the area of Web Engineering and Web-based Information Systems (WIS). Because modern WISs have complex structures and are difficult to implement, various design approaches are developed. Hera is the name of a model-driven methodology, developed by the Hera research group, for designing WISs, using the separation-of-concerns principle which distinguishes the content data from the navigational structure and from the presentational issues, resulting in three layers: semantic layer, application layer and presentation layer. The specification in each layer is captured by means of one or more models. The Hera methodology [2] is part of the Hera framework which also contains an engine, called the Hera Presentation Generator (HPG) [3]. This engine interprets the Hera models (the WIS specification) and implements a WIS. Currently HPG needs the models to be specified in the RDFS\/XML [4] format. Because RDFS\/XML is a verbose format and creating it by hand is tedious and error prone, editors were developed which facilitate the construction of the models by providing ways to visually construct them. However, the current model editors have several shortcomings. The goal of the project was the development of an application, called Hera Studio, for designing WISs with improved model editors. This thesis reports the way how Hera Studio is designed and implemented. Hera Studio features a model editor, capable of constructing two types of models and exporting them to RDFS\/XML. These model types are also defined in this thesis by means of meta-models.","venue":"","year":2006.0,"referenceCount":17,"citationCount":0,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"2077264490","name":"Ren\u00e9 Kochen"}]},{"paperId":"037f870b9cafda26a34cb9b439ee8c3f0f229704","title":"An Effective and Efficient Re-ranking Framework for Social Image Search","abstract":null,"venue":"International Conference on Database Systems for Advanced Applications","year":2020.0,"referenceCount":26,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":"2020-09-24","authors":[{"authorId":"2064915794","name":"Bo Lu"},{"authorId":"14886336","name":"Ye Yuan"},{"authorId":"2329311","name":"Yurong Cheng"},{"authorId":"8349792","name":"Guoren Wang"},{"authorId":"2067779889","name":"Xiaodong Duan"}]},{"paperId":"037fdd7c6e63ef519b9573dff8fe79781d6233d9","title":"A Community based Approach for Managing Ontology Alignments","abstract":"The Semantic Web is rapidly becoming a defacto distributed repository for semantically represented data, thus leveraging on the added on value of the network e\ufb00ect. Various ontology mapping techniques and tools have been devised to facilitate the bridging and integration of distributed data repositories. Nevertheless, ontology mapping can bene\ufb01t from human supervision to increase accuracy of results. The spread of Web 2.0 approaches demonstrate the possibility of using collaborative techniques for reaching consensus. While a number of prototypes for collaborative ontology construction are being developed, collaborative ontology mapping is not yet well investigated. In this paper, we describe a prototype that combines o\ufb00-the-shelf ontology mapping tools with social software techniques to enable users to collaborate on mapping ontologies.","venue":"Organizational Memories","year":2008.0,"referenceCount":28,"citationCount":13,"fieldsOfStudy":["Computer Science"],"publicationDate":"2008-10-26","authors":[{"authorId":"3132568","name":"Gianluca Correndo"},{"authorId":"145842687","name":"Harith Alani"},{"authorId":"37836120","name":"P. Smart"}]},{"paperId":"03809784015d6739c9bae0f3b60cce23e8b69d3c","title":"A Linked-Data-Driven and Semantically-Enabled Journal Portal for Scientometrics","abstract":null,"venue":"International Workshop on the Semantic Web","year":2013.0,"referenceCount":19,"citationCount":48,"fieldsOfStudy":["Computer Science"],"publicationDate":"2013-10-21","authors":[{"authorId":"46972426","name":"Yingjie Hu"},{"authorId":"1727108","name":"K. Janowicz"},{"authorId":"2486029","name":"Grant McKenzie"},{"authorId":"2069875011","name":"Kunal Sengupta"},{"authorId":"1699771","name":"P. Hitzler"}]},{"paperId":"0381ca3615ca9cc0e737b99559f1adc1b6576694","title":"Knowledge Modelling for Deductive Web Mining","abstract":null,"venue":"International Conference Knowledge Engineering and Knowledge Management","year":2004.0,"referenceCount":34,"citationCount":16,"fieldsOfStudy":["Computer Science"],"publicationDate":"2004-10-05","authors":[{"authorId":"1740821","name":"V. Sv\u00e1tek"},{"authorId":"1708672","name":"M. Labsk\u00fd"},{"authorId":"2875292","name":"Miroslav Vacura"}]},{"paperId":"0383028036137221d086e920f0e0282e6bdabfee","title":"A Geospatial Semantic Web Visual Query Tool","abstract":"As geospatial data are becoming more widely used through mobile devices and location sensitive applications, the potential value of linked open geospatial data in particular has grown, and a foundation is being developed for the Semantic Geospatial Web. Protocols such as GeoSPARQL and stSPARQL extend SPARQL in order to take advantage of spatial relationships inherent in geospatial data. This paper presents GeoQuery, a graphical geospatial query tool that is based on Semantic Web technologies. GeoQuery presents a map-based user interface to geospatial search functions and geospatial operators. Rather than using a proprietary geospatial database, GeoQuery enables queries against any GeoSPARQL endpoint by translating queries expressed via its graphical user interface into GeoSPARQL queries, allowing geographic information scientists and other Web users to query linked data without knowing GeoSPARQL syntax.","venue":"","year":2014.0,"referenceCount":13,"citationCount":1,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"7933190","name":"Ralph F. Grove"},{"authorId":"2115382120","name":"James Wilson"},{"authorId":"3123807","name":"Dave Kolas"},{"authorId":"2285265","name":"N. Wiegand"}]},{"paperId":"0384d35971cc578b774e11597e2bade04ade0f73","title":"Enhanced Search Method for Ontology Classification","abstract":"The Web ontology language (OWL) has become a W3C recommendation to publish and share ontologies on the semantic web. In order to derive hidden information (classification, satisfiability and realization) of OWL ontology, a number of OWL reasoners have been introduced. Most of reasoners use both top-down and bottom-up search for ontology classification. In this paper, we propose an enhanced method of optimizing the ontology classification process of ontology reasoning. One goal of this paper is to provide such a available algorithm for future implementers of ontology reasoning system. Building the optimization method that came off best into ontology reasoning system greatly enhanced its efficiency. Our work focuses on two key aspects: The first and foremost, we describe classical methods for ontology classification. As subsumption testing to classify ontology is costly, it is important to ensure that the classification process uses the smallest number of tests. Therefore, we consider enhanced method and evaluate their effect on four different types of test ontology. The result of the experiment was that the enhanced search method increases performance improvement 30% something like that compare with the classical method.","venue":"2008 IEEE International Workshop on Semantic Computing and Applications","year":2008.0,"referenceCount":8,"citationCount":6,"fieldsOfStudy":["Computer Science"],"publicationDate":"2008-07-10","authors":[{"authorId":"2109233076","name":"J.-M. Kim"},{"authorId":"2107607310","name":"S. Kwon"},{"authorId":"33869780","name":"Y.-T. Park"}]},{"paperId":"03862a86decc4accc66aea3a1ea6fe1ed8a86c1d","title":"VOLT: A Provenance-Producing, Transparent SPARQL Proxy for the On-Demand Computation of Linked Data and its Application to Spatiotemporally Dependent Data","abstract":null,"venue":"Extended Semantic Web Conference","year":2016.0,"referenceCount":12,"citationCount":20,"fieldsOfStudy":["Computer Science"],"publicationDate":"2016-05-29","authors":[{"authorId":"3404528","name":"Blake Regalia"},{"authorId":"1727108","name":"K. Janowicz"},{"authorId":"152277141","name":"Song Gao"}]},{"paperId":"0386802fd4438cf007d583d2dd4fa065de501095","title":"Augmenting Human Computed Lightweight Semantics","abstract":"Semantic web has to overcome several challenges ranging from web resource annotation to domain modelling. Acquiring general or domain knowledge ontologies is done by automated approaches with only limited sucess or is left to costly human experts. Games with a Purpose offer an opportunity to employ broader crowd of laics into these tasks by transforming tasks to the appealing fun. We build upon our previous research of the Little Search Game, a search query formulation game for acquiring lightweight network of unnamed term relationships. We analyze these relationships for types and argue for suitability of this network to provide non-taxonomic relationships, so much needed in existing knowledge bases.","venue":"","year":2011.0,"referenceCount":8,"citationCount":1,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"3165716","name":"Jakub Simko"}]},{"paperId":"0386c7629d0e805f0d5ed63c608076386a353e5e","title":"Extraction and Semantic Annotation of Workshop Proceedings in HTML Using RML","abstract":null,"venue":"SemWebEval@ESWC","year":2014.0,"referenceCount":7,"citationCount":14,"fieldsOfStudy":["Computer Science"],"publicationDate":"2014-05-25","authors":[{"authorId":"1722023","name":"Anastasia Dimou"},{"authorId":"2701137","name":"M. V. Sande"},{"authorId":"2370758","name":"Pieter Colpaert"},{"authorId":"2925775","name":"Laurens De Vocht"},{"authorId":"1723397","name":"R. Verborgh"},{"authorId":"1691320","name":"E. Mannens"},{"authorId":"144520698","name":"R. Walle"}]},{"paperId":"0386cff06cfc6d53d895a350d1cc29dee43c1c66","title":"Probabilistic Relational Models for Operational Risk: A New Application Area and an Implementation Using Domain Ontologies","abstract":null,"venue":"","year":2012.0,"referenceCount":14,"citationCount":1,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"49773417","name":"Marcus Spies"}]},{"paperId":"038901331eb1b274774401bdc7d08f58878e9757","title":"Web Services Orchestration in the WebContent Semantic Web Framework","abstract":"We present the design and implementation of a Web services orchestration engine developed to support the WebContent semantic Web framework. This framework is under development in the context of the WebContent project, whose goal is to provide a scalable and robust platform for the development of semantic content management applications for diverse domains. The WebContent framework is based on a set of core services able to perform the main tasks associated with semantic content and data management, as well as on the adoption of a common document model based on XML, which facilitates the exchange and retrieval of information. Our contribution lies in providing the necessary infrastructure to effectively and efficiently coordinate the diverse services and data sources, thus facilitating the rapid development of flexible and reliable applications.","venue":"Mexican International Conference on Computer Science","year":2008.0,"referenceCount":16,"citationCount":4,"fieldsOfStudy":["Computer Science"],"publicationDate":"2008-10-06","authors":[{"authorId":"1405410806","name":"V\u00edctor Cuevas-Vicentt\u00edn"},{"authorId":"1393643717","name":"Genoveva Vargas-Solar"},{"authorId":"1681227","name":"C. Collet"}]},{"paperId":"0389a3b0fcdb4c244628e603ffaff620f6575bfc","title":"Incorporating Deep Visual Features into Multiobjective based Multi-view Search Results Clustering","abstract":"Current paper explores the use of multi-view learning for search result clustering. A web-snippet can be represented using multiple views. Apart from textual view cued by both the semantic and syntactic information, a complimentary view extracted from images contained in the web-snippets is also utilized in the current framework. A single consensus partitioning is finally obtained after consulting these two individual views by the deployment of a multiobjective based clustering technique. Several objective functions including the values of a cluster quality measure measuring the goodness of partitionings obtained using different views and an agreement-disagreement index, quantifying the amount of oneness among multiple views in generating partitionings are optimized simultaneously using AMOSA. In order to detect the number of clusters automatically, concepts of variable length solutions and a vast range of permutation operators are introduced in the clustering process. Finally, a set of alternative partitioning are obtained on the final Pareto front by the proposed multi-view based multiobjective technique. Experimental results by the proposed approach on several benchmark test datasets of SRC with respect to different performance metrics evidently establish the power of visual and text-based views in achieving better search result clustering.","venue":"International Conference on Computational Linguistics","year":2018.0,"referenceCount":40,"citationCount":3,"fieldsOfStudy":["Computer Science"],"publicationDate":"2018-08-01","authors":[{"authorId":"47277026","name":"Sayantan Mitra"},{"authorId":"144231505","name":"Mohammed Hasanuzzaman"},{"authorId":"145470045","name":"S. Saha"},{"authorId":"144315616","name":"Andy Way"}]},{"paperId":"0389bab58a970f381ba85643b4b301cda3b07ca3","title":"Linguistic repercussions of COVID-19: A corpus study on four languages","abstract":"Abstract The global reach of the COVID-19 pandemic and the ensuing localized policy reactions provides a case to uncover how a global crisis translates into linguistic discourse. Based on the JSI Timestamped Web Corpora that are automatically POS-tagged and accessible via SketchEngine, this study compares French, German, Dutch, and English. After identifying the main names used to denote the virus and its disease, we extracted a total of 1,697 associated terms (according to logDice values) retrieved from news media data from January through October 2020. These associated words were then organized into categories describing the properties of the virus and the disease, their spatio-temporal features and their cause\u2013effect dependencies. Analyzing the output cross-linguistically and across the first 10 months of the pandemic, a fairly stable semantic discourse space is found within and across each of the four languages, with an overall clear preference for visual and biomedical features as associated terms, though significant diatopic and diachronic shifts in the discourse space are also attested.","venue":"Open Linguistics","year":2022.0,"referenceCount":27,"citationCount":1,"fieldsOfStudy":["Medicine"],"publicationDate":"2022-01-01","authors":[{"authorId":"2071828727","name":"E. Cartier"},{"authorId":"31265584","name":"A. Onysko"},{"authorId":"1412653163","name":"Esme Winter-Froemel"},{"authorId":"66114631","name":"E. Zenner"},{"authorId":"40374369","name":"Gisle Andersen"},{"authorId":"1408396902","name":"B\u00e9ryl Hilberink-Schulpen"},{"authorId":"3493661","name":"U. Nederstigt"},{"authorId":"2059365624","name":"Elizabeth Peterson"},{"authorId":"151478979","name":"Frank van Meurs"}]},{"paperId":"038d05b86b98acc48be967730e9f6d813b02ee2f","title":"Sharing-Aware Scheduling of Web Services","abstract":null,"venue":"Asia-Pacific Web Conference","year":2014.0,"referenceCount":15,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":"2014-09-05","authors":[{"authorId":"2157886917","name":"Junyan Jiang"},{"authorId":"87738912","name":"Zhiyong Peng"},{"authorId":"2108067682","name":"Xiaoying Wu"},{"authorId":"2065692039","name":"Nan Liang"}]},{"paperId":"038d4fb53c77aa87cd4762bea62ba314327ab8d4","title":"Improving Link Analysis through Considering Hosts and Blocks","abstract":"Link analysis has shown great potential in Web structure mining. Most existing link analysis methods treat a Web page as a node, a hyperlink as an edge in the Web graph. However, in reality, a Web page's importance is also affected by its semantic factor, the structure of WWW, and other factors. Therefore, traditional link analysis methods may not be so precise in reality. It is observed that the WWW has three layers: host layer, Web page layer and host layer. Based on this concept, it is considered merging the host-page relationship and the page-block relationship to improve the result of link analysis. Experiment results demonstrate the effectiveness of our approach","venue":"International Conference on Wirtschaftsinformatik","year":2006.0,"referenceCount":8,"citationCount":1,"fieldsOfStudy":["Computer Science"],"publicationDate":"2006-12-18","authors":[{"authorId":"73440991","name":"Qiang Wang"},{"authorId":"2157170387","name":"Yan Liu"},{"authorId":"3097083","name":"Junyong Luo"},{"authorId":"2056973172","name":"Jing Ning"},{"authorId":"2053124536","name":"Qing Yao"}]},{"paperId":"038e73ace49a6a6baddc7e3a4a4bb328834393c1","title":"Towards Near Real-Time Social Recommendations for the Enterprise","abstract":null,"venue":"Innovations in Knowledge Management","year":2016.0,"referenceCount":31,"citationCount":0,"fieldsOfStudy":["Business","Computer Science"],"publicationDate":null,"authors":[{"authorId":"35087883","name":"Benjamin Heitmann"},{"authorId":"46606883","name":"Maciej Dabrowski"},{"authorId":"144547839","name":"Conor Hayes"},{"authorId":"143894626","name":"K. Griffin"}]},{"paperId":"038ffb7566e74e8dc6ea3047a522914b81cccba7","title":"VAMP: Semantic Validation of MPEG-7 Proles","abstract":"This paper describes the VAMP web application for the validation of MPEG-7 descriptions with respect to semantic constraints dened in a prole. The","venue":"","year":2007.0,"referenceCount":10,"citationCount":1,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"1725855","name":"M. Hausenblas"},{"authorId":"35537256","name":"W. Bailer"},{"authorId":"116986618","name":"Forschungsgesellschaft mbH"},{"authorId":"1684267","name":"Raphael Troncy"},{"authorId":"103420045","name":"Cwi Amsterdam"}]},{"paperId":"039342c37d6efbcea1ee6e43f73e241386939806","title":"Dynamic Customization and Validation of Product Data Models Using Semantic Web Tools","abstract":null,"venue":"Product Lifecycle Management","year":2012.0,"referenceCount":13,"citationCount":5,"fieldsOfStudy":["Computer Science"],"publicationDate":"2012-07-09","authors":[{"authorId":"3420093","name":"Sylv\u00e8re Krima"},{"authorId":"2048059","name":"A. B. Feeney"},{"authorId":"1784025","name":"S. Foufou"}]},{"paperId":"0393df97b6bb9ea7050e5fa2c0177c481c55374d","title":"Research on Semantic Discovery Technology of Parts Based on Knowledge Reuse","abstract":"Organization should focus on how to implement effection mechanics of knowledge reuse so as to improve its core competitiveness under the era of big data. The maturity of semantic web technology has brought new opportunities for knowledge reuse. First of all, through the semantic description to achieve the relationship between the characteristics of the parts, the capture of attributes. Secondly, construct a network of semantic information structure, which describes the relationship between the parts of the characteristics, the relationship between the characteristics and the relationship between the attributes, the intrinsic link between the relationship. Finally, through the design of \"knowledge reuse discovery algorithm based on knowledge similarity\" to meet the demand of service engine's knowledge reuse. In this paper, the knowledge collection is added to the database, through the design of the discovery algorithm to obtain the design requirements of the parts in the database, to provide effective knowledge service for parts decision.","venue":"International Conference on Intelligent Human-Machine Systems and Cybernetics","year":2016.0,"referenceCount":20,"citationCount":0,"fieldsOfStudy":["Engineering"],"publicationDate":"2016-08-01","authors":[{"authorId":"2153078415","name":"Cheng Xu"},{"authorId":"2101569532","name":"Zhang Yu-Shi"}]},{"paperId":"03941a6b46954c17b42453d63522eee4efe45cb2","title":"Corda Security Ontology: Example of Post-Trade Matching and Confirmation","abstract":". Blockchain technology is ready to revolutionise the \ufb01nancial industry. The \ufb01nancial industry has various security challenges (e.g., tampering, repudiation, denial of service, etc) . Also, the domain of information security has problems related to conceptual ambiguity and the semantic gap. The Corda platform provides suitable technological infrastructure to build the blockchain-based application (CorDapp) in the \ufb01nancial industry to overcome security challenges. In this paper, we build a Corda-based security ontology (CordaSecOnt) to improve the security of \ufb01nancial industry from an ontological analysis that combines blockchain-based Corda platform. We use Web ontology language (OWL) to build a semantic knowledge base to eliminate conceptual ambiguity and semantic gap in information security. Our ontology provides classi\ufb01-cations of assets, security criteria, threats, vulnerabilities, risk treatments, security requirements, countermeasures and their relations. We evaluate the ontology by performing security risk management (SRM) of capital market post-trade matching and con\ufb01rmation.","venue":"Baltic Journal of Modern Computing","year":2020.0,"referenceCount":57,"citationCount":7,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"37390344","name":"Mubashar Iqbal"},{"authorId":"2112115","name":"Raimundas Matulevi\u010dius"}]},{"paperId":"039639999bd46b91bfb2d14813f29c447e0d1103","title":"Smart Browser based on Semantic Web using RFID Technology","abstract":"Data entered into RFID tags are used for saving costs and enhancing competitiveness in the development of applications in various industrial areas. RFID readers perform the identification and search of hundreds of objects, which are tags. RFID technology that identifies objects on request of dynamic linking and tracking is composed of application components supporting information infrastructure. Despite their many advantages, existing applications, which do not consider elements related to real.time data communication among remote RFID devices, cannot support connections among heterogeneous devices effectively. As different network devices are installed in applications separately and go through different query analysis processes, there happen the delays of monitoring or errors in data conversion. The present study implements a RFID database handling system in semantic Web environment for integrated management of information extracted from RFID tags regardless of application. Users\u2019 RFID tags are identified by a RFID reader mounted on an application, and the data are sent to the RFID database processing system, and then the process converts the information into a semantic Web language. Data transmitted on the standardized semantic Web base are translated by a smart browser and displayed on the screen. The use of a semantic Web language enables reasoning on meaningful relations and this, in turn, makes it easy to expand the functions by adding modules.","venue":"","year":2008.0,"referenceCount":12,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":"2008-12-28","authors":[{"authorId":"9429001","name":"Chang-Woo Song"},{"authorId":"46663442","name":"Jung-Hyun Lee"}]},{"paperId":"0397187834403a1dc4cade12cc263f4965b47ccd","title":"Semantic Shift Detection in Semantic Web","abstract":"This paper present a method to discover the semantic shift detection(SSD) in semantic. In the way we can detect the shift with the link consisted in web. By usage of topic shifts techniques as terms frequently occurring in documents. Our experiments results show that a number of topics can shift along in a group of terms with same semantic.","venue":"2009 Fifth International Conference on Semantics, Knowledge and Grid","year":2009.0,"referenceCount":9,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":"2009-10-12","authors":[{"authorId":"144993781","name":"Ke Ren"},{"authorId":"2838109","name":"Zhixing Huang"},{"authorId":"145382326","name":"Anping Zhao"},{"authorId":"1735618","name":"Yuhui Qiu"}]},{"paperId":"039729361530213883be0daec44d67fc743c6213","title":"Data integration with the Climate Science Modelling Language","abstract":"Abstract. The Climate Science Modelling Language (CSML) has been developed by the NERC DataGrid (NDG) project as a standards-based data model and XML markup for describing and constructing climate science datasets. It uses conceptual models from emerging standards in GIS to define a number of feature types, and adopts schemas of the Geography Markup Language (GML) where possible for encoding. A prototype deployment of CSML is being trialled across the curated archives of the British Atmospheric and Oceanographic Data Centres. These data include a wide range of data types \u2013 both observational and model \u2013 and heterogeneous file-based storage systems. CSML provides a semantic abstraction layer for data files, and is exposed through higher level data delivery services. In NDG these will include file instantiation services (for formats of choice) and the web services of the Open Geospatial Consortium (OGC).","venue":"","year":2006.0,"referenceCount":14,"citationCount":73,"fieldsOfStudy":["Computer Science"],"publicationDate":"2006-06-06","authors":[{"authorId":"49768046","name":"A. Woolf"},{"authorId":"2247555377","name":"Bryan Lawrence"},{"authorId":"2242071588","name":"Roy K. Lowry"},{"authorId":"3128930","name":"K. K. Dam"},{"authorId":"29827459","name":"R. Cramer"},{"authorId":"145341074","name":"Marta Gutierrez"},{"authorId":"2062675807","name":"Siva Kondapalli"},{"authorId":"40466132","name":"Susan Latham"},{"authorId":"31841819","name":"D. Lowe"},{"authorId":"1450805637","name":"K. O'Neill"},{"authorId":"2242069528","name":"Ag Stephens"}]},{"paperId":"03993e15b711dae84ac2ada308858a10971fd8c1","title":"Continuous Semantics to Analyze Real-Time Data","abstract":"The traditional semantic approach has difficulties dealing with the dynamic domains involved in social, mobile, and sensor webs. Continuous semantics, which captures changing conceptualizations and relevant knowledge, can help us model those domains and analyze the related real-time data.","venue":"IEEE Internet Computing","year":2010.0,"referenceCount":11,"citationCount":47,"fieldsOfStudy":["Computer Science"],"publicationDate":"2010-11-01","authors":[{"authorId":"144463965","name":"A. Sheth"},{"authorId":"11170094","name":"Christopher Thomas"},{"authorId":"144909257","name":"P. Mehra"}]},{"paperId":"039977c80e9376895bd0c62f1645eef411cabc1e","title":"Web Recommendation Based on Back Propagation Neural Networks","abstract":null,"venue":"International Symposium on Neural Networks","year":2011.0,"referenceCount":9,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":"2011-05-29","authors":[{"authorId":"144091318","name":"Jiang Zhong"},{"authorId":"70750363","name":"S. Deng"},{"authorId":"145686408","name":"Y. Cheng"}]},{"paperId":"039a0437da4cc93ea0b12126c8e5dd8f001b41a8","title":"Resenha - Semantic Web Technologies: trends and research in ontology-based systems","abstract":"Semantic Web Technologies: trends and research in ontology-based systems John Davies, Rudi Studer & Paul Warren. DOI: 10.3395\/reciis.v3i1.245pt \n \nlink para o texto completo: http:\/\/www.revista.cict.fiocruz.br\/index.php\/reciis\/article\/view\/245\/260","venue":"","year":2011.0,"referenceCount":0,"citationCount":0,"fieldsOfStudy":["Computer Science"],"publicationDate":"2011-07-27","authors":[{"authorId":"1772063","name":"K. Breitman"}]},{"paperId":"039a21ccb332537880e2b52d53d7efa1ddba7ad4","title":"Rule-based semantic web services matching strategy","abstract":"With the development of Web services technology, the number of service increases rapidly, and it becomes a challenge task that how to efficiently discovery the services that exactly match the user's requirements from the large scale of services library. Many semantic Web services discovery technologies proposed by the recent literatures only focus on the keyword-based or primary semantic based service's matching. This paper studies the rules and rule reasoning based service matching algorithm in the background of large scale services library. Firstly, the formal descriptions of semantic web services and service matching is presented. The services' matching are divided into four levels: Exact, Plugin, Subsume and Fail and their formal descriptions are also presented. Then, the service matching is regarded as rule-based reasoning issues. A set of match rules are firstly given and the related services set is retrieved from services ontology base through rule-based reasoning, and their matching levels are determined by distinguishing the relationships between service's I\/O and user's request I\/O. Finally, the experiment based on two services sets show that the proposed services matching strategy can easily implement the smart service discovery and obtains the high service discovery efficiency in comparison with the traditional global traversal strategy.","venue":"International Symposium on Multispectral Image Processing and Pattern Recognition","year":2011.0,"referenceCount":11,"citationCount":2,"fieldsOfStudy":["Computer Science","Engineering"],"publicationDate":"2011-11-20","authors":[{"authorId":"1682890","name":"Hong Fan"},{"authorId":"2142017065","name":"Zhihua Wang"}]},{"paperId":"039a66965732048459a47da7fc8c2f06240cba51","title":"BiLSTM_SAE:A Hybrid Deep Learning Framework for Predictive Data Analytics System in Tra\ufffdc Modeling","abstract":"Big data has been utilized and attracted various researchers due to the phenomenal increase in computational application which has developed an overwhelming flow of data. Further, with an expeditious blooming of emerging applications such as social media applications, semantic Web, and bioinformatics applications, data heterogeneity is increasing swiftly. Accordingly, a variety of data needs to be executed with less high accuracy and less. However, effective data analysis and processing of large - scale data are compelling which is considered a critical challenge in the current scenario. To overcome these issues, various techniques have been developed and executed but still, it is significant to improve in accuracy. The current study proposed a hybrid technique of BiLSTM - SAE has been proposed for business big data analytics. Bidirectional LSTM is considered as an advanced version of the conventional LSTM approach. The performance comparison of the proposed method BiLSTM - SAE with existing Random forest - RF has been processed. The final result reported that the proposed method BiLSTM - SAE had been procured with better accuracy of 0.836. Moreover, the training and validation accuracy and loss on different performance metrics have been studied and conducted in the research.","venue":"","year":2023.0,"referenceCount":29,"citationCount":0,"fieldsOfStudy":null,"publicationDate":null,"authors":[{"authorId":"47270940","name":"Shubhashish Goswami"}]},{"paperId":"039aa53f8d19b181bdcf1eeab88537c2fa26ff0c","title":"Corpus analysis for indexing: when corpus-based terminology makes a difference","abstract":"This paper describes preliminary work in corpus-based indexing of a sizeable specialized Web portal, with (comparable, but not parallel) information in Portuguese and English. The interdisciplinary work involved illustrates the urgent need to create greater cooperation between information retrieval and corpus-based terminology. The aim of the work described is twofold: to provide a case for terminology-based search engine deployment while improving the availability of the information in a specific Website, and to suggest further measures in order to successfully marry IR and corpus-based terminology. After presenting the Corpografo, a fairly mature Web-based environment for terminology work which includes information extraction capabilities such as named entity recognition and semiautomatic harvesting of definitions and semantic relations, we describe the practical task we wanted to deal with, namely, improving Linguateca\u2019s search system over its website by adding properly chosen","venue":"","year":2005.0,"referenceCount":11,"citationCount":4,"fieldsOfStudy":["Computer Science"],"publicationDate":null,"authors":[{"authorId":"146528739","name":"D. Oliveira"},{"authorId":"144419509","name":"L. Sarmento"},{"authorId":"2186469","name":"Belinda Maia"},{"authorId":"145928342","name":"Diana Santos"}]}]