{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9e41648-21ee-4d27-a831-6c6d10a97a29",
   "metadata": {},
   "source": [
    "# 1. DATA INGESTION\n",
    "\n",
    "## 1.1 Enter the title of a paper you're curious about  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "638f9408-b29c-4523-8627-a38bcf6a4e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from helper_func import paginate_api_requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e25f638b-2ccb-4d00-bcaa-f437491667f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:helper_func:Fetching results 0 to 100 from https://api.semanticscholar.org/graph/v1/paper/search/bulk?query=Do+eye+movements+enhance+visual+memory+retrieval%3F&fields=paperId%2Ctitle%2Cauthors%2Cyear%2CpublicationDate%2Cvenue%2CreferenceCount%2CcitationCount%2CfieldsOfStudy&offset=0&limit=100\n",
      "INFO:helper_func:Retrieved all results. Total: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "https://api.semanticscholar.org/graph/v1/paper/search/bulk\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paperId</th>\n",
       "      <th>title</th>\n",
       "      <th>venue</th>\n",
       "      <th>year</th>\n",
       "      <th>referenceCount</th>\n",
       "      <th>citationCount</th>\n",
       "      <th>fieldsOfStudy</th>\n",
       "      <th>publicationDate</th>\n",
       "      <th>authors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0895f43dfd4aa7a6a31936aa66e110d0e20e970e</td>\n",
       "      <td>Do eye movements enhance visual memory retrieval?</td>\n",
       "      <td>Vision Research</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>56</td>\n",
       "      <td>9</td>\n",
       "      <td>[Medicine, Psychology]</td>\n",
       "      <td>2020-08-19</td>\n",
       "      <td>[{'authorId': '23785707', 'name': 'H. Kinjo'},...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6fa6dfe54198b8938632062ebaa32373ade680e7</td>\n",
       "      <td>Precise Timing Matters: Modulating Human Memor...</td>\n",
       "      <td>bioRxiv</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>[Biology]</td>\n",
       "      <td>2024-04-13</td>\n",
       "      <td>[{'authorId': '2075794910', 'name': 'C. Katz'}...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7dbeed4823a7c44571102427a8125b635081859c</td>\n",
       "      <td>Identifying User Behaviour Between Logged Inte...</td>\n",
       "      <td>UIIR@SIGIR</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>[Computer Science]</td>\n",
       "      <td>None</td>\n",
       "      <td>[{'authorId': '8530169', 'name': 'Max L. Wilso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>805df08aadda9034ede88a6f724dc0d2528bb0f8</td>\n",
       "      <td>EFFECT OF TASK-IRRELEVANT GAZE ON MEMORY 1 Jus...</td>\n",
       "      <td></td>\n",
       "      <td>2016.0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[{'authorId': '114017803', 'name': 'J. J. Wang'}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>98892be4b82567c86be22c0688a01106c9742fe6</td>\n",
       "      <td>Source (or Part of the following Source): Type...</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>65</td>\n",
       "      <td>60</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[{'authorId': '2302749851', 'name': 'Z. Samara...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>e06bec8d53bfbaa63da0f04bd4883ea51502120f</td>\n",
       "      <td>A Medical Image Retrieval Framework in Cogniti...</td>\n",
       "      <td></td>\n",
       "      <td>2013.0</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[{'authorId': '70105481', 'name': 'H. Moulick'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>e3f98f33036b9f574d88064918f2474c65d039c5</td>\n",
       "      <td>Recognition of incidentally learned visual sea...</td>\n",
       "      <td>Journal of Experimental Psychology. Learning, ...</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>50</td>\n",
       "      <td>16</td>\n",
       "      <td>[Medicine, Psychology]</td>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>[{'authorId': '4633341', 'name': 'Efsun Annac'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ed839471141089b8b5bd47ac5fba687eaaf3dc14</td>\n",
       "      <td>Running head: BILATERAL EYE-MOVEMENTS The Impa...</td>\n",
       "      <td></td>\n",
       "      <td>2019.0</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[{'authorId': '40807263', 'name': 'Michael J. ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    paperId  \\\n",
       "0  0895f43dfd4aa7a6a31936aa66e110d0e20e970e   \n",
       "1  6fa6dfe54198b8938632062ebaa32373ade680e7   \n",
       "2  7dbeed4823a7c44571102427a8125b635081859c   \n",
       "3  805df08aadda9034ede88a6f724dc0d2528bb0f8   \n",
       "4  98892be4b82567c86be22c0688a01106c9742fe6   \n",
       "5  e06bec8d53bfbaa63da0f04bd4883ea51502120f   \n",
       "6  e3f98f33036b9f574d88064918f2474c65d039c5   \n",
       "7  ed839471141089b8b5bd47ac5fba687eaaf3dc14   \n",
       "\n",
       "                                               title  \\\n",
       "0  Do eye movements enhance visual memory retrieval?   \n",
       "1  Precise Timing Matters: Modulating Human Memor...   \n",
       "2  Identifying User Behaviour Between Logged Inte...   \n",
       "3  EFFECT OF TASK-IRRELEVANT GAZE ON MEMORY 1 Jus...   \n",
       "4  Source (or Part of the following Source): Type...   \n",
       "5  A Medical Image Retrieval Framework in Cogniti...   \n",
       "6  Recognition of incidentally learned visual sea...   \n",
       "7  Running head: BILATERAL EYE-MOVEMENTS The Impa...   \n",
       "\n",
       "                                               venue    year  referenceCount  \\\n",
       "0                                    Vision Research  2020.0              56   \n",
       "1                                            bioRxiv  2024.0              85   \n",
       "2                                         UIIR@SIGIR  2009.0              16   \n",
       "3                                                     2016.0              24   \n",
       "4                                                        NaN              65   \n",
       "5                                                     2013.0              36   \n",
       "6  Journal of Experimental Psychology. Learning, ...  2019.0              50   \n",
       "7                                                     2019.0              58   \n",
       "\n",
       "   citationCount           fieldsOfStudy publicationDate  \\\n",
       "0              9  [Medicine, Psychology]      2020-08-19   \n",
       "1              0               [Biology]      2024-04-13   \n",
       "2              0      [Computer Science]            None   \n",
       "3              0                    None            None   \n",
       "4             60                    None            None   \n",
       "5              0                    None            None   \n",
       "6             16  [Medicine, Psychology]      2019-12-01   \n",
       "7              0                    None            None   \n",
       "\n",
       "                                             authors  \n",
       "0  [{'authorId': '23785707', 'name': 'H. Kinjo'},...  \n",
       "1  [{'authorId': '2075794910', 'name': 'C. Katz'}...  \n",
       "2  [{'authorId': '8530169', 'name': 'Max L. Wilso...  \n",
       "3  [{'authorId': '114017803', 'name': 'J. J. Wang'}]  \n",
       "4  [{'authorId': '2302749851', 'name': 'Z. Samara...  \n",
       "5  [{'authorId': '70105481', 'name': 'H. Moulick'...  \n",
       "6  [{'authorId': '4633341', 'name': 'Efsun Annac'...  \n",
       "7  [{'authorId': '40807263', 'name': 'Michael J. ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TRY A MORE GENERAL QUERY:\n",
    "# query, endpoint = 'barbara hidalgo sotelo', '/author/search'  #First get the authorID\n",
    "# query, endpoint = 'juan sequeda', '/author/search'\n",
    "# query, endpoint = 'the semantic web', '/paper/search/bulk'  \n",
    "# query, endpoint = \"Modelling Search for People in 900 Scenes: a Combined Source Model of Eye Guidance\", '/paper/search/bulk'    \n",
    "query, endpoint = \"Do eye movements enhance visual memory retrieval?\", '/paper/search/bulk'    \n",
    "\n",
    "base_url = \"https://api.semanticscholar.org/graph/v1\"\n",
    "params = {'query': query}\n",
    "\n",
    "if endpoint.find('/paper/search/bulk')!=-1:\n",
    "    params['fields'] = \"paperId,title,authors,year,publicationDate,venue,referenceCount,citationCount,fieldsOfStudy\"\n",
    "    save_prefix = 'paper_details_bulk'\n",
    "    \n",
    "elif endpoint.find('paper/search')!=-1:\n",
    "    params['fields'] = \"paperId,title,authors,year,publicationDate,venue,referenceCount,citationCount,fieldsOfStudy\"\n",
    "    save_prefix = 'paper_details_search'\n",
    "\n",
    "elif endpoint.find('author/search/bulk')!=-1: \n",
    "    params['fields'] = \"authorId,name,affiliations,paperCount,citationCount,hIndex,url\"\n",
    "    save_prefix = 'author_details'\n",
    "\n",
    "    results = list( paginate_api_requests(\n",
    "                        base_url = f\"{base_url}{endpoint}\",\n",
    "                        params = params ) )\n",
    "\n",
    "elif endpoint.find('author/search')!=-1: \n",
    "    params['fields'] = \"authorId,name,affiliations,paperCount,citationCount,hIndex,url\"\n",
    "    save_prefix = 'author_details'\n",
    "else:\n",
    "    save_prefix = 'other'  #by default, id and name or title are usually returned when no fields are requested\n",
    "    \n",
    "results = list( paginate_api_requests(\n",
    "                    base_url = f\"{base_url}{endpoint}\",\n",
    "                    params = params ) )\n",
    "\n",
    "DF = pd.DataFrame(results)\n",
    "print(f\"\\n\\n{base_url}{endpoint}\\n\\n\")\n",
    "DF\n",
    "\n",
    "# Save results\n",
    "# DF.to_csv(f'{save_prefix}.csv')\n",
    "# DF.to_json(f'{save_prefix}.json', orient='records')\n",
    "# DF.to_pickle(f'{save_prefix}.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b9e64d-2667-4172-b147-2d801a1a0530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paper_title = 'Modelling Search for People in 900 Scenes: a Combined Source Model of Eye Guidance'\n",
    "n_matches, paper_id, paper_title, pub_year, referenceCount, citationCount = DF.shape[0], DF['paperId'][0],  DF['title'][0],  DF['year'][0], DF['referenceCount'][0], DF['citationCount'][0]\n",
    "\n",
    "print(endpoint)\n",
    "print(f\"\\nFound {n_matches} matches for '{query}'\\nSelecting the first:\\n\")\n",
    "print(f\"**Title**\\t{paper_title}({pub_year})\\n**PaperID**\\t{paper_id}\\n**Num References**\\t{referenceCount}\\n**Num Citations**\\t{citationCount}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43f5f9b-4eee-4754-be1f-c7881673f030",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9516d0e8-ef2b-497d-888f-654d03338bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from helper_func import *\n",
    "\n",
    "# #ORIGINAL VERSION OF SEEDING:\n",
    "# title = \"Modelling Search for People in 900 Scenes: a Combined Source Model of Eye Guidance\"  \n",
    "\n",
    "# # Search API.SEMANTICSCHOLAR.ORG for paper by TITLE\n",
    "# search_result = search_paper_by_title(title)\n",
    "\n",
    "# # Get the paper ID of the first returned result\n",
    "# if len(search_result['data'])>0:\n",
    "#     paper_id, paper_title = search_result['data'][0]['paperId'], search_result['data'][0]['title']\n",
    "# else:\n",
    "#     paper_id = None\n",
    "\n",
    "# print(f\"\\nFound {search_result['total']} matches | Selecting the first:\\n**Title**\\t{paper_title}\\n**PaperID**\\t{paper_id}\")\n",
    "\n",
    "# paper_title = 'Modelling Search for People in 900 Scenes: a Combined Source Model of Eye Guidance'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a71442e-42ce-4468-9939-0618e3df6efe",
   "metadata": {},
   "source": [
    "## 1.2 Open the body of knowledge \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59382f0f-bc7e-4b57-b228-fff53ad0a172",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF = pd.read_csv('storage/MEGA_paper_INFO.csv').drop(['Unnamed: 0','0'],axis=1)\n",
    "DF.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258f89e9-84c3-46d6-ab19-316ef863d0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN FUNCTION TO CALL\n",
    "def expand_nodes(known_nodes) -> list:\n",
    "\n",
    "    # Start with a list of paper details\n",
    "    if type(known_nodes) == pd.DataFrame:\n",
    "        expanded_details = known_nodes.to_dict(orient='records')\n",
    "        DF = known_nodes.copy()\n",
    "    elif type(known_nodes) == list:\n",
    "        expanded_details = known_nodes.copy()\n",
    "        DF = pd.DataFrame(known_nodes)\n",
    "\n",
    "    # Expand a cloud of nodes around any paper who has been cited\n",
    "    for index, row in DF.iterrows():\n",
    "        print(f\"{index} of {DF.shape[0]}\")\n",
    "        citation_count, title = int(row['citationCount']), row['title']\n",
    "    \n",
    "        if citation_count > 0:\n",
    "            print(f'**{citation_count}** papers that cited: {title}')\n",
    "\n",
    "            # Get the IDs of citing papers\n",
    "            IDs = retrieve_citations_by_id(row['paperId'])\n",
    "\n",
    "            # Pull details for any IDs **not already in \"known_nodes\"**\n",
    "            IDs = [paperId for paperId in IDs if paperId not in DF['paperId'].tolist()]\n",
    "            if len(IDs)>0:\n",
    "                print(f'Get details for the {len(IDs)} papers not in the cloud yet')\n",
    "                time.sleep(2.2)\n",
    "\n",
    "                # Add to level of knowledge\n",
    "                details = batch_paper_details(IDs)\n",
    "                expanded_details.append(details)\n",
    "    \n",
    "                # Save results\n",
    "                with open('storage/MEGA_paper_details.json', 'w') as f:\n",
    "                    json.dump(expanded_details, f, indent=2)\n",
    "\n",
    "            # Pause so as to not tax API\n",
    "            time.sleep(2.2)\n",
    "    \n",
    "    return expanded_details\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35af9e1e-d4ce-4b7c-b6c8-0d538f517c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will check to see whether all of papers in \"paperId\" column that have been cited by other papers\n",
    "more_city_details = expand_nodes(DF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f5d728-c92c-49ff-b99c-130bdce0db7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SEARCH FOR AN AUTHOR's ID:\n",
    "r = requests.post(\n",
    "    'https://api.semanticscholar.org/graph/v1/author/search',\n",
    "    params={'fields': 'name,url,affiliations,paperCount,citationCount,hIndex'},\n",
    "    json={\"ids\": authorIds}\n",
    ")\n",
    "\n",
    "endpoint = f\"{base_url}/paper/search\"\n",
    "params = {\n",
    "    'query': title,\n",
    "    'fields': 'paperId,title,authors,year,venue'\n",
    "}\n",
    "\n",
    "try:\n",
    "    response = requests.get(endpoint, params=params)  \n",
    "    response.raise_for_status()\n",
    "    return response.json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b0864c-8f18-4995-a1dd-4f3f856932b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d7910979-cff2-4510-b959-4ad642ae18fc",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---\n",
    "\n",
    "STOP!\n",
    "\n",
    "\n",
    "## Query AUTHORS endpoint to get details of paper_authors\n",
    "\n",
    "Source node: **author_name**  \n",
    "Relationship: *CO_AUTHORED*  \n",
    "Target node: **paper_title**  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab00986-ecc8-45e2-98a2-73e0f71212ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract AuthorIDs\n",
    "authorIds = []\n",
    "[authorIds.append(d['authorId']) for d in author_details['data']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d27d57-bd94-487e-943a-16ba96fcdd74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loadPrev = False\n",
    "if loadPrev:\n",
    "    # Open previously saved results:  seed_author_info (JSON) and authorDF\n",
    "    with open('storage/author_INFO.json', 'r') as f:\n",
    "        seed_author_info = json.load(f)\n",
    "    authorDF = pd.DataFrame(seed_author_info)\n",
    "else:    \n",
    "    # BATCH REQUEST INFO ABOUT AUTHORS:\n",
    "    r = requests.post(\n",
    "        'https://api.semanticscholar.org/graph/v1/author/batch',\n",
    "        params={'fields': 'name,url,affiliations,paperCount,citationCount,hIndex'},\n",
    "        json={\"ids\": authorIds}\n",
    "    )\n",
    "    seed_author_info = r.json() \n",
    "    \n",
    "    # Save results as seed_author_info.JSON and author_INFO.CSV\n",
    "    authorDF = pd.DataFrame(seed_author_info)\n",
    "    authorDF.to_csv('storage/author_INFO.csv') \n",
    "    with open('storage/author_INFO.json', 'w') as f:\n",
    "        json.dump(seed_author_info, f, indent=2)\n",
    "    \n",
    "\n",
    "# PERSON OBJECT\n",
    "# name\n",
    "# authorId\n",
    "# url\n",
    "# affiliations\n",
    "# paperCount\n",
    "# citationCount\n",
    "# hIndex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2416888a-21c9-4cd2-b8a6-4e9832f13093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONVERT TO TRIPLES\n",
    "rows, pID = [], []\n",
    "for index, item in enumerate(seed_author_info):\n",
    "    rows.append([item['name'], \"CO_AUTHORED\", paper_title])\n",
    "    pID.append(item['authorId'])    \n",
    "    #print(f\"{item['name']} CO_AUTHORED {paper_title}\")  \n",
    "    \n",
    "# Save results\n",
    "df_authors = pd.DataFrame(rows, index=pID, columns=['subject','predicate','object'])\n",
    "df_authors.to_csv('storage/triples_author.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520a2962-58af-4719-a64b-e56ae875ac14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3fc6f029-8ae8-45dd-a352-cff7a6f5f6dc",
   "metadata": {},
   "source": [
    "## Query CITATIONS endpoint to get papers citing seed paper\n",
    "\n",
    "Source node: **paper_id**  \n",
    "Relationship: *CITED_BY*  \n",
    "Target node: **citedPaperIDs**  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97bfcc12-6f0a-4ff1-b346-68d4d0342df7",
   "metadata": {},
   "source": [
    "ISSUE = Querying the paper details endpoint generally led to 429 Errors (too many queries; no API key as of 12/13/24) \n",
    "```\n",
    "# paper_params=\"paperId,title,authors,year,publicationDate,venue,abstract,referenceCount,citationCount,fieldsOfStudy\"\n",
    "# endpoint = f\"https://api.semanticscholar.org/graph/v1/paper/{paper_id}/\"\n",
    "# response = requests.get(endpoint, params={'fields': paper_params})\n",
    "# response.json()\n",
    "```\n",
    "SOLUTION...\n",
    "**Get details for multiple papers at once**  \n",
    "\n",
    "Limitations:  \n",
    "Can only process 500 paper ids at a time.  \n",
    "Can only return up to 10 MB of data at a time.  \n",
    "Can only return up to 9999 citations at a time.  \n",
    "For a list of supported IDs reference the \"Details about a paper\" endpoint.  \n",
    "\n",
    "https://api.semanticscholar.org/api-docs/#tag/Paper-Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23cee90-936f-41de-b354-da8388ccae83",
   "metadata": {},
   "outputs": [],
   "source": [
    "loadPrev = True\n",
    "if loadPrev:\n",
    "    # Open previously saved results\n",
    "    with open('storage/papers_cited_seed.json', 'r') as f:\n",
    "        cited_paper_details = json.load(f)\n",
    "     DF = pd.DataFrame(cited_paper_details)\n",
    "else:    \n",
    "\n",
    "    # Query citations of paperId \n",
    "    # Goal: retrieve details about the papers citing this paper (i.e. papers in whose bibliography this paper appears; source: SemanticScholar docs)\n",
    "    try:\n",
    "        # Use the paginate function in helper_func.py b/c >100 results are expected\n",
    "        cited_paper_ids = list( paginate_api_requests(\n",
    "                                    base_url=f\"https://api.semanticscholar.org/graph/v1/paper/{paper_id}/citations\",\n",
    "                                    params={\"fields\": \"paperId\"}\n",
    "                                    )\n",
    "                              )    \n",
    "        print(f\"Successfully retrieved {len(cited_paper_ids)} papers\")       \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e} when querying the citations endpoint\")\n",
    "        \n",
    "    # Get paperIDs of citing papers to do batch lookup of desired details -- Including original paper_id -- NEXT STEP: Create nodes\n",
    "    citedPaperIds = [paper_id]\n",
    "    [citedPaperIds.append(d['citingPaper']['paperId']) for d in cited_paper_ids]\n",
    "    print('\\nNext step: Use paperIDs to get batch paper info')\n",
    "\n",
    "    \n",
    "    #BATCH REQUEST INFO ABOUT PAPERS:\n",
    "    paper_params=\"paperId,title,authors,year,publicationDate,venue,abstract,referenceCount,citationCount,fieldsOfStudy\"\n",
    "    citedPaperIds.append(citedPaperIds)\n",
    "    \n",
    "    r = requests.post(\n",
    "        'https://api.semanticscholar.org/graph/v1/paper/batch',\n",
    "        params={'fields': paper_params},\n",
    "        json={\"ids\": citedPaperIds}\n",
    "    )\n",
    "    \n",
    "    cited_paper_details = r.json()\n",
    "    DF = pd.DataFrame(cited_paper_details)\n",
    "\n",
    "    # Save results\n",
    "    DF.to_csv('storage/paper_INFO.csv')\n",
    "    with open('storage/papers_cited_seed.json', 'w') as f:\n",
    "        json.dump(cited_paper_details, f, indent=2)\n",
    "\n",
    "print(f\"LoadPrev: {loadPrev} - Retrieved details on {len(cited_paper_details)} papers (SEED + PAPERS CITED BY SEED)\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3ce163-28a9-448b-99b8-6856995d1ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## PULL INFO OF AUTHORS OF {PAPERS THAT CITED THE SEED PAPER}\n",
    "\n",
    "## DONE: AUGMENTING KNOWLEDGE GRAPH BY IDENTIFYING WHO CITED THE {PAPERS THAT CITED THE SEED PAPER}\n",
    "\n",
    "## THEN, THEIR AUTHORS..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cc750f-35d3-4b8b-84fe-17e6cda6c057",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f3870a01-b545-4253-ae15-ee85e6d651fc",
   "metadata": {},
   "source": [
    "### 1. Which cited papers have citations themselves? \n",
    "\n",
    "264 out of the 318 citations of Modeling 900 Scenes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b19db8-9b3e-4c55-8076-3778e3b99478",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e2a832-d246-4b42-99a9-fb7d24e455c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: TEST THIS..\n",
    "more_city_details = expand_nodes(some df...)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c3dcbe-9fe1-4402-bf7e-ce2457351b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5049209-637f-489d-8aa7-48967b3670d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Original Paper Details\n",
    "# MEGA_DF = DF.copy()  <= THIS IS THE CATALOG\n",
    "# mega_cited_details = cited_paper_details.copy()\n",
    "# cnt=0\n",
    "# for index, row in DF.iterrows():\n",
    "#     print(f\"{index} of {DF.shape[0]}\")\n",
    "#     citation_count, title = row['citationCount'], row['title']\n",
    "\n",
    "#     if citation_count > 0:\n",
    "#         print(f'Searching for {citation_count} papers that cited: {title}')\n",
    "#         more_paper_info, DF2 = retrieve_paper_id_citations(row['paperId'])\n",
    "\n",
    "#         # Add to level of knowledge\n",
    "#         MEGA_DF = pd.concat([MEGA_DF,DF2],axis=0)\n",
    "#         mega_cited_details.append(more_paper_info)\n",
    "\n",
    "#         # Save results\n",
    "#         MEGA_DF.to_csv('storage/MEGA_paper_INFO.csv')\n",
    "#         with open('storage/MEGA_papers_cited_seed.json', 'w') as f:\n",
    "#             json.dump(cited_paper_details, f, indent=2)\n",
    "\n",
    "#         # Pause\n",
    "#         print('Pausing...')\n",
    "#         time.sleep(1.1)\n",
    "#     cnt+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a4d382-9282-4762-a7b3-7876dacfc789",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430c20c5-391c-4f06-bcfa-67df784493c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c26ea0d-1bd7-4a7e-83f5-4fb0e8bb3fae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8427f537-ea73-40b6-a2e1-0b4e3c3b0a7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330cc615-d44d-4914-9f57-bd6031078643",
   "metadata": {},
   "outputs": [],
   "source": [
    "new = MEGA_DF.drop_duplicates(subset='paperId', keep='first')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc44936-aaeb-4b13-9c2c-760bbf999516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the DataFrame to nicely formatted JSON file\n",
    "json_file_path = 'output2.json'\n",
    "new.to_json(json_file_path, orient='records', indent=2)\n",
    "\n",
    "print(f\"DataFrame has been converted to JSON file: {json_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c332d1-4af5-4bae-997d-e96587896bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data = new.to_json(orient='records')\n",
    "json_string = json.dumps(json.loads(json_data), separators=(',', ':'))\n",
    "json_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ad030f-1d5f-4382-b1d1-3cea69dace7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1379c033-d8d5-4f0c-9bc3-2cf8089eb5b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ef46a7-d77a-48a8-8c37-5f727f504b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENRICH KG with cited papers (paperID as the index)\n",
    "def build_triples(details_dict, subject_col, relation, predicate_col):\n",
    "\n",
    "    rows, rowsIDs, pID = [], [], []\n",
    "    for index, item in enumerate(cited_paper_details):\n",
    "        pID.append(item['paperId'])    \n",
    "        rows.append( [paper_title, \"CITED_BY\", item['title'] ] )\n",
    "        rowsIDs.append( [paper_id, \"CITED_BY\", item['paperId'] ] )\n",
    "        #print(f\"{paper_title} CITED_BY {item['title']}\")  \n",
    "    \n",
    "    df = pd.DataFrame(rows, index=pID, columns=['subject','predicate','object'])\n",
    "    dfIDs = pd.DataFrame(rowsIDs, index=pID, columns=['subject','predicate','object'])\n",
    "\n",
    "    return df, dfIDs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfab15ac-79ca-47ac-a91a-02f245c4b4ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0191e056-99fe-446b-96a7-306cf3c6f94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cited_paper_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14ae7a5-c1c0-4192-98ab-758df56d417c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ee152a-e733-403c-876c-a0213c4f2823",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0a332862-3315-4aca-b26a-f10389986dbe",
   "metadata": {},
   "source": [
    "## Construct a Knowledge Graph of relationships\n",
    "\n",
    "### 1. Store Relationships as Triples (use DF)\n",
    "\n",
    "#### What Are Triples?\n",
    "Triples are in the format `(subject, predicate, object)` and represent the core of a knowledge graph:\n",
    "- **Subject**: The entity (e.g., a paper).  \n",
    "- **Predicate**: The relationship (e.g., \"cites\").  \n",
    "- **Object**: The related entity (e.g., another paper).  \n",
    "\n",
    "For example:   `(\"Paper A\", \"cites\", \"Paper B\")`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6019c48-3437-4317-b62d-f8ff5944bcd3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ENRICH KG with cited papers (paperID as the index)\n",
    "rows, rowsIDs, pID = [], [], []\n",
    "for index, item in enumerate(cited_paper_details[1:]):\n",
    "    pID.append(item['paperId'])    \n",
    "    rows.append( [paper_title, \"CITED_BY\", item['title'] ] )\n",
    "    rowsIDs.append( [paper_id, \"CITED_BY\", item['paperId'] ] )\n",
    "    #print(f\"{paper_title} CITED_BY {item['title']}\")  \n",
    "    \n",
    "df = pd.DataFrame(rows, index=pID, columns=['subject','predicate','object'])\n",
    "dfIDs = pd.DataFrame(rowsIDs, index=pID, columns=['subject','predicate','object'])\n",
    "\n",
    "# Save the relationships\n",
    "df.to_csv(\"storage/triples_titles.csv\")\n",
    "dfIDs.to_csv(\"storage/triples_ids.csv\")\n",
    "\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14a20d9-7172-4160-8258-46924fade1b2",
   "metadata": {},
   "source": [
    "### 2. Convert DataFrame of paper IDs to RDF\n",
    "**RDFLib is a library designed for working with triples in RDF format**\n",
    "\n",
    "#### INPUT: Triples in dfID\n",
    "#### KEY OUTPUT: **RDFlib Graph**  \n",
    "- Stored as a Turtle file (`citation_graph.ttl`).\n",
    "- Can be queried using SPARQL or visualized using RDF tools.\n",
    "\n",
    "Supports SPARQL queries for advanced analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0214136f-2cc5-42b2-9751-3a5c348cf2e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install rdflib\n",
    "from rdflib import Graph, URIRef, Literal\n",
    "\n",
    "# Initialize an RDFlib Graph\n",
    "rdf_graph = Graph()\n",
    "\n",
    "# Add triples to the graph\n",
    "for _, row in dfIDs.iterrows():\n",
    "    subject = URIRef(row['subject'])\n",
    "    predicate = URIRef(row['predicate'])\n",
    "    obj = URIRef(row['object']) if row['object'].startswith(\"Paper\") else Literal(row['object'])\n",
    "    rdf_graph.add((subject, predicate, obj))\n",
    "\n",
    "# Save the graph to a file\n",
    "rdf_graph.serialize(\"citation_graph.ttl\", format=\"turtle\")\n",
    "print(\"Graph serialized to citation_graph.ttl\")\n",
    "\n",
    "# Print the graph contents\n",
    "print(rdf_graph.serialize(format=\"turtle\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da2f5f4-2164-4c20-9754-594947e18103",
   "metadata": {},
   "source": [
    "---\n",
    "### 3. Convert DataFrame of Papers into PyTorch Geometric Object\n",
    "\n",
    "PyTorch-Geometric (PyG) is a good idea because its Data object can store graphs efficiently for embedding models like TransE or GCN for later ML tasks\n",
    "\n",
    "#### INPUT: Triples in df \n",
    "#### KEY OUTPUT: **PyTorch Geometric Object**  \n",
    "- `edge_index`: A tensor of shape (2, num_edges) specifying edge connections.  \n",
    "- `edge_attr` (optional): A tensor of edge attributes (e.g., predicate IDs).  \n",
    "\n",
    "- `edge_index`: Tensor representation of edges.\n",
    "- `edge_attr`: Tensor representation of predicates.\n",
    "\n",
    "Directly usable in graph neural networks (e.g., GCN, GAT).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25689bf8-e2fe-4d1a-bde3-6136655f407e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# Map nodes and predicates for papers\n",
    "node_to_id = {node: i for i, node in enumerate(set(df['subject']).union(set(df['object'])))}\n",
    "predicate_to_id = {pred: i for i, pred in enumerate(df['predicate'].unique())}\n",
    "\n",
    "# Create edge_index and edge_attr tensors\n",
    "edge_index = torch.tensor([\n",
    "    [node_to_id[row['subject']], node_to_id[row['object']]]\n",
    "    for _, row in df.iterrows()\n",
    "], dtype=torch.long).T  # Transpose to match PyG format\n",
    "\n",
    "edge_attr = torch.tensor([\n",
    "    predicate_to_id[row['predicate']]\n",
    "    for _, row in df.iterrows()\n",
    "], dtype=torch.long)\n",
    "\n",
    "# Initialize PyTorch Geometric Data object\n",
    "data = Data(edge_index=edge_index, edge_attr=edge_attr, num_nodes=len(node_to_id))\n",
    "\n",
    "# Print PyTorch Geometric object\n",
    "print(\"Edge Index:\")\n",
    "print(data.edge_index)\n",
    "print(\"\\nEdge Attributes:\")\n",
    "print(data.edge_attr)\n",
    "print(\"\\nNumber of Nodes:\", data.num_nodes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d51e47f-211d-486c-af01-8cacabb5b7fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c119b4af-6463-40c2-a124-fe8b74c85571",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b820894e-b6e0-4f47-9cf3-e5d1d6204a31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb74a495-87cc-4e01-b971-684788c9361a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33744eab-69f2-4937-8c2f-7d25fc78c002",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d781c3f2-87ff-4d17-b112-f63d0cf10058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Nodes: \n",
    "# ... Seed PaperId,\n",
    "\n",
    "# ... Seed Paper Field Of Study, \n",
    "# ... Seed Paper Authors, \n",
    "# ... Seed Paper Author Institutions, \n",
    "# ... Seed Paper Author Institutions City/State/Country/Continent\n",
    "\n",
    "# ... All 1st degree CITED_BY nodes, cited_paper_details['paperId']\n",
    "# ... (repeat with the above 5 lines for the cited papers)\n",
    "# ... For each of those, e.g. 318 or so... \n",
    "\n",
    "# ... SELECT A SUBSET OF MOST INFLUENTIAL PAPERS (FILTER by parameter boolean and possibly a citedBy threshold) \n",
    "# ... Get a list of CITED_BY relationships for each of those, e.g. 100 or so... \"2nd degree\" nodes\n",
    "\n",
    "# ... All 2nd degree CITED_BY nodes, cited_paper_details['paperId']\n",
    "# ... (repeat with the above 5 lines for the cited papers)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c5e190-aed8-4c30-9be9-0a050b9dbdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save AFFILIATED_WITH RELATIONSHIPS\n",
    "# - AuthorIds => AFFILIATED_WITH => INSTITUTION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d447ea1-e468-4b95-872f-c4df92766cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save LOCATED_IN RELATIONSHIPS\n",
    "# - INSTITUTION => LOCATED_IN => PLACE (City/State/Country/Continent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460282ae-8805-4759-92a2-0adcfa98dd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save CITED_BY RELATIONSHIPS\n",
    "# - Seed PaperId => Cited by => cited_paper_details['paperId']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7b9a4c-d474-4ccd-a660-b683b36f2220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save CO-AUTHORED RELATIONSHIPS\n",
    "# - Seed Paper Authors => Co-Authored => Seed PaperId\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cc31d9-dbf3-4927-9504-2d73a58e53d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save FIELD OF STUDY\n",
    "# ... Add Nodes for all available FieldsOfStudy from PaperNodes\n",
    "\n",
    "# Save BELONGS_TO RELATIONSHIPS\n",
    "# - PaperID => Belongs_to => FieldOfStudy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8709a0e2-5864-45d4-b4ff-8f01996668a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cited_paper_details[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde5c559-35b9-4e6e-a79a-02867d24d98a",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a6c62a-1a0e-4685-ab1a-2b0089bdb040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as NoSQL db in aws -- saves ever having to query again, super flexible to access\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bce5d3-d518-4575-bb0e-2a37df066fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as Neo4J graph -- same as above, super easy to visualize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122d8a8f-2dc0-48a3-9d90-937e88a7f25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51ae4c3-9807-43ef-b6b9-f68a78c43432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f1447b-d4cb-481f-93a8-776ab4c98c79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503bf457-957f-460b-91ec-da1bb2257de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ORIGINAL WORKFLOW AFTER SEARCHING FOR SEED: - Still working through bugs b/c getting paper details gets a 429 error\n",
    "\n",
    "# if search_result and search_result.get('data'):\n",
    "#     # Get the first result's paper ID\n",
    "#     paper_id = search_result['data'][0]['paperId']\n",
    "    \n",
    "#     # Get detailed information about the paper\n",
    "#     paper_details = collector.get_paper_details(paper_id)\n",
    "    \n",
    "#     if paper_details:\n",
    "#         # Extract relationships\n",
    "#         relationships = collector.extract_relationships(paper_details)\n",
    "        \n",
    "#         # Save the relationships to JSON files\n",
    "#         for rel_type, rel_data in relationships.items():\n",
    "#             if rel_data:  # Only save if there's data\n",
    "#                 filename = f\"{rel_type}_relationships.json\"\n",
    "#                 with open(filename, 'w') as f:\n",
    "#                     json.dump(rel_data, f, indent=2)\n",
    "#                 print(f\"Saved {len(rel_data)} {rel_type} relationships to {filename}\")\n",
    "\n",
    "# # if __name__ == \"__main__\":\n",
    "# #     main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac67afe-e186-474a-ba14-dac8235f3e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# import time\n",
    "# from typing import Dict, List, Generator, Optional\n",
    "# import logging\n",
    "\n",
    "# class SemanticScholarPaginator:\n",
    "#     def __init__(self, rate_limit_pause: float = 1.0):\n",
    "#         self.base_url = \"https://api.semanticscholar.org/graph/v1\"\n",
    "#         # self.headers = {\"x-api-key\": api_key}\n",
    "#         self.rate_limit_pause = rate_limit_pause\n",
    "        \n",
    "#         # Set up logging\n",
    "#         logging.basicConfig(level=logging.INFO)\n",
    "#         self.logger = logging.getLogger(__name__)\n",
    "        \n",
    "#     def get_citing_papers(self, paper_id: str, fields: str) -> Generator[Dict, None, None]:\n",
    "#         \"\"\"\n",
    "#         Get all citing papers using pagination.\n",
    "        \n",
    "#         Args:\n",
    "#             paper_id: Semantic Scholar Paper ID\n",
    "#             fields: Comma-separated string of fields to retrieve\n",
    "            \n",
    "#         Yields:\n",
    "#             Dictionary containing paper information\n",
    "#         \"\"\"\n",
    "#         offset = 0\n",
    "#         total_retrieved = 0\n",
    "        \n",
    "#         while True:\n",
    "#             endpoint = f\"{self.base_url}/paper/{paper_id}/citations\"\n",
    "#             params = {\n",
    "#                 'fields': fields,\n",
    "#                 'offset': offset,\n",
    "#                 'limit': 100  # Max allowed by API\n",
    "#             }\n",
    "            \n",
    "#             try:\n",
    "#                 # Make API request\n",
    "#                 self.logger.info(f\"Fetching results {offset} to {offset + 100}\")\n",
    "#                 response = requests.get(endpoint,  params=params)\n",
    "#                 response.raise_for_status()\n",
    "                \n",
    "#                 data = response.json()\n",
    "                \n",
    "#                 # Check if we got any results\n",
    "#                 if not data.get('data'):\n",
    "#                     self.logger.info(\"No more results to retrieve\")\n",
    "#                     break\n",
    "                    \n",
    "#                 # Process each paper in the current batch\n",
    "#                 for paper in data['data']:\n",
    "#                     total_retrieved += 1\n",
    "#                     yield paper\n",
    "                \n",
    "#                 # Check if we've retrieved all results\n",
    "#                 if 'next' not in data:\n",
    "#                     self.logger.info(f\"Retrieved all results. Total: {total_retrieved}\")\n",
    "#                     break\n",
    "                    \n",
    "#                 # Update offset for next batch\n",
    "#                 offset = data['next']\n",
    "                \n",
    "#                 # Respect rate limits\n",
    "#                 time.sleep(self.rate_limit_pause)\n",
    "                \n",
    "#             except requests.exceptions.RequestException as e:\n",
    "#                 self.logger.error(f\"Error fetching results: {e}\")\n",
    "#                 if response.status_code == 429:  # Too Many Requests\n",
    "#                     self.logger.info(\"Rate limit hit. Waiting 60 seconds...\")\n",
    "#                     time.sleep(60)\n",
    "#                     continue\n",
    "#                 else:\n",
    "#                     raise\n",
    "                    \n",
    "#     def collect_all_citing_papers(self, paper_id: str, fields: str) -> List[Dict]:\n",
    "#         \"\"\"\n",
    "#         Collect all citing papers into a list.\n",
    "        \n",
    "#         Args:\n",
    "#             paper_id: Semantic Scholar Paper ID\n",
    "#             fields: Comma-separated string of fields to retrieve\n",
    "            \n",
    "#         Returns:\n",
    "#             List of all citing papers\n",
    "#         \"\"\"\n",
    "#         return list(self.get_citing_papers(paper_id, fields))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd547be-f48a-457e-a52a-fa520792a5f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Example usage\n",
    "# paginator = SemanticScholarPaginator()\n",
    "    \n",
    "# # Fields we want to retrieve\n",
    "# fields = \"paperId,title,authors,year,venue,abstract,fieldsOfStudy\"\n",
    "    \n",
    "# # Collect all citing papers\n",
    "# try:\n",
    "#     citingPaperList = paginator.collect_all_citing_papers(paper_id, fields)\n",
    "    \n",
    "#     # Save results\n",
    "#     with open('papers_cited_seed.json', 'w') as f:\n",
    "#         json.dump(citingPaperList, f, indent=2)\n",
    "        \n",
    "#     print(f\"Successfully retrieved details on {len(citingPaperList)} papers (CITED BY SEED)\")\n",
    "#     print(json.dumps(citingPaperList[0:3], indent=2))\n",
    "\n",
    "# except Exception as e:\n",
    "#     print(f\"An error occurred: {e}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52aa1f8c-9f5d-4995-a152-7e2068c3e9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Barbara's blog will include a tutorial titled 'How to build an in-memory RAG app using the Llama-Index Starter Tutorial and a Google Drive folder to index and query documents in the Drive folder.' The project will involve using Python, Llama-Index, and Google Drive for data ingestion, building an index over documents using HuggingFace embeddings, and creating a Streamlit front-end for querying the index. The tutorial will use a fun topic, such as 'Dogs,' to make the example engaging. In Post #1, Barbara would like users to be able to make the following choices: For Data Ingestion: Use a Google Drive folder or a Local folder; Set which embedding model (HuggingFace) and Text Splitter (SentenceSplitter) to use; Set the chunk size for splitting. For now, it is acceptable if the Google Drive logic is not connected. If the user selects a local folder to ingest documents from, that is sufficient. Barbara is open to designing the UI elements in the Streamlit app for a future time when there may be multiple available selections, even if the current app draft only has one item in a selectbox.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e2fea8-5369-4da8-a522-9879a75532e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f35294-5570-4ddc-a7f8-9b5318a71502",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch-Link-Pred",
   "language": "python",
   "name": "myproject"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
