# Developer Guide: Architecture & Design

Welcome to the technical heart of Citation Compass! This guide explains the system architecture, design decisions, and implementation patterns that power the platform. Whether you're extending functionality, debugging issues, or just curious about how it all works, you're in the right place.

!!! tip "Just Getting Started?"
    If you haven't set up the platform yet, check out the [Getting Started](getting-started.md) guide first. This document assumes you have a working installation.

## Overview

Citation Compass is a system for academic citation network analysis, prediction, and exploration. It integrates features from multiple components to provide a unified solution for citation analysis, machine learning predictions, and interactive visualization.

![System architecture](assets/diagrams/system-architecture.png){ width="900" }

![User journey flow](assets/diagrams/user-journey-flow.png){ width="900" }

## System Architecture

```
┌─────────────────────────────────────────────────────────────┐
│                    Web Interface Layer                       │
├─────────────────────────────────────────────────────────────┤
│  Streamlit Application (app.py)                             │
│  ├── Home Page                                              │
│  ├── ML Predictions                                         │
│  ├── Embedding Explorer                                     │
│  ├── Enhanced Visualizations                                │
│  ├── Results Interpretation                                 │
│  └── Analysis Pipeline                                      │
└─────────────────────────────────────────────────────────────┘
                            │
┌─────────────────────────────────────────────────────────────┐
│                    Service Layer                            │
├─────────────────────────────────────────────────────────────┤
│  ML Service (TransE Model)    │  Analytics Service          │
│  ├── Model Loading            │  ├── Network Analysis       │
│  ├── Predictions              │  ├── Performance Metrics    │
│  ├── Embeddings               │  ├── Temporal Analysis      │
│  └── Caching                  │  └── Export Engine         │
└─────────────────────────────────────────────────────────────┘
                            │
┌─────────────────────────────────────────────────────────────┐
│                     Data Layer                              │
├─────────────────────────────────────────────────────────────┤
│  Unified API Client           │  Database Connection        │
│  ├── Semantic Scholar API     │  ├── Neo4j Driver          │
│  ├── Rate Limiting            │  ├── Query Execution       │
│  ├── Caching                  │  ├── Schema Management     │
│  └── Batch Processing         │  └── Connection Pooling    │
└─────────────────────────────────────────────────────────────┘
                            │
┌─────────────────────────────────────────────────────────────┐
│                    Storage Layer                            │
├─────────────────────────────────────────────────────────────┤
│  Neo4j Graph Database         │  ML Model Files            │
│  ├── Paper Nodes              │  ├── TransE Model (.pt)    │
│  ├── Author Nodes             │  ├── Entity Mapping (.pkl) │
│  ├── Citation Edges           │  └── Metadata (.pkl)       │
│  └── Venue/Field/Year Nodes   │                            │
└─────────────────────────────────────────────────────────────┘
```

## Core Components

### 1. Configuration Management (`src/config/`)
- **settings.py**: Environment-based configuration with validation
- **database.py**: Neo4j queries and database configuration

### 2. Data Models (`src/models/`)
- **paper.py**: Paper entity models with Pydantic validation
- **author.py**: Author and collaboration models  
- **citation.py**: Citation relationship models
- **ml.py**: Machine learning model interfaces
- **network.py**: Network analysis data structures

### 3. Database Layer (`src/database/`)
- **connection.py**: Enhanced Neo4j connection with error handling and caching
- **schema.py**: Unified database schema definitions
- **migrations/**: Schema migration scripts (placeholder)

### 4. Data Access (`src/data/`)
- **unified_api_client.py**: Comprehensive Semantic Scholar API client
- **api_config.py**: API configuration and rate limiting settings
- **unified_database.py**: Database abstraction layer

### 5. Service Layer (`src/services/`)
- **ml_service.py**: TransE model service with caching and optimization
- **analytics_service.py**: Network analysis and metrics computation

### 6. Analytics Engine (`src/analytics/`)
- **network_analysis.py**: Graph analysis algorithms
- **contextual_explanations.py**: Academic result interpretation  
- **performance_metrics.py**: Model evaluation metrics
- **temporal_analysis.py**: Time-series citation analysis
- **export_engine.py**: Multi-format result export

### 7. Web Interface (`src/streamlit_app/`)
- **ML_Predictions.py**: Interactive citation prediction interface
- **Embedding_Explorer.py**: Paper embedding visualization
- **Enhanced_Visualizations.py**: Advanced network visualizations
- **Results_Interpretation.py**: Contextual result interpretation
- **Notebook_Pipeline.py**: Interactive analysis workflows

## Data Flow

### 1. Data Ingestion
```
External APIs → Unified API Client → Data Models → Neo4j Database
```

### 2. ML Pipeline
```
Neo4j Data → ML Service → TransE Model → Predictions → Cache
```

### 3. Analysis Pipeline
```
Database Query → Analytics Service → Metrics Computation → Export Engine
```

### 4. User Interface
```
User Input → Streamlit Pages → Services → Database/ML → Results Display
```

## Key Design Patterns

### 1. Dependency Injection
- Services are injected into components for testability
- Configuration is environment-driven with validation

### 2. Caching Strategy
- **API Client**: Response caching with TTL and LRU eviction
- **ML Service**: Prediction caching for performance
- **Database**: Query result caching

### 3. Error Handling
- Comprehensive exception handling at all layers
- Graceful degradation for missing dependencies
- Detailed logging for debugging

### 4. Type Safety
- Pydantic models for data validation
- Type hints throughout codebase
- Runtime validation for critical paths

## Scalability Considerations

### 1. Database
- Connection pooling for concurrent access
- Indexed queries for performance
- Batch operations for bulk updates

### 2. API Client
- Rate limiting to respect API constraints
- Pagination for large datasets
- Retry logic for transient failures

### 3. ML Service
- Model caching to avoid repeated loading
- Batch prediction capabilities
- Device-aware computation (CPU/GPU)

### 4. Web Interface
- Streamlit caching for expensive operations
- Progressive loading for large datasets
- Session state management

## Security Considerations

### 1. Credentials Management
- Environment variable configuration
- No hardcoded credentials
- Support for multiple naming conventions

### 2. Input Validation
- Pydantic model validation
- SQL injection prevention through parameterized queries
- API input sanitization

### 3. Error Information
- Sanitized error messages for users
- Detailed logging for developers
- No sensitive data in logs

## Deployment Architecture

### Development Environment
```
Local Machine
├── Python Virtual Environment
├── Local Neo4j Instance (or Neo4j AuraDB)
├── Streamlit Development Server
└── ML Model Files (local)
```

### Production Environment
```
Cloud Infrastructure
├── Container Orchestration (Docker/Kubernetes)
├── Managed Neo4j Database (AuraDB)
├── Application Server (Streamlit/FastAPI)
├── Model Storage (S3/GCS)
└── Monitoring & Logging
```

## Testing Strategy

### 1. Unit Tests
- Individual component testing
- Mock dependencies for isolation
- Comprehensive model validation

### 2. Integration Tests
- End-to-end workflow testing
- Database integration validation
- API client testing with live services

### 3. Performance Tests
- Load testing for database queries
- ML service benchmarking
- API rate limit validation

## Technical Decision Rationale

### 💡 Core Architectural Decisions

#### **Why Neo4j Graph Database vs. Traditional SQL?**
**Decision**: Neo4j for citation network storage  
**Rationale**: 
- Citation networks are inherently graph-structured (papers → citations → papers)
- Graph traversal queries (finding citation paths) are exponentially faster in Neo4j
- Native support for graph algorithms (PageRank, community detection)
- Scales better for network analysis compared to complex SQL joins

**Alternative Considered**: PostgreSQL with recursive CTEs  
**Why Rejected**: Complex citation path queries become unwieldy and slow at scale

#### **Why TransE Embeddings vs. Node2Vec/DeepWalk?**
**Decision**: TransE (Translating Embeddings) for citation prediction  
**Rationale**:
- Designed specifically for link prediction in knowledge graphs
- Learns semantic relationships: `embedding(paper_A) + embedding("CITES") ≈ embedding(paper_B)`
- Superior performance on sparse networks (citation networks are ~99.99% sparse)
- Interpretable: distance in embedding space corresponds to citation likelihood

**Alternatives Considered**: Node2Vec, Graph Attention Networks  
**Why Rejected**: Node2Vec doesn't handle directed relationships well; GANs require more training data

#### **Why Streamlit vs. React/Flask?**
**Decision**: Streamlit for web interface  
**Rationale**:
- Rapid prototyping for data science applications
- Built-in caching mechanisms perfect for ML model serving
- Native Python integration (no JavaScript needed)
- Interactive widgets ideal for parameter exploration

**Trade-off**: Less customization flexibility vs. faster development

#### **Why Service-Oriented Architecture vs. Monolith?**
**Decision**: Service layer pattern with ML/Analytics separation  
**Rationale**:
- ML models have different scaling characteristics than web services
- Enables independent model updates without affecting analytics
- Clear separation of concerns for testing and maintenance
- Prepares codebase for microservices migration

### 🚀 Performance Optimization Decisions

#### **Why Embedding Dimension = 128?**
**Decision**: 128-dimensional embeddings  
**Rationale**:
- Sweet spot for 12K entity network: sufficient expressiveness without overfitting
- Memory efficient: 12K × 128 = 1.5M parameters (6MB model)
- Faster training and inference compared to 256+ dimensions
- Research shows diminishing returns beyond 128D for networks this size

#### **Why Margin Ranking Loss vs. Cross-Entropy?**
**Decision**: Margin ranking loss for TransE training  
**Rationale**:
- Designed for ranking problems (which citations are more likely?)
- Encourages relative scoring rather than absolute probabilities
- Better performance on imbalanced datasets (citations are rare events)
- Aligns with evaluation metrics (MRR, Hits@K)

#### **Why Negative Sampling Ratio 1:1?**
**Decision**: Equal positive and negative samples  
**Rationale**:
- Balanced training prevents model bias toward negative predictions
- Computationally efficient while maintaining learning quality
- Higher ratios (1:5, 1:10) didn't improve performance significantly
- Matches the evaluation setup for fair comparison

### 📊 Data Pipeline Design Decisions

#### **Why Streaming API Integration vs. Bulk Downloads?**
**Decision**: Streaming with progressive updates  
**Rationale**:
- Real-time progress feedback improves user experience
- Handles API rate limits gracefully (Semantic Scholar: 100 req/sec)
- Resumable: failed imports can continue from where they stopped
- Memory efficient for large datasets

#### **Why Pydantic Models vs. Raw Dictionaries?**
**Decision**: Pydantic for all data models  
**Rationale**:
- Runtime type validation prevents data corruption
- Automatic serialization/deserialization
- Self-documenting code through type hints
- Integration with FastAPI if we add REST endpoints

#### **Why LRU Caching vs. Redis?**
**Decision**: In-memory LRU caching for ML predictions  
**Rationale**:
- Simpler deployment (no external dependencies)
- Lower latency for repeated predictions
- Sufficient for single-instance deployment
- Easy migration to Redis for production scaling

### 🛡️ Reliability & Testing Decisions

#### **Why Fallback Mechanisms in Notebooks?**
**Decision**: Graceful degradation when services unavailable  
**Rationale**:
- Portfolio demonstration works without full infrastructure
- Database connectivity issues don't block analysis
- Enables development on various environments (local, cloud, etc.)
- Better user experience for exploratory data analysis

#### **Why Comprehensive Error Handling vs. "Fail Fast"?**
**Decision**: Extensive try/catch blocks with user-friendly messages  
**Rationale**:
- Academic researchers are domain experts, not software engineers
- Partial results are often still valuable for research
- Clear error messages aid in troubleshooting
- Supports iterative exploration workflow

### 🎯 Business Logic Decisions

#### **Why Demo Mode vs. Requiring Full Setup?**
**Decision**: Zero-configuration demo mode for immediate exploration  
**Rationale**:
- Reduces friction for evaluation and experimentation
- Showcases capabilities without infrastructure commitment
- Enables offline development and presentation
- Maya's insight: "30-second recruiter scan" - demo mode delivers immediate value

#### **Why Multiple Export Formats (CSV, JSON, LaTeX)?**
**Decision**: Comprehensive export options  
**Rationale**:
- Researchers need integration with existing workflows
- LaTeX export for academic paper inclusion
- CSV for spreadsheet analysis
- JSON for programmatic access
- Different audiences prefer different formats

## Future Enhancements

### 1. Microservices Architecture
- Split monolithic services into focused microservices
- API gateway for service orchestration
- Independent scaling and deployment

### 2. Real-time Updates
- Streaming data ingestion
- Live model retraining
- WebSocket-based UI updates

### 3. Advanced Analytics
- Graph neural networks for citation prediction
- Multi-modal analysis (text + citations)
- Collaborative filtering approaches

---

## Developer Resources

### Helpful Guides
- **[Neo4j Health Monitoring](resources/neo4j-health-monitoring.md)** - Keep your database alive with automated pings (essential for free tier users!)
- **[API Reference](api.md)** - Complete API documentation with examples
- **[Models Documentation](api/models.md)** - Pydantic data models
- **[Services Documentation](api/services.md)** - Service layer details

### Common Development Tasks

**Running Tests:**
```bash
# All tests
python -m pytest tests/ -v

# Specific modules
python -m pytest tests/test_ml_service.py -v

# With coverage
python -m pytest tests/ --cov=src --cov-report=html
```

**Code Quality:**
```bash
# Format code
black src/ tests/ --line-length 100
isort src/ tests/ --profile black

# Type checking
mypy src/

# Linting
flake8 src/ tests/
```

**Documentation:**
```bash
# Serve documentation locally
mkdocs serve

# Build documentation
mkdocs build
```

### Getting Help

- **[GitHub Issues](https://github.com/dagny099/citation-compass/issues)** - Report bugs or request features
- **[User Guide](user-guide/overview.md)** - End-user documentation
- **[Notebooks](notebooks/overview.md)** - Analysis pipeline examples

---

*This developer guide is maintained as the system evolves. Last updated: October 2025*
